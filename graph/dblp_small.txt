#*Residue number system in computer arithmetic
#@Jesus Ocampo Tuazon
#t1969
#c
#index203999


#*Interactive computing in a numerical analysis course
#@James E. McKenna
#t1975
#cACM SIGCUE Outlook
#index303323


#*Euclid: a program which conjectures, proves and evaluates theorems in elementary geometry.
#@John Denbigh Starkey
#t1974
#c
#index188499


#*Task Scheduling in Systems with Nonpreemptible Recources
#@Wojciech Cellary
#t1977
#cProceedings of the Third International Symposium on Measuring, Modelling and Evaluating Computer Systems
#index275081


#*Syntactic analysis by digital computer
#@M. P. Barnett,R. P. Futrelle
#t1962
#cCommunications of the ACM
#index328475
#%319989
#%328541
#!This paper provides an account of the Shadow language that is used to describe syntax and of a corresponding subroutine that enables a computer to perform syntactic analysis. The input to this subroutine consists of a string to be analyzed and a description of the syntax that is to be used. The syntax is expressed in the Shadow language. The output consists of a trace table that expresses the results of the syntactic analysis in a tabular form. Several versions of the subroutine and some associated programs have been in use now for over three years. The present account of the language and the subroutine contains a summary of material that has been described previously in unpublished reports and also some additional discussion of the work in relation to the more general questions of problem-oriented languages and string transformations.


#*A Combinatorial Algorithm for Solving Covering Problems
#@I. Tomescu
#t1973
#cIEEE Transactions on Computers
#index336445
#!In this correspondence a new combinational algorithm for the covering problems is proposed and computational experiments are analyzed.


#*Execution characteristics of programs in a page-on-demand system
#@John W. Boyse
#t1974
#cCommunications of the ACM
#index332163
#%203231
#%318912
#%327897
#%554090
#%332602
#!h show the execution characteristics of two types of commonly used programs in a large-scale, time-shared computer system. A software monitoring facility built into the supervisor was used for data collection during normal system operation. These data were analyzed, and results of this analysis are presented for a Fortran compiler and an interactive line file editor. Probability distribution functions and other data are given for such things as CPU intervals, I/O intervals, and the number of such intervals during execution. Empirical distributions are compared with simple theoretical distributions (exponential, hyperexponential, and geometric). Other data show paging characteristics of tasks as a function of the number of pages those tasks have in core.


#*A New Approach to the Fault Location of Combinational Circuits
#@S. Y. H. Su
#t1972
#cIEEE Transactions on Computers
#index353664
#!A systematic approach to the location of a single failure in a combinational logic network is presented. The method utilizes only the required tests and needs no fault table. The structure of the logic network is taken into consideration when selecting the tests to be applied. For tree networks, we start from the gate that generates a primary output and sequentially trace back through the stages of the network according to a fixed set of rules. At each stage we either locate the fault or determine the direction of the trace.


#*Least Change Secant Updates for Quasi-Newton Methods
#@John E. Dennis, Jr.,Robert B. Schnabel
#t1978
#c
#index114277
#!In many problems involving the solution of a system of nonlinear equations, it is necessary to keep an approximation to the Jacobian matrix which is updated at each iteration. Computational experience indicates that the best updates are those that minimize some reasonable measure of the change to the current Jacobian approximation subject to the new approximation obeying a secant condition and perhaps some other approximation properties such as symmetry. In this paper we extend the affine case of a theorem of Cheney and Goldstein on proximity maps of convex sets to show that a generalization of the symmetrization technique of Powell always generates least change updates. This generalization has such broad applicability that we obtain an easy unified derivation of all the most successful updates. Furthermore, our techniques apply to interesting new cases such as when the secant condition might be inconsistent with some essential approximation property like sparsity. We also offer advice on how to choose the properties which are to be incorporated into the approximations and how to choose the measure of changes to be minimized.


#*A Binary Floating-Point Resistor
#@Y. Paker
#t1971
#cIEEE Transactions on Computers
#index343032
#!The digital computer control of physical processes requires parameters that can be altered digitally. A resistor design is described that provides settings in a wide range with fixed precision. For this purpose a binary floating-point format is used both for expressing the resistor values and for the digital setting. A resistor structure is given that yields values expressed by the above format. Implementation employing electromechanical and electronic components is presented. The configuration described compares favorably with a straightforward binary design. It is expected that such a resistor will be especially useful for hybrid passive-network analyzer applications and, employed as a reference device, for the digital-to-analog and analog-to-digital conversion of other kinds of quantities.


#*The relative importance of sources of information for keeping programmers up-to-date
#@Robert P. Taylor,James Fisher
#t1979
#cProceedings of the sixteenth annual SIGCPR conference
#index548472
#%549987
#!This paper reports on an extension of survey research begun in 1977 and reported previously. [1], [2] The first phase of that research dealt with how practicing programmers keep up to date, investigating the effects of educational background, age, working environment, and other factors on how up to date the programmers claimed to be [1]. The measure of being up to date was based on the programmer's response to a multiple-item question about programming practice. That item included four sub-items involving structured programming concepts; the respondent's combined &ldquo;score&rdquo; on these four sub-items was the key. The original questionnaire is reproduced in Figure 1. The sub-items are 16A through 16D. In the second phase, the same questionnaire, unmodified, was administered to a different group of programmers and the results compared.


#*Algorithm 34: Gamma function
#@M. F. Lipp
#t1961
#cCommunications of the ACM
#index324704


#*Job shop scheduling by means of simulation and an optimum-seeking search
#@James C. Emery
#t1969
#cProceedings of the third conference on Applications of simulation
#index554363
#!The paper discusses a job shop simulator designed for use in the scheduling of a set of jobs. The simulator has been implemented in the form of a Fortran program. The simulator can be used in conjunction with a search program that adjusts priority rule parameters in seeking an improved schedule.


#*Extending Concurrent Pascal to allow dynamic resource management
#@A. Silberschatz,R. B. Kieburtz,A. Bernstein
#t1976
#cProceedings of the 2nd international conference on Software engineering
#index549108
#!In Concurrent Pascal, the syntactic and semantic definition of the language prevents the inadvertent definition of a program that might violate the integrity of a shared data object. However, the language also does not allow the dynamic allocation of reusable resources among processes, and this restriction seems unnecessarily stringent. This paper proposes the addition to Concurrent Pascal of a new type of program component, to be called a resource manager. By this means, dynamic resource allocation can be accomplished both safely and efficiently. The notion that a process holds access rights to a resource is generalized to the notion that it holds capability rights, but the capability to actually make use of a resource is granted dynamically. The anonymity of dynamically allocatable resources is also guaranteed.


#*Computer Storage Systems and Technology
#@Richard E. Matick
#t1977
#c
#index625954


#*A multi-microprocessor design
#@Helmut Berndt
#t1974
#cConference record of the 7th annual workshop on Microprogramming
#index545998
#!In the low-to-medium performance range of computer systems, the designer is faced with ever increasing input/output requirements which cannot be accommodated in the traditional way. In the past as well in present day computers of sufficient internal performance the input/output part and the instruction execution part of a central processing unit are combined. In order to provide high input/output data rates on smaller machines, a multiprocessor system must be used. Different design alternatives are discussed using microprogram controlled processors. The paper focusses on a design, where dedicated processors for internal and external processing needs are combined with a maintenance processor and the memory system in a star-like configuration. Microprogramming needs and hardware support vary widely in such a design. The central processor handling the internal tasks like instruction execution and interrupt processing requires the customary complex and powerful microinstruction repertoire. The processor for the external tasks - the input/output processor - performs all data transfers and executes channel programs. Here, realtime behavior is essential while the microinstruction set is fairly small and simple. In dealing with these design principles, the realization of such a computer will be discussed as an example.


#*Implementation of the AWACS Passive Tracking Algorithms on a Goodyear STARAN
#@Brian W. Prentice
#t1974
#cProceedings of the Sagamore Computer Conference on Parallel Processing
#index274727


#*Pattern recognition using masks with positive and negative weighted areas
#@William Joseph Fitzgerald, Jr.
#t1965
#c
#index185743


#*Proposal for a feasible programming system
#@Philip R. Bagley
#t1959
#cCommunications of the ACM
#index320718


#*QUEST: the design of a very high level, pedagogic programming language
#@T. I. Fenner,M. A. Jenkins,R. D. Tennent
#t1973
#cACM SIGPLAN Notices
#index301559
#%192411
#%321744
#%550835
#%319134
#%321318


#*Computer phobia: who's afraid of the carnivorous computer?
#@
#t1979
#cProceedings of the 7th annual ACM SIGUCCS conference on User services
#index443060


#*The architecture of an ALGOL 60 computer implemented with distributed processors
#@Leonard S. Haynes
#t1977
#cACM SIGARCH Computer Architecture News
#index544850
#%192863
#!In conventional computer systems, the computer hardware does not actually execute the user's source program. Instead, a software compiler and link editor transform the program into low level machine code which is executed by the hardware. This mapping from a high-level language to a von Neumann instruction set is a. Computationally costly because compilers and link editors are big and slow. b. Inefficient because the object code is generally poor. c. Error prone because compilers and link editors are difficult to design, debug, and maintain. Furthermore, diagnostic messages for execution errors (an arithmetic overflow for example) are either cryptic and require the user to be familiar with the machine language (i.e., a dump), or the object code generated must require considerable run time overhead to permit run time errors to refer back to the users source program (i.e., pointers and tables, etc.).


#*Health services (Session 4)
#@
#t1973
#cProceedings of the 6th conference on Winter simulation
#index550146
#!Simulation in the health services has seen increasing use. While many papers have been written, only a few have cited the monetary savings which the application of the technique has created. Two of the papers in this session fall into this latter category. The third paper considers the use of health auxiliaries to alleviate pressing health manpower problems.


#*Ein System zur Erfassung und Verwaltung von Benutzerdaten in einem Universit&auml;tsrechenzentrum
#@Hans Georg Göhring
#t1979
#cGI - 9. Jahrestagung
#index268521


#*Lucid, a Nonprocedural Language with Iteration
#@E. A. Ashcroft,W. W. Wadge
#t1976
#c
#index189294


#*The definition of the control and environment structure of programming languages
#@Robert George Herriot
#t1971
#c
#index197162


#*On the connections between range of variable and control structure testing
#@Hermann Kopetz
#t1975
#cProceedings of the international conference on Reliable software
#index548502
#%321876
#%549651
#!This paper discusses the subject of systematic program testing from a software engineering point of view. A number of different software error types are defined to facilitate the analysis of the error detection capability of a software module. It is found that many practical programs are, at best, conditionally Correct. Consequently it is not possible to establish the correctness of such a program even by an exhaustive test of the control structure. Keeping those insights in mind, some applicable techniques for the construction, error treatment and test of practical software systems are presented.


#*Computer applications for prospective public school administrators
#@Alton R. Goddard
#t1975
#cProceedings of the fifth SIGCSE technical symposium on Computer science education
#index545327
#!The purpose of this paper is to discuss and analyze the instructional programs needed to prepare prospective public school administrators for today's technological decisions. Most states require public school administrators to obtain an administrator's certificate earned by the satisfactory completion of a certain collection of course work considered necessary for their professional preparation. For example, an administrator's certificate in the state of Texas requires from forty-five to sixty hours of prescribed graduate level course work. The course work at East Texas State University was modified about two years ago to include a three-semester-hour course in computer science. It was believed that all prospective administrators could benefit by at least this amount of exposure to the procedures of automatic data processing. The course was designed to accommodate graduate students in education with very little or no background in computer science. This type of student tends to be initially petrified at the thought of having to take a course in computer science. However, after some exposure to computer science terminology, they are ready to pursue the primary educational objective of the course. This objective is to prepare a prospective superintendent or principal to assume his position in a public school system with some knowledge of how to intelligently use whatever automatic data processing capability is or might possibly become available for his district's use.


#*The Architecture of Coherent Information System: A General Problem Solving System
#@C. V. Srinivasan
#t1976
#cIEEE Transactions on Computers
#index352706
#!This paper discusses the architecture of a metasystem, which can be used to generate intelligent information systems for different domains of discourse. It points out the kinds of knowledge accepted by the system, and the way the knowledge is used to do nontrivial problem solving. The organization of the system makes it possible for it to function in the context of a large and expanding data base. The metasystem provides a basis for the definition of the concept of machine understanding in terms of the models that the machine can build in a domain, and the way it can use the models.


#*Identifier Search Mechanisms: A Survey and Generalized Model
#@Dennis G. Severance
#t1974
#cACM Computing Surveys (CSUR)
#index318002
#%196997
#%314219
#%316264
#%317076
#%317208
#%317966
#%324107
#%320010
#%319235
#%327071
#%327191
#%548359
#%331443
#%330016
#%327682
#%328711
#%544722
#%332042
#%321235
#%330910


#*Electronic Imaging Techniques: A Handbook of Conventional and Computer-Controlled Animation, Optical, and Editing Processes
#@Eli L. Levitan
#t1977
#c
#index12088


#*A time-space tradeoff for sorting and related non-oblivious computations
#@Allan Borodin,Michael J. Fischer,David G. Kirkpatrick,Nancy A. Lynch,Martin Tompa
#t1979
#cACM SIGACT News
#index433897


#*On the numerical solution of boundary value problems for linear ordinary differential equations
#@James T. Day,George W. Collins, II
#t1964
#cCommunications of the ACM
#index320589
#!A numerical method is presented for the solution of boundary value problems involving linear ordinary differential equations. The method described is noniterative and makes use of any one-step numerical integration scheme to reduce the problem from one of boundary values to one of initial values. Comments are made concerning some numerical results of applying the method to a specific problem. In addition an extension of the algorithm described to more general problems is discussed.


#*Scheduling in multiprogrammed computer systems
#@Paul Robert Kleindorfer
#t1970
#c
#index186246


#*An interactive statistical modelling package in APL
#@Yuan Liu,Amrit L. Goel
#t1973
#cProceedings of the ACM annual conference
#index550390
#!In this paper we describe an APL package developed for building statistical models interactively. The package consists of seven functional units with four major functions DATA, MODEL, REGRESSION and RESIDUAL, each of which is controlled by a set of commands. Several auxiliary functions are also available. The use of the package is illustrated through a numerical example.


#*Fixed-point algorithms and almost-complementary sets
#@John Freidenfelds
#t1972
#c
#index193302


#*Asymptotic behavior of solutions of perturbed autonomous contingent equations.
#@James Pasquale Foti
#t1974
#c
#index192601


#*Experience with distributed processing on a host/satellite graphics system
#@Janet Michel,Andries van Dam
#t1976
#cACM SIGGRAPH Computer Graphics
#index239331
#%190408
#!The problem cf distributing an application between two processors has been investigated by studying an interactive graphics application that is divided between a time-shared host computer and a dedicated satellite system. The division of labor in the application is determined by a network flow assignment algorithm. The effect of variation in availability of the host computer on the distribution of the application is also studied. In particular, host availability is an important factor in determining the task distribution. As host availability decreased, procedures miqrate from the host to the satellite.


#*Errurs: seeing double
#@Gerald M. Weinberg
#t1978
#cACM SIGDOC Asterisk Journal of Computer Documentation
#index14647
#!Today, dear subject, I will subject you to the subject of <u>heteronyms</u>.


#*Selecting a successful director of EDP
#@Mark R. Bomball,Roland D. Spaniol
#t1975
#cProceedings of the thirteenth annual SIGCPR conference
#index550199
#!The purpose of this study was to investigate the characteristics which seem to indicate successful performance by managers of computer installations. By studying many factors that were similar and dissimilar among directors of educational EDP installations, it was hoped that some variables would prove to be significant predictors of success for future candidates seeking such a position. It should be emphasized that the purpose of this paper was not to produce a &ldquo;cookbook recipe&rdquo;for selecting supervisory personnel. Rather, its purpose was to determine if some general guideline characteristics exist which would prove helpful in carrying out future selection processes and, if so, to identify these characteristics.


#*An investigation of the application of microprocessors to low cost area navigation capabilities for general aviation.
#@Wayne Douglass Smith
#t1976
#c
#index199692


#*Proceedings of the 6th SIGCSE symposium on Computer science education
#@
#t1976
#cACM SIGCSE Bulletin
#index305297


#*Texture Analysis Using Generalized Co-occurrence Matrices
#@L. S. Davis,S. Johns,J. K. Aggarwal
#t1979
#c
#index197989


#*Statistical multiplexing of data and encoded voice in a transparent intelligent network
#@M. E. Ulug,J. G. Gruber
#t1977
#cProceedings of the fifth symposium on Data communications
#index546237
#!The paper describes the work done thus far in the development of a means of statistically multiplexing data and encoded voice in a transparent and intelligent network called TI-NET. A review of previous work in packetized voice transmission in a conventional packet switched network (ARPANET) has revealed problems related to large fixed and variable transmission delays. These problems result in degradations in speech quality in the form of time scale distortion and gaps due to very late or lost packets. The paper shows that TI-NET has various features which counter the above problems, and thereby make it appear very suitable for encoded voice transmission. The paper describes a software implementation of a protocol for encoded voice transmission which takes advantage of the 60 to 65% idle time in conversations (one way) so that only active periods in speech need be transmitted; this is not possible with present frame synchronous vocoders which transmit continuously. The paper describes the present experimental TI-NET which consists of two nodes (PDP11's) joined by a 9.6 kb/s link. For convenience the protocol for encoded voice transmission has been implemented in the TI-NET nodes, and the transparent transmission of data and encoded voice has been demonstrated. With regard to packetizing synchronous messages within TI-NET, a new protocol is described (and has been implemented) for padding partially filled &ldquo;minipackets&rdquo; that are likely to occur at the end of most synchronous messages. In addition, the paper discusses the features of another aspect of TI-NET, i.e. satellite extension nodes, which are used to enable both local and remote regions of high data concentration to access the subnet through 12-14 GHZ satellite links. It is shown that the advantages of accessing TI-NET by satellite extension nodes (as compared to accessing a conventional packet switched network by terrestrial facilities), include lower communication costs, greater accuracy and security, and smaller entrance delay. Finally, the paper describes an experiment in which data and encoded voice was transmitted from a TI-NET node at Carleton University, Ottawa, at 9.6 kb/s in &ldquo;multiuser&rdquo; packets, over the Hermes (CTS) satellite to NASA AMES Research Center in California, where it was looped back and returned to the same TI-NET node. The significance of the work described in the paper is that it represents an important step in the development of a transparent and intelligent public network capable of transmitting encoded voice (at 9.6 kb/s and lower rates) and data. Such a network can serve as an integrated system for data and voice and provide cost benefits to its users through savings in bandwidth of the order of 50 to 1, by statistically multiplexing data with vocoded voice.


#*Studies on clustered files.
#@Yin Chun Anita Wong
#t1978
#c
#index200313


#*Simulation as an alternative to linear programming
#@Susan L. Solomon
#t1977
#cACM SIGSIM Simulation Digest
#index575023
#!It is commonly accepted that general classes of problems are best solved using particular techniques. For example, critical path scheduling problems can often be formulated for solution by linear programming, but this approach would not recommend itself for cost reasons to the vast majority of those having access to a PERT or CPM heuristic package. Likewise, the classic product mix or blending problem which pervades the end-of-chapter exercises following a discussion of linear programming is assumed to be "best" solved using graphical methods or the Simplex algorithm. Simulation might offer a reasonable alternative solution vehicle in many circumstances like these, yet some operations research analysts tend to consider its use only "when all else fails". That is, simulation is the technique of last resort.


#*Book reviews
#@
#t1973
#cACM SIGCAS Computers and Society
#index305694


#*Left-Fitting Translations
#@Hans-Peter Kriegel,Thomas Ottmann
#t1977
#cProceedings of the Fourth Colloquium on Automata, Languages and Programming
#index355789


#*Algorithms for network flow problems with convex separable costs.
#@John Gregory Klincewicz
#t1979
#c
#index187893


#*ACM president's letter: austerity
#@Anthony Ralston
#t1972
#cCommunications of the ACM
#index319402


#*Computer system simulation of an on-line interactive command and control system
#@Herman Fischer
#t1971
#cProceedings of the 5th conference on Winter simulation
#index548093
#!A computer simulation model was used as an analysis &ldquo;tool&rdquo; for computer system design trade-offs for an on-line interactive command and control system preliminary design study project. Three basic hardware configurations were modelled at the hardware interrupt/byte flow level: a. A Centralized Dual Multiprocessor b. Dual Computers c. A Distributed System of Central and Remote Computers The software of the system was modelled in several modules: a. The Operating System Routines b. The Data Base Management Routines c. Interactive File Maintenance and Query Routines d. Object-Coded Functional Applications Programs e. Support and Control Software Each module consists of parametric descriptions for each corresponding loadable software module (e.g., load module size, re-enterability) and procedural descriptions (e.g., read/write statements, processing statements, calls to system macros and other subroutines). The simulation is conducted in two modes: A fast-forward mode to load-up the system, and an observation mode to collect detailed data. A history tape of the environmental stimuli (interactive operator loads) on the system, produced by a separate &ldquo;loading model&rdquo;, enters tasks into the system. The system model is implemented on the IBM 360, Model 65 Computer using a high level computer systems simulation language. The technique developed was so successful that it is now being actively used as a design tool and system performance evaluator, providing a means to minimize the technical risk in the development of all of Litton DSD's major software projects.


#*The geometric dimension of complex virtual bundles
#@Bertha Ann Lauritzen Mount
#t1970
#c
#index197126


#*Right brother trees
#@Th. Ottmann,H. W. Six,D. Wood
#t1978
#cCommunications of the ACM
#index330678
#%322763
#%327524
#!Insertion and deletion algorithms are provided for the class of right (or one-sided) brother trees which have O (log n) performance. The importance of these results stems from the close relationship of right brother trees to one-sided height-balanced trees which have an insertion algorithm operating in O (log2 n). Further, although both insertion and deletion can be carried out in O (log n) time for right brother trees, it appears that the insertion algorithm is inherently much more difficult than the deletion algorithm&mdash;the reverse of what one usually obtains.


#*Analyse eletrischer Schaltpl&auml;ne mit einfachen Schaltungssymbolen
#@Horst Bunke
#t1978
#cBildverarbeitung und Mustererkennung, DAGM Symposium
#index571206


#*Structure of a direct high-level language processor
#@Howard M. Bloom
#t1973
#cProceedings of a symposium on High-level-language computer architecture
#index312945


#*Algorithm 125: Weightcoeff
#@H. Rutishauser
#t1962
#cCommunications of the ACM
#index329525


#*Microprogrammed significance arithmetic with tapered floating point representation
#@Clement Luk
#t1974
#cConference record of the 7th annual workshop on Microprogramming
#index550514
#%329355
#!To automatically indicate a bound for the propagated and generated errors due to finite representation of numeric values on a computer using floating point representations, two methods are used, the &ldquo;normalized method&rdquo; and the &ldquo;unnormalized method&rdquo;. The normalized method uses a normalized representation and an index to indicate the number of significant digits. The unnormalized method retains only the significant digits. This paper reports a micro-implementation of binary significance arithmetic using the normalized method with a new floating point representation. The normalized method is chosen for two reasons: (1) as indicated by Carr [2 ] , a normalized floating point procedure always gives a better result than an unnormalized procedure, and (2) this floating point representation takes advantage of a special property of normalization to afford increased exponent range and to retain potentially an extra binary digit (bit) for values between 0 and 1 as compared against conventional floating point format.


#*Implementierung eines Microcomputer-Mehrrechnersystems
#@Olaf Kaestner
#t1979
#cMicrocomputing, Tagung III/1979 des German Chapter of the ACM
#index562201


#*RUNCIBLE&mdash;algebraic translation on a limited computer
#@Donald E. Knuth
#t1959
#cCommunications of the ACM
#index315817
#%331118


#*Colored petri nets: their properties and applications.
#@Cristian Radu Zervos
#t1977
#c
#index202196


#*For Statements and the Copy Rule
#@I. D. Hill
#t1967
#cIssue 25 (March 1967)
#index102911
#%332108
#%107217


#*Effects of an intervention program to integrate communication skills with active learning techniques in mathematics computation.
#@Therese Elaine Ridgway Snyder
#t1978
#c
#index192347


#*Business and management data processing II: A systems approach for the application of computerized scheduling techniques and the RCA-PERT/Cost program
#@M. E. Haskins, Jr.,N. E. Sondak
#t1962
#cProceedings of the 1962 ACM national conference on Digest of technical papers
#index555097
#!COMPUTERIZED SCHEDULING techniques such as PERT and Critical Path Scheduling have received a good deal of attention recently because of their successful application to a large number of complex projects. However, their usage could be greatly extended if the potential user could be supplied with a more formalized technique for the analysis of a project. This technique should reduce the cost of the use of computerized scheduling by reducing the time and effort required to arrive at a suitable schedule for the project. This paper will present such a technique and summarize the experiences and results obtained when this methodology was used for the analysis of a wide variety of projects. In addition, there has been growing awareness that the enhancement of the basic scheduling algorithms to include factors other than time, such as manpower and costs, in the overall schedule would be most beneficial. This paper will present a practical, working, integrated computerized scheduling system including such a cost algorithm. The discussion is based on techniques evolved in the development of our PERT/Cost program. This extension now permits the inclusion of cost constraints in the design of a schedule as well as complete financial analysis of the project as it progresses.


#*A characterization of the power of vector machines
#@Vaughan R. Pratt,Michael O. Rabin,Larry J. Stockmeyer
#t1974
#cProceedings of the sixth annual ACM symposium on Theory of computing
#index547145
#%553893
#!Random access machines (RAMs) are usually defined to have registers that hold integers. While this captures in part the structure of a commercial computer, it overlooks an implementation-dependent feature of most binary oriented machines, namely their ability to operate bit by bit on the bit vectors used to represent integers. Typical operations are bit-wise Boolean operations (and, or, not, etc.) and shifts by an amount specified in some register. These operations are ideal for certain problems, such as dealing with sets represented as bit vectors, some parsing algorithms [4], propositional calculus theorem proving, and analysis of sorting networks. A RAM so implemented we shall call a vector machine.


#*User requirements
#@Richard G. Mills
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index60608
#!Changed priorities and shifts in the Nation's economic and social environment have uncovered in the private sector a chronic and crippling shortcoming in the linkage between the developers and the consumers of technology. If major dislocations and unaffordable inefficiences in our economic system are to be avoided, this gap must be closed. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Evaluation of the CFA Test Programs Via Formal Computer Descriptions
#@M. R. Barbacci
#t1977
#cComputer
#index349069
#!This article describes an architectural research facility used for the comparison of computer architectures. The facility consists of a compiler, simulator, symbolic translator, and data analysis programs.


#*Generation of Right-Linear Grammars from Regular Expressions
#@A. R. Patel
#t1971
#cIEEE Transactions on Computers
#index350060
#!A finite state language can be represented by a regular expression or a right-linear grammar. An algorithm to generate a right-linear grammar for regular expression is presented. The algorithm can be implemented on computers. A Snobol 4 program for this algorithm was written for the IBM 360/65 with success.


#*A model for type checking: with an application to ALGOL 60
#@Henry F. Ledgard
#t1972
#cCommunications of the ACM
#index328323
#%330864
#%329080
#!Most current programming languages treat computation over different classes of objects (e.g. numbers, strings, labels and functions). For correct compilation and execution, the following question then arises: is a program properly constructed so that its operations and operands are compatible? The activity of answering this question is usually called type checking. This paper attempts to isolate the notion of type checking and presents a partial solution to the type checking problem based on the notions of abstraction and application of functions. In particular, a program is mapped into an expression within a decideable subset of the &lgr;-calculus, which characterizes the type relations within the program and eliminates all other information. The determination of the type-wise correctness or incorrectness of the program is resolved by reducing its corresponding &lgr;-calculus expression to one of two normal forms, the constant &ldquo;correct&rdquo; for a type-wise correct program or the constant &ldquo;error.&rdquo; An application to type checking in Algol 60 is made, and the attendant problems faced for any notion of type checking are discussed.


#*Algorithm 350: simplex method procedure employing Lu decomposition [H]
#@Richard H. Bartels,Gene H. Golub
#t1969
#cCommunications of the ACM
#index318829


#*The Module: A System Structuring Facility in High-Level Programming Languages
#@Niklaus Wirth
#t1979
#cProceedings of a Symposium on Language Design and Programming Methodology
#index376281


#*The use of transistors in asynchronous direct-coupled computing circuits
#@Robert Ayer Kudlich
#t1955
#c
#index201140


#*Letters to the editor: gathering of misleading data with little regard for privacy
#@Russell J. Abbott
#t1968
#cCommunications of the ACM
#index323314


#*Electronic data processing: implications for the secondary school
#@Joseph B. Zapach
#t1972
#c
#index198820


#*A talking computer terminal.
#@James Albert Kutsch, Jr.
#t1976
#c
#index199858


#*Some approaches to best-match file searching
#@W. A. Burkhard,R. M. Keller
#t1973
#cCommunications of the ACM
#index320836
#%317208
#!The problem of searching the set of keys in a file to find a key which is closest to a given query key is discussed. After &ldquo;closest,&rdquo; in terms of a metric on the the key space, is suitably defined, three file structures are presented together with their corresponding search algorithms, which are intended to reduce the number of comparisons required to achieve the desired result. These methods are derived using certain inequalities satisfied by metrics and by graph-theoretic concepts. Some empirical results are presented which compare the efficiency of the methods.


#*Context approach to protection.
#@Kattamuri Ekanadham
#t1976
#c
#index191316


#*Computer Science Programs at Universities Awarding the Ph.D. Degree
#@Lloyd D. Fosdick
#t1974
#cProceedings of the twelfth annual SIGCPR conference
#index547532
#%316004
#%316178
#%318784
#%319577
#%323936
#%325216
#%327127
#%332573
#%334754
#!This paper discuss's on the Computer Science Programs at Universities Awarding the Ph.D. Degree


#*Residues and fixed point formula for complex manifolds
#@Yue Lin Lawrence Tong
#t1970
#c
#index187109


#*A compiler&mdash;compiler system
#@Robert G. Trout
#t1967
#cProceedings of the 1967 22nd national conference
#index549069
#%315849
#%316116
#%323888
#%328541
#%328874
#%332030
#!To the author's knowledge three other operational compiler-compiler systems, whose strategy is similar to the scheme documented here, have been developed. The Feldman system [6, 7, 8] is a bounded context, syntax directed system. Syntax specifications are expressed in Floyd production language (FPL) and semantics are defined in Feldman semantic language (FSL). FSL seems to be a good model on which to base semantic languages. A lexical analysis (subscan to distinguish identifiers, operators, delimiters and punctuation marks) precedes the full analysis. In the COGENT system [5], on the other hand, each character is interpreted separately, hence allowing greater flexibility (e.g. its use in a symbolic differentiation program) and enforcing more detailed attention to syntax. Syntax for a source program is virtually in Backus Normal Form (BNF) [3] and this system is syntax directed along the lines suggested by Irons [1]. Much has been written on the compiler-compiler system of Brooker and Morris [2, 22, 23] which has superficial similarities with the COGENT scheme and the system described below.


#*Technical notes
#@
#t1975
#cACM SIGAPL APL Quote Quad
#index242223


#*Remark on algorithm 16: crout with pivoting
#@George E. Forsythe
#t1960
#cCommunications of the ACM
#index335200
#%328020
#%331605


#*Engagement of interactive graphic tools in a CAD-system for digital units
#@E. Hörbst,R. Prechtl,B. Will
#t1976
#cProceedings of the 13th Design Automation Conference
#index550537
#%153803
#!The paper describes a graphical system which was developed at Siemens and the use of this system for the design automation of digital processing units.


#*An implementation of IPL-V on a small computer
#@Ned Chapin
#t1964
#cProceedings of the 1964 19th ACM national conference
#index551865
#!An implementation of IPL-V has been made that can be run on the computer most widely used by schools and colleges. This can facilitate the teaching of heuristic as well as the already available algorithmic oriented programing languages. For this implementation, the seven objectives selected lead to making the eight major choices that shaped this one-pass implementation. These choices mostly reflect decisions common to the implementation of any programing language. But in contrast to common practice, list processes were used in the implementation itself. Comparisons have been made of this implementation and other IPL-V implementations.


#*Certification of Algorithm 57: Ber or bei function
#@A. P. Relph
#t1962
#cCommunications of the ACM
#index318234


#*Performance prototyping of data management applications
#@James F. Spitzer
#t1976
#cProceedings of the 1976 annual conference
#index555052
#%329315
#%332110
#!This paper describes the construction of a performance model or prototype of a proposed data base management system (DBMS) application by the application of certain techniques from the performance measurement and data base management disciplines. Performance measurement is conducted by using a &ldquo;drive&rdquo; workload that initiates the &ldquo;real&rdquo; workload with reasonable fidelity. The &ldquo;drive&rdquo; workload is constructed in terms of data base variable primitives, which are &ldquo;inverted&rdquo; to performance variable primitives in order to construct a resource-based drive workload. The application of this drive workload to a simulation model is illustrated, showing the use of the methodology to &ldquo;tune&rdquo; important DBMS, Operating System and application program parameters.


#*Storage-efficient representation of decimal data
#@Tien Chi Chen,Irving T. Ho
#t1975
#cCommunications of the ACM
#index317871
#!Usually n decimal digits are represented by 4n bits in computers. Actually, two BCD digits can be compressed optimally and reversibly into 7 bits, and three digits into 10 bits, by a very simple algorithm based on the fixed-length combination of two variable field-length encodings. In over half of the cases the compressed code results from the conventional BCD code by simple removal of redundant 0 bits. A long decimal message can be subdivided into three-digit blocks, and separately compressed; the result differs from the asymptotic minimum length by only 0.34 percent. The hardware requirement is small, and the mappings can be done manually.


#*A conversational regression package for exploratory data analysis
#@Fred F. Newpeck,Wynn A. Abranovic
#t1976
#cACM SIGAPL APL Quote Quad
#index244768


#*Characteristics of application software maintenance
#@B. P. Lientz,E. B. Swanson,G. E. Tompkins
#t1978
#cCommunications of the ACM
#index314757
#%179654
#%548454
#%555182
#%547226
#%555074
#!Maintenance and enhancement of application software consume a major portion of the total life cycle cost of a system. Rough estimates of the total systems and programming resources consumed range as high as 75-80 percent in each category. However, the area has been given little attention in the literature. To analyze the problems in this area a questionnaire was developed and pretested. It was then submitted to 120 organizations. Respondents totaled 69. Responses were analyzed with the SPSS statistical package. The results of the analysis indicate that: (1) maintenance and enhancement do consume much of the total resources of systems and programming groups; (2) maintenance and enhancement tend to be viewed by management as at least somewhat more important than new application software development; (3) in maintenance and enhancement, problems of a management orientation tend to be more significant than those of a technical orientation; and (4) user demands for enhancements and extension constitute the most important management problem area.


#*Application of a water system computer model in the City of Scottsdale Arizona
#@Geza E. Kmetty,Meredith Flinn
#t1979
#cProceedings of the 11th conference on Winter simulation - Volume 1
#index551078
#!Development, implementation and application of a computer model to simulate an urban water system are discussed. Particular emphasis is placed upon actual use of the model by municipal water supply management. Applications described include system improvements, growth planning and fire protection capability assessment.


#*Technical writing
#@Diana Patterson
#t1976
#cACM SIGDOC Asterisk Journal of Computer Documentation
#index2997
#!Text editors and formatters are always a subject of interest to those who use them, and horror stores are common subjects of discussion, for example:March 4, 1976In the January, 1976 issue of the SICDOC Newsletter, you noted that there are "hundreds" of text editors and formatters. I am interested in these programs and would like to know the names and references of any you are familiar with or have heard about. Your opinions of their quality would also be appreciated. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Pattern recognition by retina-like devices
#@Carl Frederick Reinhold Weiman
#t1972
#c
#index203315


#*Density plateau seeking for clustering analysis.
#@Jung Wan Cho
#t1973
#c
#index187805


#*Structure-theoretic results on probabilistic automata
#@Sami Erol Gelenbe
#t1970
#c
#index199644


#*Introduction to Programming and Computer Science
#@Anthony Ralston
#t1978
#c
#index611166


#*A note on logic-oriented approaches to data abstraction
#@Farshid Nourani
#t1978
#cACM SIGSOFT Software Engineering Notes
#index437302
#%434867


#*Specifying programming language semantics: a tutorial and critique of a paper by Hoare and Lauer
#@I. Greif,A. Meyer
#t1979
#cProceedings of the 6th ACM SIGACT-SIGPLAN symposium on Principles of programming languages
#index249870
#%196117
#%325067
#%250122
#%545956
#%320995
#!Hoare and Lauer [1974] have advocated using a variety of styles of programming language definitions to fit the variety of users from implementers to program verifiers. They consider the question of whether different definitions and specifications determine the same language by showing that the definitions are what they call "consistent". However, their treatment skirts the question of whether their definitions can each be taken to specify the language adequately. Although, as we will show, any one of the kinds of semantics they discuss -- operational, relational, deductive -- can be used to specify meaning uniquely, Hoare and Lauer do not make the case in their paper. In fact, both their relational and deductive definitions are satisfied by several different semantics, only one of which is desired.Thus, the main point of this paper is to clarify the characteristics of a proper specification of language semantics and to formulate alternative specifications each of which is equally good as the language definition. We basically agree with Hoare and Lauer that several specifications can and should be given, but are disturbed by confusions about such specifications, some of which are illustrated in their paper. In particular we refer to confusions between the mathematical object which is designated to be the meaning of a program and methods for specifying that object; the similar confusion between predicate and expression; between consistency and equivalence of two definitions; between completeness of a theory and its having a unique model. While these issues are familiar in mathematical logic, we take this opportunity to survey them in the context of programming language semantics.This paper can be read without prior familiarity with Hoare and Lauer's paper. The authors plan another paper extending this work which will include a more comprehensive bibliography.


#*Using and re-using partial plans.
#@Paul Rodger Davis
#t1977
#c
#index186104


#*Security of APL applications packages
#@Paul Penfield, Jr.
#t1972
#cProceedings of the fourth international conference on APL
#index546333
#!By the term &ldquo;applications package&rdquo; is meant a set of interacting APL functions and variables that a user calls, along with certain &ldquo;background&rdquo; functions and data that are only called indirectly. If there is a proprietary interest in the package, then it is necessary to devise techniques to assure the security of the package. An interpreted language like APL might be thought to pose severe security problems, since (unlike a compiled language such as FORTRAN) the source code is always somewhere nearby. However, with proper design, reasonable security (consistent with the value of the goods protected) can be achieved. This paper deals with security for packages installed both on private computers, and on commercial time-sharing systems, with the emphasis on the latter.


#*Ghost imaging for fingerprints with the self-associative holographic memory.
#@Roland Kranz
#t1975
#c
#index201206


#*Operators and uniform forms
#@Douglas J. Keenan
#t1979
#cACM SIGAPL APL Quote Quad
#index545063
#%551705
#!A syntax for operators is formally defined. This formalization permits an extension to current operators and the introduction of new operators, two of which are proposed. The new operators, in conjunction with generalized uniform forms, are shown to have great power, allowing, among other things, easy manipulation of nested arrays.


#*A computer-assisted instructional language which interacts with the author.
#@James Larue Rogers
#t1975
#c
#index189552


#*Computers in Cardiology
#@K. M. Kempner
#t1975
#cComputer
#index351963
#!One telling measure of the digital computer's presence within the field of medicine is that in virtually all of the larger hospitals throughout the world, computer scientists and engineers can be found at the side of medical professionals. Together, these interdisciplinary team members are deeply involved in the solution of many medical problems.


#*An interactive computer graphic system for molecular studies
#@William Vaughn Wright
#t1972
#c
#index194410


#*An approach to modeling simulation programs
#@Philip C. Cooley
#t1974
#cProceedings of the 7th conference on Winter simulation - Volume 2
#index545520
#!There is a specific problem structure encountered in certain socioeconomic problems. The problem structure is characterized as a queuing network. By using certain concepts from activity network problems an efficient software system can be defined for the solution of queuing network problems. This paper discusses the conceptualization of the queuing network structure as a set of basic building blocks. The building blocks are the basis of a simulation software package designed to model queuing network problems.


#*On quasiconformality in several complex variables
#@Ricardo Nirenberg
#t1966
#c
#index204951


#*BLAISE - 1726
#@Richard Belgard
#t1974
#cSupplement to the conference record of the 7th annual workshop on Microprogramming
#index547985
#!Microprogramming as a valuable tool for both experimental and production products is shown through the effective realization of an alien, experimental architecture by a microprogrammable host machine Described is the micro-implementation of the BLAISE machine on the Burroughs B1726. Some of the features of the high-level language oriented architecture are discussed with respect to implementation schemes. A structured micro- program organization is presented, illustrating the benefits of the approach


#*On the generation of ALGOL68 programs involving infinite modes
#@L. Meertens
#t1969
#cIssue 30 (February 1969)
#index100942


#*Optimal scheduling of task groups on tightly coupled multiprocessors.
#@Leslie Jill Miller
#t1979
#c
#index205363


#*A proposal for publication and exchange of program proofs
#@Susan L. Gerhart
#t1978
#cACM SIGSOFT Software Engineering Notes
#index437343


#*What's wrong with APL?
#@Philip S. Abrams
#t1975
#cProceedings of seventh international conference on APL
#index545750
#%198171
#%205438
#%323728
#%550673
#!Throughout history, every time a new idea has come along there have been many people quick to criticize it. As often as not, such criticism has come from detractors of the idea, and has been motivated by its threat to older, more established beliefs. The Biblical prophets, Socrates, Jesus, Copernicus, Galileo, Pasteur, Marx, Darwin, Stravinsky, and countless others, all experienced resistance to their ideas for essentially emotional rather than intellectual reasons. From its early days as &ldquo;Iverson Notation&rdquo; through its more recent development, APL has been the target of heated discussion. This paper is a criticism of APL, but I believe, different from others. I am not a detractor of APL; in fact, I have been a supporter, developer, and promoter of the language for quite some time. Therefore, the intention of this review is not to suggest that since APL has faults it is worthless. To the contrary, I hope that these comments will lead to further improvements of APL and perhaps suggest some of the directions to consider in the development of its successors. This paper could not have been written much earlier. It is because APL has come of age, both in the theoretical domain and in the commercial world, that it is possible to look at it publicly with a critical eye. The discussion that follows is written for the APL community, present and future. My wish is that APL &ldquo;believers&rdquo; will accept this analysis in the constructive spirit in which it is offered, and that those who still do not appreciate the beauty, elegance, and practical power of APL will not take these comments out of the context in which they are presented.


#*ACM President's Letter: ethics
#@Anthony Ralston
#t1974
#cCommunications of the ACM
#index314360


#*SIGBDP (Panel Session)
#@James F. Hubbert,Earl C. Joseph,Walter G. Wohlgemuth
#t1976
#cProceedings of the 1976 annual conference
#index544880
#!Computer auditing is a new and growing profession which combines a data processing expertise with the more established discipline of auditing. As with any new profession, computer auditing's role is still evolving. The panelists in this session will attempt to define this role.


#*Two square-root approximations
#@W. G. Wadey
#t1958
#cCommunications of the ACM
#index324180


#*Complex preprocessing for pattern recognition
#@Albert L. Zobrist
#t1971
#cProceedings of the 1971 26th annual conference
#index545358
#%322663
#!The construction of pattern recognition machines may eventually depend upon the development of highly complex preprocessors. This claim is supported by a discussion of the importance of perceptual grouping. Since complex preprocessing will assess more of the basic structure of a visual scene, internal representations will have to be more descriptive in nature. Two approches to descriptive internal representation are mentioned. Two of the author's programs are reviewed. One plays the Oriental game of GO at a human level and the other can recognize digitized hand printed characters. Both programs use a geometry preserving representation of features, so that calculations involving the features can assess the original geometry of the input. In addition, the GO program calculates groups of stones and performs other types of &ldquo;complex&rdquo;processing. Practical and philosophical arguments are given for the use of internal representation by pattern recognition programs.


#*CDALGO - a test pattern generation program
#@Glen D. Vaughn
#t1976
#cProceedings of the 13th Design Automation Conference
#index547641
#%550944
#!CDALGO is a test pattern generation program for LSI devices. It is designed to generate minimal sequences that are stable and hazard free.


#*Computer science education in small colleges
#@Richard Austing,Gerald Engel
#t1972
#cProceedings of the second SIGCSE technical symposium on Education in computer science
#index550898
#!A Subcommittee on Small College Programs, was appointed by the Committee on Curriculum in Computer Science, of the Association for Computing Machinery in 1969. This group was charged with responsibility of making recommendations for the development of programs in computer science in smaller colleges and universities. The report will consider course structure, to be offered with the constraints of limited faculty, and with a wide variety of objectives. Outlines of the key courses will be included, as well as recommendations for independent study courses. Another significant factor involved in these considerations, is the relationship of computer science to the computer center, and to the college as a whole. In particular, the service nature of the department and the center, and the development of meaningful computer use within the schools will be considered. Finally, recommendations will be given regarding faculty acquisition and development.


#*Evaluation of Repeated Integrals of the Coerror Function
#@Walter Gautschi
#t1977
#cACM Transactions on Mathematical Software (TOMS)
#index316922
#%319307


#*Surveyor's Forum: Devising the Rhetoric of Rhetorical Devices
#@Nathan Relles
#t1978
#cACM Computing Surveys (CSUR)
#index329793


#*A practical deadlock avoidance algorithm for data base systems
#@David B. Lomet
#t1977
#cProceedings of the 1977 ACM SIGMOD international conference on Management of data
#index620025
#%314206
#%332343
#!A new algorithm is presented for avoiding system deadlocks. Because its performance has little dependence on the number of lockable resources, it is particularly well suited to use in data base systems which may have millions of individually lockable records. A further advantage is that both exclusive and shared locking are accommodated. The algorithm is presented in some detail and its performance and functional characteristics discussed.


#*Human factors influencing the command, control and communication functions of a timesharing system
#@Jon A. Stewart
#t1976
#cProceedings of the 4th annual ACM SIGUCCS conference on User services
#index235746
#!The intent of this paper is to explore various human factors which influence the design of a timesharing system and its processors; to examine characteristics of existing systems; and, to propose solutions which more nearly suit the requirements of the timesharing user. Most illustrations will be drawn from extensive personal use and observations of users of two particular systems --- the XEROX CP-V system on a Sigma 9 and TOPS10 on the DECSystem-10. Both these systems are characterized by extremely flexible command capabilities, almost if not complete compatibility with their batch facilities and very crisp response (for both the CPU resource and file system functions) when under proper administrative controls. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Perturbations of eigenvalues of non-normal matrices
#@A. van der Sluis
#t1975
#cCommunications of the ACM
#index328175
#%457304
#!The problem considered is to give bounds for finite perturbations of simple and multiple eigenvalues &lgr;i of nonnormal matrices, where these bounds are in terms of the eigenvalues {&lgr;i}, the departure from normality &sgr;, and the Frobenius norm &Verbar; &Dgr;A &Verbar; F of the perturbation matrix, but not in terms of the eigensystem. The bounds which are derived are shown to be almost attainable for any set of all matrices of given {&lgr;i} and &sgr;. One conclusion is that, very roughly speaking, a simple eigenvalue &lgr;1 is perturbed by |&Dgr;&lgr;1| &lsim; &Verbar; &Dgr;A &Verbar;F &middot; &prod; (&sgr;/&thgr;j) where &thgr;j is of the order of magnitude of |&lgr;1 - &lgr;j|, the product being extended over all j where &thgr;j &lsim; &sgr;.


#*Building synergistic EDP teams
#@Kathryn M. Bartol
#t1977
#cProceedings of the fifteenth annual SIGCPR conference
#index551690
#%614035
#!A team is termed &ldquo;synergistic&rdquo; when the members working together are able to achieve results significantly beyond what could be expected from the same team members working relatively independently. Unfortunately, placing several employees into a work group and calling them a team does not necessarily result in the desired synergy. On the contrary, a team can function so ineffectively as to actually reduce the potential output of various individual members. Therefore, it is not surprising that Powers and Dickson (1973) found no direct relationship between MIS project success and such elements as the systems experience of project personnel or the utilization of a project team composed of MIS staff and user personnel. To achieve a synergistic effect, teams must be carefully built and developed through the assistance of EDP management. This paper draws on the literature related to group behavior, decision making, and organizational structure to identify a number of factors which affect the ability of EDP teams to achieve synergistic effects. Two types of factors are discussed: (1) structural factors and (2) process factors. Structural factors focus on the basic parameters within which the team operates and include team size, appropriate choices of technical expertise, resource allocation, and reward systems. Process factors relate to the ongoing operations and interrelationships of the team and include such elements as interpersonal skills, modes of conflict resultion, and team leadership. Failure of EDP management to concern itself with the structural and process factors of teams could doom the team concept in situations where, with proper attention to team building, a team could deliver the best results.


#*A functional approach to structured combinational-logic design.
#@Gerald Norris Shapiro
#t1974
#c
#index200785


#*ANSWERS: A hydrologic / water quality simulator for watershed research
#@David B. Beasley,Larry F. Huggins
#t1978
#cProceedings of the 10th conference on Winter simulation - Volume 2
#index552297
#!In recent years, a greatly increased emphasis has been placed on improving and maintaining the quality of our national water resources. Agencies and individuals from both within and without the various levels of government are seeking information concerning the effects that land use, management, and conservation practices or structures might have on the quality and quantity of water from both agricultural and non-agricultural watersheds. ANSWERS (Areal Nonpoint Source Watershed Environment Response Simulation) was developed in an effort to supply the desired information described above for primarily agricultural watersheds. The simulation consists of a hydrologic model and a sediment detachment/transport model along with several routing schemes necessary to describe the movement of water in overland, subsurface, and channel flow phases. This simulation, unlike many large-scale watershed simulations, uses distributed (rather than lumped) parameters and is event (rather than long-term) oriented. These operational features generally yield a better understanding of the hydrologic and water quality interactions involved in a watershed by allowing the user to physically describe those processes at every point within the catchment during the period when the processes are most active, i.e., during an event. The concepts, as well as the basic mathematical model used in ANSWERS, are presented. General data needs and user considerations are also listed. In addition, the usefulness of ANSWERS as a planning tool is demonstrated by simulating several management schemes for a largely agricultural watershed in northeastern Indiana.


#*Jossle: a language for specifying and structuring the semantic phase of translators.
#@John Robert White
#t1973
#c
#index205310


#*Structured descriptions of complex curved objects for recognition and visual memory.
#@Ramakant Nevatia
#t1975
#c
#index192833


#*Law enforcement: do the systems really provide the information and safeguards promised?
#@Glen E. Pommerening Howard Bjorklund Melvin F. Bockelman Alan A. Hamilton
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index68344
#!Law Enforcement---An updating of the advances made in providing information for the management of law enforcement and problems still facing these activities and the resources being brought to bear on their solutions.


#*FDIC Bank Management Simulation
#@Kalman J. Cohen,J. Timothy Heames
#t1967
#cProceedings of the 1967 22nd national conference
#index548320
#!The following paper describes research that the authors are currently conducting in the development of a large, complex bank management simulation. The simulation, to be called the FDIC Bank Management Simulation, will be a computer model of commercial banks competing against one another and other financial institutions in the economic marketplace.


#*Call for Papers
#@
#t1975
#cComputer
#index338003


#*A study of the effects of the electronic computer on the functions of management as performed in selected commercial banks
#@Rex Farmer Galloway
#t1970
#c
#index197414


#*APL authorization processing
#@JOHN R. BLANCHARD
#t1975
#cProceedings of seventh international conference on APL
#index550556
#!Xerox APL used at the XCC (Xerox Computer Center) in Webster, New York. There are several APL applications, some of which serve to manipulate reasonably-sized (10 megabytes) data bases. A shortcoming of UTS (Universal Timesharing System) and the follow-on monitor, CP-V (Control Program Five) is that file access is not handled very well. The salient points of file access controls available to the user under CP-V are as follows: 1. Files may be passworded, 2.'Read' I and 'write' accounts may be specified at the time the file is created. 3. Instead of specifying read and write accounts, the file's owner may say 'ALL' or 'NONE' with the expected results. There are several problems associated with the mechanisms described above, and they are described We chose authorization files to attack this problem. This method is one which allows a user to have a large list of accessors to his files. Briefly, the implementation of authorization files is discussed in the next paragraphs.


#*Prediction of wiring space requirements for LSI
#@W. R. Heller,W. F. Michail,W. E. Donath
#t1977
#cProceedings of the 14th Design Automation Conference
#index554155
#%547565
#%554378
#!A stochastic model is developed for estimating wiring space requirements for one-dimensional layouts. This model uses as input the number of devices in the complex to be wired, the average length of a connection, and the average number of connections per device, to compute the probability of successfully wiring the devices as a function of the number of tracks provided. A heuristic approach is used to extend this model to the two-dimensional case, and tested against experimen-tal studies. Satisfactory agreement is found between a priori calculations of track requirements for the two-dimensional case against global wiring solutions for artificially generated problems, and for some layouts of actual logic complexes.


#*Algorithm 472: procedures for natural spline interpolation [E1]
#@John G. Herriot,Christian H. Reinsch
#t1973
#cCommunications of the ACM
#index327884


#*Digital computer simulation studies: Studies of information networks
#@Kevin D. Reilly
#t1968
#cProceedings of the second conference on Applications of simulations
#index553039
#!Digital computer simulation models for analysis of information networks are being developed. Concepts from a variety of sources (2,3,6,8) provide the basis for formulation of the models. Several of the major aspects that are incorporated include: user behavior; scheduling within the information processing center; (machine- readable) file organization and maintenance; and distribution of conventional library resources. A single comprehensive model for the entire network is also being developed to allow for detailed study of special portions of the system, followed by a study of the effects of changes in the sub-system upon the entire system. Using a higher level programming language (GPS/360) was deemed to be essential because of the necessity of model change and adaptation imposed upon us in this area. Modelling must allow for many different detailed systems designs (corresponding to the variety of plans) and for changes in any single plan many of which cannot be foreseen.


#*A model highlighting the security of operating systems
#@Richard W. Conn,Richard H. Yamamoto
#t1974
#cProceedings of the 1974 annual conference - Volume 1
#index546257
#%199468
#%316233
#%322720
#%324613
#%326966
#%330178
#%335280
#%335588
#%549140
#%552668
#%546754
#%552388
#%550526
#!The major thrust toward providing secure computing facilities has gone into the design of, or models for, new operating systems. Work directed toward securing current systems has, for the most part, taken the form of penetration attempts. Penetration efforts have led several authors to identify generic weaknesses, but grouping by weakness has not led to formal methods. An approach showing greater promise in identifying trouble spots, as well as characterizing existing operating systems in a more general sense, lies in forming graph models in which nodes are program modules or data structures, and arcs are access or shared resource synchronization paths. A given system should be capable of reduction to a graph of this sort by appropriate analysis of its load modules.


#*State Minimization of Incompletely Specified Sequential Machines
#@J. Kella
#t1970
#cIEEE Transactions on Computers
#index345134
#!This paper describes a new method for the state minimization of incompletely specified sequential machines. Previously described methods start with generating all maximal compatibles of states of the original incompletely specified machine and then try to find a closed cover which consists of a minimal number of MCs or portions of MCs. This process involves a long enumeration process and, as the number of states grows, turns out to be impractical for hand calculation.


#*SIMPLAN: Moving simulation into the board room
#@R. Britton Mayo
#t1977
#cProceedings of the 9th conference on Winter simulation - Volume 2
#index547557
#!In many organizations, a primary obstacle to the productive use of simulation techniques is the difficulty in communicating the nature of the underlying process to a programmer or analyst. Often, only one or two people understand the organization's simulation requirements for a particular project, and these people seldom have sufficient expertise in data processing areas to implement the desired modeling system. If the model could be constructed directly by the people who are to be the end users of its output, more satisfactory and accurate results can almost always be obtained. One method of accomplishing this is through a modeling language which can be learned quickly and easily by people with no prior computer background.


#*A disquieting output error
#@William R. Knight
#t1977
#cACM SIGNUM Newsletter
#index107741
#!What use to compute accurately the inverse of a matrix or the solution of a differential equation if the output routine mangles the accurate answer? No program is better than the output service which prints its results. This note reports a horrid malfunction of a particular output facility.


#*Transferability of government information systems, problems and solutions. Is it cost effective?
#@Verne H. Tanner, Jr.,James J. Trainor Nelson A. Howell,Charles D. Trigg
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index66616
#!One of the most significant challenges facing state information coordinators today deals with the ability or lack of ability to make use of the proven concepts of systems developed in other jurisdictions. The panel will attempt to develop a definition of the word "transferability," to outline the restraints and pitfalls which prevent a successful transfer and to suggest ideas and methods which can avoid these problems. While specific examples presented by the panel will deal with state activities, their problems and solutions should be of importance not only to all levels of government on a horizontal plan, but also to all levels of government on a vertical plan.


#*Definition of software
#@Bernard A. Galler
#t1962
#cCommunications of the ACM
#index314284


#*Retrieval of current physics journal literature utilizing automatic and traditional classification techniques
#@Julie Hallmark Bichteler
#t1973
#c
#index188548


#*Computer application to cardiovascular disease
#@Charles Lee Townsend
#t1963
#c
#index197654


#*Geometric modeling for computer vision.
#@Bruce Guenther Baumgart
#t1974
#c
#index197330


#*Direct microprogrammed execution of the intermediate text from a high-level language compiler
#@Francois Robert Broca,Richard E. Merwin
#t1973
#cProceedings of the ACM annual conference
#index549511
#%320395
#%334053
#!Microprogramming commonly executed operations can improve the computational speed of data processing systems. This paper describes how microprogramming may be used to execute directly the intermediate text generated by a high-level language compiler after syntactic and semantic analysis of the input source program. Direct microprogrammed execution of common forms of intermediate text - i.e.: quadruples, triples, and duos - has been simulated. A comparison is made, in terms of storage requirements and execution time, of this direct microprogrammed system scheme with the present methods which result in machine language representation and execution of the intermediate text. Direct generation of a microprogram from the high-level language statements is also examined. Timing assumptions for comparative purposes have been based on the IBM 360 MOD 50 system. Simulation and timing estimates for the microprograms have been carried out on a microprogram directed simulator which closely represents the architectural organization of the MOD 50.


#*Hardware Test Technology
#@K. R. Anderson
#t1979
#cComputer
#index348787
#!The testing of digital systems has grown increasingly complex. LSI circuits, commonplace in today's systems, require thorough testing at the component level. VLSI adds even more complexity. How are these challenges being met? This special issue surveys the state-of-the-art and attempts to answer the question.


#*On-line Text Editing: A Survey
#@Andries van Dam,David E. Rice
#t1971
#cACM Computing Surveys (CSUR)
#index316325
#%316426
#%330350
#%319134
#!This paper is a survey of current methods for the on-line creation and editing of computer programs and of ordinary manuscripts text. The characteristics of on-line editing systems are examined and examples of various implementations are described in three categories: program editors, text editors, and terminals with local editing facilities.


#*Development in file manipulation techniques
#@Charles Bachman
#t1966
#cCommunications of the ACM
#index327283


#*Theory and computation of integer linear programs
#@Pran Nath Wahi
#t1969
#c
#index200240


#*Algorithm for the computation of the coefficients of powers of polynomials.
#@Grace Yun-Loh (Yeh) Chen
#t1974
#c
#index203600


#*Performance of Storage Management in an Implementation of SNOBOL4
#@G. D. Ripley
#t1978
#cIEEE Transactions on Software Engineering
#index347077
#!Results of measuring the performance of the storage management subsystem in an implementation of SNOBOL4 are described. By instrumenting the storage management system, data concerning the size, lifetime, and use of storage blocks were collected. These data, like those obtained from conventional time measurement techniques, were used to locate program inefficiencies. In addition, these measurements uncovered some deficiencies in the storage management system, and provided the basis upon which to judge the heuristics used in the garbage collector.


#*RIG, Rochester's Intelligent Gateway: System Overview
#@J. E. Ball
#t1976
#cIEEE Transactions on Software Engineering
#index337726
#!Rochester's Intelligent Gateway (RIG) system provides convenient access to a wide range of computing facilities. The system includes five large minicomputers in a very fast internal network, disk and tape storage, a printer/plotter and a number of display terminals. These are connected to larger campus machines (IBM 360/65 and DEC KL10) and to the ARPANET. The operating system and other software support for such a system present some interesting design problems. This paper contains a high-level technical discussion of the software designs, many of which will be treated in more detail in subsequent reports.


#*An interactive man-machine approach to the computer logic partitioning problem
#@M. Hanan,A. Mennone,P. K. Wolff, Sr.
#t1974
#cProceedings of the 11th Design Automation Workshop
#index549281
#%548551
#!The problem of partitioning computer logic has been attacked in the past by manual and automatic techniques. We describe an interactive approach which combines aspects of both approaches and creates results which are better than those obtainable by either approach independently. An overview of the system is presented, several algorithms discussed and experimental results are given.


#*A comparison of two methods for digital computer simulation of systems inwhich there are continuous change and intermittent intervals of complex activity
#@Alan Francis Babich
#t1972
#c
#index196118


#*An algorithm for nonlinear parameter estimation
#@Norman Max Steen
#t1972
#c
#index189102


#*Towards automation of proofs by induction
#@Friedrich W. von Henke
#t1977
#cProceedings of the 3rd GI-Conference on Theoretical Computer Science
#index273881


#*A brief account: Implementation and applications of a Pascal program verifier (Position Statement)
#@David C. Luckham
#t1978
#cProceedings of the 1978 annual conference - Volume 2
#index547858
#%176082
#%192074
#%320995
#%322254
#%334248
#%555013
#%550574
#%551554
#%554871
#!The Stanford Pascal verifier is an interactive program verification system. It automates much of the work necessary to analyze a program for consistency with its documentation, and to give a rigorous mathematical proof of such consistency or to pin-point areas of inconsistency. It has been shown to have applications as an aid to programming, and to have potential for development as a new and useful tool in the production of reliable software. This verifier is a prototype system. It has inadequacies and shortcomings. It is undergoing continuous improvement, and is expected to be used eventually in conjunction with other kinds of program analyzers. In this talk we shall describe the verifier and some of the results that have been obtained using it. We shall discuss some of the problems that still stand in the way of developing verifiers to a stage where they are part of the programmer's normal working environment.


#*A computerized management information system for the worldwide business of a large commercial bank.
#@Philip Gray Stanley
#t1979
#c
#index198434


#*On the method of minimum (or "best") approximation and the method of least nth powers
#@Allen A. Goldstein,James B. Herreshoff,Norman Levine
#t1956
#cProceedings of the 1956 11th ACM national meeting
#index546169
#!There has been a renewed interest of late in the problem of approximation in the Tchebycheff sense, that is of minimizing the maximum residues. Several methods 1, 2, 3, have already been discussed and many examples of approximating functions of one variable by polynomials and rational functions, etc. have been published. On the other hand the important problem of solving an overdetermined system of linear equations in the Tchebycheff sense has not been given the attention it deserves. The possession of a practical method for the solution of this problem would make possible &ldquo;best&rdquo; approximations of functions of several variables by linear combinations of arbitrary functions. It is not widely known that an algorithm for solving this problem exists and is due to de la Vallee Poussin.4 Unfortunately the algorithm is unwieldy but it is still useful in the computation of a minimum approximation. We shall therefore outline the results of de la Vallee Poussin before discussing some new methods with which we have been experimenting.


#*Editors' note
#@C. H. Lindsey
#t1973
#cIssue 36 (November 1973)
#index97761


#*Computer-assisted planning model for school districts
#@Robert A. Nielsen,Vincent R. LoCascio
#t1972
#cACM SIGSIM Simulation Digest
#index575376
#!As demands for improved public school education intensify and become increasingly uncompromising, educators are striving to learn how to make critical decisions better and more quickly. While they recognize the need for installing sophisticated planning and control systems, they also realize that from a practical standpoint such systems must carry a reasonable price tag, require only a moderate amount of time to implement, and be simple enough for non-technical people to understand and use.


#*Touch-Tone input techniques: Data entry using a constrained keyboard
#@E. J. Desautels,S. B. Soffer
#t1974
#cProceedings of the 1974 annual conference - Volume 1
#index554772
#%191793
#%323418
#%324042
#%548492
#!The problems involved in using a smaller alphabet than that naturally called for are investigated, with attention focussed on the use of 12 digit keyboards such as found on Touch-Tone (trademark reg.) telephones. The feasibility of avoiding the use of codebooks or user encodings is examined for some medical information systems, and a technique to minimize redundant inputs is described.


#*Letter to the editor: criticisms of ALGOL 60
#@Bruce Arden,Bernard A. Galler,Robert M. Graham
#t1961
#cCommunications of the ACM
#index327844


#*Remark on algorithm 324
#@G. Bayer
#t1973
#cCommunications of the ACM
#index321219


#*The effects of multiplexing on a computer-communications system
#@Charles D. Pack
#t1973
#cCommunications of the ACM
#index328248
#%332795
#%545128
#!A study is made of the way in which asynchronous time division multiplexing changes the stochastic nature of the arrival process from a user to the computer and, consequently, affects the performance of a time-shared computer-communications system. It is concluded that while, for certain values of system parameters, there is noticeable improvement in the performance of the computer (model), in the sense that time-shared scheduling delays are reduced, these improvements are offset by the transmission delays imposed by multiplexing so that there may be little or no change in the computer-communications system performance. Analytical and simulation results are based on the model of the computer-communications system being an M/D/1 queue (the multiplexor) in tandem with a single exponential server (the computer). Analytical results include a general description of the output process of an M/D/1 queue and the conditions under which this output process is approximately Poisson.


#*A CRT report generating system
#@Henry C. Lucas, Jr.
#t1974
#cCommunications of the ACM
#index325430
#%550646


#*Present and future in design automation systems
#@Takuo Kitamura,Tadashi Watanabe
#t1973
#cProceedings of the 10th Design Automation Workshop
#index551089
#%550351
#!In this paper, the present status of DA system, which is used in designing computers in NEC is introduced, and the development procedure and use of this system are described. Then, on the basis of the actual results of this system, the future problems of DA systems to be solved are also described. In designing the present high speed and large scale-computer, the role of DA systems becomes more and more important because the processing of complex and a great deal of data is requested, and still more accurate, reliable and rapid processing capability is required.


#*A study of the effect of user program optimization in a paging system
#@Lesin W. Comeau
#t1967
#cProceedings of the first ACM symposium on Operating System Principles
#index548290
#!Much attention has been directed to paging algorithms and little to the role of the user in this environment. This paper describes an experiment which is an attempt to determine the significance of efforts by the user to improve the paging characteristics of his program. The problem of throughput in a computing system is primarily one of balancing the flow of data and programs through a hierarchy of storages. The problem is considered solved when for every available processor cycle there is a matching demand for that cycle in the primary (execution) store. Since programs and their data usually originate in a location other than the execution store, there is a delay associated with the movement of data and programs to the primary store. The delay has two components, the operational speed (data transfer time) and the positioning, or access time, of the secondary storage device. Since the access time usually exceeds the data transfer time by an order of magnitude, the problem of transferring information to the primary store has been named the &ldquo;access gap&rdquo; problem.


#*Vector extensions to LRLTRAN
#@R. G. Zwakenberg
#t1975
#cACM SIGPLAN Notices
#index551132
#!The CDC STAR-100 brings a new concept in computing to LLL. The STAR is a string(vector) - oriented machine that is most efficient when it performs the same operations on sequentially stored operands. This approach to computer design opens up new areas of problem-solving techniques. Some algorithms that are long and cumbersome on other machines can be easily and efficiently programmed on the STAR computer. The vector extensions described in this paper represent an attempt to expand LRLTRAN (a dialect of FORTRAN) into a useful computer language for the STAR. The additions will enable an LRLTRAN-language compiler to produce vector code and hence allow the programmer to access, via LRLTRAN, the powerful STAR hardware instructions.


#*Contributions to the Annals of the History of Computing
#@
#t1979
#cIEEE Annals of the History of Computing
#index397385


#*Statistical analysis to evaluate generated distributions in simulation modeling to conserve computer time
#@Harold Joseph Highland
#t1972
#cACM SIGSIM Simulation Digest
#index581903
#!One of the pitfalls in simulation modeling is the modeler's assumption that the computer generated distributions to be used in the simulation run are sacrosanct. In many models subjected to simulation analysis, it is necessary for the modeler to 'create' various statistical distributions as part of the endogenous and/or expogenous data in the model - turn-around time in a time-sharing environment, rainfall distribution in a specific area, run times for student programs at a computer center. Two methods are usually used to develop these distributions. On the one hand, the modeler might have historic data (company records, experimenter observations) and he therefore can create an empircal distribution which he will use in simulating the model. On the other hand, the modeler might have to rely upon previous studies to estimate a possible distribution; for example, he might assume a Poisson distribution for the timing of machine breakdowns but has to make some estimate of &lambda;. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Generalized GPSS Model for Grain Terminal Elevators
#@J. E. Peterson
#t1968
#cProceedings of the second conference on Applications of simulations
#index550682
#!The generalized GPSS Model for Grain Terminal Elevators, also referred to as the Grain Terminal Simulation (GTS), unites well-defined rules of notation with a generalized, GPSS simulation program to yield a complete system for the specification and simulation of grain terminal elevators. The original development goals of general applicability, relative ease of evaluating varied policies and configurations and ease of use, have to a significant degree, been achieved.


#*Evaluation and optimization of file organizations through analytic modeling.
#@Shi Bing Yao
#t1974
#c
#index206378


#*Beyond programming languages
#@Terry Winograd
#t1979
#cCommunications of the ACM
#index320646
#%79620
#%250122
#%317475
#%319134
#%319630
#%325466
#%332771
#%550752
#%626474
#%544813
#%547764
#%330822
#%333782
#%335238
#%326751
#%330862
#%562103
#%333675
#!As computer technology matures, our growing ability to create large systems is leading to basic changes in the nature of programming. Current programming language concepts will not be adequate for building and maintaining systems of the complexity called for by the tasks we attempt. Just as high level languages enabled the programmer to escape from the intricacies of a machine's order code, higher level programming systems can provide the means to understand and manipulate complex systems and components. In order to develop such systems, we need to shift our attention away from the detailed specification of algorithms, towards the description of the properties of the packages and objects with which we build. This paper analyzes some of the shortcomings of programming languages as they now exist, and lays out some possible directions for future research.


#*A Parallel Radix-4 Fast Fourier Transform Computer
#@M. J. Corinthios
#t1975
#cIEEE Transactions on Computers
#index347914
#!The organization and functional design of a parallel radix-4 fast Fourier transform (FFT) computer for real-time signal processing of wide-band signals is introduced.


#*Euclid and PASCAL
#@Ted Venema,Jim des Rivieres
#t1978
#cACM SIGPLAN Notices
#index305898
#%320995
#%307418
#%554145
#!The programming language Euclid was intended for writing system programs that could be verifiable by state-of-the-art verification methods. Since verification was not an explicit goal in the design of Pascal, it is not surprising that this gave rise to differences between the two languages. The Euclid designers intended to change Pascal only where it fell short of this goal. This paper examines differences in the two languages in the light of this objective. These differences are roughly grouped under the headings verification, system programming, and user-oriented changes.


#*Revised ALGOL 68 Report. ERRATA-4
#@C. H. Lindsey
#t1976
#cIssue 39 (February 1976)
#index107865


#*Abstraction mechanisms in CLU
#@Barbara Liskov,Alan Snyder,Russell Atkinson,Craig Schaffert
#t1977
#cCommunications of the ACM
#index319630
#%552136
#%329899
#%335365
#!CLU is a new programming language designed to support the use of abstractions in program construction. Work in programming methodology has led to the realization that three kinds of abstractions&mdash;procedural, control, and especially data abstractions&mdash;are useful in the programming process. Of these, only the procedural abstraction is supported well by conventional languages, through the procedure or subroutine. CLU provides, in addition to procedures, novel linguistic mechanisms that support the use of data and control abstractions. This paper provides an introduction to the abstraction mechanisms in CLU. By means of programming examples, the utility of the three kinds of abstractions in program construction is illustrated, and it is shown how CLU programs may be written to use and implement abstractions. The CLU library, which permits incremental program development with complete type checking performed at compile time, is also discussed.


#*A new aspect of Some Post algebras
#@Serge Perrine
#t1978
#cProceedings of the eighth international symposium on Multiple-valued logic
#index551801
#!Some Post algebras are nothing but commutative unitary algebras L over a finite field K where Fermat theorem holds in L.


#*Dimensioning of message-switched computer-communication networks with end-to-end window flow-control
#@Jackson Y.K. Chan,Nicolas D. Georganas
#t1979
#cProceedings of the sixth symposium on Data communications
#index550775
#!A message-switched computer network with end-to-end window flow control is considered. Using recently developed heuristics for the numerical solution of such networks, an algorithm for the selection of &ldquo;good&rdquo; flow-control window settings is developed. The criterion of performance is the ratio of the network average throughput versus average network delay. An example network demonstrates the results.


#*A performance index for emulation environments in digital systems
#@Ayola N. Akonteh
#t1979
#cACM SIGMICRO Newsletter
#index6550
#%331310
#%333760
#!This study develops a formal representation of an emulation environment and defines an emulator in terms of a transformation process &tau;(x,y) equivalent to an environment Mxy created by imbedding the state image of a target machine y into a host machine x. A performance index &rho;xy of the emulator is developed to indicate its relative versatility.


#*A constructive approach to reliable synchronization code
#@Mark S. Laventhal
#t1979
#cProceedings of the 4th international conference on Software engineering
#index553225
#%116512
#%320699
#%332514
#!This paper describes a new approach to developing reliable software for communication between parallel processes. The basis of this approach is the shared use of abstract data objects, and the separation of synchronization-related software from the software performing the actual data access. The paper presents a language in which synchronization behavior for abstract data objects can be specified independently of other kinds of behavior. Specifications written in this language can be used as a basis for constructing the required synchronization software automatically. Also discussed is the use of such specifications in verifying properties of programs which make use of the abstract objects for interprocess communication.


#*Implementation consideration for machine translation
#@Allen B. Tucker, Jr.,Giuliano Gnugnoli,Long Vo Nguyen,Bedrich Chaloupka
#t1978
#cProceedings of the 1978 annual conference - Volume 2
#index553909
#!This paper describes the implementation and operational features of a machine translation (MT) system for Spanish and English text. Sample translations from Spanish to English and English to Spanish are illustrated. The system's computer hardware and software requirements are also presented, along with an assessment of the ongoing machine dictionary management requirements.


#*The datacomputer: a network data utility
#@Thomas Marill,Dale Stern
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index68665
#%334566
#!The Datacomputer is a large-scale data management and storage utility for use by a network of computers. The system is designed to provide facilities for data sharing among dissimilar machines, rapid access to large on-line files, storage economy through shared use of a trillion-bit store, and improved access control.


#*The assignment to a type procedure identifier
#@H. Bekic
#t1964
#cIssue 18 (October 1964)
#index105271


#*Modeling high-current effects in bipolar transistors for use in computer-aided distortion analysis.
#@Donald George Duff
#t1977
#c
#index201789


#*Index to Doctoral Dissertations
#@Harves Rahe
#t1975
#c
#index610629


#*How to develop module logic using pseudo-code and stepwise refinement
#@Anthony A. Lekkos,Carl M. Peters
#t1978
#cProceedings of the 15th Design Automation Conference
#index550599
#%153572
#%335365
#!The use of pseudo-code and the stepwise refinement process in developing the logic of modules is discussed, and the advantages of this method are analyzed. An example is given to illustrate the steps to be taken in analyzing the function, selecting data structure and algorithm, abstracting the function in pseudo-code, expanding the function into subfunctions, and finally, verifying the function.


#*Relation between wedge cancellation and localization for complexes with two cells
#@Edward Allen Molnar
#t1972
#c
#index187644


#*Classification and enumeration of autonomous sequential machines
#@Hollis Franklin Ryan
#t1967
#c
#index195178


#*The internal structure of the FORTRAN CEP translator
#@O. G. Mancino,M. Morandi Cecchi
#t1965
#cCommunications of the ACM
#index318400
#%322772


#*A study in programming techniques
#@Kurt Maly
#t1973
#c
#index206106


#*Algorithm 253: [F2]: Eigenvalues of real symmetric matrix by the QR method
#@P. A. Businger
#t1965
#cCommunications of the ACM
#index326655


#*The EZ GCD algorithm
#@Joel Moses,David Y. Y. Yun
#t1973
#cProceedings of the ACM annual conference
#index552545
#%81323
#%190148
#%326180
#!This paper presents a preliminary report on a new algorithm for computing the Greatest Common Divisor (GCD) of two multivariate polynomials over the integers. The algorithm is strongly influenced by the method used for factoring multivariate polynomials over the integers. It uses an extension of the Hensel lemma approach originally suggested by Zassenhaus for factoring univariate polynomials over the integers. We point out that the cost of the Modular GCD algorithm applied to sparse multivariate polynomials grows at least exponentially in the number of variables appearing in the GCD. This growth is largely independent of the number of terms in the GCD. The new algorithm, called the EZ (Extended Zassenhaus) GCD Algorithm, appears to have a computing bound which in most cases is a polynomial function of the number of terms in the original polynomials and the sum of the degrees of the variables in them. Especially difficult cases for the EZ GCD Algorithm are described. Applications of the algorithm to the computation of contents and square-free decompositions of polynomials are indicated.


#*A new approach to construction of computer systems
#@Tatsuya Hayashi
#t1975
#cProceedings of the 1975 annual conference
#index549857
#%322720
#%323836
#%334053
#%553667
#!In this paper we propose a new method in which original form of the whole system (described in a design and implementation language called DEAPLAN) is directly implemented as it is without either modification or transformation. In other words a kind of high level language machine is considered in the more throughgoing way. Our hardware apparently has neither CPU nor storage device and only consists of a large number of quantum processing units (QPUs) except channels and peripherals. Therefore, extremely speaking, the main contemporary concepts such as virtual space, reenterability and multiplexing of CPU as well as compiling and linkage editing are all disappeared in our system. The identity of implemented version of the system with the original form seems to give a more fundamental solution to the problem of the rapid growth of operating systems compared with the mere structured programming and so on.


#*Proceedings of the 1976 ACM SIGMETRICS conference on Computer performance modeling measurement and evaluation
#@
#t1976
#cJoint International Conference on Measurement and Modeling of Computer Systems
#index548437


#*An investigation of novice programmer errors in IBM 370 (OS) assembly language
#@Joan M. Chabert,T. F. Higginbotham
#t1976
#cProceedings of the 14th annual Southeast regional conference
#index611767
#!Novice Assembly Language programmer errors were "trapped" and tabulated according to type and frequency by programming assignment. In addition, the number of runs per programming assignment were investigated.Recommendations were made to facilitate the reduction of numbers of errors by novice IBM 370 (OS) Assembly Language Programmers.


#*Editor's note
#@C. H. Lindsey
#t1978
#cIssue 43 (December 1978)
#index98671


#*Statistical programs for the IBM 650&mdash;Part I
#@John W. Hamblen
#t1959
#cCommunications of the ACM
#index314853


#*Numerical analysis II: Numerical analysis of two generalized elliptic integrals
#@D. W. C. Shen,M. L. El-Sabbagh
#t1962
#cProceedings of the 1962 ACM national conference on Digest of technical papers
#index547922
#!Numerical Analysis of Two Generalized Elliptic Integrals


#*The C programming language
#@B. W. Kernighan,D. M. Ritchie
#t1978
#c
#index178360


#*On algorithms for nonlinear prediction.
#@Shashi Prabha Phoha
#t1976
#c
#index194200


#*An overview of SL5
#@Ralph E. Griswold,David R. Hanson
#t1977
#cACM SIGPLAN Notices
#index309951
#%79620
#%544938
#%552573
#%548209
#%554395
#%551259


#*A Data-Storage Format for Information System Files
#@F. D. Anzelmo
#t1971
#cIEEE Transactions on Computers
#index346459
#!In developing its chemical information system, Chemical Abstracts Service (CAS) has built files which require hundreds of millions of bytes of storage and in which data elements may range in length from zero in one instance to several hundred bytes in another. To cope with this size and variability, CAS has developed an internal standardized storage format and has implemented it on the IBM System/360. This format, which is called Standard File Format (SFF), accommodates a mix of fixed-and variable-length data elements and permits the addition and deletion of data elements without affecting the program code. Symbolic addressing of data elements is achieved through the use of a directory within each record in the file. Implementation of standardized files has permitted the CAS system to operate with greater generality and flexibility.


#*On the revised ALGOL 68 Report
#@M. Sintzoff
#t1973
#cIssue 36 (November 1973)
#index108720


#*Computer assisted instruction comes of age in a public school system
#@William M. Richardson
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index68157
#!During the late 1960's a number of public schools began experimenting with the development and use of computer-assisted and computer-managed instruction. Funding for these public school projects was provided primarily by Title III of the Elementary and Secondary Education Act of 1965, or other sources of federal funds. Due to the reduced availability of federal funding, few new public school CAI projects have been initiated since 1970. It is, however, very encouraging to analyze the results of the few active public schools CAI projects. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*The Logic of Aliasing
#@Robert Cartwright,Derek Oppen
#t1978
#c
#index117319
#!We give a new version of Hoare''s logic which correctly handles programs with aliased variables. The central proof rules of the logic (procedure call and assignment) are proved sound and complete.


#*A methodology for the analysis of auxiliary storage systems
#@Thomas Gregory Delutis
#t1972
#c
#index193327


#*Validation criteria for computer system simulations
#@Toby J. Teorey
#t1975
#cProceedings of the 3rd symposium on Simulation of computer systems
#index550741
#%81323
#!Validation of computer system simulation models is a common concern of both the programmer/analyst and the decision maker. This paper addresses the question of what are the major characteristics of the empirical aspects of validation and how one might carry out such a validation process for complex computer system models. Validation is described in terms of verification of the authenticity of the random number and random variate generators and of the independent variables established for the model, a proper choice of dependent (response) variables to observe in both the simulation model and the actual system itself (i.e., two sets of data), a choice of statistical tests for comparing their distributional properties, and the ability to predict system performance based on future changes in the actual system configuration. The concepts of validation are clarified through the example of an actual detailed model constructed for the input/output subsystem for a Burroughs B6700 computer. A validation process is proposed which specifies data that should be collected from the simulation model, which relates experiences with obtaining the coordinate live test data from the actual system under consideration, and finally shows how statistical tests can be applied to verify or reject the hypothesis that both sets of data result from the same population. Empirical data is presented to aid in the understanding of the concepts.


#*Optimization techniques in designing relational database systems.
#@Wu-Haung Cheng
#t1978
#c
#index201003


#*PDEL&mdash;a language for partial differential equations
#@Alfonso F. Cárdenas,Walter J. Karplus
#t1970
#cCommunications of the ACM
#index321200
#%314624
#%334877
#!Conventional computer methods available to solve continuous system problems characterized by partial differential equations are very time-consuming and cumbersome. A convenient, easy to learn and to use, high level problem oriented language to solve and study partial differential equation problems has been designed; a practical translator for the language has also been designed, and a working version of it has been constructed for a significant portion of the language. This Partial Differential Equation Language, PDEL, is outlined, and the highlights of the translator are briefly summarized.


#*Data recovery in a photo-digital storage system
#@R. L. Griffith
#t1969
#cIBM Journal of Research and Development
#index18059
#!A data-recovery feature has been developed for recovering electron-beam recorded information which is microscopic in dimension and has been partially obliterated by flaws in a photographic-film recording medium. This feature provides (1) backup procedures that exploit redundancies in the recording format for the synchronization and identification of data, (2) coding for error detection and correction of 5 independent characters in5 0 data character lines, (3) variation of machine parameters that affect reading performance, and (4) statistically optimized schedules for applying a variety of recovery techniques. Error rate is reduced from one error line in about 100 lines to less than one error line in 2.7 × 106 lines.


#*Features of an information system for Congress
#@Kenneth Janda
#t1966
#cProceedings of the 1966 21st national conference
#index553772
#!Students of government generally agree that the legislative branches of modern governments have gradually lost power relative to the power of executive authorities. This phenomenon has been referred to variously as the &ldquo;parliamentary crisis,&rdquo;1 the &ldquo;atrophy of the legislature,&rdquo;2 and the &ldquo;decline of the legislature.&rdquo;3 Although some students hold that Congress constitutes an exception to this generalization, 4 most detect the same trend in the United States. Indeed this very symposium of recommendations for revitalizing Congress is an acknowledgment of it. Congress' loss of power is manifested in three important governmental functions traditionally reserved to the legislature: initiating legislation, evaluating legislative proposals, and overseeing the execution of legislation. In recent decades, Congress has abdicated to the President its initiative in preparing a legislative program, has faltered in thoroughly evaluating proposals submitted by the President, and has been unable to exercise effective direction and control over the administration of legislation in which Congress has aquiesced.


#*Interactive communication and display of keyboard music
#@Prentiss Hadley Knowlton
#t1971
#c
#index193648


#*The analysis and scheduling of devices having rotational delays
#@Samuel Henry Fuller, III
#t1972
#c
#index185405


#*Certification of algorithm 251: function minimisation
#@R. Fletcher
#t1966
#cCommunications of the ACM
#index333804


#*The use of frame-to-frame differences in encoding computer graphics data in a network environment.
#@Arthur Israel Karshmer
#t1978
#c
#index187568


#*IFIP-62: Comments
#@J. F. Traub
#t1962
#cCommunications of the ACM
#index330680


#*Secondary key retrieval using an IBM 7090-1301 system
#@D. R. Davis,A. D. Lin
#t1965
#cCommunications of the ACM
#index320428
#%331443
#!The secondary key retrieval method involves the preparation of secondary storage lists from primary data records. Search requests are satisfied by logical operations on appropriate lists, producing a complete set of addresses of primary records relevant to the request. Experimental results are presented and a comparative analysis is given.


#*Group participation computer demonstration
#@E. M. McCormick
#t1963
#cCommunications of the ACM
#index321149
#!Engelbart1 has reported on some demonstrations in which a group functions as various parts of a digital computer. These demonstrations are concerned with binary operations including addition. However, there are occasions when it is desirable to have a group participate in a simulation which is not at this detailed level of computer operation. This note suggests a demonstration which allows a group to simulate the execution of a computer routine itself.


#*A Sampler of Formal Definitions
#@Michael Marcotty,Henry Ledgard,Gregor V. Bochmann
#t1976
#cACM Computing Surveys (CSUR)
#index331016
#%317062
#%317475
#%321433
#%324137
#%611343
#%331590
#%335296
#%550024


#*Floss: An approach to automated layout for high-volume designs
#@Y. E. Cho,A. J. Korenjak,D. E. Stockton
#t1977
#cProceedings of the 14th Design Automation Conference
#index544809
#%546655
#%551773
#%550612
#%548360
#%549495
#%546641
#%549035
#%547727
#!Traditionally, automatic IC layout programs have been constrained to produced designs in which cells are placed in rows. The resulting chips are typically too large, compared to manual layout, to be used for high-volume production. FLOSS uses a new approach &emdash; automatic packing of a manually-generated sketch &emdash; to achieve chip area that is competitive with manual layout.


#*Computer recognition of three-dimensional objects from optical images
#@Jeram Godhumal Advani
#t1971
#c
#index204851


#*Stickiness and liveness
#@Barry K. Rosen
#t1979
#cACM SIGPLAN Notices
#index303284
#%320395


#*Correctness and modularity in asynchronous systems.
#@Abraham Silberschatz
#t1976
#c
#index197239


#*Executable models in APL to introduce concepts in computer science
#@G. Bartoli,L. Bartolo,P. C. Berry,V. N. Spadavecchia
#t1975
#cProceedings of seventh international conference on APL
#index546134
#%320517
#!In this paper the Authors have undertaken to demostrate that fairly general principles of computing can be stated, and operational computer models constructed by students, with little or no attention to specifics of hardware, and that in this fashion general principles can be conveyed, and a frame can be built, in which concepts of Computer Science can he organized and structured. These general principles can be introduced by using APL functions that are both readible descriptions and executable models. With this top-down approach detail can be provided when the student is ready for it, as successive levels of the working definitions are discussed.


#*Effective application of computer graphics
#@George W. Tressel
#t1975
#cProceedings of the 2nd annual conference on Computer graphics and interactive techniques
#index232375


#*A methodology for verifying programs
#@F. W von Henke,D. C. Luckham
#t1975
#cProceedings of the international conference on Reliable software
#index555013
#%318397
#!The paper investigates methods for applying an online interactive verification system designed to prove properties of PASCAL programs. The methodology provides techniques for developing a debugged and verified version starting from an incomplete program.


#*Some complete calculi for matrices
#@Rudolf Bayer,Christoph Witzgall
#t1970
#cCommunications of the ACM
#index324076
#%331703
#!A matrix calculus is introduced with the intention of developing data structures suitable for a high level algorithmic language for mathematical programming. The paper investigates how the special structure of matrices can be described and utilized for efficient computing by saving memory space and superfluous operations. Sequences of matrices (and sequences of sequences of matrices) are considered, and matrix operators are extended to sequence operators and cumulative operators. Algorithms are given which use symbol manipulation of matrix expressions so as to find the forms best suited for computation. These forms are called normal forms. Several completeness results are obtained in the sense that for each expression an equivalent expression in normal form can be found within a specified calculus.


#*Proceedings
#@
#t1971
#c
#index617438


#*A method for finding Hamilton paths and Knight's tours
#@Ira Pohl
#t1967
#cCommunications of the ACM
#index324551
#!The use of Warnsdorff's rule for finding a knight's tour is generalized and applied to the problem of finding a Hamilton path in a graph. A graph-theoretic justification for the method is given.


#*Remark on algorithm 402
#@Robert E. Wheeler
#t1973
#cCommunications of the ACM
#index331634


#*Libraries and machine-readable data
#@Judith Rowe
#t1974
#cACM SIGSOC Bulletin
#index578946
#!Wednesday evening, July 10th, 8:30-10:30 is the time scheduled for a panel discussion: "Government Publications in Machine-Readable Form: A New Tool for the Reference Librarian." A part of the American Library Association's 1974 New York Conference, the meeting is co-sponsored by the Government Documents Round Table's (GODORT) Machine-Readable Data Files Committee, the Federal Librarians Round Table (FLIRT), the RASD Information Retrieval Committee and the RASD/RTSD/ASLA Public Documents Committee. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*F/LOGIC - An interactive fault and logic simulator for digital circuits
#@P. Wilcox,H. Rombeek
#t1976
#cProceedings of the 13th Design Automation Conference
#index553573
#%545616
#%545869
#!Digital simulators are becoming a standard and necessary CAD tool in the circuit design process. The acceptance of this design aid is a result of a number of factors, the predominant one being the over-whelming size and complexity of present day logic circuits and the requirement that a complete test plan be developed for these circuits. Another factor is that recent generation logic simulators have proven to be very flexible tools, capable of simulating very large circuits with a high degree of precision.


#*Algorithm 489: the algorithm SELECT&mdash;for finding the ith smallest of n elements [M1]
#@Robert W. Floyd,Ronald L. Rivest
#t1975
#cCommunications of the ACM
#index320085
#%322734
#!SELECT will rearrange the values of array segment X[L: R] so that X[K] (for some given K; L &le; K &le; R) will contain the (K-L+1)-th smallest value, L &le; I &le; K will imply X[I] &le; X[K], and K &le; I &le; R will imply X[I] &ge; X[K. While SELECT is thus functionally equivalent to Hoare's algorithm FIND [1], it is significantly faster on the average due to the effective use of sampling to determine the element T about which to partition X. The average time over 25 trials required by SELECT and FIND to determine the median of n elements was found experimentally to be: n 500 1000 5000 10000 SELECT 89 ms. 141 ms. 493 ms. 877 ms. FIND 104 ms. 197 ms. 1029 ms. 1964 ms. The arbitrary constants 600, .5, and .5 appearing in the algorithm minimize execution time on the particular machine used. SELECT has been shown to run in time asymptotically proportional to N + min (I, N-I), where N = L - R + 1 and I = K - L + 1. A lower bound on the running time within 9 percent of this value has also been proved [2]. Sites [3] has proved SELECT terminates.


#*Calendar
#@
#t1978
#cComputer
#index336888


#*The Altran system for rational function manipulation &mdash; a survey
#@Andrew D. Hall, Jr.
#t1971
#cCommunications of the ACM
#index327408
#%81323
#!Altran is a complete system for symbolic computation with rational functions in several variables with integer coefficients. It has been designed and implemented to handle large problems with ease and efficiency. Considerable effort has been spent to ensure a minimum amount of machine dependence in the implementation, thus permitting the system to be installed quickly and easily on a variety of computing machines. In this paper a brief description of the language, run time data structures, and implementation is given.


#*A client-based transaction system to maintain data integrity
#@William H. Paxton
#t1979
#cProceedings of the seventh ACM symposium on Operating systems principles
#index548120
#%317300
#%317485
#!This paper describes a technique for maintaining data integrity that can be implemented using capabilities typically found in existing file systems. Integrity is a property of a total collection of data. It cannot be maintained simply by using reliable primitives for reading and writing single units&mdash;the relations between the units are important also. The technique suggested in this paper ensures that data integrity will not be lost as a result of simultaneous access or as a result of crashes at inopportune times. The approach is attractive because of its relative simplicity and its modest demands on the underlying file system. The paper gives a detailed description of how consistent, atomic transactions can be implemented by client processes communicating with one or more file server computers. The discussion covers file structure, basic client operations, crash recovery, and includes an informal correctness proof.


#*Program efficiency and data structures
#@Moshe Augenstein,Aaron Tenenbaum
#t1977
#cProceedings of the eighth SIGCSE technical symposium on Computer science education
#index554987
#%79620
#%162844
#!Program efficiency is usually considered from the point of view of optimizing code. Selecting a proper data structure can have a remarkable effect on the efficiency of the final program. In this paper it is shown how one problem can be solved in several ways using several different data structures. The efficiency of the programs depend on the data structures selected.


#*CORE - a method for controlled requirement specification
#@G. P. Mullery
#t1979
#cProceedings of the 4th international conference on Software engineering
#index552079
#!Attempts to specify requirements adequately normally fail - sometimes catastrophically. One reason is the lack of a rigorously defined method which directly addresses the needs of requirement specification. CORE, the subject of this paper, is such a method. CORE is the result of several years of practical experiment by the author, using a number of published approaches to specification and design. It is supported by a diagrammatic notation whose key features are a composite of ideas drawn from several widely used notations for expression of requirement or design.


#*Mathematical techniques to improve the accuracy of computer graphic devices despite hardware limitations
#@Cloy Joseph Walter
#t1966
#c
#index193597


#*Pipeline Architecture
#@C. V. Ramamoorthy,H. F. Li
#t1977
#cACM Computing Surveys (CSUR)
#index316784
#%196359
#%546578
#%551473
#%548738


#*A very high level programming language for data processing applications
#@Michael Hammer,W. Gerry Howe,Vincent J. Kruskal,Irving Wladawsky
#t1977
#cCommunications of the ACM
#index327512
#%323412
#%323501
#!Application development today is too labor-intensive. In recent years, very high-level languages have been increasingly explored as a solution to this problem. The Business Definition Language (BDL) is such a language, one aimed at business data processing problems. The concepts in BDL mimic those which have evolved through the years in businesses using manual methods. This results in three different sublanguages or components: one for defining the business forms, one for describing the business organization, and one for writing calculations.


#*Translation Networks and Function Composition
#@Peter Wegner
#t1968
#c
#index124487


#*Processor allocation in a computer network with distributed ownership
#@Paulo Mario Bianchi Franca
#t1979
#c
#index196834


#*The high cost of software---causes and corrections
#@
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index65657


#*Accuracy of an Approximate Computer System Model
#@Marc Badel,Annie V. Y. Shum
#t1976
#cProceedings of the International Workshop organized by the Commision of the European Communities on Modelling and Performance Evaluation of Computer Systems
#index269504


#*Design considerations for the VLSI processor of X-TREE
#@David A. Patterson,E. Scott Fehr,Carlo H. Séquin
#t1979
#cProceedings of the 6th annual symposium on Computer architecture
#index545250
#%324932
#%332709
#%334053
#%552219
#%548186
#%546181
#%547741
#%554152
#%546338
#!X-NODE is a single-chip VLSI processor to be realized in the mid 1980's and to be used as a building block for a tree-structured multiprocessor system (X-TREE). Three major trends influence the design of this processor: the continuing evolution of VLSI technology, the requirements for parallelism and communication in a multiprocessor system, and the need for better support of software and high level language constructs. The influence of these trends on the processor architecture are discussed and the current state of the design of X-NODE is outlined. X-NODE will introduce several new features exploiting the full potential of VLSI technology. The processor and hierarchical memory of multiple device types will be combined on a single chip to provide a powerful processor. With basically a memory-to-memory architecture, an on-chip caching scheme provides the performance of a register based architecture. This on-chip memory hierarchy contains program and data, as well as microcode. The instruction set of any processor can thus be dynamically changed and tailored to the specific problem being executed. It is planned to support high level language constructs directly in hardware through mechanisms such as bounds checking.


#*Algorithm 503: An Automatic Program for Fredholm Integral Equations of the Second Kind [D5]
#@Kendall Atkinson
#t1976
#cACM Transactions on Mathematical Software (TOMS)
#index331757
#%335418


#*A simulation approach to the design of dynamic feedback scheduling algorithms for time-shared computer systems
#@Madeline J. Bauer
#t1974
#cACM SIGSIM Simulation Digest
#index581651
#%315247
#%331066
#%547695
#!The goal of a scheduling algorithm for a time-shared computer system is to provide acceptable request response time and resource utilization through effective resource allocation. In order to do this, it is necessary for the algorithm to be capable of adjusting itself to handle the various situations, precipitated by the set of active user requests and the computing system's status, which may occur. An effort is now underway to design the structural framework of a scheduling algorithm which will dynamically formulate its resource allocation policies and adjust its policy formulation depending on the success or failure of those policies. Once designed, the framework will then be used to construct the scheduling algorithm for a given time-shared computer system.The approach chosen for determining the practicability of the algorithm design is the inclusion of the algorithm in the simulation of a swapping time-shared computer system model. The simulation contains four basic activities: processor, input/output, swapper, each of which contains a resource allocation policy for determining a priority ordering among those requests which have asked for the respective resource, and the user activity. User activities follow one of a number of simulated scripts which may be composed of several types of requests. Each request is given behavioral traits dependent on its type.While the complete algorithm is not yet implemented within the simulation, preliminary results suggest that some improvement in response time may be possible.


#*The design of a digital computer contouring control system
#@Alan Edward Middleditch
#t1973
#c
#index193511


#*Control structures for programming languages
#@David Allen Fisher
#t1970
#c
#index201463


#*Session 9b: human oriented user services
#@
#t1976
#cProceedings of the 4th annual ACM SIGUCCS conference on User services
#index234047


#*Algorithms: QuadI
#@R. J. Herbold
#t1960
#cCommunications of the ACM
#index318003


#*The fast Fourier transform its role as an algebraic algorithm
#@John D. Lipson
#t1976
#cProceedings of the 1976 annual conference
#index548470
#%81323
#!In the past decade the Cooley-Tukey fast Fourier transform (FFT) [1] has achieved the status of a &ldquo;super&rdquo; algorithm. As a numerical (complex field) algorithm, the FFT has revolutionized large scale time series analysis in a way that counts most&mdash;economic. (See, e.g., Refs. 3-6.) Since the late sixties, the FFT has also emerged as an important algebraic(abstract field) algorithm, with many interesting applications to the theory and practice of algebraic computing. The abstract character of the FFT, in particular its role as an algebraic algorithm, is what this paper is about. Our discussion centres around the following questions: 1. What is the discreteFourier transform? 2. What is the fastFourier transform? 3. What is its role in algebraiccomputing? 4. Is a finite field(mod p) FFT feasible?


#*IEEE Computer Society Bylaws
#@
#t1976
#cComputer
#index343514


#*Literature review bibliography of simulation optimitation
#@William Farrell
#t1977
#cProceedings of the 9th conference on Winter simulation - Volume 1
#index551874
#%318306
#%326322
#%546246
#%546528
#%550122
#%554928
#!Management Scientists and systems analysts often wish to find the values of input variables which optimize (maximize or minimize) some function of system performance. If the system can be described analytically, mathematical programming is used to find the optimum. When systems are too complicated to be described analytically, simulation is the appropriate tool for modelling systems. Therefore, methods of optimization through simulation are quite important to the management scientist. This paper consists of a discussion and a bibliography of the optimization of simulated systems.


#*The control of response times in multi-class systems by memory allocation
#@J. H. Hine,I. Mitrani,S. Tsur
#t1979
#cCommunications of the ACM
#index328722
#%327033
#%327311
#%548829
#%545147
#%331474
#%558520


#*B74-14 Data Base Systems
#@E. C. Joseph
#t1974
#cIEEE Transactions on Computers
#index341135
#!This excellent book is the sixth in a series of volumes stemming from symposia in areas of current interest in computer science by the Courant Institute of Mathematical Sciences of New York University.


#*Comments on tape reels
#@Clay L. Perry
#t1964
#cCommunications of the ACM
#index318971


#*Programmer paranoia revisited
#@Pat Barnes
#t1975
#cProceedings of the thirteenth annual SIGCPR conference
#index546019
#%458820
#%551038
#%548849
#!Since man has been curious and concerned about anything probably he has been curious and concerned about man. It seems logical that man's ability to speculate, question and reason would be turned toward the understanding of himself and others. It further seems logical that since modern man is a creature of work, man has sought to understand the aspect of his being which is associated with work. Current literature reflects the opinion that an individual's personality is a key consideration in his job success. The conclusions of recent studies have been that a theory of occupational choice must account for an individual's &ldquo;style of life&rdquo; (Armatas and Collister, 1962, Adams, 1969, and Sherman, 1972). The results of these studies indicated that there is a subtle relationship between emotional adjustment and vocational behavior and the individual's resultant relative feeling of well-being.


#*Structured programming considered harmful
#@William Slater,Howard Modell
#t1978
#cACM SIGPLAN Notices
#index309563


#*Software: issues in programming language design
#@
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index63259


#*Algorithms for determining the essential arcs and a basis subgraph of a digraph
#@Bernard Harold Dickman
#t1970
#c
#index196245


#*Biological primitives
#@E. C. DeLand
#t1972
#cProceedings of the 1972 SIGGRAPH seminar on Computer graphics in medicine
#index553294
#!In developing the graphics computer system BIOMOD, we were concerned primarily with the user-system interface. Rather than developing a formal higher-level language specific to modeling in biology, it appeared more fruitful to examine empirically the activities of the modeling process, and to attempt to design so that these activities would be simple to perform. Unfortunately, however, it still functioned easily only for chemists, mathematicians, and programmers; a biologist would still not write FORTRAN or differential equations to describe the basic functions&mdash;for example, a neuron&mdash;of his problem. We would like, therefore, to describe a set of basic biological functions, or primitives, which can have unambiguous definitions and can be parameterized as required in a straightforward, clear way so that they can be called from the library and used in a new problem context. An extension of this concept is to prepare programmed modules, such as a capillary resistance bed, or models, such as a model of the four-chambered heart as a pump, which could be used as required. However, these latter modeling units are not easily parameterized and are usually too individually stylized to carry over from model to model. Instead, we have been concerned with more basic units which can be standardized, as will be described in subsequent sections of this paper. We first briefly describe the BIOMOD system itself.


#*Algorithm 290: linear equations, exact solutions
#@J. Boothroyd
#t1966
#cCommunications of the ACM
#index318245


#*A note on the generation of rosary permutations
#@Ronald C. Read
#t1972
#cCommunications of the ACM
#index326804
#%317640
#%325318
#!Harada [1] has given a method of generating rosary permutations, and of associating an integer with each such permutation in a one-to-one manner. In this note we show that both these ends can be achieved more easily than by Harada's method.


#*A normative simulation for airline marketing planning
#@Randall L. Schultz,Joe A. Dodson, Jr.
#t1974
#cProceedings of the 7th conference on Winter simulation - Volume 2
#index546086
#!This paper reports on the development of a heuristic aid to making marketing planning decisions that is data based and explicitly considers the uncertainty of competitive behavior. An application of the model to an airline market provides conclusions about the nature of the market and how to assess competitive response. Normative simulation appears to have good potential as a decision-making aid for marketing managers.


#*Computer simulation of organizational choice processes under conditions of ambiguity and conflict - the case of West German universities
#@Holger Franck
#t1977
#cProceedings of the 9th conference on Winter simulation - Volume 1
#index552137
#!This article deals with the computer simulation of processes of organizational choice under conditions of ambiguity and/or conflict. It is in line with efforts by Cohen, March, Olsen and others to investigate in those areas of problem resolution and organizational choice, which have not been covered by traditional rational theories relevant for organizational choice and problem solving such as organization theory, microeconomics, operation research, or planning theory. It goes beyond these efforts by taking into account a realistic organizational structure, non-choice processes, communication and activation processes, basic political conflict, and long-run changes in choice processes by certain outcomes of personnel decisions. A corresponding computer simulation model implemented in SIMSCRIPT II.5 and some experimentation and validation endeavors are described. The model serves at this stage of development above all as a conceptual framework for theory and empirical research. Most of the incorporated special assumptions stem from observations of choice processes and interviews of participants West German universities. It is argued, however, that conditions of ambiguity and conflict hold for many organizations.


#*Algorithm 461: cubic spline solutions to a class of functional differential equations
#@F. J. Burkowski,W. D. Hoskins
#t1973
#cCommunications of the ACM
#index328817


#*Das Problem der 'unendlichen Modi' in Algol 68
#@Stephen Heilbrunner
#t1974
#cGI - 4. Jahrestagung
#index272531


#*A graphics-aided programming system
#@David F. Bantz
#t1970
#c
#index204664


#*Performance of update algorithms for replicated data in a distributed database.
#@Hector Garcia-Molina
#t1979
#c
#index186912


#*Algorithms for rational function arithmetic operations
#@Ellis Horowitz
#t1972
#cProceedings of the fourth annual ACM symposium on Theory of computing
#index550465
#%81323
#%554969
#%552261
#%555033
#%551947
#!Despite recent advances in speeding up many arithmetic and algebraic algorithms plus a general increase in algorithm analyses, no computing time study has ever been done for algorithms which perform the rational function arithmetic operations. Mathematical symbol manipulation systems which provide for operations on rational functions use algorithms which were initially given by P. Henrici in 1956. In this paper, these algorithms are precisely specified and their computing times analyzed. Then, new algorithms based on the use of modular arithmetic are developed and analyzed. It is shown that the computing time for adding and taking the derivative of rational functions is 2 orders of magnitude faster using the modular algorithms. Also, the computing time for rational function multiplication will be one order of magnitude faster using the modular algorithm.


#*Implications of educational innovations
#@William S. Dorn
#t1971
#cACM SIGCUE Outlook
#index306383


#*Numerical methods for nonlinear stress wave propagation (abstract)
#@Larry D. Bertholf
#t1975
#cACM SIGNUM Newsletter
#index100621
#!The partial differential equations characterizing stress wave propagation problems include conservation of volume, mass, momentum, and energy plus the constitutive relations for the materials involved. Generally these constitutive relations are nonlinear and numerical methods are required for solutions in various coordinate systems and spatial dimensions. The philosophy of stress wave propagation code development and application at Sandia Laboratories is given in this paper. The way different methods are developed, utilized, and tested is illustrated by many examples in which code solutions are compared to analytic solutions, experiments, and solutions from other codes.


#*Numerical methods for volterra functional differential equations
#@Lucio Tavernini
#t1969
#c
#index186115


#*A computer simulation of a language conditioning of attitude paradigm.
#@Mark Nataupsky
#t1974
#c
#index199331


#*On the efficiency of extensible languages.
#@John Dudley Woolley
#t1973
#c
#index204205


#*Group discussion on diagnostic checks
#@J. J. Eachus
#t1953
#cPapers and discussions presented at the Dec. 8-10, 1953, eastern joint AIEE-IRE computer conference: information processing systems---reliability and requirements
#index400769
#!A group of about 60 conference members met to discuss diagnostic checks. Many of the conferees contributed to the discussion but in this summary no attempt is made to associate the individual members or their affiliation with their comments. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A queueing theory study of time-shared computer systems
#@Philip John Rasch
#t1967
#c
#index186496


#*Pattern Recognition Data Bases Available
#@
#t1973
#cComputer
#index336450


#*New Products
#@D. A. Michalopoulos
#t1975
#cComputer
#index337153
#!In a recent four-part product announcement, Computer Automation, Inc., introduced a pair of computers that expand the firm's reach "from the fast-growing microcomputer market all the way to the large-scale minicomputer market," according to Sol Zasloff, marketing vice president.


#*Management Information System simulation models: A conceptual approach
#@Stanley R. Weingart
#t1969
#cProceedings of the 1969 24th national conference
#index554412
#!Management Information Systems (MIS) provide management with information necessary for decision making in all areas of the firm. This paper presents a conceptual approach to construction of MIS simulation models. Such models may be used for efficient structuring of real world systems. The approach used herein incorporates a simple system of flow diagramming the functional elements of the MIS. From the flow diagrams a set of difference equations is developed to provide a model structure for computer simulation runs. The &ldquo;quality&rdquo; of the MIS is determined by the information content of the data provided for the management decision making.


#*NSF Support of Basic Research in Computer Science
#@J. R. Lehmann
#t1978
#cComputer
#index398730
#!Interestingly enough, much of the computer architecture research currently supported by the National Science Foundation is related to the theme of this issue. Below, John R. Lehmann, program director of NSF's Computer Systems Design Program, has provided a list of principal investigators and the titles of their research, as well as a brief statement on how to submit a research proposal.


#*Computerized conferencing for the deaf and handicapped
#@Murray Turoff
#t1975
#cIssue 16 (June 1975)
#index311984
#!This summary paper briefly describes a unique an d relatively new medium for human communication utilizing current computer and communication technology. However, emphasis is placed on the tremendous potential benefits that this form of communication can have for the deaf and physically handicapped since this form of communication eliminates restrictions on communication imposed by lack of mobility or transportation, lack of speech, and requirements of time coincidence among members of a discussion.


#*Upward and Downward Diagonalization over Axiomatic Complexity Classes
#@Robert L. Constable
#t1969
#c
#index121256
#!This report considers special cases of the question ``What conditions on u() and t() guarantees that $R^{\Phi}_{t}() \neq $R^{\Phi}_{u}()$?'''' where $R^{\Phi}_{t}()$ is the class of recursive functions whose $\Phi$ complexity is bounded by t(). In particular the condition $\stackrel{inf}{n\rightarrow\infty} \frac{t(n)}{u(n)} = 0$ and $\stackrel{lim}{n\rightarrow\infty} \frac{t(n)}{u(n)} = 0$ are examined, and it is shown that certain results of Hartmanis, Stearns and Hennis are in one sense the best possible. It is then shown that the diagonalization techniques used in results of this type are of two different sorts, upward and downward. The differences are made precise and very general conditions are found under which each type applies. These conditions widely generalize several well-known results for time and tape complexity measures. In the final section, the report considers some properties of a special class of names for complexity classes. The techniques used in Lemma 3.3 and Theorems 5.1 and 7.1 are new and promise wider application. Also, new results of Borodin and McCreight and Meyer are used, but otherwise the methods are those of Blum.


#*Algorithm 103: Simpson's rule integrator
#@Guy F. Kuncir
#t1962
#cCommunications of the ACM
#index326973


#*An Interactive Graphics System for the design of integrated circuits
#@Beatriz Infante,Diane Bracken,Bill McCalla,Sam Yamakoshi,Ellis Cohen
#t1978
#cProceedings of the 15th Design Automation Conference
#index554627
#%551773
#!IGS (Interactive Graphics System) is a computer design aid specifically developed for the layout of integrated circuits. User specification of process information makes the system process-independent while retaining the features which make it a useful layout tool. The ability to place interconnect on a coarse grid greatly diminishes the chances of misalignment. Automatic, incremental checking of cell-to-cell, cell-to-component, and component-to-component spacing reduces the number of design rule violations. Rudimentary forms of topology verification are provided in the ability to trace electrical connectivity.


#*Proceedings of the 12th annual symposium on Simulation
#@Garnet J. Borror
#t1979
#cAnnual Simulation Symposium
#index551284


#*A New Method to Show Lower Bounds for Polynomials which are Hard to Compute
#@Joos Heintz
#t1979
#cProceedings of the 4th GI-Conference on Theoretical Computer Science
#index272399


#*Application of Church-Rosser Properties to Increase the Parallelism and Efficiency of Algorithms
#@Mariangiola Dezani-Ciancaglini,Maddalena Zacchi
#t1974
#cProceedings of the 2nd Colloquium on Automata, Languages and Programming
#index365994


#*The mobile programming system: STAGE2
#@W. M. Waite
#t1970
#cCommunications of the ACM
#index317571
#%304306
#%314181
#%329679
#%324194
#%330768
#%320395
#%328774
#!STAGE2 is the second level of a bootstrap sequence which is easily implemented on any computer. It is a flexible, powerful macro processor designed specifically as a tool for constructing machine-independent software. In this paper the features provided by STAGE2 are summarized, and the implementation techniques which have made it possible to have STAGE2 running on a new machine with less than one man-week of effort are discussed. The approach has been successful on over 15 machines of widely varying characteristics.


#*SIGART (Paper Session)
#@Robert Wilensky,Robert F. Simmons,Arvin Levine,Mitchell Marcus
#t1976
#cProceedings of the 1976 annual conference
#index549405
#!Natural language processing has had a spurt of interest in recent years, due in part to a new focus on the representation and structure of knowledge. The papers in this session cover all ends of natural language research, parsing, generating, and memory and inference. The advances to be reported on here indicate that the possibility of natural communication with machines may be closer than had been anticipated.


#*Third time charm: Stronger prediction of programmer performance by software complexity metrics
#@Bill Curtis,Sylvia B. Sheppard,Phil Milliman
#t1979
#cProceedings of the 4th international conference on Software engineering
#index551792
#%323839
#%548454
#%622654
#!This experiment is the third in a series investigating characteristics of software which are related to its psychological complexity. A major focus of this research has been to validate the use of software complexity metrics for predicting programmer performance. In this experiment we improved experimental procedures which produced only modest results in the previous two studies. The experimental task required 54 experienced Fortran programmers to locate a single bug in each of three programs. Performance was measured by the time to locate and successfully correct the bug. Much stronger results were obtained than in earlier studies. Halstead's E proved to be the best predictor of performance, followed by McCabe's v (G) and the number of lines of code.


#*An example of a pragmatic approach to portable interactive graphics
#@Lyle B. Smith
#t1974
#cProceedings of the 1st annual conference on Computer graphics and interactive techniques
#index246067
#!Standards for graphics subroutines would encourage the coding of portable programs using graphics. However such standards do not yet exist. In this paper a small set of generally available primitive subroutines, and FORTRAN, are used to pragmatically provide a degree of portability for a second level graphics package. This package consists of only nine subroutines and yet provides considerable power for coding interactive graphical numerically oriented programs.


#*Recursive processes and ALGOL translation
#@A. A. Grau
#t1961
#cCommunications of the ACM
#index317760
#%327973


#*On the Power of Multiplication in Random Access Machines
#@Juris Hartmanis,Janos Simon
#t1974
#c
#index110212
#!We consider random access machines with a multiplication operation, having the added capability of computing logical operations on bit vectors in parallel. The contents of a register are considered both as an integer and as a vector of bits and both arithmetic and boolean operations may be used on the same register. We prove that, counting one operation as a unit of time and considering the machines as acceptors, deterministic and non-deterministic polynomial time acceptable languages are the same, and are exactly the languages recognizable in polynomial tape by Turing machines. We observe that the same measure on machines without multiplication is polynomially related to Turing machine time thus the added computational power due to multiplication in random access machines is equivalent to the computaitonal power which polynomially tape-bounded Turing machine computations have over polynomially time-bounded computations. Therefore, in this formulation, it is not harder to multiply than to add if and only if PTAPE=PTIME for Turing machines. We also discuss other instruction sets for random access machines and their computational power.


#*Efficient encoding of machine instructions
#@Johan W. Stevenson,Andrew S. Tanenbaum
#t1979
#cACM SIGARCH Computer Architecture News
#index124160
#%315820


#*Saving tapes in the simulation of multihead turing machines
#@Victor L. Bennison
#t1974
#cACM SIGACT News
#index433696


#*Algorithm 256: modified Graeffe method [C2]
#@A. A. Grau
#t1965
#cCommunications of the ACM
#index328286


#*Formal semantic descriptions of applicative languages.
#@Gerald Alan Jones
#t1977
#c
#index194451


#*New bounds on formula size
#@Mike Paterson
#t1977
#cProceedings of the 3rd GI-Conference on Theoretical Computer Science
#index271195


#*An interactive FORTRAN structuring aid
#@Julian E. Gomez
#t1979
#cProceedings of the 4th international conference on Software engineering
#index551271
#%153803
#%550011
#!This paper describes a tool at the Jet Propulsion Laboratory which aids a programmer in converting FORTRAN to a structured syntax. The program is a highly interactive system using computer graphics techniques to facilitate the operations necessary for such a conversion. Editing and structure recognition capabilities, including the ability to handle arbitrary levels of block structure, have been combined into a system that reduces the effort involved in updating old software.


#*An automatic decision-logic-table processor
#@Donald J. Lemoine
#t1971
#cACM SIGPLAN Notices
#index305888
#%315438
#%334177
#!The value of decision-logic-tables as a tool for computer programming has been brought forth by the development of several programming languages. The well-known decision-logic-table programming languages are designed as input to translators. Instead of converting the input decision-logic tables to an executable form, these translators convert the source program to some other well-known language, such as Fortran. The appropriate compiler then converts the resulting source-language program to an executable form.The DEcision Logic TAble programming language, Delta, described here, is an automatic decision table processor, eliminating the need to translate the input into some intermediate source language. Basic features of decision-logic tables are used as a foundation for Delta. The syntax of Delta is similar to that of PL/I. Although Delta is limited in scope, it is expandable. Derived from the Purdue University Fast Fortran Translator, Pufft, the Delta processor performs both a syntax analysis and generates code, in one pass. The code generated is not machine language, but is an internal representation of the object language program.


#*A testable condition on intersection of context-free languages
#@Harold Lewis Pierson
#t1972
#c
#index197151


#*Note on Minimal Congruences on Transition Graphs
#@B. Reusch
#t1972
#cIEEE Transactions on Computers
#index345737
#!A new proof is given for the following fact: All minimal congruences on a transition graph are of one of four types and can easily be obtained by inspecting the graph.


#*A low cost satellite for fast interactive graphics in a time-sharing environment
#@B. Meyer
#t1979
#cProceedings of the 16th Design Automation Conference
#index551182
#%153803
#!This paper describes a system that improves the performance of a time-shared host computer for users of TEK-TRONIX series 4010/4014/4015 graphics terminals. The system consists of a mini or microcomputer situated at the terminal, a program that runs in the satellite computer, and a library of FORTRAN callable subroutines that provide a convenient interface between an application program in the host computer and the program in the satellite computer. The system ensures that the satellite has advance information about the expected dialogue, so that the satellite is able to react instantly to input from the user, even if the response of the host computer is slow. The satellite gathers several trivial inputs together and sends them to the host in a burst. This allows the program in the host to process more information each time it is rolled into memory, hence the efficiency of its operation is improved. The satellite also performs such operations as zooming, repainting and identification of entites on the screen.


#*Intermediate Languages: Current Status
#@William M. Waite
#t1976
#cPortability of Numerical Software, Workshop
#index262907


#*Computability theory in admissible domains
#@E. Sciore,A. Tang
#t1978
#cProceedings of the tenth annual ACM symposium on Theory of computing
#index545569
#%122505
#%183108
#%205675
#!Denotational semantics was introduced by Strachey as a means of defining semantics of programming languages. It's mathematical foundation was justified by Scott [14] in 1969 when he introduced continuous lattices to model data types and showed how to solve reflexive domain equations. It is not the case that any solution of a given reflexive domain equation is a suitable model for studying denotational semantics. In programming languages, the constructs that we deal with can all be realizable by some machines, hence their meanings, considered as mathematical objects in a lattice, should be computable. In other words, we need a solution where we can formalize the notion of computability. Of course, this means that many continuous lattices are irrelevant to the study of denotational semantics of programming languages. It is the purpose of this paper to isolate those lattices which are relevant.


#*Fast computational techniques for pseudoinverse and wiener image restoration.
#@Faramarz Davarian
#t1975
#c
#index188472


#*Virtual terminal management in a multiple process environment
#@Keith A. Lantz,Richard F. Rashid
#t1979
#cProceedings of the seventh ACM symposium on Operating systems principles
#index548054
#%153803
#%198826
#%554497
#%549882
#%553813
#!Rochester's Intelligent Gateway provides its users with the facilities for communicating simultaneously with a large number of processes spread out among various computer systems. We have adopted the philosophy that the user should be able to manage any number of concurrent tasks or jobs, viewing their output on his display device as he desires. To achieve this goal the Virtual Terminal Management System (VTMS) converts a single physical terminal into multiple virtual terminals, each of which may be written to or queried for user input. VTMS extends the features of the physical terminal by providing extensive editing facilities, the capacity to maintain all output In disk-based data structures, and sophisticated mechanisms for the management of screen space. Virtual terminals are device-independent; the specific characteristics of the physical terminal are known only to the lowest-level I/O handlers for that device. VTMS Is currently running on a network of six minicomputers supporting various text and raster-graphics displays.


#*Design of Totally Self-Checking Check Circuits for m-Out-of-n Codes
#@D. A. Anderson
#t1973
#cIEEE Transactions on Computers
#index338824
#!The design of totally self-checking check circuits for m-out-of-n codes is described. Totally self-checking m-out-of-n checkers provide an error indication whenever the input is not an m-out-of-n code or whenever a fault occurs within the checker itself. Since the checker checks itself, there is no need for additional maintenance access or periodic exercise of the checker to verify its ability to detect errors. The basic structure of the checker relies on the use of majority detection circuits. Various gate level implementations for the majority detection circuits are also presented, although the self-checking capability of the checker does not depend on their particular implementation since they are exhaustively tested by code inputs. The self-testing checkers for k-out-of-2k codes are discussed in the most detail since the totally self-checking checkers for 1-out-of-n and arbitrary m-out-of-n codes are constructed by first translating the code to a k-out-of-2k code via a totally self-checking translator.


#*Remarks on algorithms 2 and 3
#@J. H. Wilkinson
#t1961
#cCommunications of the ACM
#index315715


#*On the criteria to be used in decomposing systems into modules
#@D. L. Parnas
#t1972
#cCommunications of the ACM
#index329737
#%316233
#%321876
#%334248
#%553638
#%331066
#!This paper discusses modularization as a mechanism for improving the flexibility and comprehensibility of a system while allowing the shortening of its development time. The effectiveness of a &ldquo;modularization&rdquo; is dependent upon the criteria used in dividing the system into modules. A system design problem is presented and both a conventional and unconventional decomposition are described. It is shown that the unconventional decompositions have distinct advantages for the goals outlined. The criteria used in arriving at the decompositions are discussed. The unconventional decomposition, if implemented with the conventional assumption that a module consists of one or more subroutines, will be less efficient in most cases. An alternative approach to implementation which does not have this effect is sketched.


#*Models of light reflection for computer synthesized pictures
#@James F. Blinn
#t1977
#cACM SIGGRAPH Computer Graphics
#index233473
#%326818
#!In the production of computer generated pictures of three dimensional objects, one stage of the calculation is the determination of the intensity of a given object once its visibility has been established. This is typically done by modelling the surface as a perfect diffuser, sometimes with a specular component added for the simulation of hilights. This paper presents a more accurate function for the generation of hilights which is based on some experimental measurements of how light reflects from real surfaces. It differs from previous models in that the intensity of the hilight changes with the direction of the light source. Also the position and shape of the hilights is somewhat different from that generated by simpler models. Finally, the hilight function generates different results when simulating metallic vs. nonmetallic surfaces. Many of the effects so generated are somewhat subtle and are apparent only during movie sequences. Some representative still frames from such movies are included.


#*National and international developments in providing data information services
#@Judith S. Rowe
#t1976
#cProceedings of the 4th annual ACM SIGUCCS conference on User services
#index235054


#*Three levels of accuracy for the simulation of different fault types in digital systems
#@E. W. Thompson,S. A. Szygenda
#t1975
#cProceedings of the 12th Design Automation Conference
#index548547
#%545616
#%546573
#%550250
#%554216
#!CC-TEGAS3 is a time domain digital logic simulation and test generation system. Presently there are six primary modes of simulation with other modes in development. Modes one through three are for true value simulation only and are used for logic verification and design verification. Modes four through six correspond to modes one through three, respectively, but are for fault simulation. These later modes allow a user to simulate faults at either the logic verification level, (using assignable nominal element propagation delays), or at the design verification level using assignable minimum-maximum delay times. Mode six represents one of the most accurate fault simulators yet to be implemented. The description, analysis, design considerations, implementation techniques, and data structures used in the fault simulation modes of the CC-TEGAS3 system are the subject of this paper.


#*Fail-Softness Criteria in the Realization of a Minicomputer Disk Operating System to be Used in an "Open-Shop" University Environment
#@J. Harms
#t1974
#cGI - 4. Jahrestagung
#index272381


#*A quantitative evaluation of the effectiveness of quality assurance as experienced on a large-scale software development effort
#@Peter Chase Belford,Carlo Broglio
#t1978
#cACM SIGSOFT Software Engineering Notes
#index547854
#!The purpose of quality assurance on software projects is to achieve high quality products on schedule, within cost, and in compliance with contract requirements. However, historically, the effectiveness of these activities on software projects has not been quantitatively demonstrable because of a lack of data collected on the project combined with a lack of insight into the operational reliability of the system. Quality assurance is a collection of activities on a contractual deliverable whose purpose is to impart a degree of confidence that the deliverable will conform to the customer's concept of what was procured. Under these conditions, quality assurance must be performed with respect to a documented baseline of the concept. This baseline can address the need in the form of requirement statements; the conceptual approach to be followed in the form of a functional specification; or the design to be implemented in the form of a design specification. Further, these baselines are hierarchical in the sense that when quality assurance is applied to a level it is implicitly applied to all lower levels; e.g., if the need is to be satisfied, the conceptual approach must be satisfied. Effective quality assurance programs impart a high degree of confidence to the customer without significant impacts on schedule or cost. Historically, this effectiveness has not been quantitatively demonstrable because of a lack of data collected on the project combined with a lack of insight into the operational reliability of the system.


#*The University of Manchester computing machine
#@F. C. Williams,T. Kilburn
#t1951
#cPapers and discussions presented at the Dec. 10-12, 1951, joint AIEE-IRE computer conference: Review of electronic digital computers
#index388131
#!The computing machine which now is operating at the University of Manchester, represents the culmination of a research project of several years' standing. It seems appropriate to outline the various steps in the development of this project, since these have given the final machine its major characteristics.


#*Dynamische Bildanalyse und Verlaufsbeobachtungen als angewandte Szenen-Analyse in der Augenheilkunde
#@M. Mertz
#t1979
#cAngewandte Szenenanalyse, DAGM Symposium
#index568280


#*The algebraic solution of large sparse systems of linear equations using REDUCE 2
#@Martin L. Griss
#t1974
#cProceedings of the 1974 annual conference - Volume 1
#index545280
#%317826
#%548412
#%553724
#!This paper discusses some of the problems encountered during the solution of a large system of sparse linear equations with algebraic coefficients, using REDUCE 2. Of particular importance is intermediate expression swell, which ultimately uses up all the available storage, and produces voluminous unreadable output. By optimally ordering the equations (optimal pivoting algorithms), and decomposing the intermediate expressions, so as to share common sub-expressions (&ldquo;hash coded CONS&rdquo;), a considerable saving in storage is achieved. By suitably renaming frequently used common sub-expressions, using the table built up above, and outputting these first, followed by the more complex expressions, a simplification in the output occurs. These techniques are general, and may be useful in any problem with large expressions to store and output.


#*An approach to the introductory computer science course for non-majors
#@Robert N. Cook
#t1977
#cProceedings of the eighth SIGCSE technical symposium on Computer science education
#index551982
#%547388
#%550520
#%551529
#%619771
#%552751
#!The course described in this paper is intended for students who are not majoring in computer science or mathematics. In a typical semester students majoring in such diverse fields as dietetics, sociology, psychology, elementary education, accounting, broadcasting, physical education, music, industrial technology, english, business administration, chemistry and secretarial science are enrolled in the course. Virtually the only common element in the background of the students enrolled in the course is their lack of a previous university course in either mathematics or computer science. The highest level of mathematical education that may be expected is first year high school algebra; occasionally even that expectation is too high. 4 For students with this background many of the available textbooks are not satisfactory. This paper will attempt to further clarify the nature of the course by stating its objectives, by discussing the choice of a language for the course, by discussing what topics normally included in available textbooks are not desirable, and finally by suggesting topics which are desirable in an introductory course for non majors.


#*Latin squares and magnetic-core matrix storage
#@Nelson M. Blachman
#t1956
#cProceedings of the 1956 11th ACM national meeting
#index547306


#*Production programming by revenue curve analysis
#@A. G. Beged Dov,C. D. Carmichael,S. T. Ferguson,I. E. Mitchell,W. H. Struble
#t1968
#cProceedings of the second conference on Applications of simulations
#index550605
#!We grant that share of the market can and should be an important consideration in setting corporate goals, but it must not be the sole objective. We believe that total market forecasts and the determination of a firm's own sales plan are valid, reasonable and necessary elements of a total decision system, but they are not the whole system. We have developed a procedure, based on the maximax principle1 and the application of the principle of subsidiarity,2 to evaluate the influences bearing on profitability and to optimize profit on a continuing basis, thus providing management with a fully systematized, immediate and rational basis for decisions under an infinite variety of factual or hypothetical situations with respect to those elements basic to the profitable operation of a manufacturing firm. We have formulated a model by which optimization will be achieved through the development of demand curves for various products (using factual, reliable quantitative information from within the firm) and interrogating these curves for the price where profit will be maximized, taking into consideration the demand elasticity for each product, manufacturing capacity limitations and production cost factors. We have developed a computer program which can perform the numerous repetitive calculations required to optimize the various factors. This program was written, de-bugged and test problems were run to demonstrate the effectiveness of the model. Appropriate documentation supporting the computer program is provided, as well as the finished reports generated by the program.


#*A man-computer simulation of corporate strategy formulation in a technology-based firm
#@Henry Raymond Radosevich
#t1969
#c
#index195888


#*A variant method of file searching
#@M. D. Mc Ilroy
#t1963
#cCommunications of the ACM
#index328711
#%321235
#%331443
#!Trapping an instruction which cannot normally be trapped can be worthwhile, particularly when an existing program is to be revised. However, under those circumstances one would desire to replace instructions on a one-for-one basis.


#*A Set of Invariants Within the Power Spectrum of Unitary Transformations
#@S. Wendling
#t1978
#cIEEE Transactions on Computers
#index347696
#!This correspondence presents a device for designing unitary transformations based on the Hadamard transform process. The notion of "invariants" within the power spectrum of one-dimensional transformations is developed and the specific case of some widespread transformations is considered. The results are extended to two-dimensional transformations and a character recognition experiment using the invariants thus obtained is presented.


#*MASS&mdash;a mail service simulation
#@Paul L. Tuan,David S. Nee
#t1969
#cProceedings of the third conference on Applications of simulation
#index547959
#!This model was developed for the U.S. Post Office Department for the purpose of evaluating the relative merits of alternative mail processing, handling, and transportation plans. It may be used to evaluate proposed mail sorting and routing schemes, man-power allocations, new mail processing equipment, transportation scheduling, and mail volume fluctuations.


#*Integer goal programming: methods, computations, applications.
#@Richard Lewis Morris
#t1976
#c
#index198382


#*Simplification by Cooperating Decision Procedures
#@Greg Nelson,Derek C. Oppen
#t1979
#cACM Transactions on Programming Languages and Systems (TOPLAS)
#index331447
#!A method for combining decision procedures for several theories into a single decision procedure for their combination is described, and a simplifier based on this method is discussed. The simplifier finds a normal form for any expression formed from individual variables, the usual Boolean connectives, the equality predicate =, the conditional function if-then-else, the integers, the arithmetic functions and predicates +, -, and &le;, the Lisp functions and predicates car, cdr, cons, and atom, the functions store and select for storing into and selecting from arrays, and uninterpreted function symbols. If the expression is a theorem it is simplified to the constant true, so the simplifier can be used as a decision procedure for the quantifier-free theory containing these functions and predicates. The simplifier is currently used in the Stanford Pascal Verifier.


#*Report of session on concurrency
#@Michael D. Schroeder
#t1973
#cProceeding of ACM SIGPLAN - SIGOPS interface meeting on Programming languages - operating systems
#index550500
#%546630
#!This session was devoted to discussion of primitives for synchronizing the execution of concurrent processes. Jack Dennis introduced the session by noting that concurrent activity in a computer systems leads to the possibility of nondeterminacy. While most users with applications programs do not want nondeterminate results, some applications are inherently nondeterminate in part, e.g., an airline seat reservation system. At a lower level, the programmers of the operating system itself need to write both determinate and nondeterminate programs. The challenge is in providing primitives at each level in a system which guarantee determinacy when that is required, yet allow the construction of nondeterminate programs when that is required. As a basis for discussion, Dennis invited Rick Holt to make a short presentation on the levels in a computer system and their relationship to synchronizing primitives. Holt indicated that the principle reason we have concurrency in computer systems is the economic necessity to run I/O devices in parallel with the much faster central processors. There are also fancier reasons, like constructing nondeterminate computations. Concurrency is usually handled by embedding various synchronizing primitives in the system or in high-level programming languages. In order to decide what primitives are appropriate you need to know what problems are to be solved. The problems being solved depend in turn upon the level of the computer system being considered. A computer system can be divided into five levels: hardware, kernel, nucleus, subsystems, and applications. The kernel multiplexes the central processors, implementing processes. At this level very simple synchronization primitives may be sufficient, like turning off interrupts. A critical problem at this level is the processor allocation strategy and maintaining queues of waiting processes. The nucleus is responsible for sharing devices. We want to be able to write device managers that multiplex data paths and schedule the use of these paths. These managers can be built in two ways: distributed managers that execute as part of user processes or centralized managers that execute in their own processes. Dijkstra has told us how to handle the concurrency generated by decentralized managers using primitives like P and V. Message passing works for centralized managers. (Note that message buffers are an important system resource to be managed. They cannot be managed using message switching, so this management must occur in the kernel.) At the levels of subsystems and applications something more complex and specifically suited to certain applications may be required to control concurrency. At all levels concurrency is interrelated with problems of protection, reliability, and pre-emption. If we ignore these problems we will miss entirely the problems of implementing primitives to control concurrency. Holt also discussed the primitives used at the various levels in the SUE system, as described in his working paper.


#*An extended attribute grammar for Pascal
#@David A. Watt
#t1979
#cACM SIGPLAN Notices
#index304869
#%240173


#*Suggestion concerning the notions of ALGOL and ALGOL-like translators
#@Peter Naur
#t1961
#cIssue 12 (April 1961)
#index108164


#*Phas-structure productions in PL/I: Phas-structure productions in PL/I0
#@Ira Pohl
#t1967
#cCommunications of the ACM
#index330733


#*Requirements of the bureau of old-age and survivors insurance for electronic data processing equipment
#@Edward E. Stickell
#t1953
#cProceedings of the February 4-6, 1953, western computer conference
#index410036
#!The activities of the Division of Accounting Operations of the Bureau of Old-Age and Survivors Insurance have been referred to, upon occasion, as one of the biggest bookkeeping jobs in the world. Whether this condition is true or not depends on how it is measured. Certainly, by the yardstick of costs, it would not appear that the job is at all near the biggest. On the basis of comparisons similar to those made in business, the gross costs of operations represent only 1/2 of 1 percent of total gross income. Furthermore, the system shows no signs of becoming the biggest in terms of cost. In a ten year period, an approximately 50 percent increase in basic work loads has been absorbed with no significant or compensatory increase in personnel. It is felt, therefore, that if the job qualifies as being one of the biggest in volume, it also might qualify as one of the smallest in terms of proportionate costs. However, regardless of how it is measured, the job represents a real challenge to those who administer it and to those who would furnish it with suitable electronic paraphernalia. For these reasons, the following problems are presented with pleasure at the opportunity and with confidence in the know-how represented at this conference to solder together whatever combinations of wires, tubes, diodes and transistors that are found to be necessary in each case.


#*Proceedings of the 10th SIGCSE symposium on Computer science education
#@
#t1979
#cACM SIGCSE Bulletin
#index300859


#*Design verification based on functional abstraction
#@S. Leinwand,T. Lamdan
#t1979
#cProceedings of the 16th Design Automation Conference
#index551446
#%546167
#%546797
#%551639
#!The aim of this report is to show the feasibility of automatic hardware verification based on functional abstraction. This is defined as the process of extracting the behavior of a product from its static structural description. A general discussion of possible approaches to design verification points out that functional abstraction is a very important part of any system for automatic hardware verification. Some of the tools developed for proofs of program correctness can be used when dealing with digital designs. In the present paper, the problems specific to hardware verification are singled out and investigated. Several tools specific to design verification, that were developed during the reported research, are briefly reviewed. The appendix begins with results of automatic analysis of basic modules (actual TTL components: flip-flops and an adder). These modules are then used in the realisation of more complex circuits. As an instructive example, three different designs implementing the same specifications are analyzed, and it is shown that the reported system is able to extract their common behavior.


#*A Software Engineering Graduate Curriculum
#@Leon G. Stucki,Lawrence J. Peters
#t1978
#cProceedings of the 1978 annual conference
#index553779
#%546157
#%547128
#%553175
#!Picking up any large city Sunday paper one cannot help but be impressed by the large demand for &ldquo;software engineers.&rdquo; Upon reflection, several questions are raised: Who are these mythical software engineers? What do they do? Where do they come from? Why are they here? Where are they going? Industry and government alike are crying out for software engineers while universities have yet to establish any real software engineering curricula. The state of affairs is actually even more complex than this in that we don't even really know who these mythical software engineers are. In fact, the term &ldquo;software engineering&rdquo; is not commonly agreed upon as to its exact meaning. People in the field are not sure what terminology best describes the nature of their work [1, 2]. During a recent software engineering conference approximately 500 attendees were asked their formal occupation; approximately 20% of those in attendance indicated that they were software engineers. The others used terms such as: Systems Analyst, Programmers, Managers, etc. All of these jobs contain elements (technical and managerial) of software engineering, and tend to point out the multi-faceted aspect of this field.


#*Lossiness in tessellation automata.
#@Edward Hazelton Brownlee, Jr.
#t1975
#c
#index200950


#*Algorithmic selection of the best method for compressing map data strings
#@E. L. Amidon,G. S. Akin
#t1971
#cCommunications of the ACM
#index331279
#%313848
#!The best of a dozen different methods for compressing map data is illustrated. The choices are generated by encoding data strings&mdash;sequence of like codes&mdash;by three methods and in four directions. Relationships are developed between compression alternatives to avoid comparing all of them. The technique has been used to compress data from forest resource maps, but is widely applicable to map and photographic data reduction.


#*Practical Parallel Band Triangular System Solvers
#@S. C. Chen,D. J. Kuck,A. H. Sameh
#t1978
#cACM Transactions on Mathematical Software (TOMS)
#index331898
#%201941


#*Making Systems Work: The Psychology of Business Systems
#@William C. Ramsgard
#t1977
#c
#index608261


#*On holomorphic mappings of complex manifolds
#@Yung-Chen Lu
#t1967
#c
#index192992


#*The inner product computer
#@Earl Eugene Swartzlander, Jr.
#t1972
#c
#index188691


#*Design considerations for microprogramming languages
#@Gregory R. Lloyd,Andries van Dam
#t1974
#cACM SIGMICRO Newsletter
#index3797
#%553113
#%547007
#%319282
#%552132
#%554894
#!The growing acceptance of user-microprogrammable computers indicates that microprogramming, as a discipline, will require development of user-oriented microprogramming support. A number of approaches (definition of sophisticated target machines, microcode assemblers, and higher level microprogramming languages) have been proposed. The issues involved in choosing support tools include the range of proposed applications, hardware parallelism (horizental or minimally encoded control vs. vertically encoded control) and constraints on performance. After reviewing some of these tradeoffs, design considerations for higher level microprogramming languages are considered. One of the most important design decisions is fixing the level of the language, defined on a continuum from symbolic assemblers, through general purpose programming languages such as PL/I. A tailored language concept is defined and illustrated, using as an example a microprogramming language for a horizontally encoded microprogrammable computer currently under development.


#*Shortest Path Problems and Tree Grammars: An Algebraic Framework
#@Alfonso Catalano,Stefania Gnesi,Ugo Montanari
#t1978
#cProceedings of the International Workshop on Graph-Grammars and Their Application to Computer Science and Biology
#index262033


#*Computerized Blood Gas Interpretation and Reporting System
#@R. M. Gardner
#t1975
#cComputer
#index344673
#!With the increased sophistication of laboratory instrumentation, physician and nursing staffs are being presented with large amounts of clinical data which they are expected to interpret in order to formulate proper therapy for their patients. One of the recent advances has been the development of arterial blood gas analysis. This test now provides reliable, accurate data on the blood gas status of patients, thereby presenting information to clinical staffs which was not available before. Accompanying these improvements in technique has been a steady increase in knowledge and studies performed on various blood gas disorders.1-8


#*A language for modeling and simulating dynamic systems
#@R. J. Parente,H. S. Krasnow
#t1967
#cCommunications of the ACM
#index324022
#%319282
#%323755


#*Hidden lines elimination for a rotating object
#@Yutaka Matsushita
#t1972
#cCommunications of the ACM
#index317396
#!A method is presented of determining which parts of three-dimensional objects are visible and which are invisible when the objects are rotated about some axis. This paper describes a polygon comparison scheme in which the relationships of two polygons can be classified into tree types, and also discusses how the relationship is changed for each pair of polygons under rotation about some axis. A rotation table is defined for each pair of polygons, which remains fixed as long as rotation is about one axis and provides a means of rapidly determining the visible and hidden line relationship between two polygons. Additional work must be done to extend this approach to simultaneous rotation about several axes.


#*Academic computing at Atlanta University Center-a consortium of six predominantly black institutions
#@Louise S. Morrison,Grover C. Simmons
#t1976
#cACM SIGCSE Bulletin
#index552747
#!Atlanta University Center is the largest private institution of Black higher education in the world and the second oldest consortium of schools in the nation. When the Center began offering an undergraduate degree in computer science in 1969, it was the first institution in Georgia to do so. Now there are 50 majors, and each semester the Center-Coordinated Computer Science Department teaches approximately 250 students for the six institutions comprising the Atlanta University Center. In this paper the computer science curriculum is described and programs and services provided by this department are detailed.


#*Using procedures in list processing
#@V. J. Rayward-Smith
#t1977
#cProceedings of the Strathclyde ALGOL 68 conference
#index555341
#%97643
#!In many situations the atoms in a list can require a considerable amount of storage space or can be difficult to evaluate. When handling algorithms which only refer to a few atoms of a list much time and space can be wasted if the whole list is stored. In this paper an attempt is made to store lists as procedures which are only evaluated if absolutely necessary. The difficulties which arise when programming such a list processor in Algol 68 are caused by inherent scoping problems. A solution is presented for linear lists together with an example based on the processing of an infinite list.


#*COBOL: a sample problem
#@Thomas N. Mackinson
#t1961
#cCommunications of the ACM
#index326425
#!COBOL (COmmon Business Oriented Language) is an English Language programming system which is capable of being implemented on a wide variety of electronic digital computers for use in the solution of business data processing problems. The idea was conceived in May, 1959 at a meeting called in the Pentagon by Mr. Charles Phillips of the Office of the Assistant Secretary of Defense, Comptroller. The purpose of this meeting was to consider the desirability and the feasibility of establishing a common language for the programming of electronic computers for data processing. Representatives from computer user installations, both government and industrial, computer manufacturers, universities, and others concerned with computers were present. There was almost unanimous agreement that the project was both desirable and feasible. The COnference on DAta SYstems Languages (CODASYL) was established, and three committees were defined and staffed. These committees were the Short Range Committee, the Intermediate Range Committee, and the Long Range Committee. Each committee had its own goal and its own time scale. The coordination of the work to be performed was to be accomplished by an Executive Committee.


#*Error detection and correction in binary parallel digital computers
#@James Evans Robertson
#t1952
#c
#index198545


#*A Unified Approach to Microcomputer Software Development
#@T. G. Rauscher
#t1978
#cComputer
#index336108
#!An ordered sequence of stages, well-supported development tools, good programming practices-management backing brings it all together in microprocessor-based development.


#*&ldquo;Algorithm&rdquo; and &ldquo;formula&rdquo;
#@T. Wangsness,J. Franklin
#t1966
#cCommunications of the ACM
#index316156
#%329977
#%334174
#%319774


#*Aesthetics and the human factor in programming
#@Andrei P. Ershov
#t1972
#cCommunications of the ACM
#index316941


#*Experience in the design, implementation and use of PL-11, a programming language for the PDP-11
#@Robert D. Russell
#t1976
#cACM SIGPLAN Notices
#index544735
#%301351
#%318194
#!PL-11 is a programming language for the PDP-11 family of computers designed and implemented as part of the OMEGA Project at CERN (the European Organization for Nuclear Research). Its purpose is to provide an effective tool for both physicists and systems programmers to use in building real-time data acquisition systems that are on-line to high-energy physics experiments. It is a fairly typical member of the PL-class of programming languages (44) which are based on the initial design of PL360 (41) (see Table 1). Each of these languages represents a linguistic model of its specific machine architecture, thereby providing a Systems Implementation Language (SIL) that is extremely efficient on its target machine, yet is also highly effective for human programmers to use. The need for such a tool is obvious on all computer systems, but especially on minicomputers, where most applications are in fact &ldquo;systems programs&rdquo;. For example, in any data acquisition environment the distinction between &ldquo;user&rdquo; and &ldquo;operating system&rdquo; largely disappears&mdash;the user's prime concern is to handle time-dependent sequences of events involving the manipulation of special I/O devices through direct status checking and data streaming&mdash;all functions which are usually buried in the operating system of conventional computing systems. This paper discusses four years of experience with PL-11, especially as this relates to the general topic of SILs on minicomputers.


#*Effectiveness of an optimizing compiler for arithmetic expressions
#@James A. Painter
#t1970
#cProceedings of a symposium on Compiler optimization
#index547762
#!This paper defines the notion of effectiveness of an optimizing compiler and presents a proof that a simple optimizing compiler is effective. An optimizing compiler typically consists of a basic compiler and a set of optimizations for special cases. The fundamental notion of effectiveness is that the basic compiler is correct, all of the optimization transformations preserve correctness, and produce essentially equivalent programs which have a smaller value relative to a specified weighting function.


#*Proceedings of the 1974 annual conference - Volume 1
#@
#t1974
#cACM Annual Conference/Annual Meeting
#index546012


#*Computer aided design system for logic equipment applied to design of electronic switching equipment
#@Tatsuro Hirano,Kazuyuki Hirakawa
#t1973
#cProceedings of the 10th Design Automation Workshop
#index546679
#%546545
#%551973
#!This description is intended for the purpose of relating a brief history of the development of the design automation system in our OKI Electric Industry Co., Ltd. and an outline of the design automation system used at present in our company; it relates specially an introduction of the package design system which is one of the subsystems in the design automation systems. Moreover, with regard to the electronic switching equipment, type DEX developed by the Nippon Telegraph Telephone Public Corporation and the four manufacturers (OKI Electric Industry Co., Ltd., Nippon Electric Co., Ltd., Fujitsu Co., and Hitachi Co., Ltd.) in the field of production of telecommunication equipments in Japan, it relates how the design files were applied to the production and inspection process in our plant.


#*The state of computer oriented curricula in business schools 1970
#@J. L. McKenney,F. M. Tonge
#t1971
#cCommunications of the ACM
#index325914
#!The ACM Committee on Computer Education for Management, supported by a National Science Foundation Grant, is established to appraise the state of the art and to develop a series of recommendations for improving computer education for management. To provide the Committee with material for its study of curricular needs, five regional meetings in the United States were held in 1970, at each of which a broad cross section of invited academicians and practitioners considered the state of curricula in business schools. Three topics were covered: curricula for the general manager; computer-related material in required and functional courses; and curricula for students concentrating on computer-based information systems. An analysis of the minutes of the meetings revealed a common set of experiences which raised similar pedagogic and economic issues. This presentation gives a summary of the discussions; a condensation of the pedagogic and substantive concerns raised; and consideration of the resource allocation issues involved. Preliminary to the Committee's recommendations for improving computer education for management, this report has been prepared to provide the participants and the administrators of their institutions with background information for the ongoing task of course development. Chairman of the ten-man Committee is Daniel Teichroew (The University of Michigan).


#*Recent technical reports
#@SIGACT News Staff
#t1974
#cACM SIGACT News
#index434506


#*Automatic programming and compilers II: WIZOR, a compiler, compiler for the GE 225 computer
#@D. W. Scott
#t1962
#cProceedings of the 1962 ACM national conference on Digest of technical papers
#index552725
#!THE WIZOR COMPILER, a GE-225 computer program, has been designed to aid in reducing the cost of translating from the flow-graph specification of a new compiler to a machine-language binary program of that compiler, in one pass through the computer. The WIZOR program is some what faster than the machine-language assembly program, in producing more or less equivalent binary programs. WIZOR compiler language statements are generally more concise and easily followed than the same program written in symbolic machine-language statements.


#*Authors' Reply5
#@E. G. Henrichon
#t1970
#cIEEE Transactions on Computers
#index351275
#!The authors wish to thank G. W. Beakley and F. B. Tuteur for their identification of a source of difficulty in the analysis of the non- parametric procedure as originally proposed. We shall reexamine our analysis in the light of this new development and will report on any modifications at a later date.


#*An aggregate computer simulation model of media selection
#@Robert Aydelotte Fleck, Jr.
#t1971
#c
#index196238


#*An Algebra for Logic Systems Switching Circuits Application
#@P. L. Tison
#t1971
#cIEEE Transactions on Computers
#index348764
#!The goal of this note is to present a new logical variable, the "degree of freedom," which is more refined than the usual Boolean variable, and also the very general algebra which may be formulated using the concept of "degree of freedom."


#*T01A-programming languages: T01A3-Readability and GOTO-free programming
#@Dennis Bunde
#t1974
#cProceedings of the 2nd annual computer science conference on Program information abstracts
#index547543
#!Readability in computer language design is important to facilitate the communication of algorithms between users, in debugging, and in program modification. Reading for comprehension involves forming an internal model of what is being said. Both program proving and program reading involve manipulating this model. In order for the human to apply operators to this model, it is necessary to remember it. There is a psychological cost associated with remembering the model. This cost is an increasing function of the human memory load. Two results consistent with this view are: I. Minimizing the scope of variables, labels, and functions increases the readability of programs. 2. The control structure of the optimally readable language is neither completely GOTO-free nor completely GOTO structured.


#*An Algorithm for Deciding the Convergence of the Rational Iteration xn+1= f(xn)
#@Richard J. Fateman
#t1977
#cACM Transactions on Mathematical Software (TOMS)
#index322335
#%548899
#%544529


#*Elements of Programming Style
#@Brian W. Kernighan,P. J. Plauger
#t1974
#c
#index447950


#*Remarks on and certification of algorithm 52: a set of test matrices
#@P. Naur
#t1963
#cCommunications of the ACM
#index329546


#*Properties of inference rules and automatic formulation of new rules in afriedman-type theorem-proving system
#@Stefan Feyock
#t1971
#c
#index206101


#*Calendar
#@
#t1972
#cComputer
#index345466


#*An experimental laboratory for pattern recognition and signal processing
#@N. M. Herbst,P. M. Will
#t1972
#cCommunications of the ACM
#index320858
#%320503
#!An interactive computer-controlled scanning and display system has been in operation at the IBM Thomas J. Watson Research Center for three years. The system includes two flying-spot scanners and a TV camera specially interfaced to a process control digital computer, dot-mode and vector displays, analog input and output facilities, and a variety of other experimental equipment. The system design and programming support are described and typical applications in scanner control, optical character recognition, and image processing are presented.


#*An Implementation of a Pseudoperipheral Node Finder
#@Alan George,Joseph W. H. Liu
#t1979
#cACM Transactions on Mathematical Software (TOMS)
#index313657
#%333575
#%545133


#*Arithmetizing declarations: an application to COBOL
#@Melvin E. Conway,Joseph Speroni
#t1963
#cCommunications of the ACM
#index314454
#%328541


#*Computers in society&mdash;a course description, purpose and rationale
#@Hans E. Lee
#t1972
#cProceedings of the second SIGCSE technical symposium on Education in computer science
#index549721
#!Irrespective of one's personal position on the role of computers in society, it is indeed desirable that all college graduates in the coming years have a realistic even though minimal understanding of how computers work and how they may be directed to implement and maintain almost any desired social system. Consequently, the primary purpose of this course on computers in society is to give an elementary but sound fundamental understanding of how computers work, what they can do, what applications of computer technology currently exist or are now in research consideration, and the relationships of these applications to the role of man in society. Thus, the course is conceived as a citizen's social problems course in which much of the time will be devoted to documentation of the claim that society is undergoing a computer revolution and to illumination of this position by the presentation of several problem areas resulting from computer applications.


#*GLOSS: a high level machine
#@Robert G. Herriot
#t1973
#cProceedings of a symposium on High-level-language computer architecture
#index303539
#%197162
#%331797
#%319134
#%552238


#*LL(k) Parsing for Attributed Grammars
#@D. R. Milton,Charles N. Fischer
#t1979
#cProceedings of the 6th Colloquium, on Automata, Languages and Programming
#index361775


#*A system for interactive acquisition and administration of geometric data for thematic map production
#@Klaus Tuerke
#t1976
#cACM SIGGRAPH Computer Graphics
#index247783
#!Most computer assisted information systems for planning purposes are designed to produce thematic maps as output. Graphic data processing, on the other hand, has not yet reached the degree of perfection already achieved in other fields of EDP, e.g. commercial and statistical applications. The author and his collegues are integrating cartographic data and presentation techniques gradually into an information system.Within the system being described, the geometric data base is considered as a line network. The edges of the network are represented by strings of orthogonal coordinates (Segment definitions). A unique identifier is assigned to each coordinate string, and the areal units are defined by a sequence of edge identifiers (Polygon definitions).In order to obtain error-free files, strict rules have to be observed and a high degree of accuracy has to be achieved.For this purpose, an interactive system - DIGNET - has been developed to fullfill these objectives: (1) guide the operator through the digitizing session, (2) ask for the appropriate input, (3) create the reference tables, (4) react to erroneous input and operation, (5) detect digitizer malfunctions, (6) allow immediate graphic replay of the digitized data.In order to facilitate the manipulation of the boundary network files, a number of utility programs have been added to the DIGNET-System; among them (1) DIGEDI - to prepare maps for digitzing, (2) DIGLIST - to list all results from digitizing sessions, (3) DIGMERGE - to merge two or more submaps into one final map.


#*Divergence, convergence, and speed of convergence of continued fractions 1 plus k(a(,n)/1); a(,n) are complex numbers
#@Leo Jerome Lange
#t1960
#c
#index202096


#*Equipment maintenance studies using a combination of discrete event and continuous system simulation
#@Harold G. Hixson
#t1969
#cProceedings of the third conference on Applications of simulation
#index552757
#!These studies were undertaken to investigate the costs of alternative equipment maintenance procedures. The paper describes the scope of the investigation, the need for both discrete and continuous representation, the study costs and results, and the potential for using this model for additional applications.


#*Quality of decision versus depth of search on game trees
#@Dana S. Nau
#t1979
#c
#index201623


#*Computer generated images for medical applications
#@Alexander Sunguroff,Donald Greenberg
#t1978
#cProceedings of the 5th annual conference on Computer graphics and interactive techniques
#index547732
#%197075
#%233473
#!Two computer graphics systems for the presentation of biomedical information for diagnosis and treatment planning are described. Both systems presented utilize computer tomographic (CT) data as input. One of the systems produces three-dimensional surface representations of organs and anatomical features found within the body. The other system is a radiation treatment planning aid which uses tomographic data in its computations.


#*Automatic discovery of heuristics for nondeterministic programs from sample execution traces
#@Salvatore Joseph Stolfo
#t1979
#c
#index201637


#*Remark on algorithm 53: Nth roots of a complex number
#@C. W. Nestor, Jr.
#t1961
#cCommunications of the ACM
#index324975


#*Algorithm 153: gomory
#@F. L. Bauer
#t1963
#cCommunications of the ACM
#index323444


#*Information seeking strategies for decision-making in a particular kind of choice situation
#@Linda Anne Sikorski
#t1973
#c
#index203911


#*The future of CAM systems
#@M. Eugene Merchant
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index72322
#!A recent Delphi-type forecast of the future of manufacturing carried out by the International Institution for Production Engineering Research (CIRP) resulted in 94 forecast events on which good consensus was obtained. Of these, 24, or over one-fourth, strongly indicated that the computer-integrated automatic factory would be a full-blown reality well before the end of this century. The three key events which summarize this aspect of that forecast are as follows: 1. By 1980 (median), a computer software system for full automation and optimization of all steps in the manufacturing of a part will be developed and in wide use. 2. By 1985 (median), full on-line automation and optimization of complete manufacturing plants, controlled by a central computer, will be a reality. 3. By 1990 (median), more than 50 percent of the machine tools produced will not have a "stand-alone" use, but will be part of a versatile manufacturing system, featuring automatic part handling between stations, and being controlled from a central process computer.


#*Trends in certification and professionalism
#@Fred H. Harris
#t1979
#cProceedings of the 1979 annual conference
#index553975
#!This presentation will focus on trends which are affecting certification and professionalism among computing personnel. Such trends, both from within the industry and from without, will be discussed with emphasis on the still pending choice between voluntary certification and mandatory licensing. The enhancement of certification programs accelerated in the seventies with the establishment of ICCP and the associated support of the major computer societies. Proposals for licensing data processing personnel have emerged in the meantime but have not yet received sufficient endorsement from computing personnel to be seriously considered by legislators. Reasons typically given for such lack of support include the dynamic state of knowledge in our field on the one hand and, on the other, the lack of appreciation for exactly who should be licensed and for what specific purposes. Indeed, when licensing was first suggested, many took the position that it was premature for these reasons. More narrow proposals for licensing now have emerged which may be more supportable, and several trends are evident which will accelerate possible considerations. Pertinent ones include accelerating developments in software engineering (including the specification, design, techniques for implementation, and maintenance of systems) which better assure system quality and correctness; increased public awareness of computer-related incidents which impact public health and safety; increased attention within the courts and among other professional groups to malpractice in our field; and increased efforts toward strengthening privacy legislation and laws which deal with computer-related white collar crimes. Offsetting these, of course, is a general trend away from regulation of occupational groups. Each of these will be reviewed in detail and placed in perspective.


#*Correctness influenced design of parallel programming languages.
#@Frederick Gerald Sayward
#t1976
#c
#index196877


#*Twinkle box: a three-dimensional computer input device
#@Robert P. Burton,Ivan E. Sutherland
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index60896
#!During the past fifteen years, use of two-dimensional computer input/output devices has become commonplace. Since the earliest uses of the light pen for target identification in air defense systems it has been obvious that two-dimensional input would be interesting and useful. A large number of two-dimensional tablets and digitizers have been developed and have come into quite effective use. These devices have made use of mechanical, electrical, magnetic, optical, and acoustic phenomena. (See bibliographical references.)


#*Writing computer program in freshman calculus
#@Gabriel J. Basil
#t1976
#cACM SIGCUE Outlook
#index304434


#*The Development of Ada, the DoD Language
#@Brian A. Wichmann
#t1979
#cGI - 9. Jahrestagung
#index266548


#*A rapid Braille transliteration technique for certain IBM machine
#@Walter J. Weller,Virginia C. Klema
#t1965
#cCommunications of the ACM
#index320270


#*Two typical representation theorems for symmetrical Heyting algebras of order n
#@Luisa Iturrioz
#t1978
#cProceedings of the eighth international symposium on Multiple-valued logic
#index545443
#!The theory of the many-valued logics related to classical and intuitionistic ones has been developed in the past. On the other hand, as an attempt to study symmetries on formal logic, Moisil has introduced a propositional calculus, called general symmetrical modal. In connection with the latter, we have built up, in a standard way, a many-valued propositional calculus. In order to consider this many-valued logic from an algebraic standpoint, we introduce the notion of a symmetrical Heyting algebra of order n. We present here only two typical representation theorems for these algebraic structures.


#*New product applications: microprogrammed bipolar microcomputers are assembled from integrated circuit blocks
#@Stanley Habib
#t1975
#cACM SIGMICRO Newsletter
#index14353
#!Many other system organizations, including multiprocessors, can be imoplemented. For example, many MCU-control memory sections can share one central processor (CP) array when many similar machines or devices must be controlled. Sharing a CP array will rarely affect control speed, since control data is processed at rates far higher than normal machine operating rates.


#*LOGE: a highly effective system for logic design automation
#@W. Grass,H. M. Lipp
#t1979
#cACM SIGDA Newsletter
#index103316
#%325403
#%330721
#!Nearly all activities which have been published or which are known concentrate on those topics of computer-aided design related to layout of chips and boards and to testing and documentation. Systems which support logic design itself are not very widespread and are often out of focus. One of the inherent reasons may be that design engineers for whom CAD tools for logic design are developed, show a lot of scepticism and prejudice against those aids. They don't accept the idea that part of their personal work could be substituted by computer based algorithms.


#*A unifying approach to scheduling
#@Manfred Ruschitzka,R. S. Fabry
#t1977
#cCommunications of the ACM
#index320034
#%314331
#%315247
#%330178
#%330464
#!This paper presents a scheme for classifying scheduling algorithms based on an abstract model of a scheduling system which formalizes the notion of priority. Various classes of scheduling algorithms are defined and related to existing algorithms. A criterion for the implementation efficiency of an algorithm is developed and results in the definition of time-invariant algorithms, which include most of the commonly implemented ones. For time-invariant algorithms, the dependence of processing rates on priorities is derived. The abstract model provides a framework for implementing flexible schedulers in real operating systems. The policy-driven scheduler of Bernstein and Sharp is discussed as an example of


#*A simple algorithm for computing the generalized inverse of a matrix
#@B. Rust,W. R. Burrus,C. Schneeberger
#t1966
#cCommunications of the ACM
#index324154


#*Acceptance of computers in education
#@Ludwig Braun
#t1971
#cACM SIGCUE Outlook
#index310375


#*A Method for Obtaining SPOOF's
#@Siu-Chong Si
#t1975
#cIEEE Transactions on Computers
#index350658
#!A compatibility relationship on network paths is defined in such a way that the maximal compatibles are isomorphic to the products in the "structure and parity-observing output function" (SPOOF), a subscripted Boolean expression for the network output that uniquely specifies the network structure. For a given network, the path compatibility relations are easy to find, as are the maximal compatibles and hence the SPOOF for the network output. Because the collection of all the path compatibility relations, conveniently displayed in matrix form, completely characterizes the network, the compatibility matrix can be used for a variety of purposes.


#*A digital musical instrument
#@Alan Bradford Hayes
#t1972
#c
#index194753


#*A demand paging simulator
#@Dennis Leinbaugh
#t1977
#cProceedings of the eighth SIGCSE technical symposium on Computer science education
#index545828
#%250727
#%549200
#%551501
#%554587
#%545909
#%546639
#%553329
#%552530
#%547687
#%551588
#!A simulator is presented that allows a student to quickly write a demand paging memory management system. The simulator provides a job stream, support routines (such as read a page into memory), extensive error checking and debugging, and performance evaluation. This simulator is intended for a first course in operating systems to acquaint a student with the mechanics involved in demand paging or a second course where more time would be spent developing and evaluating page removal algorithms and job scheduling algorithms.


#*Syntactic Recognition of Paralel Proceses in Formally Defined Complexes of Interacting Digital Systems
#@Pamela Z. Smith,D. R. Fitzwater
#t1974
#cProceedings of the Sagamore Computer Conference on Parallel Processing
#index264152


#*Surveyor's Forum: A Recurrent Problem
#@Edward A. Bender
#t1979
#cACM Computing Surveys (CSUR)
#index325174


#*An efficient form of inverse for sparse matrices
#@Wm. Orchard-Eays
#t1956
#cProceedings of the 1956 11th ACM national meeting
#index550952
#!In attempting to shorten linear programming computations, Dr. Harry Markowitz proposed, in 1954, a method for inverting a sparse matrix based on selective elimination and re-substitution. By minimizing the number of non-zero multipliers and addends used in applying the inverse, the computation time is cut sharply. After a slight modification, it was found possible to put all the resulting transformations in the same format as the standard product form of inverse, long used in the simplex method, and a code for the JOHNNIAC computer using this method has proved very efficient. We will merely illustrate the method with an example.


#*The problem of programming communication with changing machines: a proposed solution
#@J. Strong,J. Wegstein,A. Tritter,J. Olsztyn,O. Mock,T. Steel
#t1958
#cCommunications of the ACM
#index325361


#*The complexity of loop programs
#@Albert R. Meyer,Dennis M. Ritchie
#t1967
#cProceedings of the 1967 22nd national conference
#index554609
#!Anyone familiar with the theory of computability will be aware that practical conclusions from the theory must be drawn with caution. If a problem can theoretically be solved by computation, this does not mean that it is practical to do so. Conversely, if a problem is formally undecidable, this does not mean that the subcases of primary interest are impervious to solution by algorithmic methods. In the next section we describe such a class of programs, called &ldquo;Loop programs.&rdquo; Each Loop program consists only of assignment statements and iteration (loop) statements, the latter resembling the DO statement of FORTRAN, and special cases of the FOR and THROUGH statements of ALGOL and MAD. The bound on the running time of a Loop program is determined essentially by the length of the program and the depth of nesting of its loops.


#*Inductive inference on computer generated patterns
#@Mary Kenneth Keller
#t1965
#c
#index203341


#*Techniques and modules for element specification in a time - delay logic simulator
#@John L. Fike,S. A. Szygenda
#t1973
#cProceedings of the 1st symposium on Simulation of computer systems
#index546594
#%550250
#!This paper describes the development of element models (basic gates and flip-flops) for use in a multi-modal, assignable-delay logic simulator known as TEGAS2. The basic mechanism of this event-driven simulator is first described, together with the operation of the three basic simulation modes (nominal-delay two-value simulation, nominal-delay three-value simulation, and three-value simulation using an ambiguity region to provide race and hazard detection). The criteria used in developing the element models were: 1) The element should operate in a consistent manner for all simulation modes; 2) A basic set of circuit building blocks should be available; 3) The element evaluation should be relatively rapid; and 4) The set of element routines should be extensible. In order to discuss the above philosophy in detail, the desired operation of the And element is first described for each simulation mode. Equations are then derived from this description, and finally the Fortran statements are obtained. The handling of memory elements in a simulator poses a special problem. A Delay (&ldquo;D&rdquo;) flip-flop is used as an illustration of memory element modeling techniques; again, the development starts with a verbal description of the operation and arrives at the Fortran statements for the various simulation modes. A level-triggered master-slave J-K flip-flop is then used as a vehicle for a general discussion of the problems associated with more complex memory elements. A brief description is also given of the clocked S-R models used in the system.


#*State the problem before describing the solution
#@Leslie Lamport
#t1978
#cACM SIGSOFT Software Engineering Notes
#index434751


#*Scheduling to reduce conflict in meetings
#@Joseph E. Grimes
#t1970
#cCommunications of the ACM
#index329535
#%122513
#%320620
#%322350
#%325308
#%334967
#!Conflicts in scheduling can be treated as defining an undirected linear graph independently of the relation of the activities in conflict to additional constraints of time and space. Each connected component of such a graph, which can be found by an algorithm described by Gotlieb and Corneil, corresponds to a set of events that must be scheduled at different times.


#*Modeling of solids for three-dimensional finite-element analysis.
#@Bruce Eric Brown
#t1977
#c
#index194083


#*MPS - Eine variable Mikroprogrammiersprache
#@H. Anlauff,P. Groß
#t1979
#cMicrocomputing, Tagung III/1979 des German Chapter of the ACM
#index271552


#*Identifying project scope
#@Philip Lelle
#t1977
#cACM SIGDOC Asterisk Journal of Computer Documentation
#index578914
#!After the initial two months of gathering documents and identifying sources, determination of the scope of the project was begun. The BLS/OWS (Bureau of Labor Statistics, Occupational Wage Survey) System involves several hundred people, distributed in Washington and eight Regional Offices. However, only a few dozen people are totally involved with the OWS System. There are many other Surveys conducted by BLS and the greater portion of time of those peripherally involved in OWS is spent on non-OWS matters. In terms or information flow, between the authors/producers of the OWS System and the users, the direction had been a "pull" by the user's from the Systems group. One of the volumes to be developed had to change this situation, turn it around to "push" the information out to the user. Another volume was defined to be directed towards people in management positions both in BLS and other agencies, and would contain general information about the OWS System. Finally, the System's documentation required for maintenance and running production would be a volume each. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Maximal clause length resolution.
#@Vesko Genov Marinov
#t1973
#c
#index206386


#*Introduction to Logic and Switching Theory
#@Nripendra U. Biswas
#t1975
#c
#index444679


#*On Time Versus Space
#@John E. Hopcroft,Wolfgang J. Paul,Leslie Valiant
#t1975
#c
#index119451
#!It is shown that every deterministic multitape Turing machine of time complexity t(n)/log t(n). Consequently, for tape constructable t(n), the class of languages recognizable by multitape Turing machines of time complexity t(n) is strictly contained in the class of languages recognized by Turing machines of tape complexity t(n). In particular, the context sensitive languages can not be recognized in linear time by deterministic multitape Turing machines. Keywords and phrases: Turing machines, time complexity, tape complexity.


#*Delay equalizer design - numerical analysis, digital computer techniques.
#@Joseph John Lang
#t1961
#c
#index188587


#*Comment on London's certification of algorithms 245
#@K. A. Redish
#t1971
#cCommunications of the ACM
#index332112
#%81323
#%316151
#%318397
#%319012
#%320995
#%329475
#!In his Certification of Algorithm 245 [1], Ralph L. London exhibits a common confusion between an algorithm, its representation, and its implementation on a processor&mdash;a code. In the present state of the art we can attempt, in general, to prove an algorithm and to test a code. For example, London states that &ldquo;&hellip; the algorithm TREESORT 3 [2] is proved to perform properly its claimed task of sorting an array M[1:n] into ascending order.&rdquo; While this is true of the algorithm, it is not true of the code unless we place restrictions on the array elements. The trouble arises in this example from the finite precision of processors; the Boolean expression A &ge; B (real A, B) will usually be implemented as A - B &ge; 0, which can fail due to floating point overflow or underflow.


#*Empirical estimates of program entropy.
#@Richard Eric Sweet
#t1977
#c
#index186225


#*Automated sign design and stencil cutting system
#@W. M. Barnes
#t1974
#cProceedings of the 11th Design Automation Workshop
#index551944
#!The automation of artistic art form provided a real challange in terms of new software and hardware design for a computer system. The complete system has been in operation daily since July 1972 and provides the necessary features to design and produce stencil art work for sign making.


#*Some test results on the SIMSCRIPT II. 5 and SIMPL/1 pseudorandom number generators
#@George S. Fishman
#t1976
#cACM SIGSIM Simulation Digest
#index575438
#%325239
#!This paper presents results of applying the runs up and down test, the chi-square goodness-of-fit test and the serial test to streams of pseudo-random number generators implemented in the IBM version of SIMSCRIPT II.5, in SIMPL/1 and using their default seeds. Although this limited testing prevents general conclusions, the results presented here do identify several areas of concern. Because of the limited publication of such test information in the learned literature, it is regrettably not possible to offer a completely acceptable method of removing these concerns.


#*Two-Level Grammars
#@C. H. A. Koster
#t1976
#cCompiler Construction, An Advanced Course, 2nd ed.
#index567028


#*A performance study of a Network Front End
#@Susan S. Poh,Paul D. Stoneburner,David C. Wood
#t1979
#cProceedings of the sixth symposium on Data communications
#index547916
#!A Network Front End (NFE) is a mini-computer which is used to connect a host computer to the communicating network. The purpose of using an NFE, as contrasted to connecting the host computer directly to the network, is to reduce the processing load imparted to the host computer by the network interfacing software. This paper presents a comparative evaluation of the NFE attachment method in relation to the host direct connection method. The comparative evaluation addressed two major areas: the impact on the host of the network interface software and end-to-end network performance. Various evaluation experiments were conducted, the results of which indicate that the NFE is a promising alternative to host direct connection in terms of performance in the WWMCCS Intercomputer Network (WIN). In addition, the NFE also has the capability to satisfy the standardized high capacity host-AUTODIN II interface requirement and to provide other features, such as direct terminal to network connection and network security, not available in the WIN architecture. It is recommended that refinement of the NFE and further development be continued.


#*The application of cryptography to data base security.
#@Ehud Gudes
#t1976
#c
#index197938


#*Microsystems Opinion: Critique of the F8 Microprocessor
#@D. Caulkins
#t1977
#cComputer
#index353008
#!The Fairchild F8 is a control microprocessor whose architecture is considerably different from most machines in the same price and performance class. Good computer architecture is consistent, symmetrical, and coherent; the programmer is provided with the maximum amount of information possible after each operation and his freedom of action is limited as little as possible. A machine with these qualities behaves in the way one expects it to behave; it is free of special cases and peculiar quirks. The F8 falls considerably short of meeting these goals. It predates most equivalent micros; its designers seem to have had little contact with others doing similar things. This background has resulted in a machine combining brilliant design concepts with ugly flaws. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Algorithm 400: Modified Havie integration
#@George C. Wallick
#t1970
#cCommunications of the ACM
#index324517
#%319659
#%322128
#%332378
#%325609


#*Programming style
#@B. W. Kernighan,P. J. Plauger
#t1974
#cProceedings of the fourth SIGCSE technical symposium on Computer science education
#index550905
#!Programs written with good style are easier to read and understand, and typically smaller and more efficient than those written badly, regardless of the language used. Yet most programmers have never been taught programming style&mdash;as proof we need only look at their programs. In this paper we will discuss several principles of programming style, illustrating our points by criticizing and rewriting some real programs. The examples are all taken verbatim from programming textbooks, and the revisions have all been tested.


#*Microprogramming for probability distribution sampling
#@T. G. Lewis
#t1972
#cProceedings of the ACM annual conference - Volume 1
#index232638
#%190128
#%323098
#!Microprogramming of special instructions for sampling of random variates from any probability distribution is a means of increasing sampling speed. The diversity of sampling techniques is narrowed to one general algorithm; conditional bit sampling. Conditional bit sampling, uses a high speed uniform random number generator based on feedback shift registers to sample one bit at a time. The probability of a bit being a one in the j-th position of a binary expanded variate is stored in a table of conditional probabilities. A comparison with the pseudorandom number yields a one or zero. The table of conditional probabilities is generated once and passed through an instruction to the microprogram which performs the sampling. One user instruction is issued for each variate returned.


#*Software verification and validation in practice and theory (Position Statement)
#@Sabina H. Saib
#t1978
#cProceedings of the 1978 annual conference - Volume 2
#index545937
#%176082
#%553615
#!The techniques and tools that are available to the developer of practical software systems today are oriented towards the detection of errors in a test environment. That is, the software has been designed, coded, walked through, and tested by the designers, and is now to be subjected to outside verification and validation. Among the test tools that can be used to aid in the testing process are JAVS1, FAVS2, RXVP3, PACE4, and PET5.


#*The Design of a User Interface for a Sparse Matrix Package
#@Alan George,Joseph W. H. Liu
#t1979
#cACM Transactions on Mathematical Software (TOMS)
#index324598
#%328151


#*On the numerical solution of the initial value problem y'' = f(x,y)
#@Peter Bruce Worland
#t1971
#c
#index196045


#*Invited papers: History of writing compilers
#@D. E. Knuth
#t1962
#cProceedings of the 1962 ACM national conference on Digest of technical papers
#index553217
#!THIS PAPER will discuss the evolution of techniques used in writing compilers, from IT and FORTRAN to the present day. Five years ago it was very difficult to explain the internal mechanisms of a compiler, since the various phases of translation were jumbled together into a huge, sprawling algorithm. The passing of time has shown how to distinguish the various components of this process, revealing a basic simplicity.


#*Comparative complexity of grammar forms
#@Seymour Ginsburg,Nancy Lynch
#t1975
#cProceedings of seventh annual ACM symposium on Theory of computing
#index549741
#!The definition of &ldquo;grammar form&rdquo; introduced in [CG] makes it possible to state and prove results about various types of grammars in a uniform way. Among questions naturally formalizable in this framework are many about the complexity or efficiency of grammars of different kinds. Grammar forms provide a reasonable way of considering the totality of other forms we might use, and so answering the question with both upper and lower bound results. The general question considered in this paper is the following: which grammar forms are more efficient than other grammar forms for the expression of classes of languages, and how much gain in efficiency is possible? Our results deal solely with context-free grammars, and use both derivation complexity and size of grammars as complexity measures.


#*The explicit factorization of two commonly occuring matrices
#@D. Kershaw
#t1972
#cACM SIGNUM Newsletter
#index100720
#!Tridiagonal and periodic tridiagonal matrices often occur in numerical analysis and frequently in examination questions. Two such matrices are presented here together with their LU factorizations. The constructive proofs of the results are tedious but verification is straightforward. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Threaded code
#@James R. Bell
#t1973
#cCommunications of the ACM
#index322192
#!The concept of &ldquo;threaded code&rdquo; is presented as an alternative to machine language code. Hardware and software realizations of it are given. In software it is realized as interpretive code not needing an interpreter. Extensions and optimizations are mentioned.


#*A measure for program locality in demand paging
#@Robert L. Hedges,Udo W. Pooch
#t1975
#cProceedings of the 1975 annual conference
#index551343
#%191280
#%316426
#%330178
#!The concept of information flow and information theory, adapted from the management sciences, is utilized to provide a measure of program locality that could be used to analyze, compare, and extend various replacement algorithms. A Locality Matrix Model (LMM) is derived and analyzed in the areas of page fault reductions and the determination of memory requirements to contain any inherent program locality. This approach of dynamic clustering page references is used to predict stationary behavior of the reference string.


#*A note on reflection-free permutation enumeration
#@Mohit Kumar Roy
#t1977
#cCommunications of the ACM
#index327273
#%314271
#%314508
#%314633
#!Earlier it was shown by the present author [1] that among the classical algorithms for the generation of permutation sequences, only the Trotter-Johnson algorithm [2, 3] has the property that the reflection of any permutation in the first half of the enumeration appears only in the second half. Two permutations are called reflections of each other if one read from left to right is the same as the other read from right to left. Lenstra [4] has discussed the usefulness of this property in certain applications. Recently Ives [5] has produced a series of four permutation algorithms of which two (algorithms c and d) possess the said property.


#*Fortran + preprocessor = Utopia 84
#@Makoto Arisawa,Minoru Iuchi
#t1979
#cACM SIGPLAN Notices
#index305835
#%304640
#%305039
#%312273
#%306853
#%312725
#%311787
#%307853
#%306205
#%310381


#*Remark on algorithm 231 [F1]: matrix inversion
#@Mats Ferring
#t1965
#cCommunications of the ACM
#index318514


#*Simulated research experiences for teaching research methodology: some educational computing implications
#@
#t1976
#cACM SIGSOC Bulletin
#index577857
#!Despite the enormous growth of educational computing, the systemic connections of these efforts with important aspects of sociological education and research remain ambiguous. Notable are the tenuous linkages with sociological theory, university priorities on research, and enduring concerns of sociologists over social criticism and reform. This paper is addressed to this ambiguity. Drawing illustrations from the use of computer simulations of social research, a broad base for the development of educational computing is advocated which allows a clearer interface of such computing with theory, research, and social criticism within sociology. (I) Educational computing based on sociological theory allows a translation of experiences across variable educational contexts. (II) Recognizing the human-computer interface in these settings as an ubiquitous contemporary occurrence and hence a crucial research site obviates the traditional split between teaching and research which can be problematic in educational computing. (III) Evaluation lends realism to discussion of theory in sociology courses and is responsive to traditional and contemporary concerns with social criticism and social reform.


#*Time domain analysis and optimization of nonlinear networks by digital computer
#@Paul Michael Russo
#t1970
#c
#index205491


#*Philosophic comments on data base context and management in design automation
#@Edwin B. Hassler, Jr.
#t1974
#cProceedings of the 11th Design Automation Workshop
#index554953
#!The word &ldquo;context&rdquo; in the title is chosen quite specifically. In design automation the data base structure and organization are relevant but not of primary concern: rather, the content of a data base and its interaction with various processes are of greater importance. It might appear that the word &ldquo;environment&rdquo; is more appropriate in this context, but this is true only if it is further qualified. Therefore, I have chosen to use the word &ldquo;context&rdquo;, since where a design automation data base is utilized it should explain its own meaning by virtue of being there; otherwise, it is not performing the function for which it was designed. The words &ldquo;design automation&rdquo; are not well defined in common usage. In the eyes of some people design automation is a very restrictive discipline relating only to the actual design of a device as small as a circuit composed of only a few electrical components, or a piece of mechanical cabinetry. Design automation in its broadest sense must be concerned with the life of a device from conception to end of life. Under this definition of design automation a device is a complete entity.


#*Statistical properties of speech, music and noises, and the detection of speech in noise
#@William James Hurd
#t1967
#c
#index194532


#*DIRECT - a multiprocessor organization for supporting relational data base management systems
#@David J. DeWitt
#t1978
#cProceedings of the 5th annual symposium on Computer architecture
#index547542
#%305945
#%326368
#%334566
#%550081
#%553232
#!The design of DIRECT, a multiprocessor organization for supporting relational data base management systems is presented. DIRECT has a MIMD (multiple instruction stream, multiple data stream) architecture. It can simultaneously support both intra-query and inter-query concurrency. The number of processors assigned to a query is dynamically determined by the priority of the query and the size of the relations it references. The size of a relation is not limited to that of the associative memory as in some previous data base machines. Concurrent updates are controlled through address translation tables which are maintained by a controlling processor. DIRECT is being implemented using LSI-11/03 microprocessors and CCD memories which are searched in an associative manner. A novel cross-point switch is used to connect the LSI-11 processors to the CCD memories. While cross-point switches have proven too expensive for use in general purpose parallel processors, their application in DIRECT demonstrates that these switches can be successfully used in specialized applications.


#*A. P. I. S. Academic Project Information System
#@John P. Peddicord
#t1978
#cProceedings of the 6th annual ACM SIGUCCS conference on User services
#index554105
#!Project management, planning and control; these are all concerns of management in commerce and industry, but do we in University Computing Centers share these concerns? I believe we do, but for many reasons, some of which we have in common with data processing in general and some of which are unique to the academic environment, there is no established and universally accepted management methodology in University Computing Centers. A particular result of the rapid technological change in D.P. is the difficulty of finding and keeping technically competent people. Once found they must be continually challenged otherwise they are likely to move on. Nevertheless, a User Services Department must maintain a high level of technical competence and this is, unfortunately, difficult to resolve with its primary function as a service organisation, in that, for the most part, technicians are not altruistic in nature. Their gratification is derived from interaction with a computer and face-to-face encounters are anathema to them.


#*Towards Automatic Auditing of Records
#@R. C. T. Lee
#t1978
#cIEEE Transactions on Software Engineering
#index353132
#!We computer scientists face at least two problems in promoting the use of computerized data-base systems: 1) some important data might be missing; 2) there might be errors in the data. Both of these problems can be quite serious. If they cannot be solved, it will be quite hard to convince potential users that computerized information systems are useful.


#*Analyze - Compose - Display computer aided space planning
#@Franz S. Veit
#t1971
#cProceedings of the 8th Design Automation Workshop
#index550273
#!ACD is an approach for space allocation which uses the digital computer for analysis of large quantities of subjective data. It allows direct participation by an increased number of people in the solution generating process, and facilitates the investigation of a greater number of alternate spatial concepts than traditional procedures would normally permit.


#*Guest Editorial for the Special Collection from the Third International Conference on Software Engineering.
#@
#t1978
#cIEEE Transactions on Software Engineering
#index337612


#*Image acquisition, processing and display using unconstrained scanning techniques
#@Garbis Hagop Keludjian
#t1970
#c
#index191718


#*Data types and program correctness
#@Barbara H. Liskov
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index73727
#%326074
#%552816
#!One of the most important current software issues is reliability, and accordingly, a major criterion of programming language design must be that the language contribute to the production of reliable programs. Although there are other important aspects of software reliability (e.g., fault tolerance), the most fundamental is program correctness: does the program do what it is supposed to do? A language can contribute to this goal by enhancing the provability of its programs. This paper discusses the impact of user-defined data types on program provability.


#*An application of simulation to the improvement of fork truck operations
#@Michael L. Morrison
#t1971
#cProceedings of the 5th conference on Winter simulation
#index550384
#!Most manufacturing operations assign fork trucks to the individual shop units which need them. This can lead to excessive numbers of fork trucks and low average utilization. The pooling of fork truck resources under a central authority can resolve this problem. Fewer trucks are needed in operations with fork truck pools to provide an equivalent level of service. The purpose of his report is to document the results of a simulation study of the operation of a fork truck pool in a mass manufacturing operation and to demonstrate the practicality of such a plan.


#*The use of empirical observations in the development of formal models
#@Lawrence H. Miller
#t1979
#cACM SIGSOC Bulletin
#index581539
#!The Xerox 800 is a very simple word processing machine. At Xerox, however, we are finding that a large number of people are calling up their service representative and saying, "Take this machine out - I don't want it." This, of course, causes a great deal of concern. The main reason for recalls of this machine is not because it breaks down, not because it produces results that are unsatisfactory, but because it is virtually impossible to use, and to learn to use! One of the reasons this problem occurs is that, for the type of people who are using these very low level, simple kinds of computer systems, there is an extremely high turnover rate in the offices. In the Los Angeles area, the turnover rates for secretaries in law offices (for example) can be anywhere from 50 per cent to 200 per cent per year; that means that a person stays for an average of six months or less. Most of the people who are using these kinds of systems and who only stay around for a short period of time can be described as naive or inexperienced users of the system. If they are having this kind of trouble with a very simple system like the 800 typing system, I think we can imagine the kinds of problems that we can expect in much more complex systems, such as fully automated text editors, graphics packages, forms handlers, data base inquiry systems, management information systems, etc.


#*A shared-resource schema for parallel computation.
#@Noel James Bell, Sr.
#t1977
#c
#index204535


#*A scheduling philosophy for multiprocessing systems
#@Butler W. Lampson
#t1968
#cCommunications of the ACM
#index321548
#%322720


#*Hashing schemes for extendible arrays (Extended Abstract)
#@Arnold L. Rosenberg,Larry J. Stockmeyer
#t1975
#cProceedings of seventh annual ACM symposium on Theory of computing
#index546311
#%79620
#!The use of hashing schemes for storing extendible arrays is investigated. It is shown that extendible hashing schemes whose worst-case access behavior is close to optimal must utilize storage inefficiently; conversely, hashing schemes that utilize storage too conservatively are inevitably poor in expected access time. If requirements on the utilization of storage are relaxed slightly, then one can find rather efficient extendible hashing schemes. Specifically, for any dimensionality of arrays, one can find extendible hashing schemes which at once utilize storage well [fewer than 2p storage locations need be set aside for storing arrays having p or fewer positions] and enjoy good access characteristics [expected access time is 0(1), and worst-case access time is 0(log log p) for p- or fewer-position arrays]. Moreover, at the cost of only an additive increase in access time, storage demands can be decreased to (l+&egr;)p locations for arbitrary &egr;>0. In fact, if one will abide a more drastic degradation of access efficiency, one can lower storage demands to p+o(p) locations.


#*Pattern recognition using tiling systems and two-dimensional automata.
#@Charles Francis Swart
#t1977
#c
#index202151


#*Program debugging using COBOL '74
#@George N. Baird
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index56272
#!The testing and checkout of production software often consumes upwards of 50 percent of the effort that goes into the development of the system. The absence in most programming languages of language elements specifically defined for debugging programs contributes to the time and effort involved in the checkout of systems due to programmers having to use various techniques to improvise debugging code. This was especially true of the 1968 COBOL Standard in that there were no language elements dedicated to the debugging and proving correctness of programs.


#*Local constraints in the syntax and semantics of programming languages.
#@Kang Yueh
#t1978
#c
#index194632


#*The use of computers in electrical power management
#@David Goodling,Gary Garner
#t1976
#cProceedings of the 14th annual Southeast regional conference
#index626435
#!This paper discusses the use of computers in the management of electrical energy. Material is presented that will be useful to a prospective power management system designer or buyer with emphasis on computer software and hardware. Various components of a power management environment are defined: power company, power consuming installation and the computerized controller. The computer is represented as a tool used by the power consuming installation to reduce the demand for electricity. A detailed description of a power management system is given with particular attention focused on the following areas: inputs and outputs to the system, calculation schemes, system feedback characteristics, hardware requirements, system architecture and limitations on system effectiveness. Implementation tradeoffs are discussed.


#*A performance study of the tenex operating system's pager module.
#@Mirko Albert Radelja
#t1976
#c
#index195981


#*Construction algorithms for knot spaces which contain incompressible surfaces of arbitrarily high genus.
#@Richard Frank Gustafson
#t1975
#c
#index195723


#*An algorithm for a form of the problem av = lambda bv
#@Donald Edward Arnurius
#t1966
#c
#index192332


#*A comment on axiomatic approaches to programming
#@B. R. Hunt
#t1970
#cCommunications of the ACM
#index332754
#%320995
#!Reference is made to the paper by C. A. R. Hoare [1] which discusses the fundamentals of an axiomatic approach to computer programming. One advantage for an axiomatic system proposed by Hoare is that an axiomatic description of computer programs would allow the application of deductive inference to formally and conclusively prove that a computer program performs the computation the designer intended. The purpose of this short communication is to discuss the relationship between Hoare's concepts and an approach in a book by Wymore [2].


#*Sequential conjugate gradient-restoration algorithm for the minimization of constrained functions
#@John Clark Heideman
#t1970
#c
#index202106


#*A two-parameter family of approximations to the two-dimensional heat equation
#@Hatem M. Khalil
#t1970
#c
#index190106


#*The automated inference of tree systems.
#@Barry Arthur Levine
#t1979
#c
#index196772


#*A New Approach to Proving the Correctness of Multiprocess Programs
#@Leslie Lamport
#t1979
#cACM Transactions on Programming Languages and Systems (TOPLAS)
#index318266
#%314817
#%317477
#%335107
#%319217
#%334601
#%321015
#!A new, nonassertional approach to proving multiprocess program correctness is described by proving the correctness of a new algorithm to solve the mutual exclusion problem. The algorithm is an improved version of the bakery algorithm. It is specified and proved correct without being decomposed into indivisible, atomic operations. This allows two different implementations for a conventional, nondistributed system. Moreover, the approach provides a sufficiently general specification of the algorithm to allow nontrivial implementations for a distributed system as well.


#*Shared Logic Realizations of Dynamically Self-Checked and Fault-Tolerant Logic
#@M. Y. Osman
#t1973
#cIEEE Transactions on Computers
#index346679
#!Dynamically self-checked or fault-tolerant realizations of switching functions and sequential machines are proposed under a fault model that permits arbitrary logic faults in a single-logic module, where the modules are explicitly defined. These realizations permit considerable logic sharing, organized around an (n, m, r)-basis for decomposing switching functions. The logic sharing permits more economical realizations than can be obtained using classical parity and triple-modular redundancy schemes for obtaining logic circuits with the corresponding property.


#*Polyfact: a learning program that factors multivariable polynomials.
#@Billy Gene Claybrook
#t1972
#c
#index192978


#*Scientific Applications: An algorithm for identifying the ergodic subchains and transient states of a stochastic matrix
#@B. L. Fox,D. M. Landi
#t1968
#cCommunications of the ACM
#index314753
#!An algorithm for identifying the ergodic subchains and transient states of a stochastic matrix is presented. Applications in Markov renewal programming and in the construction of variable length codes are reviewed, and an updating procedure for dealing with certain sequences of stochastic matrices is discussed. Computation times are investigated experimentally and compared with those of another recently proposed method.


#*A language for boolean function representation and manipulation
#@Iong Chen,B. D. Carroll
#t1976
#cProceedings of the 14th annual Southeast regional conference
#index610155
#!Boolean algebra is used extensively in the analysis and design of digital logic circuits, in the generation of test patterns for logic circuits, and in numerous other practical applications. Hand calculations involving Boolean equations become impractical when the equations involve a large number of variables or when the number of equations is large. Computerized processing of Boolean equations can significantly extend the range of problems that can be solved using Boolean algebra.A language ABAL (Auburn Boolean Algebra Language) is described in this paper that permits machine representation and manipulation of Boolean functions. Functions may be specified in algebraic form or as lists of minterms or maxterms. Types of operations available in the language include functional form changes, simplification rules, prime implicant or prime implicate generation, functional minimization, functional combinations using Boolean operators, and truth table generation. ABAL is written in BASIC-PLUS for execution on a DEC PDP 11/40 RSTS/E System.


#*A practitioner's guide to addressing algorithms
#@Dennis Severance,Ricardo Duhne
#t1976
#cCommunications of the ACM
#index329675
#%317208
#%318002
#%321235
#%330016
#%544722
#!This paper consolidates a number of popular rules of thumb which have been suggested for the design of record addressing algorithms, and discusses the applicability of these rules to large commercial databases. Guidelines for selecting identifier transformations, overflow techniques, loading factors, bucket sizes, and loading order are considered. Particular attention is focused on the reasonableness of common heuristics for determining primary or secondary bucket sizes. A mathematical model which explicitly considers storage device characteristics and time/space cost tradeoffs is used to analyze the effect of design parameters on overall system costs. A specific design example is presented and solved.


#*A dispersion pass algorithm for the polyphase merge
#@Armando G. Mendoza
#t1962
#cCommunications of the ACM
#index319557
#%333684
#!This paper presents a new manner of dispersing strings for a Polyphase merge. If the number of strings dispersed is between two levels acceptable by Polyphase merge, a more economical technique of reaching the next level for Polyphase merge is shown and proved.


#*Automata theory motivated by problem solving
#@Ivan M. Havel
#t1974
#cACM SIGACT News
#index438404


#*Verbal and graphical language for the AED system: A progress report
#@Douglas T. Ross,Clarence G. Feldmann
#t1964
#cProceedings of the SHARE design automation workshop
#index552014
#!For Computer-Aided Design use of time-sharing a single language which can take either verbal or graphical form is required. This paper describes how a single language processing technique, which is in turn a special application of more general concepts concerning the step-by-step growth and processing of large structures of interrelated elements, can efficiently process both language forms in the same manner. Illustrations of the concepts involved are also drawn from the methods used in the AED-0 Compiler, an efficient ALGOL-60-based compiler used in Computer-Aided Design work, which is available as a public command in the Project MAC CTSS. &ldquo;This paper was prepared for presentation at a special symposium concerning Project MAC, held at MIT May 6, 7, 1964, under the auspices of the MIT Industrial Liaison Program. The paper summarizes much of the material presented by Mr. Ross at the Share Automation Workshop. A non-time-shared version of the AED-0 Compiler described in the paper will be available through Share in the future. "Work reported herein was supported by Project MAC, an M.I.T. research program sponsored by the Advance Research Projects Agency, Department of Defense, under Office of Naval Research Contract Number Nonr-4102(01) and by the Fabrication Branch, Manufacturing Technology Laboratory, Aeronautical Systems Division, United States Air Force under Contract No. AF-33(600)- 42859. Reproduction in whole or in part is permitted for any purpose of the United States Government.&rdquo;


#*Accessing a data base through a minicomputer
#@Charles A. Lupien,R. D. Harrison, Jr.,E. Lowenthal,T. Richley
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index68627
#!Several speakers will address the notion of using small scale computing devices (or minicomputers) and associated data storage units as data base management "machines." These machines communicate with larger host processors to satisfy data handling requests emanating from programs running on the host. This is tantamount to removing the DBMS software from large main frames (e.g., IMS and total) and housing such software in one or more peripheral computers.


#*Control Program Modelling Techniques
#@H. A. Ernst
#t1974
#cRechnerstrukturen und Betriebsprogrammierung
#index556729


#*Machine recognition of handprinted characters
#@Philip Sanford Noe
#t1970
#c
#index200615


#*Berkeley Array Processor
#@W. Y. Dere,D. J. Sakrison
#t1970
#cIEEE Transactions on Computers
#index344350
#!The Berkeley array processor is a special-purpose computer designed to perform the operations of correlation, convolution, recursive filtering, matrix multiplication, as well as a variant of the Cooley-Tukey algorithm, and others. This note describes the logical organization and performance of this device.


#*A Church-Rosser theorem for graph grammars
#@Barry K. Rosen
#t1975
#cACM SIGACT News
#index434545
#%365994


#*Vertical Migration for Performance Enhancement in Layered Hardware/Firmware/Software Systems
#@J. Stockenberg
#t1978
#cComputer
#index337418
#!Vertical migration is a technique which improves system performance by moving software primitives through layers of application program and operating system software and microcode.


#*The Strategic Petroleum Reserve Distribution (SPRED) simulation model
#@Dennis Taillie,John Neidlinger,Joseph Demasco,William Begenyi
#t1978
#cProceedings of the 10th conference on Winter simulation - Volume 2
#index554941
#!The Strategic Petroleum Reserve Distribution (SPRED) Model is a large scale computer simulation model developed by ERNST ERNST, Washington, D.C. for the Department of Energy (DOE) and the Maritime Administration, Department of Commerce. The Model has been developed using SIMSCRIPT II.5 in an interactive timesharing mode. The Model is a versatile tool for studying present and future import patterns at U.S. ports, as well as for analyzing the alternative solutions to problems concerning the realistic and efficient distribution of the strategic petroleum reserve. This paper describes the system the Model simulates, various types of potential Model applications and the Model structure.


#*Dda curve generator for a high performance computer graphic system.
#@Mike M. Lee
#t1978
#c
#index189811


#*Crossfertilization Of DBMS Research With Other Disciplines Of Computer Science (Panel Discussion)
#@Bharat Bhargava,Stephen R. Kimbleton,Barbara H. Liskov,Jack Minker,J. D. Ullman
#t1978
#cProceedings of the 1978 annual conference
#index550985
#!The DBMS research is moving towards formalization of its problems and solutions. The DBMS researcher can learn and use the techniques that have been developed in formalizing the concepts in Operating systems, Artificial Intelligence, Adaptive systems and Pattern Recognition, and Programming Languages. The panel members are currently involved in research oriented towards cross fertilization of DBMS and various disciplines of computer science. The panel will try to identify commonality of problems, approach and solutions. We hope the discussion will stimulate research in the database area that can fully exploit what we have learned elsewhere.


#*A grassroots approach to teacher training: the Oregon council for computer education
#@Tim G. Kelley
#t1975
#cACM SIGCUE Outlook
#index301812
#!The paper discusses factors contributing to the problem of preparing present and future teachers to accept and become skilled in the use of computers in the instructional process, and the obstacles to achieving a solution.The unique organizational activities of the Oregon Council for Computer Education are presented as a possible solution mechanism. The Council is described as a collective effort to work toward solutions of the many facets of the problem in a coordinated way statewide. The history and structure of the organization are presented, pitfalls described, and some of the accomplishments to date mentioned.


#*New Products
#@
#t1970
#cComputer
#index353470
#!With this issue, the New Product emphasis is structured toward providing an understanding of technological developments, as well as providing the traditional source of product information pertinent to the system developer. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A communications interface for computer networks
#@Donald Karp,Salomon Seroussi
#t1971
#cProceedings of the ACM second symposium on Problems in the optimizations of data communications systems
#index550815
#!The scope of this presentation is to describe the architecture of a communications line protocol for computer networks. Development and implementation details will be introduced where necessary to clarify the presentation. The need for an architecture to facilitate inter-processor communications has been a requirement to the computing industry for several years. The described line protocol was derived through an experiment with a computer network designed for heterogeneous machines, and which utilized existing software. Due to the inflexibility encountered by this approach, the architecture is being re-implemented using our own software. The line interface was defined with flexibility as the foremost requirement. The protocol developed utilizes a minimum set of line control characters. Information is passed in the header portion of the transmitted block providing the capability of identifying a wider range of line control and user related functions. Error recovery has been implemented based on the same type of messages and by transferring line timing responsibilities from the hardware to the software.


#*A simple technique for digital division
#@Salil K. Nandi,E. V. Krishnamurthy
#t1967
#cCommunications of the ACM
#index330230
#%321158
#%331397


#*Algorithms: evaluation of the Chebyshev polynomial Tn(X) by recursion
#@G. M. Galler
#t1960
#cCommunications of the ACM
#index314185


#*The direct interpretation: processors and languages.
#@Andrew M. Welin
#t1975
#c
#index187578


#*A decomposition algorithm for integer programming problems with many columns
#@Jeremy F. Shapiro
#t1972
#cProceedings of the ACM annual conference - Volume 1
#index231434


#*A reprogramming machine
#@William H. Burge
#t1966
#cCommunications of the ACM
#index320953
#%318294
#%553500
#%330864
#!In this paper a description is given of a model programming system which is directed by a programming language and has a library for storing the user's items. Rules are given for transforming programs written in the language and for rearranging the items in the library so that they share their common parts. Some speculations are made about how the mechanical detection of common parts or patterns of library items could help a user to solve his problems, and about the relationships between the behavior of the reprogramming machine and human intelligent behavior.


#*Digital computer solution of shockwave pattern in dense traffic flow
#@Frank F. Paal
#t1969
#c
#index199261


#*Gasp-iv: a combined continuous/discrete fortran based simulation language
#@Nicholas Richard Hurst
#t1973
#c
#index200484


#*Tree-structured programs
#@Eberhard Wegner
#t1973
#cCommunications of the ACM
#index322205
#%333369
#%331066
#!With this note I hope to bridge the gap between the adherents of structured programming and the devotees of the unrestricted goto. I describe a style of programming which combines the advantages of structured programming with nearly all the power of the jump.


#*Patching is alive and, lamentably, thriving in the real-time world
#@Robert L. Glass
#t1978
#cACM SIGPLAN Notices
#index311822


#*Modell zur Ermittlung eines dezentralisierten Rechnersystems mit minimalen Kosten
#@Paul Schmitz,Alfred Schönlein
#t1976
#cRechnernetze und Datenfernverarbeitung, Fachtagung der GI und NTG
#index380733


#*Cost optimization in multi-processor computer systems
#@Gary Michael Giddings
#t1969
#c
#index199289


#*Doing too much for the user
#@Bob Paver
#t1977
#cProceedings of the 5th annual ACM SIGUCCS conference on User services
#index549467
#!In attempting to keep all users happy, all of the time, user services personnel sometimes overextend and over-commit themselves, the software and the hardware. There are special circumstances that require special action, but special attention cannot be supplied on a continuing basis. Nevertheless, users frequently cannot or will not recognize the difference between normal and special services. The user develops an unrealistic expectation of what the computation center can provide. Such an expectation inevitably leads to frustration and possibly to hostility because the resources to meet that expectation are not continuously available. The causes and symptoms of these unrealistic expectatiors and means for their removal and prevention will be discussed.


#*The relationship between computational circuit complexity and radix
#@James R. Armstrong
#t1976
#cProceedings of the sixth international symposium on Multiple-valued logic
#index551006
#%196746
#!The relationship between computational circuit complexity and radix is analyzed. Circuit complexity is measured by the computation time or the number of (d, r) modules in the circuit. The effect of radix on complexity is determined by showing what happens to lower bounds on computation time and number of modules when the radix is varied. If the radix is changed from d1 to d2, the lower bound on computation time is changed by the additive factor logr (logd2d1); the lower bound on number of modules is multiplied by (logd2d1) or log(d2d1)2.


#*Closely coupled multiprocessor systems
#@Richard H. Eckhouse, Jr.,David L. Nelson
#t1976
#cProceedings of the 14th annual Southeast regional conference
#index609453
#!This paper presents the results of an effort to determine the performance, operational characteristics, hardware and software requirements, and the potential applications base for a symmetric system of closely coupled multiprocessors. Based on experience described herein, multiprocessing provides an effective way to increase the range of system performance with a single CPU product line, thereby serving a wider class of applications and market areas and providing explicit growth channels for applications whose computing requirements grow in time.A prototype system has been built using PDP-11/40 processors, multiported memories, and UNIBUS windows, for the purpose of determining its performance and operational characteristics. The RSX-11M real time operating system has been modified to support multiprocessing on this configuration. Theoretical analysis has provided a mathematical expression for system throughput as a function of the number of processors, memory banks, and memory utilization factors. Performance measurements have been related to theoretical analysis so that analytic means can predict the performance of configurations beyond the scope of the prototype hardware.For certain applications, the system cost-performance ratio is improved. The cost effectiveness of multiprocessing is contingent upon low processor/bus utilization of memory, or a high degree of parallelism in the memory system, such as interleaving or banking. Furthermore, realization of the potential afforded by multiprocessing hardware can only be attained in properly structured multiprogrammed operating systems.


#*Automatische Wolkenbildanalyse aus Satellitenbildern
#@E. R. Reinhardt,Peter Schwarzmann
#t1979
#cAngewandte Szenenanalyse, DAGM Symposium
#index558593


#*Multiple faults in Reed-Muller canonic networks
#@K. K. Saluja,S. M. Reddy
#t1972
#cProceedings of the 13th Annual Symposium on Switching and Automata Theory (swat 1972)
#index398052
#!Fault detecting test sets to detect multiple stuck-at-faults in certain networks realizing Reed-Muller canonic expressions are given. It is shown that to detect t faults, t ≥ 1, in a network realizing an arbitrary n-variable logic function only 4 + Σ i=1 [log22t] (in) tests need be applied ([x] is the integer part of x) and that these tests are independent of the function being realized. Techniques to design the checker for these test sets are given.


#*Test data as an aid in proving program correctness
#@Matthew Geller
#t1978
#cCommunications of the ACM
#index326676
#%315592
#%316263
#%545453
#%554548
#%554610
#%549450
#%544750
#%546667
#!Proofs of program correctness tend to be long and tedious, whereas testing, though useful in detecting errors, usually does not guarantee correctness. This paper introduces a technique whereby test data can be used in proving program correctness. In addition to simplifying the process of providing correctness, this method simplifies the process of providing accurate specification for a program. The applicability of this technique to procedures and recursive programs is demonstrated.


#*The computation and application of vector congruence classes
#@Zavdi L. Lichtman
#t1976
#cProceedings of the third ACM symposium on Symbolic and algebraic computation
#index551750
#%188061
#!In a similar fashion to the partitioning of the integers into residue classes, integer spaces (finitely generated free Z-modules) can be partitioned into complete or incomplete vector congruence classes. Complete vector congruence classes are computable by an application of the Smith normal form. The problem of computing efficiently incomplete vector congruence classes is discussed and a few methods are suggested. The application of complete and incomplete vector congruence classes is in performing set-theoretic operations on integer spaces. All set-theoretic operations can be performed on integer spaces which partition into complete vector congruence classes. Some set-theoretic operations can also be performed on integer spaces which partition into incomplete vector congruence classes, but not always in a satisfactory manner.


#*Conference Report: Microprocessors in Automation and Communications
#@W. Myers
#t1978
#cComputer
#index338807
#!As befits the mother of the democracies, debate on the role the microprocessor is to play in Great Britain is vigorous. Even the Prime Minister, James Callaghan, has joined the fray, telling the Labour Party conference at Blackpool that the microprocessor exemplifies the kind of technological change Britain must accommodate in the 1980's. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Error analysis of digital filters with logarithmic number system.
#@Tomio Kurokawa
#t1978
#c
#index192287


#*An algorithm for finding a fundamental set of cycles of a graph
#@Keith Paton
#t1969
#cCommunications of the ACM
#index316210
#%334967
#!A fast method is presented for finding a fundamental set of cycles for an undirected finite graph. A spanning tree is grown and the vertices examined in turn, unexamined vertices being stored in a pushdown list to await examination. One stage in the process is to take the top element v of the pushdown list and examine it, i.e. inspect all those edges (v, z) of the graph for which z has not yet been examined. If z is already in the tree, a fundamental cycle is added; if not, the edge (v, z) is placed in the tree. There is exactly one such stage for each of the n vertices of the graph. For large n, the store required increases as n2 and the time as n&ggr; where &ggr; depends on the type of graph involved. &ggr; is bounded below by 2 and above by 3, and it is shown that both bounds are attained. In terms of storage our algorithm is similar to that of Gotlieb and Corneil and superior to that of Welch; in terms of speed it is similar to that of Welch and superior to that of Gotlieb and Corneil. Tests show our algorithm to be remarkably efficient (&ggr; = 2) on random graphs.


#*Especially for the blind
#@
#t1975
#cIssue 17 (November 1975)
#index304885


#*A computer aid for Schenkerian analysis
#@Stephen W Smoliar
#t1979
#cProceedings of the 1979 annual conference
#index554179
#!This is an account of an attempt to incorporate the computer into research in music theory. The approach to music theory has been heavily influenced by the writings of Heinrich Schenker. However, Schenker's theories have not been followed strictly. Rather, they have served as a launching pad for a theoretical approach to music which is highly compatible with computer programming. This application of the computer differs considerably from past computer-oriented music-theoretic research. In particular, all computations involve symbolic list processing and are therefore quite removed from both those programs which compile reams of statistics or those which scan long strings of characters meant to encode a musical score [4].


#*Certification of algorithm 169: Newton interpolation with forward divided differences
#@Henry C. Thacher, Jr.
#t1963
#cCommunications of the ACM
#index316730


#*A Unified Approach to the Specification and Verification of Abstract DataTypes
#@L. Flon
#t1978
#c
#index203236


#*Separation of simultaneous vocalic utterances of two talkers.
#@Thomas Whitney Parsons
#t1975
#c
#index197241


#*The design of computer-controlled linear multivariable systems using modern control theory.
#@Khalil Mohamad Zahr
#t1973
#c
#index200132


#*Proceedings of the 14th Design Automation Conference
#@
#t1977
#cAnnual ACM IEEE Design Automation Conference
#index550420


#*A user looks at da&mdash;yesterday, today, tomorrow
#@A. E. Fitch
#t1969
#cProceedings of the 6th annual Design Automation Conference
#index550351
#!While much has been written about the technical detail of Design Automation, little has written about how a amp-ldquo;user&rdquo; views DA. This paper will not address the technical details of Design Automation, nor will it consider the entire range of DA facilities and users in existence today. Instead, the paper will contrast a specific user's needs to the facilities available to that user yesterday and today. This contrast will follow a general definition of the term DA, and a detailed description of the various tasks confronting the particular user. For the purpose of this paper, the user's job is to develop a computing system.


#*&ldquo;A generalized learning&rdquo; game
#@Howard A. Peelle
#t1974
#cProceedings of the sixth international conference on APL
#index555270
#!APL is used to describe a &ldquo;learning&rdquo; game, generalized to a class of rules.


#*Certification of Algorithm 31: Gamma function
#@Peter G. Behrenz
#t1962
#cCommunications of the ACM
#index323878


#*Factorizations, Congruences, and the Decomposition of Automata and Systems
#@Joseph A. Goguen,James W. Thatcher,Eric G. Wagner,Jesse B. Wright
#t1974
#cProceedings of the 3rd Symposium on Mathematical Foundations of Computer Science
#index363841


#*Parallel techniques (application to coding of linear function of memory variables).
#@Harold Robert George Trout
#t1972
#c
#index186671


#*The solution of partial differential equations by difference methods using the electronic differential analyzer
#@R. M. Howe,V. S. Haneman
#t1953
#cProceedings of the February 4-6, 1953, western computer conference
#index411489
#!Partial differential equations can be approximated by systems of simultaneous ordinary differential equations by replacing one or more of the partial derivatives by the appropriate finite differences. The resulting systems of equations can sometimes be solved directly by an electric analog computer employing passive circuits (e.g. the Caltech analog computer), or by an electronic differential analyzer employing feedback amplifiers (e.g. the Reeves Electronic Analog Computer). The latter type of computer has several important advantages, including versatility, ability to handle nonlinear partial differential equations, and flexibility in selecting time scales. Both theoretical analysis of the accuracies attainable with the difference method and actual solution examples using the electronic differential analyzer are described. Types of partial differential equations considered include the heat, wave, and beam equations. Real-time simulation of aircraft structures is discussed. The actual computer solutions were carried out on the electronic differential analyzer of the Department of Aeronautical Engineering. As a result of the promise shown by the difference method discussed in this report, construction of an 80--amplifier analyzer has begun.


#*Algorithm 486: Numerical inversion of Laplace transform [D5]
#@Francoise Veillon
#t1974
#cCommunications of the ACM
#index329707
#%319461
#%332501
#%332084
#!This work forms part of a thesis presented in Grenoble in March 1972. Improvements made to the Dubner and Abate algorithm for numerical inversion of the Laplace transform [1] have led to results which compare favorably with theirs and those of Bellmann [2], and Stehfest [3]. The Dubner method leads to the approximation formula: &fnof;(t) = 2eat/T[1/2Re{F(a)} + &sum;&infin;k-1 Re{F(a + ik&pgr;/T)}cos(k&pgr;t/T)], (1) where F(s) is the Laplace transform of &fnof;(t) and a is positive and greater than the real parts of the singularities of &fnof;(t).


#*Multiplexing techniques for data transmission over packet switched radio systems.
#@Michel Olivier Scholl
#t1976
#c
#index205678


#*Hierarchical design and efficient implementation in SETL: a case study
#@Edmond Schonberg
#t1979
#cACM SIGPLAN Notices
#index310515
#%326226
#%325026


#*A Relational Problem Definition Language For Structured Data Processing
#@Leland L. Beck
#t1978
#cProceedings of the 1978 annual conference
#index546759
#%201818
#%325979
#%608406
#!A relational problem definition language for transaction-oriented data processing systems is described and is shown to be relationally complete. Methods are given for converting a problem statement written in this language into a network of processes and files; this network representation can be optimized to produce an efficient implementation of the problem using any available data management software. In effect, this approach allows the automatic reorganization of application programs to provide efficient operation in a changing environment; no alteration of the original problem statement is required.


#*Develop your computer performance pattern
#@J. D. Noe,N. W. Runstein
#t1974
#cACM SIGMETRICS Performance Evaluation Review
#index550694
#!Is the load on your computer shifting? Did that change to faster access disks really help? Would more core memory increase throughput appreciably, or would it be necessary to also increase central processor power? These are three quite different kinds of questions; one concerns detecting a long-term trend, another assessing the effects of a system change, and a third estimating effects of the decision to alter the configuration. Yet all of these require knowledge of current and past system performance, the type of knowledge that must be the result of long-term performance monitoring. This is not simple enough to be picked up overnight or in one series of experiments, nor can it be assessed by watching one or two parameters over a long period. One must have a thorough understanding of the pattern of performance by knowing the mean values of a number of measures and knowing something about the variations from these means. This paper hardly needs to recommend that computer managers establish an understanding of performance pattern; they already are very conscious of the need. What it does is recount development of a method of doing so for the CDC 6400 at the University of Washington and of the selection of &ldquo;Kiviat Graphs&rdquo; as a means to present data in a synoptic form. The remainder of this paper will give a brief account of the authors' experience in designing a measurement system for the CDC 6400 at the University of Washington Computer Center. This will include comments on the approach to deciding what to measure an d display for the synoptic view of the system, as well as how to provide more detailed data for backup. Examples of the use of Kiviat Graphs [4] to show the effects of load shift and of a system configuration change are included, and the effect of a change of operating system will be noted.


#*Sensitivity of predictive scheduling
#@Ka-Lai Leung,Roger C. Wood,Willy Wai-Yee Chiu
#t1975
#cACM SIGSIM Simulation Digest
#index577219
#%185401
#%313289
#%324484
#%332853
#!A popular CPU (Central Processing Unit) scheduling strategy is to give high priority to those jobs with short CPU service times. There are several algorithms for predicting which jobs among all the resident jobs have short service times. No scheme, however, has proved to be 100% accurate in identifying the short jobs. This paper, utilizing results from both simulation and mathematical models, studies the sensitivity of CPU utilization to the accuracy of the predictive algorithm.


#*A language implementation design for a multiprocessor computer system
#@P. Hibbard,A. Hisgen,T. Rodeheffer
#t1978
#cProceedings of the 5th annual symposium on Computer architecture
#index554170
#%328811
#%580721
#!Theoretical and experimental results have indicated that automatic decompositions can discover modest amounts of parallelism. These investigations have tended to ignore the practical problems of language run-time organization, such as synchronization, communication, memory organization, resource management, and input/output. This paper describes a language implementation effort which combines the investigation of implicit and explicit parallel decomposition facilities with the practical considerations of system organization on a multiprocessor computer, Cm*.


#*Iterative Realization of Multivalued Logic Systems
#@V. P. Srini
#t1979
#cIEEE Transactions on Computers
#index351318
#!The realization of multivalued combinational functions and sequential machines by using arrays of one type of cells is considered. The algebra used for the multivalued logic system has two binary operations and a set of unary operations. Each of these operations is realized by a cellular array. The cells are combinational and implemented by using binary logic gates. The cells are also designed so that all unrestricted multiple faults in arrays of these cells are detectable. Multivalued combinational functions, storage elements, and sequential machines are realized by interconnecting the arrays realizing the operations.


#*Application of simulation to detail design of a telephone Directory Assistance System Computer number 68
#@John A. Noecker
#t1971
#cProceedings of the 5th conference on Winter simulation
#index546717
#%191620
#%554917
#!This paper presents results of several DAS/C system design studies and shows how simulation is used to support these studies at the detail level while simultaneously monitoring the overall design to assure meeting the system objectives. This paper is concerned with the systems analysis associated with the IRC inquiry function. The analyses of the IRC update function and the operator's job is currently under way and may be reported in the future.


#*Direct execution of C-string compiler texts
#@Charles W. Bridges,Abd-Elfattah Mohamed Abd-alla
#t1979
#cProceedings of the 12th annual workshop on Microprogramming
#index546424
#%194918
#%305040
#%319907
#%331907
#%553644
#!High level language (HLL) computer architectures refer to those computers which are designed to accept either HLL source texts directly or intermediate texts preprocessed and prepared by HLL compilers. This paper investigates the direct execution of three C-string formats: duos, triples, and quadruples. Software simulators are developed which directly execute these C-string formats on an IBM 3033 architecture. The simulators are then executed for each of the C-string formats, testing the efficiency of each directly executed language (DEL) format for various workloads, on different mainframe architectures, and for five different HLL's. The results demonstrate that triples are the most efficient DEL format in support of most HLL texts on large-scale mainframes.


#*Distributed Process Control: A Micro-Mini Marriage
#@J. C. Hargreaves
#t1977
#cComputer
#index337615
#!Real-time process control problems in computer testing of automobile engines have led to the development of a low-cost microprocessor-based general-purpose minicomputer peripheral controller at the Chrysler Corporation Technical Computer Center in Detroit. Advantages of the new system over minicomputer-only or microcomputer-only systems include both improved system flexibility and better use of system resources. For example, because of their low cost and programmability, multiple microprocessors can be used to handle commonly encountered process control tasks. This feature is especially valuable in systems requiring frequent modifications because of constant changes in governmental standards or other parameters. Minicomputer-based systems, on the other hand, offer sophisticated executives, batch processing, and large data base capability. Besides combining these features, a central mini distributed microsystem offers the additional advantage of allowing the minicomputer to handle the loose coupling of two or more microcomputer tasks.


#*Highlights of the Computer Elements Workshop Mesa, Arizona
#@W. Rosenbluth
#t1978
#cComputer
#index345856
#!This special issue on the business of applying microelectronic components (commonly lumped under the term "microprocessors") is dedicated to the proposition that the LSI microelectronics generation is now replacing the MSI TTL generation for the vast majority of applications for electronic control and intelligence. With this transition, the skills repertoire formerly attributed to the "systems man" must now be acquired by the "LSI components man." In effect, the systems engineering chore has moved one step closer to the device engineer.


#*Scheduling independent processors with different storage capacities
#@D. G. Kafura,V. Y. Shen
#t1974
#cProceedings of the 1974 annual conference - Volume 1
#index553697
#%187174
#%325753
#%544896
#%546894
#%551608
#!The analysis of multiprocessor scheduling strategies has been the focus of substantial research in recent years. Because of the inherent complexity of the general scheduling problem, many researchers have proposed simple mathematical models of computing systems and analyzed the worst-case performance bounds of heuristic scheduling algorithms. This paper presents the analysis of simple scheduling strategies on a model of a computer system with an arbitrary number of identical but independent processors each with a possibly different storage capacity. Most simple strategies are shown to be unattractive as the bound on their worst-case behavior increases without limit. However, two strategies are presented with worst-case bounds asymptotically approaching 2. In addition, if the system has a preemptive-resume feature, a simple optimal strategy exists that will produce minimal-length schedules for any given task set.


#*Cauchy type representations for functions of a complex variable
#@Richard Solomon Ballance
#t1956
#c
#index189385


#*List tracing in systems allowing multiple cell-types
#@Robert R. Fenichel
#t1971
#cCommunications of the ACM
#index323571
#%318294
#%333194
#%330067
#%327458
#%328831
#!List-processing systems have each allowed the use of only a single size and configuration of list cell. In this paper a system is described which allows the use of arbitrarily many different sizes and configurations of list cells, possibly not specified until run time.


#*The lemniscate constants
#@John Todd
#t1975
#cCommunications of the ACM
#index328480
#!The lemniscate constants, and indeed some of the methods used for actually computing them, have played an enormous part in the development of mathematics. An account is given here of some of the methods used&mdash;most of the derivations can be made by elementary methods. This material can be used for teaching purposes, and there is much relevant and interesting historical material. The acceleration methods developed for the purpose of evaluating these constants are useful in other problems.


#*A Formal Syntax for PL/CS
#@Tim Teitelbaum
#t1976
#c
#index120199
#!This document contains a formal syntax for the PL/CS programming language. As is customary, the defining context-free grammar generates a somewhat larger language than PL/CS. That is, only those restrictions conveniently expressed by context-free productions are incorporated in the definition. However, all legal PL/CS programs are contained in the language defined. With some exceptions, the formal syntax defines the language described in: Conway, R., "PL/CS A Highly-Disciplined Subset of PL/C", Dept. of Computer Science, Cornell University, TR 76-273. The present report supersedes this earlier report as the document defining the syntax of the PL/CS subset.


#*forum
#@Martin A. Goetz
#t1973
#cCommunications of the ACM
#index321317


#*An interactive system to teach Fortran
#@Dennis M. Conti
#t1970
#cACM SIGCUE Outlook
#index301512
#%329191
#%317150


#*A simulation environment for performing dataflow research
#@Steve P. Landry,Bruce D. Shriver
#t1979
#cProceedings of the 1979 ACM SIGMETRICS conference on Simulation, measurement and modeling of computer systems
#index551770
#%550243
#!Dataflow languages and processors are currently being extensively studied because of their respective ability to specify and execute programs which exhibit a high degree of parallel and/or asynchronous activity [12, 7]. This paper describes a comprehensive simulation environment that allows for the execution and monitoring of dataflow programs. One overall objective of this facility was to meet the needs of researchers in such diverse areas as computer architecture, algorithm analysis, and language design and implementation. Another objective was to accommodate the semantics of several of the contending abstract dataflow models [2, 4]. Additionally, it was desired to enhance the abstract dataflow models which the simulator would support. These objectives, combined with the desired debugging and metering requirements, directed the design of the overall system. A brief introduction to dataflow and its related terminology is given to assist the reader. A companion paper [6] describes an augmentation to the basic simulation facility presented here that allows for the execution of dataflow programs on processors having finite resources.


#*Transformation of loop programs for parallel execution.
#@Daniel Shih-Chia Lo
#t1976
#c
#index198534


#*One method of introducing APL
#@K. W. Smillie
#t1979
#cACM SIGAPL APL Quote Quad
#index252841
#!A Summary of APL is given, together with a set of APL functions that allow the examples in the summary to be presented simply on an IBM 5100 computer.


#*The Rio symposium
#@Robert S. McLean
#t1973
#cACM SIGCUE Outlook
#index336772
#!The Rio Symposium on Computer Education for Developing Countries, held in Rio de Janeiro early in August, 1972, drew 280 computing specialists. They came from 40 countries at virtually all stages of economic development. The majority of the attendance was from the host country, Brazil, with 155 members. The second largest group, and the most vocal in terms of presentations and comments, was from the USA with 29 members. All of the other countries had fewer than ten persons present.


#*Proceedings of the fifth SIGCSE technical symposium on Computer science education
#@Gerald L. Engel
#t1975
#cTechnical Symposium on Computer Science Education
#index549464


#*Training consultants
#@R. T. Day
#t1979
#cProceedings of the 7th annual ACM SIGUCCS conference on User services
#index449786
#!Consultants are trained to serve student and faculty computer users, first by having them observe the consulting process, and then by having them try it themselves with an experienced consultant looking on. Trainees are taught some acceptable responses to situations where they cannot readily solve the problem. They are challenged to become skillful in choosing the best response. Trainees are shown many sources of information, and then asked to become skillful in choosing among them.


#*Algorithm 181: complementary error function&mdash;large X
#@Henry C. Thacher, Jr.,Paul Shaman
#t1963
#cCommunications of the ACM
#index317077


#*Multiple fault diagnosis in combinational networks.
#@Charles Wei-Yuan Cha
#t1974
#c
#index194523


#*Zur Leistungsbewertung von Multiprozessor-Strukturen
#@Siegfried Hoener
#t1974
#cGI - 4. Jahrestagung
#index266040


#*Automated documentation in systems analysis and design
#@Lois A. Rose
#t1977
#cACM SIGDOC Asterisk Journal of Computer Documentation
#index581296
#!It seems that proper documentation of systems analysis and systems design is the most tedious, time-consuming portion of systems development. Yet few people would challenge its importance. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A More Portable Fortran Random Number Generator
#@Linus Schrage
#t1979
#cACM Transactions on Mathematical Software (TOMS)
#index325322
#%317911
#%325239
#%328674


#*Multinational information systems (Panel Discussion)
#@Richard Nolan,E. Gerald Hurst, Jr.
#t1976
#cProceedings of the 1976 annual conference
#index550826
#!Many organizations today face a unique set of problems and opportunities because they operate across international boundaries. To some extent, the growth of the multinational organization has been made possible by electronic communications. Now, more and more of these organizations are using computers to tie together their far-flung operations. The planning, organizing, and supporting of information systems for the multinational will be the focus of this session.


#*A solution to the hidden surface problem
#@M. E. Newell,R. G. Newell,T. L. Sancha
#t1972
#cProceedings of the ACM annual conference - Volume 1
#index234204
#%331365
#!A method for producing half-tone pictures by computer is presented. The basic method, which is very simple, works well in most cases, but does not handle all objects correctly. The extended method, which copes with all cases, is also described. The functions used for calculating the intensity of parts of objects, and the method for handling transparency, are discussed. Examples of pictures produced by this method are included, and the times taken to generate them are tabulated. The extended algorithm compares favourably in speed and storage requirements with other published algorithms.


#*Job shop type production scheduling by simulation
#@Ronald G. Pettit
#t1968
#cProceedings of the second conference on Applications of simulations
#index547148
#!The primary purpose of this paper is to introduce the audience to a concept that is not always appreciated by those skilled in the art of simulation. In contrast to the traditional use of simulation as a study tool, the following discussion will emphasize the potential role of simulation for operational production scheduling in job shop-like environments rather than the research-oriented role now primarily assigned to it. Simulation techniques have been employed to study nearly all phases of the manufacturing process including forecasting, long-range planning, order release, and the flow of jobs on the production floor. This paper discusses production floor scheduling of discrete production facilities with job shop characteristics. A job shop is defined as having the following characteristics: 1)there is a set of production or service facilities; 2) jobs consisting of several tasks move between facilities for service; 3) one or more tasks are performed at each facility; 4) the service time for tasks may vary from job to job; and 5) the routing between facilities may vary from job to job.


#*Proceedings of the first annual ACM symposium on Theory of computing
#@
#t1969
#cAnnual ACM Symposium on Theory of Computing
#index549060


#*A Systematic Approach to Formal Language Theory Through Parallel Rewriting
#@Grzegorz Rozenberg
#t1979
#cProceedings of the 6th Colloquium, on Automata, Languages and Programming
#index372425


#*Characteristics of the high cost of maintenance of application software.
#@Gerry Edward Tompkins
#t1977
#c
#index187916


#*A suboptimal meter allocation algorithm for power system static-state estimation.
#@Phongsak David Yehsakul
#t1978
#c
#index191114


#*Curve Fitting by a One-Pass Method With a Piecewise Cubic Polynomial
#@Kozo Ichida,Takeshi Kiyono,Fujiichi Yoshimoto
#t1977
#cACM Transactions on Mathematical Software (TOMS)
#index322235


#*Circuit frequency response analysis program with worst-case capabilities (FRWC)
#@S. J. Garrett,T. H. Vind
#t1968
#cProceedings of the 5th annual Design Automation Workshop
#index552523
#!Circuit Analysis with s digital computer has become almost commonplace. Such programs as NET-1, ECAP, SCEPTRE, CIRCUS and many others have significantly advanced the state of the art of circuit analysis. So much so that the past several years have witnessed the development of the worst-case analysis era. It is no longer sufficient just to supply a customer with a piece of electronic equipment that is thoroughly tested. Frequently, and especially when the customer is connected with the space program, an analysis is also required that shows the equipment will meet the performance specifications when component parameters are permitted to vary. These variations may be due to purchase tolerances, temperature variation, or end-of-life degradation. The analysis procedure that leads to a worst-case calculation is very tedious. The variation which gives the worst-caste performance must be selected. The analyst is given some aid in his search for the worst-case performance by some computer programs. For example, ECAP will calculate the sensitivities and the worst-case voltages in a DC circuit. However, neither the worst-case transient solution nor the worst-case frequency response solution can be obtained automatically from available programs. A digital computer program which uses the extremes of the parameter varizations to compute the worst-case performance of a lumped-linear model of an electronic circuit was developed by the authors and is presented here. The program is described in this paper in several sections. In Sections II through IV the worst-case feature is described in detail and an example is given to illustrate the use of the program. In Section V the detailed operating instructions for the program are listed. Section VI presents conclusions.


#*Parameterization of the environment for transportable numerical software
#@Brian Ford
#t1978
#cACM SIGNUM Newsletter
#index108012
#!An early draft of this note was used as a discussion document during the first meeting of the IFIP Working Group on Numerical Software (WG 2.5) in Oxford in January 1975. The meeting requested a precise specification of the purpose of the note and suggested a number of other improvements which led to a second draft. Written comment led to further changes. A third draft was discussed during a workshop on transportable numerical software in the Applied Mathematics Division of the Argonne National Laboratory in August 1975. A fourth draft was written in January 1976 and distributed widely for comment and criticism. Discussion at the NSF/ERDA workshop on portability of numerical software and at the second meeting of the IFIP WG 2.5 (both in June 1976), together with correspondence from other parties led to the preparation of the present document. Although some of the comment was contradictory, it is our belief that this final document represents a consensus view.


#*BASIC
#@Thomas E. Kurtz
#t1978
#cACM SIGPLAN Notices
#index547225
#%314674
#%320929
#%327973
#%328020
#%328541
#%334014
#%335555
#!Dartmouth College is a small university dating from 1769, and dedicated &ldquo;... for the education and instruction of Youth of the Indian Tribes in this Land in reading, writing and all parts of learning... and also of English Youth and any others.&rdquo; (Wheelock 1769.) The undergraduate student body (now nearly 4000) outnumbers all graduate students by more than 5 to 1, and majors predominantly in the Social Sciences and the Humanities (over 75 percent). In 1940 a milestone event, not well remembered until recently (Loveday 1977), took place at Dartmouth. Dr. George Stibitz of the Bell Telephone Laboratories demonstrated publicly for the first time, at the annual meeting of the American Mathematical Society, the remote use of a computer over a communications line. The computer was a relay calculator designed to carry out arithmetic on complex numbers. The terminal was a Model 26 Teletype.


#*On data error control problems in medical information systems
#@T. C. Ting,Fred R. Sias, Jr.,Eric Campbell
#t1976
#cProceedings of the 14th annual Southeast regional conference
#index608531
#!The problem of data error control is one of the significant issues in the design of medical information systems which are used for supporting medical decision making. High degree of accuracy of information is necessary when human health problems are involved.A literature survey was conducted and an examination of several existing computerized medical information systems was made. The results indicate that many systems now in use have not adequately designed to implement fully the data error control techniques now available for minimizing the data errors. The situation may be improved by carefully introducing these techniques into the information processing procedures. It also suggests that further research should be undertaken in order to develop better suited data error detecting and correcting techniques for medical information systems.A systematic analysis was made to identify the sources and the causes of the data errors in medical information processing procedures both in mannual as well as in automated systems. Data errors are classified and are discussed along with the logical data flow in a typical medical information processing model. The characteristics of the data items involved, the data structures, the nature of the data errors, and the possible data error control methods are disscussed.


#*Inference from statistical data bases.
#@Mayer Dlugach Schwartz
#t1977
#c
#index201953


#*Discussion of Jacobs paper
#@Jeanne C. Adams
#t1973
#cProceedings of the eleventh annual SIGCPS computer personnel research conference
#index552348
#%555234
#!The field of computing has grown considerably in recent years and the tasks performed on computers encompass more and more variety in scientific, industrial and business applications. The programming task itself must be defined in very broad terms if one is to cover all the activities performed in all areas where computers are used today. In his paper, Mr. Jacobs defines the programming task in very broad terms. He recognizes that current tests for personnel selection are not satisfactory and suggests that certain tests of cognitive capabilities might prove better instruments for recognizing potential programming skills. However, the predictor variables did not correlate significantly with the criterion variable, success in programming training, and his hypotheses were not supported.


#*On the necessary evolution towards improvement specialization in software production teams
#@J. Bézivin,F. Gauduel,J. L. Nebut,R. Rannou
#t1977
#cProceedings of the fifteenth annual SIGCPR conference
#index552406
#%318161
#%323067
#%550337
#!Human aspects are an essential element in the software production cycle. This has been widely recognized and several proposals such as the &ldquo;chief programmer team&rdquo; have proved their effectiveness as methodologies to produce high quality software at a lower cost. In this paper we investigate the possible short term implications of recent technological and methodological evolution on the basic structure of software production groups.


#*The development of a dynamic interactive computer graphics research and educational support environment
#@Frederick R. Stocker,Gerald G. Johnson, Jr.,Herbert A. McKinstry
#t1975
#cProceedings of the 2nd annual conference on Computer graphics and interactive techniques
#index254088
#!The Pennsylvania State University Computation Center is currently performing research and development in providing an effective research and training support environment which enables a user, whether researcher or student, to become familiar with an available base of graphics hardware and software support and to proceed to original programming with confidence and effectiveness.The main consideration is to provide an interactive programming environment in which users can become self-sufficient in coping with both hardware operation and potential as well as effective utilization of software in a reasonably short period of time. Such users should not have to be computer graphics specialists to apply a graphics system to their fields of expertise. Users should be thoroughly trained to understand and handle an available hardware/software system in order to be better able to evaluate the potential system usage directly and effectively.This paper, together with a film, describes an approach developed at the Computation Center and tested and implemented in three offerings of a Computer Science advanced undergraduate course.


#*Design of a terminal monitor for interactive programs
#@Robert Anthony Mikelskas
#t1973
#c
#index192806


#*C2: a "super-compiler" approach to automatic programming.
#@Ted James Biggerstaff
#t1976
#c
#index201548


#*Representing text structure for automatic processing.
#@Lynne Ann Price
#t1978
#c
#index206076


#*President's letter to the ACM membership: The ACM Council
#@Bernard A. Galler
#t1968
#cCommunications of the ACM
#index328870


#*Symbolic/numeric algorithms for partial differential equations
#@Dana L. Ulery,Hatem M. Khalil
#t1976
#cProceedings of the third ACM symposium on Symbolic and algebraic computation
#index552824
#%186548
#!Symbolic computation has been used to generate classes of numeric algorithms for solving linear partial differential equations A two-phase procedure is described for automatically producing multiparameter families of difference approximations to the heat operator. In the first phase, a truncated series expansion is used to form the appropriate difference operator. The coefficients of the operator, functions of free parameters, are determined in the second phase. When the region is rectilinear, Vandermonde matrices are constructed which permit this phase to be computed numerically. When the region is irregular, a symbolic approach appears to be more efficient


#*ACM president's letter: on the rituals of our clans
#@Walter M. Carlson
#t1972
#cCommunications of the ACM
#index317109


#*There's no such thing as a systems analyst
#@Edrice Addleman
#t1976
#cProceedings of the fourteenth annual computer personnel research conference
#index544995
#%619646
#!Prior SIGPR conferences have focused on training, the characteristics of workers in the field, and the social impact of computers and computer people. These issues are important, of course. But the very title of this conference, &ldquo;The Systems Analyst in Perspective,&rdquo; implies that something more is needed now. I suggest to you that there is no such thing as a systems analyst. Systems analysts do not exist. It is impossible. When I recently tried to explain to a vice president what a programmer/analyst does, he was particularly interested in the &ldquo;analyst&rdquo; part. After my feeble explanation, he said, &ldquo;Oh, well, then, I could call myself a vice-president/analyst.&rdquo; And of course he is right. Anyone who does a good job could be called an analyst, because the main characteristic of a good analyst of any kind is that he looks at what he is doing in the framework of the entire organization. (Isn't it?) I decided to begin with some definitions, so I looked up the two words &ldquo;system&rdquo; and &ldquo;analyst&rdquo; in my unabridged dictionary to give me a starting point.


#*On the representation of symmetric polynomials
#@J. K. S. McKay
#t1967
#cCommunications of the ACM
#index315784
#%321166
#%334653
#!Relations are given between certain symmetric polynomials in the light of the theory of the symmetric group. Such an approach unifies earlier work and lends insight to previously published work by Aaron Booker. A generalization of Graeffe's root-squaring technique for the determination of the roots of a polynomial is suggested.


#*Sorting nonredundant files&mdash;techniques used in the FACT compiler
#@John B. Glore
#t1963
#cCommunications of the ACM
#index327507
#!Some typical file structures, including some called &ldquo;non-redundant,&rdquo; are examined, and the methods used in FACT to sort such files are discussed.


#*The role of emulation in performance measurement and evaluation
#@Liba Svobodova,Roy Mattson
#t1976
#cProceedings of the 1976 ACM SIGMETRICS conference on Computer performance modeling measurement and evaluation
#index553493
#%551753
#%607120
#!Emulation of systems makes it possible to combine the predictive power of simulation with the advantages of measurement carried under a real system workload. An emulator is a microprogrammed implementation of the basic hardware machine. It can be easily instrumented to collect performance statistics on the instruction set processor (ISP) level and support performance measurement of different configurations and software of the emulated system. This paper describes the monitoring capabilities of the Microprogrammable Multi-Processor (MMP), a powerful emulator system that serves as an experimental tool for evaluating computer systems. The measurement capabilities of the MMP on various system levels are described, as well as existing performance monitoring tools and their applications. Preliminary results contrasting the Gibson mix and measured instruction frequencies on the AN/GYK-12 computer in a TACFIRE system are given.


#*A Diffusion Model for Multiple Class Queueing Networks
#@Erol Gelenbe,Guy Pujolle
#t1977
#cProceedings of the Third International Symposium on Measuring, Modelling and Evaluating Computer Systems
#index271355


#*The TV Turtle a Logo graphics system for raster displays
#@Henry Lieberman
#t1976
#cACM SIGGRAPH Computer Graphics
#index551081
#%153803
#!Until recently, most computer graphics systems have been oriented toward the display of line drawings, continually refreshing the screen from a display list of vectors. Developments such as plasma panel displays and rapidly declining memory prices have now made feasible raster graphics systems, which instead associate some memory with each point on the screen, and display points according to the contents of the memory. This paper discusses the advantages and limitations of such systems. Raster systems permit operations which are not feasible on vector displays, such as reading directly from the screen as well as writing it, and manipulating two dimensional areas as well as vectors. Conceptual differences between programming for raster and vector systems are illustrated with a description of the author's TV Turtle, a graphics system for raster scan video display terminals. This system is imbedded in Logo, a Lisp-like interactive programming language designed for use by kids, and is based on Logo's turtle geometry approach to graphics. Logo provides powerful ideas for using graphics which are easy for kids to learn, yet generalize naturally when advanced capabilities such as primitives for animation and color are added to the system.


#*Dynamic job scheduling in a distributed computer network with functionally similar nodes.
#@Charles Larry Satterwhite
#t1977
#c
#index202969


#*Conversion between floating point presentation
#@C. Perry
#t1960
#cCommunications of the ACM
#index329540


#*Symbiotic computer system measurement and evaluation
#@Dana Wayne Zimmerli
#t1972
#c
#index189736


#*Adaptive pattern recognition
#@Periagaram Krishnamurthi Rajasekaran
#t1971
#c
#index201606


#*EDUSAC - an educational list processing system
#@William E. Kennedy,James R. Pinkert
#t1976
#cACM SIGCSE Bulletin
#index549322
#%334426
#!This paper describes an educational version of the SAC-1 list processing system. Educational systems such as WATFIV, WATB&Oslash;L, and PL/C are available for teaching programming languages. However, the authors could find no comparable systems for list processing. Since such facilities would be useful in many courses (e.g., data structures, operating systems, symbol manipulation), EDUSAC was developed.


#*Bootstrapping XPL from IBM/360 to UNIVAC 1100
#@Stephen H. Kamnitzer
#t1975
#cACM SIGPLAN Notices
#index301351
#%546165


#*A finite domain-testing strategy for computer program testing.
#@Edward Ira Cohen
#t1978
#c
#index198165


#*Technical session I
#@
#t1967
#cProceedings of the 6th annual Southeastern regional meeting of the Association for Computing Machinery and national meeting of Biomedical Computing - Volume 1
#index614923


#*Simulation and analysis of biochemical systems: III. analysis and pattern recognition
#@David Garfinkel,William Polk,Joseph J. Higgins,Robert T. Ochser
#t1962
#cCommunications of the ACM
#index323272
#%334011
#%333706


#*The effect of expanded speech rates and expanded pauses on the short-termmemory of retardates.
#@Edward Joseph Streich
#t1976
#c
#index188899


#*Optimal representations of finite state machines for computer simulation
#@Edward James Wilkens
#t1971
#c
#index200513


#*Processor-memory interconnections for multiprocessors
#@Janak H. Patel
#t1979
#cProceedings of the 6th annual symposium on Computer architecture
#index549617
#%549076
#!A new class of interconnection networks is proposed for processor to memory communication in multiprocessing systems. These networks allow a direct link between any processor to any memory module. The cost of these networks is considerably less than that of full crossbars. Moreover, the design and control of these networks is simple. The proposed networks and the full crossbars are analyzed with respect to the bandwidth and the cost.


#*On inductive synthesis of programs
#@J. M. Barzdin
#t1979
#cProceedings on Algorithms in Modern Mathematics and Computer Science
#index271891


#*Verification of encapsulated implementations of algebraically specified data types.
#@Patrick Kirkpatrick Orr
#t1979
#c
#index190405


#*A checking method of wiring
#@Yoshiaki Koga
#t1970
#cProceedings of the 7th Design Automation Workshop
#index554841
#!This paper presents a failure mode analysis, including multiple failures, for transmission line wiring on back planes or multilayer printed circuit boards. A checking method sufficient to locate these failures by means of automatic test equipment is discussed.


#*Another participant in JUG
#@H. M. Semarne
#t1961
#cCommunications of the ACM
#index326537


#*Introduction to the Wellmade Design Methodology
#@D. L. Boyd
#t1978
#cIEEE Transactions on Software Engineering
#index342941
#!An overview of a design methodology called WELLMADE is presented. WELLMADE is a synthesis of results obtained from recent research on software engineering and the experience gained at HIS/Phoenix. The principles, procedures, and notation of WELLMADE are briefly outlined and an example is presented, illustrating the approach for deriving correct programs and the notation for its design specification.


#*Some results on almost complex structures
#@Terence Morton Heaps
#t1967
#c
#index198034


#*Interactive graphics: economics of computer graphics systems
#@
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index62638


#*A time domain study of speech sounds
#@John Crable Wauer
#t1963
#c
#index203892


#*Simulation of social groups with adaptive recognition techniques
#@Patrick Kelso Miller
#t1968
#c
#index195328


#*Synchronization of communicating processes
#@A. Nico Habermann
#t1972
#cACM SIGOPS Operating Systems Review
#index115846
#!Formalization of a well-defined synchronization mechanism can be used to prove that concurrently running processes of a system communicate correctly. This is demonstrated for a system consisting of many sending processes which deposit messages in a buffer and many receiving processes which remove messages from that buffer. The formal description makes it very easy to prove that the buffer will neither overflow nor underflow, that senders and receivers will never operate on the same message frame in the buffer nor will they run into a deadlock.


#*Structured control in programming languages
#@Charles T. Zahn, Jr.
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index62805
#%552881
#%331066
#%323067
#!Solving a problem with the aid of a computer involves the construction and execution of a program described by a linear piece of text. First, the problem-solver (programmer) translates his problem into a procedural solution embodied in a static program text, written in a programming language. Then a computer is caused to perform a dynamic sequence of actions in accordance with the commands in the program text. The reliability of this two-stage problem solution (i.e., the likelihood that the actions performed really provide a solution of the problem) depends on the degree to which the program text mirrors the possible action sequences that it causes, as well as the problem solution that it purports to implement. It is useful to speak of the "conceptual distance" between program text and action sequences or between problem definition and program text. The programmer who wants some measure of confidence in the reliability of his program must bridge both these conceptual distances. It follows that a major goal of programming language design should be to help reduce both these distances.


#*Computergest&uuml;zte Auswertung von Gescho&szlig;- und Werkzeugspuren
#@W. Deinet
#t1978
#cBildverarbeitung und Mustererkennung, DAGM Symposium
#index565369


#*An alternative approach to macro processing
#@Michael Hammer
#t1971
#cProceedings of the international symposium on Extensible languages
#index545298
#%319282
#%331218
#!This paper presents the basic principles of, and the motivation for, an alternative method of processing syntax macros. The inspiration for this work derives from some obvious shortcomings and inefficiencies in conventional macro processing schemes. However, our primary interest is not in designing a faster macro processor; rather it lies in isolating the underlying ideas of syntax macros, realizing their implications, and producing a clean and economical scheme based on these principles. The compiler model in terms of which we shall couch our discussions is a very familiar one, namely that of the two-pass compilation process. The first pass consists of syntactic and semantic analysis, and converts a source language program into an intermediate language (computation tree) form, which represents the meaning of the program. The second pass is then either an object code selector or an interpreter.


#*A Problem-Reduction Approach to Proving Simulation Between Programs
#@A. Birman
#t1976
#cIEEE Transactions on Software Engineering
#index351948
#!System correctness often presents itself as the problem of showing that two programs, the "specification" and the "implementation," are in some sense equivalent. Such a concept of equivalence is supplied by Milner's definition of simulation between programs. This paper presents a problem-reduction approach to proving simulation, and describes an interactive system designed for this purpose.


#*The Pica-B Computer An Abstract Target Machine For A Transportable Single-User Operating Environment
#@Harvey Abramson,Mark Fox,Michael Gorlick,Vince Manis,John Peck
#t1978
#cProceedings of the 1978 annual conference
#index554248
#%79620
#%205622
#%331066
#%333675
#!The Pica-B computer is a simple abstract machine designed to: 1. facilitate the portability of a simple single user operating environment written in BCPL. 2. serve the pedagogic goal of providing a basis for teaching concepts of hardware and system architecture, systems programming and programming language design in a unified setting, and 3. serve as a possible solution to the current and future software crisis caused by the advent of the micro-computer. The Pica-B is based on Richards' Intcode machine but differs from it in the addition of an (interrupt) status register and a PDP-II style memory map of I/O devices. The status register and hence interrupt and device handlers may be programmed in Pica-B code (an extension of Intcode) or in a version of BCPL with an added inline code facility, the so-called vile command. An example is given or how interrupts and I/O are handled in the Pica-B computer.


#*Editorial Policy&hellip;
#@Elliott I. Organick
#t1973
#cACM Computing Surveys (CSUR)
#index322963


#*The drazin pseudoinverse: existence, properties, and computation.
#@Emma Jane Riddle
#t1976
#c
#index200021


#*An APL system-development facility
#@Douglas W. Flower,Maurice Elliott
#t1979
#cACM SIGAPL APL Quote Quad
#index554912
#!The APL system-development facility provides a framework within which system designers can easily solve many of the problems associated with the development of large systems. Systems can be defined and set up quickly, with automatically provided database-access facilities, data dictionary, and interactive maintenance protocols. A planned procedure definition and cataloging capability will provide a report writer and direct data-base inquiry and update facility to the user. Overall system structure is transparent, allowing straightforward additions and changes to the system. Fully general data structures are supported. Additionally, all data-access mechanisms can be tailored to take optimum advantage of individual situations. The optimization techniques themselves are well-defined and localized, further insuring system maintainability.


#*Curriculum and teacher training for secondary schools
#@Donald D. Spencer
#t1971
#cACM SIGCUE Outlook
#index304550


#*The refuge relay function generator
#@K. B. Tuttle
#t1956
#cProceedings of the 1956 11th ACM national meeting
#index546231
#!The method of approximating an arbitrary function of one variable by a sequence of straight-line segments of suitable slopes is widely used to provide input functions for analogue computations. However, many of the mechanizations of this process are critical in adjustment, and require relatively highly trained personnel to expend considerable time in setting them up. The relay function generator here described was developed in an effort to arrive at a simple, reliable device which would accomplish this same purpose, and which could be set up in a purely routine manner by personnel without special training.


#*Design considerations for a QM-1 based multimicroprocessor emulation system
#@Steve Crocker
#t1978
#cACM SIGMICRO Newsletter
#index547495
#!Microprocessors, which are now readily available, are being used in the design of many systems. Soon avionic systems will be designed that use many microprocessors working together. Systems based on multiple microprocessors (MMP) will be designed to offer higher throughput and/or higher reliability than uniprocessor systems. There are now very few design tools to aid in developing or evaluating proposed microprocessor systems. One highly useful tool is an emulation facility for modeling, testing, and measuring proposed MMP systems.


#*Letters to the editor
#@George G. Heller,Irwin Greenwald,Charles W. Turk
#t1960
#cCommunications of the ACM
#index335205


#*Use of tree structures for processing files
#@Edward H. Sussenguth, Jr.
#t1963
#cCommunications of the ACM
#index330910
#%316264
#%329636
#!In data processing problems, files are frequently used which must both be searched and altered. Binary search techniques are efficient for searching large files, but the associated file organization is not readily adapted to the file alterations. Conversely, a chained file allocation permits e 1 cient alteration but cannot be searched efficiently. A file organized into a tree-like structure is discussed, and it is shown that such a file may both be searched and altered with times proportional to s logs N, where N is the number of file items and s is a parameter of the tree. It is also shown that optimizing the value of s leads to a search time which is only 25 per cent slower than the binary search. The tree organization employs two data chains and may be considered to be a compromise between the organizations for the binary search and the chained file. The relation of the tree organization to multidimensional indexing and to the trie structure is also discussed.


#*The national science foundation and support for social science computing
#@Ronald E. Anderson
#t1974
#cACM SIGSOC Bulletin
#index574476
#!Nearly two years ago, I spent several months working as a Professional Assistant in the Office of Computing Activities at the National Science Foundation in Washington, D.C. Although my assignment was to develop a concept for a program on "Computer Impact on Society", I had opportunity to become familiar with some of the projects supported in the area of computer applications for the social sciences. Actually I was already familiar with most of the projects that had been supported. However, the work assignment enabled me to have an expanded and slightly different perspective on these projects. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Symbolic Solution of Finite-Difference Equations
#@Jacques Cohen,Joel Katcoff
#t1977
#cACM Transactions on Mathematical Software (TOMS)
#index325779
#%318161
#%321664


#*A total life cycle cost model for a computer system.
#@George Allen Champine
#t1975
#c
#index185532


#*File format for data exchange between graphic data bases
#@Arthur G. Gross
#t1978
#cProceedings of the 15th Design Automation Conference
#index550973
#!A number of interactive graphics systems have been developed for cartographic applications. These systems have different capabilities and features, and little or no general provision has been made for transferring data base content between different systems or installations. A data base interchange file format has been designed for the Computer Assisted Mapping and Records Activities System, CAMRAS, sponsored by the American Public Works Association. The Association is evaluating the format for promulgation as a standard. A description of the interchange file format is given.


#*Application of an interactive graphics system to the kinematic design of an artificial knee joint
#@Roger E. Kaufman
#t1972
#cACM SIGGRAPH Computer Graphics
#index544683
#%553654
#!KINSYN is an interactive general purpose computer system for the kinematic synthesis and analysis of mechanisms. It is applicable to kinematics problems ranging from the synthesis of spacecraft antenna deployment mechanisms to the design of folding high chairs. Features of KINSYN have been described in several recent publications. The results shown in this paper were obtained during the first two or three trial runs on KINSYN. Of course, extensive work would remain to be done in order to apply these techniques to a practical artificial limb design, Nonetheless, the fact that so much useful design data can be obtained so readily with the aid of KINSYN indicates that it could be a significant aid in a physiological limb development program.


#*Simulation of human understanding of language
#@M. Ross Quillian
#t1961
#cCommunications of the ACM
#index316818


#*A building block approach to color graphics
#@J. Robert Flexer,Gio Wiederhold
#t1979
#cProceedings of the 6th annual conference on Computer graphics and interactive techniques
#index555146
#%153803
#%322663
#!Graphics and imaging are important in scientific, academic and industrial environments. In the past graphics systems have been used with large computers and were only available to a minority of users. The relatively small and specialized use of graphics has inhibited sharing of software and prevented standardization necessary for widespread use. Dense semiconductor memory has recently become easily available in large quantities and makes high resolution graphics and imaging systems feasible. The concepts leading to the design of the present system come from the need to provide a large number of graphic and imaging functions, in a compact form, to a commonly used microprocessor bus. Three fundamental functions are implemented: a video frame digitizer, an image memory, and an output video generator. Video images can be digitized in one frame time with a precision of 1, 2 or 4 bits per pixel. The video generator can display the images in gray levels or in color. The software selectable system parameters include a variety of image formats, video output controls, digitization commands, addressing modes, vertical image offset, and lightpen controls. A novel contouring digitization mode is useful to reduce images obtained in gray scale to outline form. Such real-time preprocessing reduces memory and bandwidth requirements. Photographic illustrations demonstrate various operating modes.


#*Comparison of polynomial-time reducibilities
#@Richard Ladner,Nancy Lynch,Alan Selman
#t1974
#cProceedings of the sixth annual ACM symposium on Theory of computing
#index553746
#%183108
#%544896
#%553962
#%555061
#!Comparison of the polynomial-time-bounded reducibilities introduced by Cook [1] and Karp [4] leads naturally to the definition of several intermediate truth-table reducibilities. We give definitions and comparisons for these reducibilities; we note, in particular, that all reducibilities of this type which do not have obvious implication relationships are in fact distinct in a strong sense. Proofs are by simultaneous diagonalization and encoding constructions. Work of Meyer and Stockmeyer [7] and Gill [2] then leads us to define nondeterministic versions of all of our reducibilities. Although many of the definitions degenerate, comparison of the remaining nondeterministic reducibilities among themselves and with the corresponding deterministic reducibilities yields some interesting relationships.


#*Automated selection of measurements for pattern recognition
#@Robert Gary Leonard
#t1971
#c
#index196338


#*Fault Location in a Semiconductor Random-Access Memory Unit
#@V. P. Srini
#t1978
#cIEEE Transactions on Computers
#index353446
#!A semiconductor random-accessor memory (RAM) unit is a connection of RAM chips, data cable, chip select cable, and address cable so that each storage element can be selected for writing or reading independent of previous writes or reads. The faulty RAM unit is represented by a model consisting of four types of faults: stuck-at-0 or 1 fault on data cable, chip select cable, address cable, and storage elements in RAM chips, and a type of adjacent pattern interference fault in RAM chips. The testing of a RAM unit and locating faults to the RAM chips or wires in the various cables, when the RAM unit is part of a computer system, is considered. A set of six tests has been designed to diagnose the faults in the model. The sequence in which these tests have to be performed is determined. By using this sequence faulty components in a RAM unit are located when at most one type of fault in the model is present.


#*An approach to optimization of horizontal microprograms
#@M. Tsuchiya,M. J. Gonzalez, Jr.
#t1974
#cConference record of the 7th annual workshop on Microprogramming
#index550781
#%551608
#!Detection of concurrently executable microoperations is an important consideration for effective horizontal microprogramming. Since it is highly machine-dependent and requires knowledge of highly intricate features of a machine, only limited effort has been made so far to derive an algorithm for detection of microprogram parallelism to enable optimization of horizontal microprograms. In this paper, problems involved in optimization of horizontal microprograms are described. Existing techniques are applied to detect microprogram parallelism in a sequential source microprogram to allow subsequent optimization of the microprogram in a horizontal format. An algorithm for optimization of horizontal microprograms is derived. An upper bound for microprogram execution time is determined. The results derived in this paper are very general so that they are applicable to any machine with a horizontal microinstruction format (including a vertical format which is a special case of a horizontal format). An example is given to illustrate the algorithm.


#*An adaptive pattern recognition machine using neuron-like elements.
#@Wen-Chun Lin
#t1965
#c
#index190560


#*Analysis of Logic Circuits with Faults Using Input Signal Probabilities
#@K. P. Parker
#t1975
#cIEEE Transactions on Computers
#index352300
#!A probabilistic treatment of general combinational networks has been developed. Using the notions of the probability of a signal and signal independence, algorithms have been presented to calculate the probability of the output of a logic circuit being 1. Simplifications to the algorithm result when sets of input probabilities are given the same value, and this process called bundling is described in the paper. Finally, a series of examples illustrate the application of the probabilistic approach to the analysis of faulty logic circuits.


#*Realizing Boolean connectives on the IBM 1620
#@
#t1963
#cCommunications of the ACM
#index331531
#%318956
#%329450


#*Entwurf und Einsatz eines portablen RGU-Systems f&uuml;r die Lernersteuerung: LEGIS
#@Arndt Bode
#t1975
#cGI - 5. Jahrestagung
#index276088


#*Input/Output considerations in look-ahead processing
#@William M. Conner,Edward R. Dirling
#t1977
#cACM SIGARCH Computer Architecture News
#index116499
#%328811
#!The problems associated with input/output instructions in a look-ahead processing environment are discussed. The results of an empirical study which shows the detrimental effects of such instructions on the performance of a look-ahead central processor are presented.


#*Meditations on style
#@Stephen W. Smoliar
#t1976
#cACM SIGCSE Bulletin
#index547367
#%170184
#%316233
#%321170
#%593112
#!At the 1968 NATO Conference on Software Engineering,1 Edsger W. Dijkstra remarked that he found his position, as a teacher, analogous to that of a teacher of composition at a school of music. This paper wishes to pursue this analogy in greater detail. In particular, the role of style in computer science education is assessed in terms of the corresponding role it plays in music education.


#*Recent IC Announcements
#@
#t1975
#cComputer
#index339589


#*The logical structure of the memory resource in the symbol-2R computer
#@Hamilton Richards,Roy J. Zingg
#t1973
#cProceedings of a symposium on High-level-language computer architecture
#index301197
#%547360
#%311964


#*Session 12: the quality of computing
#@
#t1976
#cProceedings of the 4th annual ACM SIGUCCS conference on User services
#index251691


#*An Application of a Method for Analysis of Cyclic Prog rams
#@N. Francez
#t1978
#cIEEE Transactions on Software Engineering
#index345330
#!A parallel program, Dijkstra's "on-the-fly" garbage collector, is proved correct using analysis along the lines suggested by Francez and Pnueli for cyclic programs. The method is briefly reviewed, and the proof is compared to another proof by D. Gries, based on a method by S. Owickd. The differences between the two approaches are discussed.


#*Hierarchical modeling of operating system structure and behavior
#@William E. Riddle
#t1972
#cProceedings of the ACM annual conference - Volume 2
#index549936
#%206111
#%316233
#%323143
#%323203
#%335365
#%554308
#!This paper presents a scheme for the succinct modeling of computer operating systems. A software system may be viewed as a group of interdependent, asynchronously operating processes, and the scheme is oriented toward the description of the interconnections and interactions in such a representation. A concise but extensive description of a reasonably sophisticated supervisory system is presented as an example of the power of the modeling scheme. Since an integral part of the language is the ability to pass freely between rough descriptions (abstractions) of the system's organization and behavior and more detailed descriptions, models in the language can be used to advantage in gaining an understanding of the system. The language is of particular value during the design of a system, providing a tool to help the orderly evolution of the design and producing a description of the system that is significantly better than traditional documentation.


#*Applications of relational data structure models in man-machine systems
#@Robert C. Gammill
#t1972
#cProceedings of the ACM annual conference - Volume 1
#index245154
#%313683
#%334070
#%323984
#%326379
#!A character string manipulation language has been created, on a pilot study basis, in order to investigate the use of associative data structures in man-machine communication. The data structure, implemented by hash coding, is used to model the environment in which communication is carried out. Examples are given which indicate that much more flexible man-machine systems can be achieved through use of such models.


#*A design automation system for telephone electronic switching system
#@Frank E. Swiatek
#t1977
#cProceedings of the 14th Design Automation Conference
#index547503
#!An overview is given of the development and operation of a large computer-aided design (CAD) system for the physical realization and documentation of Electronic Switching Systems. The No. 4 ESS physical characteristics contain frames of equipment which include a large number of plug-in digital logic thin film circuit packs. An integrated computer support system with data base management control has been developed to assist in the design of such systems. Specifications for the CAD system were jointly established by user and programming teams. The CAD system is used in a hierarchial manner. Programs are executed to design and build data bases at the circuit pack level. These data bases then form the building blocks to progess to the next level of circuit pack electrical interconnection or frame level of design and documentation. Subsequent use of the frame level data base, together with a data base which describes the physical (geometric) relationship of circuit packs in the frame yields still another data base which contains backplane detailed wiring requirements. The entry of design changes and the data base management of the large number of data bases are accomplished by the formal application of data verification and check programs following each change transaction. The computer-aided system described herein has been a significant factor in the rapid development of No. 4 ESS. Cost and schedule effectiveness has been achieved. The benefits of computerized data generated from design inception through manufacturing and testing applications has been realized.


#*Algol 68 as an implementation language for portable interpreters
#@Frank G. Pagan
#t1977
#cProceedings of the Strathclyde ALGOL 68 conference
#index548188
#%321433
#!By making use of its advanced and highly expressive facilities, Algol 68 can be used to implement interpretive language processors with an unusual degree of conceptual clarity and machine independence. The internal representations of source programs in such a processor consist of high-level data structures which are interpreted by means of a set of readable, mutually recursive Algol 68 procedures. The technique is illustrated by applying it to the implementation of a miniature sample language. Efficiency considerations and aspects of the relevant programming methodology are discussed.


#*An on-line adaptive speaker-independent word recognition system based on acoustic-phonetic analysis and statistical pattern recognition techniques.
#@Kalyanasundaram Ganesan
#t1976
#c
#index204611


#*A scheduling model for computer systems with two classes of processors.
#@Richard Edwin Buten
#t1973
#c
#index206147


#*Computer-communication network routing: dynamic, minimum spanning time, routing technique.
#@Herbert Stanley Steelman, III
#t1976
#c
#index204986


#*Numerical precision and data structures
#@Werner Schenk
#t1978
#cProceedings of the SIGNUM Conference on the Programming Environment for Development of Numerical Software
#index553001
#%303237
#%307418
#!Group T9 of the ANSI Fortran Committee X3J3 has been assigned to study the areas of numerical precision, storage and data structures, with a goal of developing technical proposals and recommendations for future revisions of the Fortran standard. Developers and users of numerical software have proposed the addition of various functions to return the base of a computer system's number representation. Also desirable are features to enhance Fortran portability, such as single and double precision word lengths, and exponent ranges. Structured types proposed include arrays, records, sets and files.


#*An algorithm for a class of stochastic linear programming problems
#@John Philip Matthews
#t1971
#c
#index193969


#*Some problems associated with interactive graphics in computer mediated tutorials
#@J. C. Weber,D. J. Linden,W. W. Frayer,W. D. Hagamen
#t1972
#cProceedings of the 1972 SIGGRAPH seminar on Computer graphics in medicine
#index554818
#!Whether one is talking about the verbal or graphic aspects of a computer mediated tutorial, there are two prime considerations. (1) How easy is it for the medical teacher to input the information? (2) How closely does the interaction with the student approximate a free format tutorial? Our experience has gone through two distinct phases. For the first two years we worked with the IBM 1500 System and its associated language COURSEWRITER II (1). The 1500 has both a CRT with light pen and a random access, computer addressed, 35mm film strip projector. For the past two years we have been working with APL/360 and an IBM 2741 Communications Terminal with no graphic capabilities. Using APL we have developed a new (author) programming language called ATS (A Tutorial System) (2,3,4). Our purpose here today is to focus on the two aspects of a computer mediated tutorial already mentioned. Because of the nature of our personal experience, we would like to compare the problems (both the similarities and differences) associated with handling verbal and graphic input. The discussion will be divided into the following major topics. (1) A brief description of the 1500 System and our contributions to it. This work has been documented previously. (2) Interfacing the medical author with the computer. (3) Providing the machine with the intelligence to handle free format interactions with the student. (4) A word about encoding verbal and graphic information.


#*Constraint-type statements in programming languages
#@M. V. Wilkes
#t1964
#cCommunications of the ACM
#index313967
#%318294
#!A proposal is made for including in a programming language statements which imply relations between variables but which are not explicit assignment statements. The compiler sets up a Newtonian iteration making use for the purpose of a routine for formal differentiation.


#*Word processing services for a university: experiences at Stanford
#@J. Siegman,J. Sandelin
#t1979
#cProceedings of the 7th annual ACM SIGUCCS conference on User services
#index449530
#!Approaches to the technical, political, economic and human factors issues in planning and provision of word processing services for a university.While usage of word processing services at Stanford's computer center has continued to grow, the University has experienced a proliferation of commercial stand alone equipment. After over a year of guiding administrative offices and academic departments in selecting among the alternatives, the interdepartmental Committee on Office Systems and Technology (COST) is preparing a recommendation for a campus-wide system.


#*A class of real-time virtual memory systems: a multi-faceted approach to computer system design.
#@Philip Avery Johnson
#t1973
#c
#index206298


#*New use for computers in the user services environment
#@Kenneth F. Lini,David R. Love
#t1979
#cProceedings of the 7th annual ACM SIGUCCS conference on User services
#index443418


#*Effectively Giving Domains
#@M. B. Smyth
#t1975
#c
#index204010


#*A machine program for theorem-proving
#@Martin Davis,George Logemann,Donald Loveland
#t1962
#cCommunications of the ACM
#index319150
#!The programming of a proof procedure is discussed in connection with trial runs and possible improvements.


#*Notice from the editor concerning back issues
#@Peter Naur
#t1960
#cIssue 9 (March 1960)
#index103920


#*Rechnergest&uuml;tzte Automobilentwicklung: Von der Sylingidee zur Produktion
#@W. Lincke,H. G. Siepmann
#t1979
#cGI - 9. Jahrestagung
#index262863


#*Decision problems in compputation models
#@Mike Paterson
#t1972
#cProceedings of the International Sympoisum on Theoretical Programming
#index265047


#*An economical algorithm for the solution of elliptic difference equationsindependent of user-supplied parameters
#@Martin Allen Diamond
#t1972
#c
#index198858


#*A cost-priority scheduling system.
#@Shu-Kong Chao
#t1973
#c
#index189261


#*KINSYN: A minicomputer-based interactive mechanism design system
#@Andrew J. Rubel,Roger E. Kaufman
#t1976
#cProceedings of the 13th Design Automation Conference
#index553738
#%553654
#!An interactive graphical linkage design system is here described in text and captioned photos. This design system, KINSYN, is highly dependent on graphics for its man-computer interaction. Dialogue with the computer has been carefully devised to take best advantage of both human decision making and machine computational abilities. No computer expertise is required to use the system. KINSYN has capabilities for closed-form synthesis of four-link mechanisms and for numerical synthesis of linkages of most other topologies. It can analyze and animate pin and slider-jointed planar devices of nearly any topology.


#*A computer simulation approach to elevator system design
#@Alton J. Penz
#t1971
#cProceedings of the 8th Design Automation Workshop
#index548109
#!Computer simulation methods enable the architech to accurately analyze the performance of specified elevator systems, thus facilitating more careful evaluation of alternative system designs than previously achievable. Simulation improves analysis because it involves replication of real-time elevator performance and does not rely on the rules of thumb and statistical assumptions incorporated into traditional analytical methods. The development of a computer simulation program for elevators requires caution to ascertain that the assumptions incorporated into the program are satisfactory and that the resulting program performs reliably and accurately. An acceptable simulation program, such as the one presented in this paper, facilitates a variety of research efforts encompassing sky lobby and express car layout strategies, dynamic peak control procedures, and cost/benefit studies of system design goals.


#*Computer Society Bylaws Correction
#@
#t1977
#cComputer
#index347458
#!Two lines were inadvertently left out of Article VI, Section 8, of the bylaws which appeared in the December issue. Section 8 is reprinted in its entirety, with the additional material in italics. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Remarks on computer program for the construction of school timetables
#@B. A. Griffith
#t1966
#cCommunications of the ACM
#index319920
#%317302
#%319774
#%332273
#%327005


#*Late papers
#@
#t1972
#cProceedings of the ACM annual conference - Volume 2
#index552702
#!This section contains papers and position statements received too late to be incorporated in the session where they will be presented. For ease of reference they are listed under their presentation section as well as under this one.


#*Interprocessor connections--capabilities, exploitation and effectiveness.
#@Kuo Yen Wen
#t1976
#c
#index198994


#*Designing optimal file systems.
#@Barnet Charles Corwin
#t1973
#c
#index192166


#*A software tool for teaching Data Structures
#@John Beidler,John Meinke
#t1978
#cACM SIGCSE Bulletin
#index553111
#%162844
#!Our Data Structures Course, first taught in 1973, was originally conceived as the keystone course of our computer science curriculum. Our curriculum's original design was influenced by Curriculum '68 and the undergraduate computer science program at Penn State University. However, we had to adapt our program to our small college environment and include a curriculum track with a business emphasis. We felt that regardless of which track in our program a student might follow, theory/systems or business/DP, there must be a strong nucleus common to both tracks. For this reason we concentrated on developing four strong courses that would be given as the freshman and sophomore year component of our curriculum. As part of this, we also saw the need for software tools to support these courses. From this, a structured programming preprocessor evolved. However, as part of this preprocessor we included timing and dynamic storage allocation features. Through a strong emphasis on structured programming that begins with our first computer science course, our second course introduces many discrete structure concepts-queues, stacks, trees, graphs, etc... Our third course is a course in assembler level programming and computer organization. These courses provide a strong foundation for our Data Structures course.


#*A graphics operating system
#@Lawrence Koenigsberg,Jon A. Meads,John Shaw,Ned Thanhouser,Steven Vollum
#t1975
#cACM SIGGRAPH Computer Graphics
#index240560
#%153803
#%550003
#%546362
#%553408
#!Stand alone graphic systems and time-shared graphics provide different benefits to a user. The same is true of refresh graphics and storage displays. An operating system is described which supports these combined modes through the integration of graphics into the operating system. Realization of the role of the system, generality, and flexibility were the major factors in the development of the system. The result is a computer graphic system providing high-level interactive graphics at a relatively low cost.


#*Descriptive databases in some design/manufacturing environments
#@Edward Marlow Hoskins
#t1979
#cProceedings of the 16th Design Automation Conference
#index551505
#!In the development of substantial integrated computer-aided design systems, one of the most crucial features is the creation of purpose-made data structures. These have to be designed with growth and change in mind and in the course of the design process can reach a substantial size. They form the central source and design information about a particular product. They are used to generate drawings, assembly information schedules etc. for production purposes as well as being the data source and repository of results for integral analytical and detail design procedures. This paper outlines some of ARC's work in the creation, implementation and use of such data structures.


#*Linear algorithms to recognize interval graphs and test for the consecutive ones property
#@Kellogg S. Booth,George S. Lueker
#t1975
#cProceedings of seventh annual ACM symposium on Theory of computing
#index553945
#!A matrix of zeroes and ones is said to have the consecutive ones property if there is a permutation of its rows such that the ones in each column appear consecutively. This paper develops a data structure which may be used to test a matrix for the consecutive ones property, and produce the desired permutation of the rows, in linear time. One application of the consecutive ones property is in recognizing interval graphs. A graph is an interval graph if there exists a 1-1 correspondence between its vertices and a set of intervals on the real line such that two vertices are adjacent if and only if the corresponding intervals have a nonempty intersection. Fulkerson and Gross have characterized interval graphs as those for which the clique versus vertex incidence matrix has the consecutive ones property. In testing this particular matrix for the consecutive ones property we may process the columns in a special order to simplify the algorithm. This yields the interval graph recognition algorithm which is presented in section 2; section 3 indicates how this algorithm may be extended to the general consecutive ones problem.


#*A linguistic approach to parallelization of an acceptor for context-free grammars
#@Billy Ray Hays
#t1970
#c
#index202997


#*An Analytic and Experimental Study of Multiple Channel Controllers
#@A. J. Smith
#t1979
#cIEEE Transactions on Computers
#index353111
#!A multiple channel controller (MCC) is a controller which switches a given number of channels among a larger number of input/output devices and permits simultaneous access to as many devices as there are channels available. A simple queuing model for multiple channel controllers is created, and an approximate solution for this model is generated. The approximate solution is found, using simulation, to be very close for those cases examined to the actual behavior of the model. Further simulations indicate that the approximate solution of the model appears to be robust with respect to changes in some of the assumptions used in making the approximation. Trace data taken from a real system are analyzed and they confirm the predicted utility of MCC's. The problem of optimal scheduling of MCC's is briefly discussed. Alternative system configurations are compared with the objective of minimizing queuing delays.


#*The future of computer applications in the architectural profession
#@Gifford H. Albright
#t1971
#cProceedings of the 8th Design Automation Workshop
#index550385


#*A data base management modeling technique and special function hardware architecture.
#@Gerard Thomas Capraro
#t1978
#c
#index199432


#*OLLS: The On-Line Logical Simulation System
#@H. Robert Howie,Richard M. Tavan
#t1971
#cProceedings of the 8th Design Automation Workshop
#index549504
#!The &ldquo;On-Line Logical Simulation System&rdquo; (OLLS) is a complete software package which permits a logic designer to interactively design, layout and simulate large digital systems using the IBM 2250 CRT. The user communicates with OLLS through a set of interactive displays using the light-pen, keyboard and programmed-function buttons. The major subsystems include file handling, device definition, drawing manipulation, simulation and input-output. OLLS is unique in its freedom of device definition, generality and adaptability. Its major contributions to the design process are fast, precise system documentation and accurate logic simulation.


#*Functional distribution of Computer Based Messaging Systems
#@John R. Pickens
#t1979
#cProceedings of the sixth symposium on Data communications
#index545186
#%549609
#%551477
#!Computer Based Messaging Systems (CBMS) is a growing but complex application of computer networking technology. Though in its infancy, CBMS presents opportunities and challanges for research into the technology of distribution systems. In this paper a multi-layered model of CBMS is developed and detailed. At each layer an inventory of functions is presented, and tradeoffs are discussed. Options for packaging CBMS range from robust centralized schemes to highly distributed intelligent terminals supported by ancillary name/address binding services, etc. Much research in the functional distribution of the CBMS application is yet required, but the development of comprehensive models, such as that of this paper, is an important step in the design process.


#*Unlanguage Grammars and Their Uses
#@R. A. Fraley
#t1977
#c
#index192912
#!A new technique is presented for using context free grammars for the definition of programming languages. Rather than accumulating a number of specialized statement formats, generalized productions specify the format of all statements. A sample unlanguage grammar is presented, and the use of this grammar is described. Some of the difficulties in parsing the language are described.


#*Some experience in building portable software
#@Max Stern
#t1978
#cProceedings of the 3rd international conference on Software engineering
#index544892
#%325278
#!Several authors have discussed methodology for making software portable, but less has been written about the specific components of programs which are likely to be system-dependent. This paper is based on several years of successful experience in making a major software product (MARK IV) transportable among many operating systems and machines. The product is implemented in assembly language and developed on a single support system for all of the "target" systems. The specific strategies and conclusions presented here are based on more general principles, and should be more or less applicable to systems developed in higher-level languages. The system dependencies are isolated in as few modules as possible. Various techniques are used to include system-dependent code at assembly time, at installation tape creation time and at customer installation time. The system-dependent functions addressed by this paper are: program start and termination, input/output, primary storage management, interrupt control, checkpointing, module loading, overlay structures and object module format and other installation considerations.


#*Complex-foliated manifolds: a new proof of the foliated riemann-roch theorem and stability results in deformation theory
#@Alice Margaret Dean
#t1979
#c
#index193144


#*COGEL - Ein Computerunterst&uuml;tztes Lehrsystem f&uuml;r den Unterricht in Programmiersprachen
#@Rolf Langebartels
#t1974
#cRechner-Gest&uuml;tzter Unterricht, RGU '74, Fachtagung-ACU-Arbeitskreis Rechner-Gest&uuml;tzter Unterricht
#index562226


#*Storing a sparse table
#@Robert Endre Tarjan,Andrew Chi-Chih Yao
#t1979
#cCommunications of the ACM
#index313748
#%313888
#!The problem of storing and searching large sparse tables is ubiquitous in computer science. The standard technique for storing such tables is hashing, but hashing has poor worst-case performance. We propose a good worst-case method for storing a static table of n entries, each an integer between 0 and N - 1. The method requires O(n) words of storage and allows O(logn N) access time. Although our method is a little complicated to use in practice, our analysis shows why a simpler algorithm used for compressing LR parsing tables works so well.


#*MSL: a microprocessors systems language
#@Shamim A. Naqvi
#t1978
#cProceedings of the 16th annual Southeast regional conference
#index610601
#%319561
#%323067
#%335624
#%544931
#!MSL is a new high level language that was designed specifically to write systems programs for small computers. It is a structured language, providing a simple description of and operations on data structures for managing lists and resources. Basic functions are contained within the language for controlling cooperating processes. Higher level functions can be incorporated by extending the language through a simple macro capability. These features in conjunction with a clear and flexible language design makes for ease of programming and provides a conceptually clear framework to the systems programmer.


#*Design considerations for a computer-based clinical physiologic research system
#@Ronald W. Hagen,Lewis J. Thomas, Jr.,Janet A. Johnson
#t1976
#cProceedings of the 1976 annual conference
#index552686
#!Experience in the design of computer-based patient monitoring and clinical physiologic research systems is drawn upon to suggest some useful design strategies and architectural configurations for such systems. Emphasis is placed on flexibility as an over-riding consideration for research systems in contrast to the level of specialization appropriate to monitoring systems. The previously undescribed clinical-research system is detailed as necessary to show where differences in both hardware and software design strategies have been necessary and appropriate. Some engineering evaluation results are cited and a clinical evaluation will be reported.


#*Fast algorithms for np-hard problems which are optimal or near-optimal with probability one.
#@Routo Terada
#t1979
#c
#index199295


#*Comments on a paper by Wallace and Mason
#@William F. Heess, Jr.
#t1970
#cCommunications of the ACM
#index328400


#*Book review
#@John C. Cherniavsky
#t1979
#cACM SIGACT News
#index437675


#*A community/junior college view of curriculum '68
#@Frank W. Connolly
#t1973
#cACM SIGCSE Bulletin
#index551867
#!Q: What is a junior or community college? A: A college that offers two years of a four year undergraduate degree. Based on such an answer it would be assumed that the difference between a four-year and a two-year college is just that&mdash;one offers four years of education and the other only two. The assumption, however, fails to recognize two less obvious but major differences between the two types of institutions: educational objectives, and student population. Differences in these factors affect all areas of a college including curricula offerings and faculty selection. For purposes of this discussion we will examine these two factors (educational objectives and student population) only in terms of computer related curricula.


#*The selection of acoustic features for text-independent speaker recognition.
#@Ronald Sang-Nam Cheung
#t1978
#c
#index195814


#*Standard Specification for S-100 Bus Interface Devices
#@K. A. Elmquist
#t1979
#cComputer
#index393392
#!This proposed standard eliminates many of the problems in the S-100 bus and upgrades it for 16-bit microprocessors. It is offered here for public comment before submission to the IEEE Standards Board.


#*Free-text inputs to utility routines
#@B. I. Blum
#t1966
#cCommunications of the ACM
#index332507
#%326719


#*A testing strategy for PLAs
#@Charles W. Cha
#t1978
#cProceedings of the 15th Design Automation Conference
#index548242
#!Programmable Logic Arrays (PLA) are finding increasing use as a cost-effective means to utilize LSI electronics. In this paper, three classes of faults, namely stuck faults, shorts and cross-point defects are defined and characterized in a PLA. The relationship between the test sets and their faults among all three classes are discussed. Finally, an algorithm for generating a test set for all three classes of faults is presented.


#*Accelerating information delivery
#@Don S. Culbertson,Dennis Elchesen,Mary Ann Swanson,Frederick G. Kilgour,Russell Shank
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index70514
#!Purpose: To describe using three example institutions, the potential size and scope of the library market for computers, peripheral units and specially designed software. There are literally thousands of libraries in the U.S.; public school, special, college, medical and law. Until recently only the largest institutions with large computer facilities and foundation grants have been able to develop the custom made systems to tend to the library housekeeping, handle enormous inventories of books, index files of journal articles, notify users of items available as fast as they are published, and search the small segment of the world's knowledge which is in machine readable form.


#*A technique for handling macro instructions
#@Irwin D. Greenwald
#t1959
#cCommunications of the ACM
#index323289


#*Automatic enumeration and evaluation of certain multiprocessor design alternatives
#@Tony Middleton
#t1977
#cACM SIGMICRO Newsletter
#index4084
#%308694
#!Quite often, a designer has to chose from several alternative ways of achieving the same end. When the number of alternatives is very large, it is useful to have an "analyser" available which will mechanically enumerate the alternatives and assign a cost to each one - finally identifying the best alternative. The author has already produced such an analyser for serial programs [1, 2]. The intention of this paper is to suggest that the approach used in this earlier work can be of relevance to the design of systems involving several processors (in particular, pipelines which are in a steady state). The analyses used are very approximate, but should be sufficient to select, from a large number of alternatives, the few alternatives which warrant detailed study (e.g. by precise simulation).


#*Evaluation and performance of computers: interaction of hardware and software parameters in tape operations
#@W. B. Edwards, Jr.
#t1965
#cProceedings of the 1965 20th national conference
#index547151
#!THE PRIMARY REASON for specifying increased capabilities in tape transports is, ostensibly, to improve the system performance in some manner, such as: (a) - storage capacity; (b) - access time/transfer rate; and (c) - error incidence and severity. The currently familiar NRZI tape transports are available in a wide variety of characteristics. Tape speeds vary from 3 to 150 ips, recording densities from 200 to 1100 bpi, and tape lengths up to 6200 feet. The performance obtained from a tape transport in an operational atmosphere depends to a large extent upon the interplay between the hardware parameters and the software characteristics. It is the purpose of this paper to explore these interactions and their influence upon the system performance.


#*A Citation Study of the Computer Science Literature
#@Gerard Salton,D. Bergmark
#t1979
#c
#index124949
#!The bibliographic references and citations which exist between documents in a given collection environment can be used to study the history and scope of particular subject areas and to assess the importance of individual authors, documents, and journals. A clustering study of the computer science literature is described using bibliographic citations as a clustering criterion, and conclusions are drawn regarding the scope of computer science, and the characteristics of individual documents in the area.


#*Introduction
#@P. O. Pistilli
#t1964
#cProceedings of the SHARE design automation workshop
#index552182


#*Programming semantics for multiprogrammed computations
#@Jack B. Dennis,Earl C. Van Horn
#t1966
#cCommunications of the ACM
#index322720
#%551103
#%334158
#%333166
#!The semantics are defined for a number of meta-instructions which perform operations essential to the writing of programs in multiprogrammed computer systems. These meta-instructions relate to parallel processing, protecting of separate computations, program debugging, and the sharing among users of memory segments and other computing objects, the names of which are hierarchically structured. The language sophistication contemplated is midway between an assembly language and an advanced algebraic language.


#*A lightpen-controlled program for online data analysis
#@John B. Goodenough
#t1965
#cCommunications of the ACM
#index329841


#*NUL: a Navigational User's Language for a network structured data base
#@Claude Deheneffe,Henri Hennebert
#t1976
#cProceedings of the 1976 ACM SIGMOD international conference on Management of data
#index614163
#%317767
#%326368
#%332170
#%548941
#!This paper presents an end-user's language which tries to solve the problem of an easy navigation through a DBTG-like data base structure. A request is expressed in a nonprocedural and hierarchically structured fashion. The dialogue is split into two main parts : first a data context definition, then the manipulations of this context.A context is a part of the data base that the user is concerned with. A context definition is formed by a set of labelled lines; each line is a condition declaration on one entity-set. By means of labels and link names declared in the data structure, a line may be connected to another one; this expresses a 'join', by the named link, between the two entity-sets involved in the two lines.The originality of the language lies in the fact that it permits the user to navigate easily and fairly naturally from one entity-set to another through a link; in fact, this navigation is mapped into a hierarchical structure which appears more comprehensible to the user.On the other hand, a manipulation is a command such as print, update, insert or other standard actions the user may want to execute on the context.


#*COMPUTER-TUTOR: From a student project to a self-paced CAI/CMI course
#@William H. Linder
#t1976
#cACM SIGCSE Bulletin
#index555256
#!COMPUTER-TUTOR is a software package that presents interactively a self-paced, competency-based course in elementary FORTRAN programming. It developed from a project in a course where students design and implement a large-scale programming application. A COMPUTER-TUTOR course, presented on a PDP11/45, consists of nine modules-each module having a lesson, quiz, and programming assignment. A student must pass the quiz in a course-module before going on to the next module. The course grade depends on the number of modules completed. The student-commands LESSON, QUIZ, PROGRAM, OUTLINE, REVIEW, and INFORMATION bring the instructional material (CAI). The instructor uses eight support commands to monitor student progress and course material. COMPUTER-TUTOR will next be expanded to include courses in BASIC and COBOL.


#*The design and performance of a database computer.
#@Krishnamurthi Kannan
#t1977
#c
#index205628


#*A method for computing regression coefficients utilizing incomplete observations
#@Cornelius James Lynch
#t1972
#c
#index187765


#*The design and construction of numerical harmonics.
#@James Edward Perry
#t1974
#c
#index187665


#*Scheduling with Memory Allocation in Multiprocessing Systems
#@Jan Weglarz
#t1976
#cProceedings of the International Workshop organized by the Commision of the European Communities on Modelling and Performance Evaluation of Computer Systems
#index260528


#*Artificial Patterns
#@A. Klinger
#t1977
#cIEEE Transactions on Software Engineering
#index343869
#!This paper deals with obtaining a data base for test and evaluation of large software systems, when at most, only a few typical pattern instances are available. Data structure variation is proposed and demonstrated for some simple images. Relationships to fundamental concepts in computer science methodology are discussed.


#*Boolean matrix multiplication using only O(nlog27 log n) bit operations
#@Kellogg S. Booth
#t1977
#cACM SIGACT News
#index435032


#*A system organization for resource allocation
#@D. M. Dahm,T. H. Gerbstadt
#t1967
#cCommunications of the ACM
#index329194
#%327006
#!This paper introduces a system for resource management using the concepts of &ldquo;process,&rdquo; &ldquo;facility,&rdquo; and &ldquo;event.&rdquo; Except for the processor no attempt has been made to give serious suggestions for the policy to be followed for resource allocation. However, a basic framework is provided in which a system analyst can express solutions to resource management problems. The paper is divided into a tutorial presentation, a description of the system primitives, and a small collection of examples of the use of the primitives.


#*Einf&uuml;rung in den Kongress aud der Sicht der VDI / VDE - Gesellschat Mess- und Regelungstechnik
#@Marl Otto Winkler
#t1974
#cGFK-GI-GMR Fachtagung Prozessrechner 1974
#index275945


#*A multiprocessing system for the direct execution of LISP
#@Rhon Williams
#t1978
#cProceedings of the fourth workshop on Computer architecture for non-numeric processing
#index553868
#%197086
#!Current implementations were found to be impractical for airborne use due to LISP's incompatability with conventional computer architectures. Direct execution of LISP with tasks distributed between three processors, seemed to be a workable solution. The language was analyzed, and a special token was devised, using a descriptor with a single pointer. Through careful distribution of responsibilities, control and data flow between the processors was minimized. Significant memory savings resulted from ASCII storage and real time garbage collection. A simulation was used to help estimate execution times and showed a factor of 50 to 100 increase in speed. Thus, through the direct execution of LISP by a multiprocessing system, Computer-Aided Decision-Making could be implimented to enhance the safety of flight operations.


#*Effective information retrieval using term accuracy
#@C. T. Yu,G. Salton
#t1977
#cCommunications of the ACM
#index318136
#!The performance of information retrieval systems can be evaluated in a number of different ways. Much of the published evaluation work is based on measuring the retrieval performance of an average user query. Unfortunately, formal proofs are difficult to construct for the average case. In the present study, retrieval evaluation is based on optimizing the performance of a specific user query. The concept of query term accuracy is introduced as the probability of occurrence of a query term in the documents relevant to that query. By relating term accuracy to the frequency of occurrence of the term in the documents of a collection it is possible to give formal proofs of the effectiveness with respect to a given user query of a number of automatic indexing systems that have been used successfully in experimental situations. Among these are inverse document frequency weighting, thesaurus construction, and phrase generation.


#*Modeling of a Bubble-Memory Organization with Self-Checking Translators to Achieve High Reliability
#@W. G. Bouricius
#t1973
#cIEEE Transactions on Computers
#index345565
#!This paper reports a study on the design and modeling of a highly reliable bubble-memory system. This system has the capability of correcting a single 16-adjacent bit-group error resulting from failures in a single basic storage module (BSM), and detecting with a probability greater than 0.99 any double errors resulting from failures in BSM's. The encoding/decoding network (memory translator) is designed to be self-checking, i.e., a single circuit failure in the translator wiH not produce an erroneous output that goes undetected. The system is able to perform reliable configuration in the event of uncorrectable BSM failures, memory translator failures, and dual-memory buffer failures; even in the presence of a single failure in the status registers controlling the configuration network. The bubble memory under study permits serial accessing of the store with 64 x 1024 bit blocks at a 100-kHz rate. The objective of this study is to develop good fault-tolerant design and analysis methods adequate for newly emerging technologies and prove the practicality by example. The reliability modeling study justifies the design philosophy adopted of employing memory data encoding and a translator to correct single group errors and detect double group errors to enhance the overall system reliability. By a proper design of the memory translator based on a new checking technique, a uniformly high percentage of multiple b-adjacent bit-group error detection is achieved through the use of a proposed code (detects 99.99695 percent of double b-adjacent bit-group errors and 99.9985 percent of triple or more b-adjacent bit-group errors).


#*Computers and testing, a new application
#@Jack H. Rhine, Jr.
#t1976
#cProceedings of the 4th annual ACM SIGUCCS conference on User services
#index247465


#*Vancouver regional health planning model
#@J. Milsum,D. Uyeno,I. Vertinsky,H. Will
#t1971
#cProceedings of the 5th conference on Winter simulation
#index546506
#!An aggregate simulation model of the health care system existing in Vancouver, Canada has been created as part of a multi-purpose regional simulation project. The model requires data on population trends, morbidity, health resource trends. Under a variety of possible policies (ZPG, for example) the effects in terms of surpluses and shortages of resources, untreated cases, and a scale of social impact attributable to Holmes are delineated over a n-year horizon. The results are intended to provide policy-makers with contingency forecasts for priority assignment, resource formation, and demand-resource matching.


#*Computer modelling of urban air quality using adaptive pattern classification
#@Ronald Edward Ruff
#t1971
#c
#index201048


#*Scientific and business applications
#@William H. Anderson
#t1959
#cCommunications of the ACM
#index332651


#*Proposals for Fortran data structures
#@David N. Smith
#t1977
#cACM SIGPLAN Notices
#index301840
#!Three proposals for extensions to the Fortran language for data structuring are made. The first is similar to the STRUCTURE statement of IBM Fortran H [1]; no processor storage allocation function is required. The second is a variation of Hoare records [2] and the third is a variation of PL/I structures [3]. These three illustrate various posibilities and are hoped to be a basis for discussion of requirements which will lead to structuring facilities in the proposed Fortran standard. [4,6,7]


#*Pattern Recognition Data Bases
#@
#t1977
#cComputer
#index336284


#*On reversible subroutines and computers that run backwards
#@E. D. Reilly, Jr.,F. D. Federighi
#t1965
#cCommunications of the ACM
#index318876
#!A computer design is described which permits subroutines to be executed backward as well as forward, either with their instructions unchanged or replaced with conjugate instructions. It is shown that using this concept a number of new subroutine types can be developed with rather unusual properties. Since these properties are analogous to certain matrix operations, a arallel nomenclature is suggested for their classification.


#*Algorithm 214: q-Bessel functions In(t)
#@J. M. S. Simões Pereira
#t1963
#cCommunications of the ACM
#index330180


#*Scheduling Parallel Processable Tasks for a Uniprocessor
#@C. V. Ramamoorthy
#t1976
#cIEEE Transactions on Computers
#index337382
#!Recent advances in multiprogramming have been concentrated on multiprocessor systems. But overlap in operations is also permissible in uniprocessor systems in which the processor instruction execution and input-output operations are handled by separate units. By maximizing the processor and input-output overlap, a program can be executed faster while the system utilization is highly improved.


#*A network model of the U. S. air transportation system
#@Aurel N. de Hollan,Arthur S. Priver,Andres Zellweger
#t1971
#cProceedings of the 5th conference on Winter simulation
#index548701
#%329679
#!A basic conceptual simulation of the entire Air Transportation System was developed to serve as an analytical tool for studying the interactions among the System elements. The simulation is designed to function in an interactive computer graphics environment which permits rapid alteration of rules and parameters, as well as continuous real-time graphical monitoring of system operations. The simulation described here is the first member in an evolving hierarchy of increasingly complex models, progressing in the direction of closer approximation to the real-world Air Transportation System.


#*Data conversion and restructuring
#@
#t1977
#cProceedings of the 1977 ACM SIGMOD international conference on Management of data
#index619507


#*Analyse eines Modells zur EA-Steuerung
#@Wolfram Dolken
#t1979
#cGI - 9. Jahrestagung
#index262309


#*Universal System Diagnosis Algorithms
#@J. E. Smith
#t1979
#cIEEE Transactions on Computers
#index347759
#!A class of simple digital system diagnosis algorithms is presented, and two members of the class are examined in detail. The algorithms are based on the assumption that good units can be replaced during the diagnosis process. Information pertaining to the system testing structure is not used by the two principal algorithms, so they can be applied regardless of system structure. The efficiency of the algorithms in terms of good units replaced is analyzed, and they are shown to compare favorably with methods for special case systems that have been proposed by others.


#*Apl*ds: an apl based hardware description and simulation system at register transfer level.
#@Radu Dumitru Balaci
#t1978
#c
#index191376


#*Groups and subgroups, presentations and representations
#@John McKay
#t1971
#cProceedings of the second ACM symposium on Symbolic and algebraic manipulation
#index546706
#!A survey of some computational techniques available to the finite group theorist and a description of several outstanding problems in which the computer may prove helpful.


#*Sensitivity of integrated voice and data networks to traffic and design variables
#@I. Gitman,B. Occhiogrosso,W. Hsieh
#t1979
#cProceedings of the sixth symposium on Data communications
#index554777
#!This paper presents quantitative results of cost/performance studies of circuit-switching, packet-switching, and hybrid (circuit/packet) switching technologies. The results expose the cost difference for alternative realizations and usage of a given network technology.


#*On complement division
#@Marvin L. Stein
#t1971
#cCommunications of the ACM
#index317643
#%329817


#*Experiments with the M N tree-searching program
#@James R. Slagle,John K. Dixon
#t1970
#cCommunications of the ACM
#index321652
#%188430
#%445001
#%553721
#%544780
#%616306
#%325824
#!The M N procedure is an improvement to the mini-max backing-up procedure widely used in computer programs for game-playing and other purposes. It is based on the principle that it is desirable to have many options when making decisions in the face of uncertainty. The mini-max procedure assigns to a MAX (MIN) node the value of the highest (lowest) valued successor to that node. The M N procedure assigns to a MAX (MIN) node some function of the M (N) highest (lowest) valued successors. An M N procedure was written in LISP to play the game of kalah, and it was demonstrated that the M N procedure is significantly superior to the mini-max procedure. The statistical significance of important conclusions is given. Since information on statistical significance has often been lacking in papers on computer experiments in the artificial intelligence field, these experiments can perhaps serve as a model for future work.


#*The network Unix system
#@Gregory L. Chesson
#t1975
#cProceedings of the fifth ACM symposium on Operating systems principles
#index547839
#%324042
#!A Network Interface Program (NIP) is that part of an operating system which interfaces with similar entities in a network. Normally, the NIP is a collection of software routines which implement interprocess communication, interhost protocols, data flow controls, and other necessary executive functions. This paper discusses the organization of the NIP currently being used with the Unix operating system on the ARPA network. The Network Unix system is noteworthy because of the natural way that network and local functions are merged. As a result the network appears as a logical extension to the local system - from the point of view of both the interactive terminal and user program.


#*Rank-Augmented LU-Algorithm for Computing Generalized Matrix Inverses
#@S. K. Sen
#t1974
#cIEEE Transactions on Computers
#index352072
#!A rank-augmnented LU-algorithm is suggested for computing a generalized inverse of a matrix. Initially suitable diagonal corrections are introduced in (the symmetrized form of) the given matrix to facilitate decomposition; a backward-correction scheme then yields a desired generalized inverse.


#*On the Design of a Language for Programming Real-Time Concurrent Processes
#@H. A. Schutz
#t1979
#cIEEE Transactions on Software Engineering
#index338468
#!ILIAD is a high-evel language for programming real-time applications which involve concurrent processing. It was designed to help scientists and engineers write reliable programs that can be read and maintained. An ILIAD program consists of a group of concurrent tasks. The tasks are autonomous and must cooperate in using the shared memory and devices in the execution environment. The language has facilities for providing secure access to these resources and for creating and synchronizing parallel instruction streams. In providing an overview of the language, the factors motivating the major design choices are discussed. A programming example illustrates how ILIAD might be applied. An assessment of the language includes a discussion of potential problem areas, both technical and nontechnical.


#*Algorithm 414: Chebyshev approximation of continuous functions by a Chebyshev system of functions
#@G. H. Golub,L. B. Smith
#t1971
#cCommunications of the ACM
#index322704
#%318526
#!The second algorithm of Remez can be used to compute the minimax approximation to a function, &fnof;(x), by a linear combination of functions, {Qi(x)}n0, which form a Chebyshev system. The only restriction on the function to be approximated is that it be continuous on a finite interval [a,b]. An Algol 60 procedure is given, which will accomplish the approximation. This implementation of the second algorithm of Remez is quite general in that the continuity of &fnof;(x) is all that is required whereas previous implementations have required differentiability, that the end points of the interval be &ldquo;critical points,&rdquo; and that the number of &ldquo;critical points&rdquo; be exactly n + 2. Discussion of the method used and of its numerical properties is given as well as some computational examples of the use of the algorithm. The use of orthogonal polynomials (which change at each iteration) as the Chebyshev system is also discussed.


#*The status and future of APL (Panel Discussion)
#@Roberson Higgins
#t1969
#cProceedings of the conference on APL
#index555134
#!We at Binghamton intend, at least for ourselves (and I believe Alberta at least expressed this interest) to abstract whatever we have that we feel we would be proud enough to make available to other people in printed form. We would hope by somewhere in early September, at the latest, that we would have available such printed documentation that we would mail to other users. I hope other people would do the same, because I, for one, see some practical problems in terms of accessing other people's facilities. Then at the SHARE Conference we hope to come up with a more formal mechanism. Somebody objected to a committee analyzing this, and I think we decided to call it a forum. We will see how that works out. These are my closing remarks. I again want to welcome everybody here, and I hope you have enjoyed this conference, and now we can get on to our last discussion.


#*Laboratory control language: a laboratory automation system.
#@Charles Richmond Garthwaite
#t1976
#c
#index198672


#*The PDP-11: A case study of how not to design condition codes
#@Robert D. Russell
#t1978
#cProceedings of the 5th annual symposium on Computer architecture
#index552265
#%116302
#%302687
#%319907
#%544735
#%547021
#!This paper investigates a design weakness in the PDP-11 architecture, namely the condition code bits. Experience with the machine has demonstrated a number of &ldquo;traps&rdquo; for the unwary programmer stemming directly from an inconsistent and sometimes confusing scheme of condition code settings. This is particularly annoying in view of the otherwise clean architectural characteristics of the machine. A number of &ldquo;principles&rdquo; are proposed that would correct the deficiencies and could therefore be used as a guide for designing future machines. The paper also presents some measurements based on actual programmatic usage of the PDP-11 that question the validity of a condition code scheme as an efficient architectural technique.


#*Infotech International Presents Michael Jackson
#@
#t1976
#cComputer
#index343970


#*Convergence of the Q-R algorithm for Hessenberg matrices
#@Beresford Parlett
#t1966
#cCommunications of the ACM
#index330854


#*Computation of Legendre series coefficients
#@Robert Piessens
#t1974
#cCommunications of the ACM
#index329380
#%314429
#!LEGSER approximates the first N + 1 coefficients Bn of the Legendre series expansion of a function &fnof;(x) having known Chebyshev series coefficients An. Several algorithms are available for the computation of coefficients An of the truncated Chebyshev series expansion on [-1, 1] &fnof;(x) &sime; &sum;&prime;Nn=0 AnTn(x), (1) where &sum;&prime; donotes a sum whose first term is halved. The commonly used algorithms are based on the orthogonal property of summation of the Chebyshev polynomials [1]. The application of the analogous property of the Legendre polynomials for the calculation of the coefficients Bn of the expansion &fnof;(x) &sime; &sum;Nn=0 BnPn(x) (2) is less suitable for practical use since it requires the abscissas and weights of the Gauss-Legendre quadrature formulas [2].


#*Teaching &ldquo;about programming&rdquo;
#@Robert F. Rosin
#t1973
#cCommunications of the ACM
#index326637
#%79620
#%309262
#%330452
#%329737
#%335365
#!This paper presents the goals and organization of a course about programming designed to provide entering students in a graduate program with a cultural enrichment in their professional lives. The students are expected to have taken at least two programming courses prior to this one and, therefore, to be familiar with at least two programming languages, both as students and users. Teaching someone how to program is similar to teaching him to play a musical instrument: neither skill can be taught&mdash;they must be learned. However, the teacher still serves several vital purposes: to present a set of rules for producing well-formed utterances; to offer numerous demonstrations of his own skill; and to function as an involved critic. Finally, the teacher is the source of information about the process in which the student is involved.


#*Man-machine referential communication in a personal information retrievalsystem
#@William Erwin Linn, Jr.
#t1972
#c
#index201111


#*On the Steady State Properties of Networks of Queues
#@F. P. Gomez
#t1972
#c
#index188832


#*A simple technique for controlled on-line system stimulation
#@Thomas E. Bell,Jo Ann Lockett
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index62643
#%551676
#%67066
#%66207
#%318875
#!Most performance analysis tools are developed with the objective of providing data in a general way, using flexible techniques, with confidence that analysts will subsequently employ them in cost/effective procedures. The inadequacy of this approach is reflected by the frequency of questions about which data to collect and how to use them. The problem is the initial emphasis on tools as an end in themselves rather than on analysis techniques.


#*A computer science option in industrial engineering
#@Dennis B. Webster,Victor A. Zaloom
#t1973
#cProceedings of the third SIGCSE technical symposium on Computer science education
#index549124
#%314806
#!This paper is concerned with the justification and development of a computer science option which has been approved for inclusion within Auburn University's Industrial Engineering curriculum. From a specification of many of the areas covered by the field of industrial engineering, it became clear that the use of the computer is an integral part of the industrial engineer's work. An analysis of the courses thought to be most useful to an industrial engineer further indicated that such courses fell into a logical sequence from which a minor area of competence in computer science could be developed. The courses comprising the option are presented by means of a precedence diagram which indicates suggested course sequencing. Also presented is the Auburn Industrial Engineering program with the embedded computer science minor.


#*Stuctured Programming at McAuto
#@C. E. Holmes
#t1975
#cComputer
#index352334
#!The history of structured programming at McDonnell Douglas Automation could be divided into two ages or eras: BC and AD. BC represents Before Clarity and AD represents After Discernment. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*An approach for a working relational data system
#@Brian Jervis,James L. Parker
#t1972
#cProceedings of 1972 ACM-SIGFIDET workshop on Data description, access and control
#index548715
#%326368
#!Users of large data bases and applications programs which access them must be prevented from having to know how the information they access is organized internally. On the other hand, systems programmers must be allowed to arrange the data base in some way which is both natural and convenient to them. This paper proposes a system which acts as an interface between a user or an applications program, and a data base which consists of multiple files of differing types. The system handles all requests for data, and returns the results in a standard way. The most important feature of this system is that it presents a standard view of data that is highly independent of its machine representation.


#*Effectiveness of instructional tapes for changing regional speech patterns
#@Ruth William Isbell Golden
#t1969
#c
#index196719


#*R68-51 The Design of an Automatic Patching System
#@G. Hannauer
#t1968
#cIEEE Transactions on Computers
#index352345
#!"Getting rid of the patchpanel" has long been the dream of analog computer users (and designers). Besides the aesthetic value of eliminating "all those messy wires," there are the more substantial advantages of shortened turnaround time, long-term low-cost problem storage and greatly simplified programming. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Microprogramming: The bridge between Hardware and Software
#@J. M. Galey
#t1975
#cComputer
#index335760
#!In the past decade, microprogramming has changed from a machine implementation process for large computing devices to a widespread design practice covering the full spectrum of machines as measured by their size, performance, and cost.


#*The INGRES protection system
#@Michael Stonebraker,Peter Rubinstein
#t1976
#cProceedings of the 1976 annual conference
#index547588
#%549071
#%548941
#%548461
#%554073
#!This paper presents the design of a protection system being implemented for the INGRES relational data base management system. A brief description of the INGRES system and its operational environment is first presented to provide the setting for the protection scheme. Mechanisms for protecting physical data files and enforcing sophisticated access control rules for shared relations are then presented. Lastly, the important design decisions concerning protection are discussed.


#*Algorithm 115: Perm
#@H. F. Trotter
#t1962
#cCommunications of the ACM
#index314633


#*The Assertion Table System for the PL/CV2 Program Verifier
#@Dean B. Krafft
#t1978
#c
#index113115
#!A system to implement the block structured storage of PL/CV2 assertions is described. The system allows certain simple logical deductions to be performed automatically. These include deductions involving propositional reasoning, associativity and commutativity of arithmetic operators, and reasoning about equality. The implementation is described at a conceptual level.


#*Algorithm 460: calculation of optimum parameters for alternating direction implicit procedures
#@Paul E. Saylor,James D. Sebastian
#t1973
#cCommunications of the ACM
#index323960


#*Reliability modeling techniques for self-repairing computer systems
#@W. G. Bouricius,W. C. Carter,P. R. Schneider
#t1969
#cProceedings of the 1969 24th national conference
#index546218
#!This paper develops techniques for generating and using mathematical models applicable to architectural evaluation of the tradeoffs involved in designing self-repairing highly reliable computers for long missions. These systems must use standby sparing and their reliability is shown to be extremely sensitive to small variations in a new design parameter, the coverage, c, defined as the probability of system recovery given the existence of a failure. Interactive terminal calculations show c to be the single most important parameter in high-reliability system design. Changing the coverage from 1 to .98 can result in orders of magnitude change in system mission time with a specified reliability. Most techniques for increasing system reliability (e.g. adding more spares) are shown to be futile in the face of an inadequate .99 coverage. Adding checking, diagnostics, etc. to improve failure coverage is shown to be the most advantageous technique by examples of system tradeoff evaluation. This mandates extensive application of modeling techniques throughout all computer system design phases.


#*Interim report on bureau of ships COBOL evaluation program
#@Milton Siegel,Albert E. Smith
#t1962
#cCommunications of the ACM
#index319310


#*From the recursive function theory newsletter
#@Howard P. Katseff
#t1978
#cACM SIGACT News
#index436111


#*Computer facility: Starter kit
#@Robert H. Randolph
#t1975
#cProceedings of the fifth SIGCSE technical symposium on Computer science education
#index545432
#!The purpose of the discussion that follows is to shed some light on the mystical process of buying a computer. The problem of computer acquisition is often approached from a very rational, very scientific perspective with lots of charts, graphs, comparisons and rating scales. Sometimes the original intent of the effort can get lost in the piles of data. What I hope to do here is to augment or clarify this super rational approach (which certainly has its place) with some practical, down to earth common sense. At the very least, what I am advocating could certainly become the basis for a more elaborate scientific approach. In order to keep things simple, I have looked at the problem of computer acquisition in terms of (1) some thinking, (2) some planning, (3) and a lot of doing.


#*Use of simulation to test the validity and sensitivity of an analytical model
#@Prosper M. Bernard
#t1973
#cProceedings of the 6th conference on Winter simulation
#index545070
#%205792
#!The purpose of the research reported here was to test formally the validity of some assumptions made in solving models by analytical techniques and to test the sensitivity of the system to the arrival distribution. The presentation refers to a simplified real-time model. The analytical solution in the literature is to derive shown results for each stage of the system and add them up to obtain the behavior of the system. Assumptions must then be made at each stage. Simulation has been used to solve the same system in terms of the same measure of efficiency, i. e. the response time. However, the system is solved as a whole, the output from one stage becoming the input to the second stage. Confidence limits have been obtained for the response time in order to test the results obtained from analytical techniques. Simulation has also been used to test the sensitivity of the system to a change in the arrival distribution. Using analysis of variance, the effect of the arrival pattern and of the interaction is determined.


#*Ordered types and a generalized <u>for</u> statement
#@Harvey Abramson
#t1977
#cACM SIGPLAN Notices
#index308257
#%79620
#%240173
#!An ordered type is a data structure together with predecessor and successor procedures and a relation defined over pairs of elements of the ordered type. A generalized for statement which uses the procedures connected with an ordered type is introduced. This allows ordered types to be used to control statement iteration in programs.


#*Multiple byte processing with full-word instructions
#@Leslie Lamport
#t1975
#cCommunications of the ACM
#index327464
#!A method is described which allows parallel processing of packed data items using only ordinary full-word computer instructions, even though the processing requires operations whose execution is contingent upon the value of a datum. It provides a useful technique for processing small data items such as alphanumeric characters.


#*A probability computing receiver
#@Raymond Keith Masnaghetti
#t1958
#c
#index203625


#*Some thoughts on associative processing languages
#@William W. Patterson
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index73621
#!Much effort has been expended in developing array and associative processors (AP's). The most notable of the former are Burroughs' ILLIAC IV and Honeywell's PEPE, while the present representative of the latter technology is the STARAN built by Goodyear Aerospace Corp. However, very little has been published on higher order languages which take advantage of the unique characteristics of these architectures. There is at least one effort to develop techniques which will extract the parallelism in ordinary FORTRAN code, as well as a number of efforts to formally describe the parallelism in algorithms. Examples are in References 2 and 3. It is true that many algorithms can be put into efficient parallel code using these techniques; however, there is a large body of problems which must be reexamined and recast into new algorithms which match the parallelism of the machine to the natural parallelism of the problem. These new algorithms will require a new language which gives the programmer the flexibility to use the features of the machine directly. The PFOR language developed for PEPE is probably the only existing language for an array processor, and some preliminary work for the RADC AP project is the only published attempt on AP languages. This paper will look at associative processing from the point of view of a programmer who has tried to write programs for an AP, and therefore will propose constructs which are convenient for the programmer and not necessarily for the compiler writer. They do, however stem from a reasonable knowledge of the basic architecture of the AP, and hence will tend to parallel it.


#*More fuel for the goto controversy
#@B. N. Dickman
#t1974
#cACM SIGPLAN Notices
#index305872


#*Syntactic and semantic augments to ALGOL
#@Joseph W. Smith
#t1960
#cCommunications of the ACM
#index330025
#%327309
#!The purpose of this paper is to propose a set of syntactic and semantic augments to ALGOL. The proposed extension are designed to facilitate the description of &ldquo;string&rdquo; manipulation in that language; they do not constitute a comprehensive language for symbol manipulation. Several such languages (LISP, IPL, &hellip;) already exist&mdash;many more will be designed and advantageously used in the future. It is felt that such languages belong in the repertoire of some language-system which contains a hierarchy of languages as well as nested &ldquo;continua&rdquo; of languages. In such systems, new languages may be embedded, appended, extracted at will. The fact that ALGOL is, implicitly, such a language-system seems to be only dimly recognized, even by designers. In any event, what is proposed in the sequel is not a language for symbol manipulation&mdash;qua language; but rather, a set of obvious extensions to the &ldquo;algebraic-language&rdquo; portion of ALGOL. To be sure, these extensions are complete in the sense that they are sufficient to describe symbol manipulations, but after all, the same statement holds for machine-language. Moreover, the extensions do not constitute a minimal set of primitives for string or symbol manipulations&mdash;in the sense that complementation, shifting, &hellip; are primitives for machine arithmetic. Such primitives are essential only to machine designers (including designers of &ldquo;augmented machine&rdquo;, the basic machine augmented by subroutines for arithmetics not included in the hardware); to append only such primitives to ALGOL is to visit the omissive sins of the machine designers upon the users of ALGOL.


#*Simulation in higher education planning: Walk before you run
#@Nancy S. Sampson
#t1978
#cProceedings of the 10th conference on Winter simulation - Volume 2
#index545034
#!A variety of simulation models exist for higher education planning applications. These models tend to be general and global in nature. The sophisticated models appear to provide quantities of detailed information in preformated, attractive reports. An introductory survey frequently influences decisions to adopt a sophisticated model, before an institution has really learned what modeling is, how to use it and how to adapt to it. Use of a trivial simulation model should not be overlooked as an aid in the planning process. Such a simulation can provide valid, understandable, useful, timely information for the planning process. It may also provide a basis for critical WHAT IF assessments. Furthermore, a trivial model can help an institution learn the how, when, where and why of planning simulation before trying to run, with a sophisticated, and perhaps unwieldy, model. Contrasting case studies of simulation applications will be used to illustrate uses, misuses and problems associated with trivial and sophisticated simulation models used in planning for higher education.


#*Optimizing binary trees grown with a sorting algorithm
#@W. A. Martin,D. N. Ness
#t1972
#cCommunications of the ACM
#index328635
#%79620
#%322734
#%548359
#!Items can be retrieved from binary trees grown with a form of the Algorithm Quicksort in an average time proportional to log n, where n is the number of items in the tree. The binary trees grown by this algorithm sometimes have some branches longer than others; therefore, it is possible to reduce the average retrieval time by restructuring the tree to make the branches as uniform in length as possible. An algorithm to do this is presented. The use of this algorithm is discussed, and it is compared with another which restructures the tree after each new item is added.


#*Algebraic manipulation
#@J. W. Bergquist
#t1974
#cProceedings of the sixth international conference on APL
#index554454
#!Functions are exhibited which allow the user to deal with polynomials in one variable and vectors of complex nut, bets using the same verbs and mathematical expressions.


#*Algorithm 384: eigenvalues and eigenvectors of a real symmetric matrix
#@G. W. Stewart
#t1970
#cCommunications of the ACM
#index313883
#%334187
#%457304


#*A test matrix for inversion procedures
#@M. L. Pei
#t1962
#cCommunications of the ACM
#index317296


#*More on the reference counter method of erasing list structures
#@J. Weizenbaum
#t1964
#cCommunications of the ACM
#index317156


#*Panel on future directions in network services
#@P. Jackson,L. Pouzin,L. Roberts,K. Uncapher
#t1979
#cProceedings of the sixth symposium on Data communications
#index547700
#!With the double-digit rate of increase in the cost of energy, transportation and personnel and the double-digit rate of decrease in the cost of computing and communications, the demand to bring remote information to users via data networks for cost savings and convenience is overwhelming. Drs. Jackson and Roberts, both associated with operating public networks, will discuss the types of future network service to be offered to the public. Monsieur Pouzin and Dr. Uncapher will address user acceptance. Wide acceptance from the public of a network service requires easy access. LOUIS POUZIN'S REMARKS: Instead of guessing what future network services will be, I would rather present my expectations. A summary of my expectations could fit in a few key statements: 1. Unobtrusive access to network services 2. Responsible commercial organizations 3. Human-oriented services Now, some developments might be useful.


#*FORTRAN enhancement
#@Han Park
#t1973
#cConference record of the 6th annual workshop on Microprogramming
#index545921
#!One of the disadvantages using higher level languages has traditionally been slow execution time. In the last decade, the large core based computer manufacturers have greatly improved execution time of higher level languages either by modifying hardware designs or by implementing slow functional areas into microcodes (firmware). In the mini-computer field, microprogramming concepts and implementations have been amplified by industrial demand and by recent technical advancements. The microprogramming concept is not new, but it took a while for computer design engineers to implement user microprogrammable computers. The utilization of user microprogrammable capability is limited only by one's imagination. The utilitarian value of microprogramming is to maximize the use of mini-computer's resources.


#*Die Anwendung der B-Spline-Approximation in Computer Graphics
#@Wolfgang Straßer
#t1974
#cGI - 4. Jahrestagung
#index260414


#*A package of computer subprograms for control system analysis
#@G. J. Williams,R. S. Miles,L. C. Casady,J. P. Edenhofer
#t1967
#cProceedings of the 4th Design Automation Conference
#index548681
#!This paper describes a package of digital computer subprograms which provides control systems engineers at Autonetics with an easy-to-use, comprehensive, and flexible design-aid tool The subprograms are written in FORTRAN IV for the IBM 7094. Most of the subprograms are similar to ones found in almost every company's program files. They provide such standard capabilities as the generation of Bode plots, Root Locus plots, Nyquist plots, Nichols charts, and time and frequency response. The package contains three subprograms, however, which are not standard. These employ dichotomous techniques to generate transfer functions for active networks and continuous control systems. Since these techniques are currently attracting widespread interest, the three subprograms which implement them will be discussed in some detail.


#*On the recursive specification of data types
#@Mitchell Wand
#t1974
#cProceedings of the Proceedings of the First International Symposium on Category Theory Applied to Computation and Control
#index567554


#*Compile time type determination in SETL
#@Aaron M. Tenenbaum
#t1974
#cProceedings of the 1974 annual conference - Volume 1
#index549802
#%546754
#!In this paper, some features of the SETL language are presented. Also discussed are two methods for determining the data types of runtime objects in higher level languages from the static program text. The first method determines the type of a variable from the way in which it is defined, while the second method determines its type from the way it is subsequently used. This technique is shown to be of value in producing optimized object code. An implementation of the technique is also discussed and an example of the results produced under the implementation for a specific SETL program is presented.


#*Computer aided analysis of insulated gate field-effect transistors
#@Mark Brown Barron
#t1970
#c
#index187513


#*Review of "OPTIMIZATION STRATEGIES FOR MICROPROGRAMS, by Kleir and Remamoorthy", IEEE Transactions, Vol. C-20 No. 7, July 1971, pp. 783-794
#@Leo Hellerman
#t1972
#cACM SIGMICRO Newsletter
#index337862


#*A cai (computer assisted instruction) language for mini-computers with sample dialogue and problems relating physics and wildland hydrology.
#@William Otto Rasmussen
#t1973
#c
#index200751


#*Letters to the editor: on &ldquo;execute&rdquo; and &ldquo;repeat&rdquo; instructions
#@E. D. Reilly
#t1965
#cCommunications of the ACM
#index332875


#*A data structure for the description and the handling of engineering drawings
#@C. Cavagna,U. Cugini
#t1976
#cACM SIGDA Newsletter
#index108508
#%316373
#!The specifications of a data structure are essentially linked to the model which it is wished to represent, to the functional links which it is wished to obtain amongst the various data and the action which it is wished to take on such structure.


#*Joint inventorship of computers
#@Gunter A. Hauptman
#t1964
#cCommunications of the ACM
#index315886
#!The term joint inventorship asks but does not necessarily answer the question, &ldquo;Who is the true inventor of a computer?&rdquo; I will try to show how &ldquo;wrong&rdquo; inventors are joined, how such improper joinder can be avoided, and its dangers. While the law permits the addition or subtraction of improperly joined inventors, it does not permit the substitution of one set of inventors for another set of inventors. Thus, despite corrective weapons, there are some pitfalls which must be avoided.


#*Special Feature: Semiconductor Memory Reliability with Error Detecting and Correcting Codes
#@L. Levine
#t1976
#cComputer
#index345635
#!Although continuing cost and performance improvements of the new bipolar and MOS RAM devices are providing strong incentives for their greatly expanded use in mainframe memory and other storage applications, these components have not yet reached the degree of reliability required for large memory systems. Fortunately, however, memory system organization is compatible with a wide variety of low-cost fault detection and correction techniques6,10,11 that go a long way toward compensating for otherwise error-prone systems.


#*More on merging
#@David E. Ferguson
#t1964
#cCommunications of the ACM
#index316217


#*Deformations of complex structures on algebraically defined strongly pseudoconvex domains.
#@David Samuel Johnson
#t1978
#c
#index197482


#*Federal law protecting your right to privacy
#@James Poage
#t1975
#cACM SIGCAS Computers and Society
#index351690
#!Privacy, like security, is something everyone wants. Asked to define privacy, people usually settle for "the right to be left alone." However, a little reflection reveals that it is nearly impossible to be left alone in a highly organized, complex society that offers security. If people want Social Security they must be willing to reveal personal data such as age, sex, marital status and income. If people wish life insurance they must reveal medical data as well as their credit rating. If people wish to legally operate a motor vehicle they must reveal identifying information and mailing address. In these, as in almost all cases, an individual gives up some personal information, some piece of personal privacy, in order to obtain some benefit from "the system." The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Utility Functions for Time-Sharing System Performance Evaluation
#@J. M. Grochow
#t1972
#cComputer
#index339639
#!As more and more economic activity shifts to service industries, meaningful evaluation of their "product" is Abecoming a topic of major concern. The service organization is constantly being evaluated by its customers and it is important for management to understand bases for this evaluation. In the case of the general purpose time-sharing system, there may in fact be several different groups of users with different desires and goals. The procedures illustrated below attempt to provide management and designers of future computer systems with a structured way


#*The design and implementation of a machine-independent general system theoretic language.
#@Lanny Joe Mullens
#t1973
#c
#index191810


#*Kontextunterst&uuml;tzte Analyse von Szenen mit bewegten Objekten
#@R. Bertelsmeier,Bernd Radig
#t1977
#cDigital Bildverarbeitung - Digital Image Processing, GI/NTG Fachtagung
#index563333


#*Modula and the Design of a Message Switching Communication System
#@Gregory R. Andrews
#t1978
#c
#index120657
#!This report describes the functions of a message switching communications system and presents an implementation in terms of the Modula programming language. In particular, the report: (1) describes a representative application of the proposed new Department of Defense high order language; (2) presents a design technique for software specification; (3) develops Modula programs for each of the message switching components; and (4) evaluates the utility of Modula as a language for the design of large parallel systems.


#*Social implications of intelligent machines
#@Margaret A. Boden
#t1978
#cProceedings of the 1978 annual conference - Volume 2
#index546931
#%317965
#%620364
#%618658
#!The much-discussed issues of privacy, unemployment, leisure, centralization of political power, and military misuse of technology are raised by work in artificial intelligence no less than by applications exploiting the &ldquo;brute force&rdquo; of computers. But this paper focuses specifically on matters associated with the social use of intelligent machines in particular. Some current and predicted developments in machine intelligence are described and possible ill and good effects these may have on society outlined. Precautionary measures that might be taken in the writing and presentation of programs to forestall the social dangers implicit in this area of research are examined.


#*The translation and normalization packages of the solid system
#@James Tilden Perry
#t1971
#c
#index196528


#*An engineering simulator
#@George Forbes
#t1966
#cCommunications of the ACM
#index326386


#*Quantile estimation in regenerative simulation: a case study
#@G. W. J. Coppus,M. P. F. M. van Dongen,J. P. C. Kleinjen
#t1977
#cACM SIGSIM Simulation Digest
#index581156
#!We model key-punching in a computer center as a queuing simulation with 2 servers (typists) and 3 priority classes (small, medium, large jobs). The 90% quantile of queuing time is estimated for different borderlines between the 3 job classes. Confidence intervals for the quantiles are based on the regenerative properties of the simulation, as derived by Iglehart (1974). They utilize the asymptotic normality of the estimated quantile, and a rather complicated expression for its variance. Numerical results are given for the quantiles (and averages) of the queuing times in each job class, for several borderlines between the 3 job classes. The effects of simulation runlength on the confidence intervals were also examined. The effects of varying job-class borderlines were tentatively modeled by a regression model.


#*Book review: "Calculating the frame of homogeneous equation systems"
#@Balder Von Hohenbalken
#t1979
#cACM SIGAPL APL Quote Quad
#index239250


#*On the use of complex filters
#@Robert Byron Crane
#t1962
#c
#index194953


#*A study of some interpretations of modal and intuitionistic logics in thefirst order predicate calculus
#@Charles Hersch Haspel
#t1972
#c
#index198272


#*Data structure, software and biomedical application of an interactive graphics system using a small computer
#@Richard Oscar Lind
#t1972
#c
#index203508


#*Symbol manipulation by threaded lists
#@A. J. Perlis,Charles Thornton
#t1960
#cCommunications of the ACM
#index324059


#*Learning algorithms for multi-class pattern classification and problems associated with on-line handwritten character recognition
#@Tian-Lih Teng
#t1969
#c
#index193799


#*Computor Simulation of Narrowband Systems
#@R. A. Manske
#t1968
#cIEEE Transactions on Computers
#index343301
#!Abstract Any narrowband signal can be represented by two low-frequency functions, containing only frequencies lower than the bandwidth, which represent the envelopes of the in-phase (cosine) and quadrature ( sine) components of the carrier frequency. To obtain the transient response of a narrowband system efficiently by computer simulation, the system can be represented by a low-frequency equivalent system, avoiding time-consuming direct simulation of carrier frequencies. This paper presents techniques by which a wide variety of narrowband systems, expressible mathematically as block diagrams, can be converted into block diagrams consisting only of low-frequency functions. The resulting low-frequency equivalent systems can be simulated on either an analog or digital computer by well-known techniques. Although the low-frequency equivalent representation presented here includes an extension of the bandpass low-pass analogy, it is not subject to many of the restrictions normally applied to this analogy. It is not necessary that the modulation be simple AM, that the filtering be symmetrical, or that only the envelope velope of the output be of interest.


#*The Operational Analysis of Queueing Network Models
#@Peter J. Denning,Jeffrey P. Buzen
#t1978
#cACM Computing Surveys (CSUR)
#index319336
#%197187
#%314002
#%331119
#%545550
#%335516
#%332931
#%331474
#%327033
#%329878
#%323873


#*Organizing distributed data bases in computer networks.
#@Katriel Dan Levin
#t1974
#c
#index204903


#*Computer technology for the realistic calculation of properties of enzyme systems
#@Lillian Garfinkel,David G. Rhoads,David Garfinkel
#t1971
#cProceedings of the 1971 26th annual conference
#index554142
#!Traditional pencil-and-paper analyses of enzyme kinetic experiments assume so much simplification that the results have limited biological significance. Althouqh performing initial velocity experiments with negligibly low enzyme concentrations in the presence of single inhibitors facilitates interpretation, there are a number of enzymes for which this method fails completely. Software has been developed for the economical simulation of enzyme behavior under realistic conditions. Enzyme activity is computed as a function of either time or concentration by solution of either differential or algebraic equations with any desired ratio of enzyme/substrate concentrations. Simulation of experiments with hexo-kinase from mouse ascites cells has permitted resolution of some apparently contradictory results and indicated guidelines for assuring reliability of data. Applications of lab. analyzers to improve interpretation of experiments and perhaps actually perform them are discussed.


#*A new product design model: The Case of a carribean resort destination
#@Richard Bjorklund
#t1977
#cProceedings of the 9th conference on Winter simulation - Volume 2
#index545860
#!The model developed in this study designs a new product based on a target market's responses to preference stimuli. The model is applied to a Caribbean resort destination. Previous research has indicated the perceptual dimensions subjects use to evaluate resort destinations might be classified as hotel related and environment attractiveness related. Since there is more than one hotel at a resort destination, the model designs a product line of many different hotels. Hotels are defined by their attributes. A list of vacationers' most popular hotels is compiled and salient hotel attributes are photographed. A preference analysis of the photographs (attributes) is undertaken using an additive linear model. Utility weights of the attributes are then generated for individual respondents in a consumer sample. An iterative heuristic search is developed that allows each person in the sample to design a more satisfying hotel. The hotel is temporarily &ldquo;built&rdquo; if it attracts more consumers than an existing hotel. Hotels having fewer rooms than the potential demand are assumed to increase prices until supply and demand are in line. The number of rooms, potential demand and mean utility at each hotel is developed. Hotels that are unprofitable are eliminated and consumers not satisfied with a hotel are assumed to vacation else where. Elimination of unsatisfied vacationers has the effect of decreasing hotel and resort destination demand. A land use plan is used to operationalize environmental attractiveness. Consumers' locate required infrastructure facilities relative to their most preferred hotel. Engineer appraisals are used to rate the relative suitability of each location at the resort destination site for every infrastructure facility. An aggregation of preferred facility location coordinates across subjects is used to define the most preferred facility location configuration. A model is developed to search unoccupied and occupied locations with the objective of moving facilities to maximal rated locations while maintaining a satisfactory correlation with the preferred facility location configuration. The configuration correlation measures consumer satisfaction with the new facility location configuration.


#*The linear postman: a message-forwarding algorithm using sequential storage
#@Mike Paterson
#t1979
#cProceedings on Algorithms in Modern Mathematics and Computer Science
#index259361


#*The copyright law: higher education and technological change
#@Michael Keplinger
#t1977
#cACM SIGCAS Computers and Society
#index306368


#*A microprogrammed implementation of an architecture simulation language
#@William C. Hopkins,Gary Davidian
#t1977
#cACM SIGMICRO Newsletter
#index554236
#%319420
#%334053
#%547985
#%549511
#!A &ldquo;Machine Representation Language&rdquo; (MRL), a tool for the evaluation and simulation of the instruction sets of computers, was designed for research in computer architecture. A novel hypothetical machine to perform the simulation uses an acyclic directed graph as its machine language. MRL requires an expandable associative memory and a recursive execution environment; the research requires extensive instrumentation of the simulation. A microprogrammed implementation satisfying these requirements was completed on the Burroughs B1700 within an academic semester. Comparisons of implementation techniques and performance between the microprogrammed system and a developmental system using Snobol-4 show the utility and efficiency of the approach.


#*Review of Computers and law: a reference work by Rod N. Freed. 1976.
#@
#t1977
#cACM SIGCAS Computers and Society
#index308663


#*An Approach to the Straightforward Production of Computer System Simulators
#@O. Tedone
#t1976
#cProceedings of the International Workshop organized by the Commision of the European Communities on Modelling and Performance Evaluation of Computer Systems
#index261408


#*Iris: a framework for the construction of clinical consultation systems.
#@Michael Louis Trigoboff
#t1978
#c
#index189149


#*Circulation List
#@Peter Naur
#t1964
#cIssue 18 (October 1964)
#index99904


#*Application of error-checking techniques to computer memory systems
#@Atulkumar Kantilal Bhatt
#t1979
#c
#index201194


#*Xaviera's establishment
#@Susan L. Solomon
#t1975
#cACM SIGSIM Simulation Digest
#index575072
#!Xaviera operates an entertainment facility in Nevada. In order to preserve her share of the market, she wishes to examine the level of service offered to her customers under the following alternative conditions.


#*A quasi-interactive approach to computer-assisted instruction.
#@Sharon Kay Fletcher
#t1976
#c
#index185680


#*Charge-out system for management acceptance and control of the computer resource
#@Richard L. Nolan,Charles Carey,Michael J. Samek,K. Sreenivasan,John V. Soden,Myron Uretsky
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index65716
#!This panel focuses on the issues of using the pricing mechanism to both control and exploit the computer resource. The pricing mechanism for computer services and charge-out systems are employed primarily for control purposes. A more powerful role exists in the area of exploiting the computer resource and engendering user management acceptance and accountability. The panel will build upon ideas in the following paper in both the management and design issues of charge-out systems.


#*Monte Carlo techniques for stochastic network analysis
#@John M. Burt,Mark B. Garman
#t1970
#cProceedings of the fourth annual conference on Applications of simulation
#index547017
#!This paper presents simulation procedures for efficiently obtaining estimates of the distribution function, or parameters thereof, of the maximal flow-time through directed acyclic networks whose activity times are random variables.


#*Towards the construction of verifiable software systems
#@L. Flon,A. N. Habermann
#t1976
#cACM SIGMOD Record
#index546285
#%320995
#%332514
#%335624
#!Data types are an important design tool because they allow freedom of abstraction. Thus, they are useful for constructing large software systems, including operating systems. It is shown that when dealing with problems of concurrency, the use of path expressions, which are associated with data, makes the task of verification simpler than when the synchronization conditions are associated with programs.


#*Design Methods for Digital Systems
#@Jean Chinal
#t1973
#c
#index625503


#*on Advances in Neuro-Information Processing: 15th International Conference, ICONIP 2008, Auckland, New Zealand, November 25-28, 2008, Revised Selected Papers, Part I
#@
#t-1
#cLecture Notes In Computer Science; Vol. 5506
#index507453


#*The exact solution of systems of linear equations with polynomial coefficients
#@Michael T. McClellan
#t1971
#cProceedings of the second ACM symposium on Symbolic and algebraic manipulation
#index554011
#%79620
#%81323
#%319226
#!An algorithm for computing exactly a general solution to a system of linear equations with coefficients that are polynomials over the integers is presented. The algorithm applies mod-p mappings and then evaluation mappings, eventually solving linear systems of equations with coefficients in GF(p) by a special Gaussian elimination algorithm. Then by applying interpolation and the Chinese Remainder Theorem a general solution is obtained. For a consistent system, the evaluation-interpolation part of the algorithm computes the determinantal RRE form of the mod-p reduced augmented system matrices. The Chinese Remainder Theorem then uses these to construct an RRE matrix with polynomial entries over the integers, from which a general solution is constructed. For an inconsistent system, only one mod-p mapping is needed. The average computing time for the algorithm is obtained and compared to that for the exact division method. The new method is found to be far superior. Also, a mod-p/evaluation mapping algorithm for computing matrix products is discussed briefly.


#*Algorithm and bound for the greatest common divisor of n integers
#@Gordon H. Bradley
#t1970
#cCommunications of the ACM
#index320378
#%81323
#%315361
#%332813
#!A new version of the Euclidean algorithm for finding the greatest common divisor of n integers ai and multipliers xi such that gcd = x1 a1 + &middot;&middot;&middot; + xn an is presented. The number of arithmetic operations and the number of storage locations are linear in n. A theorem of Lam&eacute; that gives a bound for the number of iterations of the Euclidean algorithm for two integers is extended to the case of n integers. An algorithm to construct a minimal set of multipliers is presented. A Fortran program for the algorithm appears as Comm. ACM Algorithm 386.


#*A propositionally oriented definition of the semantics of snobol4.
#@Peter H. Lutz
#t1979
#c
#index186090


#*Image processing in a university environment
#@Gregory C. Alvord,James J. Quinn
#t1975
#cProceedings of the 3rd annual ACM SIGUCCS conference on User services
#index548012
#%329900
#!The Computing Center of the State University of New York at Albany is engaged in providing an innovative service to the research community of our region. During the past few years many pages of literature have been written about image processing (Rosenfeld, 1971). In this literature are presented many application areas that have been investigated to develop algorithms for data analysis. It is our impression that much of this previous work can be brought out of the research phase and into the development phase. We, as computer service specialists, recognize the need to provide card readers and tape drives for our users with data in 'machine readable form' We further recognize that maintenance of a library of statistical and mathematical tools is our obligation to the user/research environment. Image processing has made great strides in establishing itself as a viable research tool. We believe that it is not premature to extend our definition of machine readable objects to include pictures(or what ever a TV camera can see).Further we are extending our program library to include tools tailored to the data structure inherent in images(two dimensional matricies where row and column have positional meanings).


#*Space-Time Tradeoffs for Oblivious Interger Multiplications
#@John E. Savage,Sowmitri Swamy
#t1979
#cProceedings of the 6th Colloquium, on Automata, Languages and Programming
#index360518


#*A strategic planning methodology for the computing effort in higher education: an empirical evaluation
#@James C. Wetherbe,V. Thomas Dock
#t1978
#cCommunications of the ACM
#index320255
#%179654
#%327392
#!The findings of a study designed to address the pressing problems associated with the strategic planning of the computing effort in higher education are presented here. A planning methodology was developed and tested through implementation at a university. Two years after the methodology was implemented, the effectiveness of the planning methodology was assessed in terms of the improvement of the delivery of computing services to the major institutional roles of instruction, research, and administration. Two control institutions were employed to contrast the improvements at the test institution. The results of the research indicate the planning methodology significantly enhanced the delivery of computing services.


#*A language and data structure for fact retrieval
#@William Louis Ash
#t1971
#c
#index197514


#*Concepts of a Data Independent Accessing Model
#@M. M. Astrahan,E. B. Altman,P. L. Fehder,M. E. Senko
#t1972
#cProceedings of 1972 ACM-SIGFIDET workshop on Data description, access and control
#index553631
#%549824
#!The Data Independent Accessing Model (DIAM) represents a constructive combination of the formal mathematical and the evolutionary pragmatic approaches to a Generalized Data Base Management System. It aims at a complete separation between the user's (application programmer's) model of real-world objects, events, and the relationships among them, and the internal representation of those objects, events, and relationships. At the same time, it aims at complete flexibility of internal representation in terms of simple specifications, the effects of which are easy to understand. The DIAM encompasses four levels of descriptive models (Figure 1), each providing for flexible augmentation of the descriptions of the preceding level. Specifications at each level are retained in a catalog.


#*Basic with Business Applications
#@Richard W. Lott
#t1977
#c
#index613386


#*Manipulation of algebraic expressions
#@Arnold R. M. Rom
#t1961
#cCommunications of the ACM
#index327341


#*On the Design of Programming Languages Including Mini ALgol 68
#@Leendert Ammeraal
#t1975
#cGI - 5. Jahrestagung
#index266507


#*ACM president's letter: relation of ACM activities to finances
#@Jean E. Sammet
#t1975
#cCommunications of the ACM
#index316134


#*The structure of yet another ALGOL compiler
#@H. Kanner,P. Kosinski,C. L. Robinson
#t1965
#cCommunications of the ACM
#index329299
#%316877
#%316962
#%317076
#%320929
#%328541
#%329080
#%335555
#!A high-speed &ldquo;top down&rdquo; method of syntax analysis which completely eliminates &ldquo;back-up&rdquo; of the source string has been implemented in a convenient macro-language. A technique of simulation at compile time of the use of a conventional run-time stack enables the generation of code for expressions which minimizes stores, fetches and stack-pointer motion at run time, while properly treating recursion and side effects of procedures. Block structure and recursion are handled without need for interpretive methods at run time. The &ldquo;context problem&rdquo; in the transmission to recursive procedures of parameters &ldquo;called by name&rdquo; is solved in a manner which permits the handling of the common cases of simple expressions and array identifiers with particular efficiency.


#*Program behavior and load dependent system performance.
#@Kevin Comerford Kahn
#t1976
#c
#index205049


#*Making computers safer: making computers safer through auditing
#@
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index72780


#*Joining policies in a multipriority multiclass batch computer system
#@Jair M. Babad,Mario M. Modiano
#t1976
#cCommunications of the ACM
#index322296
#!Consider a multipriority batch computer system which users from several different classes may join, with toll, service, and waiting charges. Such a system is formulated here as a semi-Markov decision process, in which the aim of arriving users is to minimize their expected loss. The optimal joining policy of arriving users who may join the system at some of its queues is a control limit policy, with a single control number for any possible queue and the user's class; a newly arriving user will join a queue that is not filled up to the control number corresponding to this queue and the user's class. In this paper control numbers, as well as lower and upper bounds for the control numbers and the capacities of the system's queues, are derived.


#*A Critique of Modula
#@Andrew Richardson
#t1979
#cProceedings of a Symposium on Language Design and Programming Methodology
#index376576


#*Development of a new discrete simulation language for modelling transportation systems.
#@Yenumula Venkata Ramana Reddy
#t1973
#c
#index187347


#*Optimal control of tandem queues
#@Raul Eric Talan
#t1973
#c
#index204530


#*A study of alternative methods for the symbolic calculation of elliptic integrals
#@Edward W. Ng,Desanka Polajnar
#t1976
#cProceedings of the third ACM symposium on Symbolic and algebraic computation
#index549007
#%314767
#!This presentation describes the study of several candidate methods for the symbolic integration of a class of irrational expressions R(x,y), where y2 is a polynomial in x and R is a rational function of x and y. Three of these methods came from classical investigations of Legendre, Jacobi, and Weierstrass whereas one came from recent investigations of Carlson. The present paper may be considered a progress report on preliminary algorithmic study and some efforts of implementation on MACSYMA. In this presentation, we describe the study of several candidate methods for the symbolic integration of a class of irrational expressions R(x,y), where y2 is a polynomial in x and R is a rational function of x and y. We shall also summarize some efforts of implementation on MACSYMA.


#*The design of system architectures for information retrieval
#@L. A. Hollaar,B. J. Hurley,D. J. Kuck,D. H. Lawrie,J. W.S. Liu,J. M. Milner,J. K. Morgan,J. R. Rinewalt,W. H. Stellhorn
#t1976
#cProceedings of the 1976 annual conference
#index553691
#!A broad-based program for studying hardware, software and human factors affecting information retrieval system performance is described. Using EUREKA, a minicomputer-based retrieval program, studies of user adaptation to an on-line system, search strategy development and use of special features are in progress. Performance comparisons are made between machine-assisted users and those using conventional printed materials. Concurrently, special-purpose retrieval hardware is being designed, and one prototype system is under construction. To support and supplement this work, various modeling and simulation studies are also in progress.


#*President's letter to the ACM membership: let's face it
#@Bernard A. Galler
#t1969
#cCommunications of the ACM
#index332562


#*A generalized polyphase merge algorithm
#@Samuel W. Reynolds
#t1961
#cCommunications of the ACM
#index333684
#!The k-generalized Fibonacci numbers are defined as in [1]. A polyphase merge (merging an equal number of sequences from k tapes onto a single unused tape) using k+1 tapes is defined in terms of linear combinations of these numbers. A method is described to output sequences onto k of k+1 tapes after the internal sorting of elements to form sequences. This method will permit a polyphase merge of sequences of sorted elements provided that enough sequences are generated internally to place the proper numbers of sequences on each of the k tapes. For each value of k, there is a set of permissible numbers that can represent the total number of sequences generated during the original output process. If one of these numbers is met exactly and if there is a specific distribution of sequences on the k tapes, then a polyphase merge may proceed. If these conditions are not met, an algorithm is necessary to adjust the numbers of sequences to permit a polyphase merge. This paper describes such an algorithm.


#*Letters to the editor: a final word on reducing truncation errors
#@David Hutchinson
#t1965
#cCommunications of the ACM
#index314273


#*A computer based pollution surveillance scheduling system.
#@Lynn J. Mckell
#t1973
#c
#index196699


#*Comments on the administrative/academic interface
#@Ronald Anton
#t1972
#cProceedings of the annual ACM SIGUCCS symposium on The administration and management of small-college computing centers
#index547326
#!Swarthmore College is a small liberal-arts college, located in southeast Pennsylvania. The attitude of the administration towards the computer until just recently was strictly hands-off. If you walked into an office and said, &ldquo;How about putting something on the computer?&rdquo;, they would get up and walk out, or they didn't hear so well that day, or something like that. At present, we are doing a lot of administrative work on the computer, mainly because the vice-president put out a letter that said, &ldquo;Use the computer.&rdquo; That was all there was to it. We are starting to bring in the general ledger and accounting system for the business office, the alumni mailing list, which is about 22,000 names, and probably next month we'll do our first mailing, and numerous other small jobs which fell our lot because Miss SO-AND-SO who's been with the college for fifty years finally retired and nobody knows how to do the work she was doing. We print things like payroll labels, which they used to print by hand once a week on the time cards&mdash;about a three-hour job that we do now in about thirty seconds. Other things are vacation and sick leave, which is a monstrous problem, mainly because nobody else can figure it out, or wants to be in charge of finding the sick leave every month. They blame it on the computer if it's wrong.


#*Computer simulation of stochastic areal growth
#@Jon Franklin Reynolds
#t1971
#c
#index206134


#*The use of simulation and gaming in information systems research
#@Theodore J. Mock,Miklos A. Vasarhelyi,John C. Fellingham
#t1974
#cProceedings of the 7th conference on Winter simulation - Volume 2
#index552822
#!Research in management information systems and in information, communication or intelligence systems in general has grown significantly within the past decade. Yet although significant work is evident at both the theoretical level with the development of information economics and statistical decision theory and at the technical level as is evidenced by the development of complex on-line networks and advanced information storage and retrieval systems, little research which has focused upon information systems has utilized gaming and simulation techniques. Such techniques have been used by the authors in a series of related studies into information systems and decision processes. The paper contains two major experimental studies. The first is a series of information economics experiments where discreet event simulation is utilized to estimate the ex ante value of more timely information in a fifteen period decision process which contains four random environmental variables. The ex ante value and the information value which is realizable given the actual decision environment are then used as a standard with which to compare actual, realized information values obtained in controlled experiments. The empirical results obtained include evidence with respect to the value of more timely information, the value of detailed budgetary feedback and the impact of these information differences on learning rates. The second main study described in this paper considers gaming used to analyze an on-line directive planning system. In this context it is not possible to estimate information value, but experimental data with respect to user attitudes, type and degree of information utilization and the impact of decision approach is obtained.


#*The semantics of information flow.
#@Thomas Bennet London
#t1977
#c
#index199313


#*Session E
#@
#t1973
#cProceedings of a symposium on High-level-language computer architecture
#index309244


#*Computer modeling of the rail transport of western coal
#@Hossain Vadie
#t1979
#c
#index191621


#*Geometric Modeling of Mechanical Parts and Processes
#@H. B. Voelcker
#t1977
#cComputer
#index347478
#!Geometry plays a crucial role in nearly all design and production activities in the discrete goods industries. Curiously, these industries' primary means for specifying geometry two-dimensional graphics has not changed significantly for more than a century. Dramatic changes are likely to occur in the next decade, however, because the deficiencies of current methods are retarding the progress of automation and are stimulating the development of new, computationally oriented schemes for handling mechanical geometry.


#*The BIG system - synergetic graphics
#@Charles E. Quenneville,Harvey Z. Kriloff
#t1976
#cProceedings of the 1976 annual conference
#index552635
#%313804
#%319498
#%320694
#%334447
#!The recent decrease in the cost of graphics hardware has created an expanded potential opportunity for the use of graphic techniques. However, this potential is reduced by a lack of agreement on the software interface for this graphics environment. In almost every forum that discusses graphical techniques, new systems are introduced that are syntactically unique, but semantically very similar2,8,16. One of the major reasons for this proliferation of graphic systems is the large number of possible tradeoffs that exist between the performance parameters of these devices. Each graphics system can be optimized for a limited number of these parameters by adjusting a feature of the system design until the best results are obtained. Where more than one design feature affects a particular performance parameter, the system designer usually selects a single feature for adjustment and restricts the user's ability to modify any others. The users discover that they cannot adequately adjust that graphics system for their particular problem, leading to the creation of yet another graphics system. An evaluation of the techniques that have been used to provide this design factor optimization reveal that applying these techniques in combination provides a greater degree of user control over the graphics environment. This synergetic behavior leads to benefits that can be derived from a graphics system that allows the user a greater variety of implementation options. This flexibility will also allow the user to somewhat compensate for the present lack of a graphics standard. A system that utilizes this methodology is described and examples of its application are shown.


#*Control of design data in the integrated ship design system
#@Peter R. Bono
#t1974
#cProceedings of the 1974 annual conference - Volume 1
#index550411
#!The Navy's Integrated Ship Design System (ISDS) is being designed as a collection of application program modules (for preliminary design) which communicate with a centralized set of data files. These files use the existing COMRADE Data Management System which was designed specifically for integrated systems. Apart from providing an environment in which to operate the engineering application modules, ISDS's main role is to manage the creation, flow and archiving of the ship design data and to control access to this data. Consequently, a major concern during the lengthy and complex ship design process is assuring the integrity of the design data as it grows and is revised over time. Planning for control of the design data requires a clear understanding of the design process and the interrelationships between the design tasks. Requirements are stated, problem areas are identified, and possible approaches for implementation are suggested.


#*The IIT MST in computer science program
#@John G. Meinke,Charles R. Bauer
#t1976
#cACM SIGCUE Outlook
#index546367
#%79620
#%328135
#!The MST program at Illinois Institute of Technology evolved as a result of Computer Science emerging as a separate discipline at the secondary school level. The State of Illinois and the Chicago Board of Education have both been investigating certification for Computer Science teachers, but at present only two states, Wisconsin and Minnesota, have certification programs for teachers of Computer Science. In the not too far distant future there will be certification programs in many states and the IIT MST program in Computer Science is designed to meet those requirements. It is important to realize before discussing the program itself that the MST program is not designed to teach people how to teach. Before entering the program, a teacher must have at least three years of superior teaching experience as well as recommendations from his principal attesting to his quality as a teacher. Of the 32 semester hours required for the MST degree, a maximum of 12 semester hours are in Computer Pedagogy, with the norm being nine. In addition, students in the program study on a part-time basis to encourage use of the principles studied at IIT in their own classrooms.


#*Detection of Storage Errors in Mass Memories Using Low-Cost Arithmetic Error Codes
#@B. Parhami
#t1978
#cIEEE Transactions on Computers
#index350661
#!Arithmetic error codes constitute a class of error codes that are preserved during most arithmetic operations. Effectiveness studies for arithmetic error codes have shown their value for concurrent detection of faults in arithmetic processors, data transmission subsystems, and main storage units in fault-tolerant computers. In this paper, it is shown that the same class of codes is also quite effective for detecting storage errors in both shift-register and magnetic-recording mass memories. Some of the results are more general and deal with properties of arithmetic error codes in detecting unidirectional failures. For example, it is shown that a low-cost arithmetic error code with check modulus A = 2N - 1 can detect any unidirectional failure which affects fewer than N bits. The use of arithmetic error codes for checking of mass memories is further justified since it eliminates the need for hard-core or self-checking code translators and reduces the number of different types of code checkers required.


#*Architecture of the IBM system/370
#@Richard P. Case,Andris Padegs
#t1978
#cCommunications of the ACM
#index331907
#%547021
#!This paper discusses the design considerations for the architectural extensions that distinguish System/370 from System/360. It comments on some experiences with the original objectives for System/360 and on the efforts to achieve them, and it describes the reasons and objectives for extending the architecture. It covers virtual storage, program control, data-manipulation instructions, timing facilities, multiprocessing, debugging and monitoring, error handling, and input/output operations. A final section tabulates some of the important parameters of the various IBM machines which implement the architecture.


#*"greedy" algorithms for some optimization problems on a lattice polyhedron.
#@Deborah Freedman Kornblum
#t1978
#c
#index205602


#*Lokale Diffusionsnetze mit benutzer- und lastunabh&auml;ngigem Overhead - C³SMA-Systeme
#@Franz-Joachim Kauffels,Otto Spaniol
#t1979
#cGI - 9. Jahrestagung
#index266093


#*A Novel Parallel Binary Counter Design with Parity Prediction and Error Detection Scheme
#@W. N. Toy
#t1971
#cIEEE Transactions on Computers
#index343078
#!In binary counters, the parity bit is not preserved when the data undergo the counting operation. It is necessary to predict the parity bit that should be used with the correct result. A special design has been devised to share as much hardware as possible between the counter and the parity prediction circuit. This reduces the number of logic gates and gives a more efficient design. The scheme involves the use of the first 0 detection for both the counting operation and the parity prediction.


#*Artificial intelligence in automated design
#@D. Jirauch
#t1966
#cProceedings of the SHARE design automation project
#index555020
#!New techniques are constantly being developed in the field of Artificial Intelligence. Too often such techniques are overlooked as being &ldquo;too far out&rdquo; to be practical. Frequently they offer a solution to a problem that might be difficult to solve by more traditional methods. Some of the techniques used in the field of artificial intelligence can be successfully applied to the field of Design Automation. Those interested in developing techniques for automating design should be aware of this potential and be on the lookout for such applications.


#*An algorithm for n-player differential games with examples in biological process control, transportation, and economic research.
#@Don L. Luttermoser
#t1974
#c
#index193470


#*Proving programs correct using abstract, high-level logic.
#@Allan Mason Stavely
#t1977
#c
#index199652


#*Modeling an experimental computer communication network
#@J. F. Hayes
#t1973
#cProceedings of the third ACM symposium on Data communications and Data networks: Analysis and design
#index553347
#!This paper reports the results of a performance study of an experimental computer communication network. The network is currently being designed and built in order to test concepts and techniques that may find future application. The network consists of synchronous digital transmission lines connected in loops to a Central Switch. User traffic enters the system through multiplexers connected to the synchronous lines. The Central Switch has the two-fold function of routing and controlling traffic. Two multiplexing techniques were examined, Demand Multiplexing (DM) and Synchronous Time Division Multiplexing (STDM). In both techniques user messages are blocked into fixed size packets, prior to multiplexing on the line. The synchronous line can carry these packets at a minimum rate of 4000 packet slots per second. In STDM each terminal is assigned a packet slot which recurs periodically. In contrast, for DM, packets are multiplexed on the line asynchronously into unoccupied packet slots. Alternative implementations of the DM technique were studied, one where each terminal transmits and receives at a maximum rate of 4000 packets per second and another where the maximum rate is 2000 packets per second. As part of its message handling function the Central Switch buffers messages in transit. This allows User Terminals to transmit and receive messages with a degree of independence from one another. However the terminal strategy affects the amount of storage required in the Central Switch. In order to prevent the loss of information when there is insufficient buffering there is a mechanism to inhibit traffic from User Terminals when the Central Switch's buffer is near overflow. Due to this control of traffic, there is a relationship between the amount of data that flows through the Switch and the amount of buffering in the Switch. Simulation results showed that there was little difference in delay performance between the two implementations of DM. However an analysis comparing DM and STDM showed a great difference in performance for all but the very heaviest line loadings. This difference increases as the number of terminals sharing the T1 line increases. Our study concentrated on two aspects of buffering in the Central Switch. We examined the relationship between throughput and the amount of storage available in the switch. The results of a simulation study showed that throughput can be quite high for all but minimal storage in the switch. Moreover, a strategy that dedicates buffers does quite well compared to common buffering. The second aspect of the study concentrated upon the User Terminal's strategy. Since each terminal acts independently, there may be strategies that make particularly high demands upon storage capacity in the Central Switch. An analysis showed that at the loadings where the system would be expected to operate, the user strategy in transmitting and receiving messages has little effect.


#*Computer representation, generation, and manipulation of graphical information
#@Gary Dean Hornbuckle
#t1967
#c
#index203784


#*Computer simulation of foliage shading in building energy loads
#@Marc Schiler,Donald P. Greenberg
#t1979
#cProceedings of the 16th Design Automation Conference
#index554135
#%153803
#%237122
#%238035
#%331365
#!The calculation of building thermal loads using the computer has been an accepted practice for several years. A substantial amount of research and theoretical investigation has been expended in attempts to accurately quantify a building's thermal behavior. A number of existing simulation packages acceptably model this behavior.1,2,3,4,5,6 The advantages of simulation are obvious, not only for the predictive information with respect to operating costs or fuel consumption, but as a potential aid for preliminary design. The influence and tradeoffs of a large number of design variables such as siting, orientation, window area, thermal resistivity, surface/volume ratios, and cost can all be examined at an early stage in the design process.


#*Line processor: a device for amplification of display terminal capabilities for text manipulation
#@Donald I. Andrews
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index71487
#%69429
#%551317
#!The Line Processor is a microcomputer-based device that was developed at Stanford Research Institute's Augmentation Research Center (ARC). It was designed to make it possible to use inexpensive alphanumeric video display terminals with ARC's sophisticated interactive information manipulation system, NLS.


#*Algorithm 97: Shortest path
#@Robert W. Floyd
#t1962
#cCommunications of the ACM
#index327782


#*Scalar Seprent, Processor for APL
#@Yves C. Fav@@@@@@@,Louis P.A. Fohichand
#t1974
#cProceedings of the sixth international conference on APL
#index555326
#!A &ldquo;Scalar Seprent Processor&rdquo; is defined. for the translation of those parts of APL expressions which contain moradic and dyadic functions. In present version of APL the execution of a simple sub-expression is triggered as soon as a function and its @@@@@@@@@@@ are found. In the Scalar S@@@ent approach the tri@@@@@@@ is delayed, it a controlled fashion, in order to reduce the overhead in the translation and execution of APL expressions.


#*Ansi study group working paper: "The Background of Computer Graphics Standardization"
#@Richard F. Puk
#t1978
#cACM SIGGRAPH Computer Graphics
#index2796
#%251234
#!In considering the feasibility of developing a standard in computer graphics, it is necessary that the computer graphics state-of-the-art as well as past and present standardization activities in the area of computer graphics be thoroughly understood. This document reviews the history of computer graphics and quickly surveys the developing technology before presenting computer graphics standardization activities to date.


#*An Algorithm for the Solution of Linear Inequalities
#@G. Nagaraja
#t1974
#cIEEE Transactions on Computers
#index341025
#!The problem of solving a system of linear inequalities is central to pattern classification where a solution to the system, consistent or not, is required. In this paper, an algorithm is developed using the method of conjugate gradients for function minimization. Specifically, it is shown that the algorithm converges to a solution in both the consistent and inconsistent cases in a finite number of steps: this is the main result. A related criterion function which has significance in pattern classification problems is derived and a variant of the algorithm to minimize the same is given along with computationally convenient modifications. A linear minimization algorithm which makes complete use of the problem structure is given: this is a part of the main algorithm. Computer simulation results for switching problems are presented and the algorithm is compared with Ho-Kashyap and accelerated relaxation algorithms; the results show that the proposed algorithm is faster than the latter algorithms with respect to both the number of iterations and time for convergence.


#*Design of a multi-level file management system
#@Edward W. Ver Hoef
#t1966
#cProceedings of the 1966 21st national conference
#index544868
#!This paper describes the file handling system developed and being implemented as a part of INTIPS, (INTe- grated Information Processing System) under the aegis of Rome Air Development Center. This file system addresses itself to the physical problem of the storage and retrieval of fixed length blocks and their organization into higher-order structures. It does not concern itself with the contents of these blocks. (For an elaboration of this distinction, see reference 1.)


#*Installing an on-line information system in the manufacturing environment
#@
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index63960


#*Computing personnel: Changes in the workplace
#@Fred A. Gluckson
#t1979
#cProceedings of the 1979 annual conference
#index550448
#!This session will concentrate on computing people and how they have been affected by the decade of the 1970's. The decade began on a sour note. In 1970 the Aerospace industry was coming down from a high, a recession was afoot in the land, and the Los Angeles Chapter of ACM conducted a seminar to help the displaced programmer. Since then our economy has followed a rocky course, with peaks and valleys in the Gross National Product. Indeed, economics dominated the news in the 1970's. But computer people fared better than others. A growing shortage of qualified staff exerted upward pressure on salaries. The Federal restrictions on merit increases made it difficult for experienced programmers to keep up with new hires. This is just one dilemma faced by systems managers in the decade of the 1970's.


#*On the segmentation and analysis of continuous musical sound by digital computer.
#@James Anderson Moorer
#t1975
#c
#index198088


#*Technical contributions describing activities underway
#@Alan Saltzman
#t1979
#cACM SIGBIO Newsletter
#index574629
#!In the November 1978 issues of Datamation, in an arcticle entitled "The Changing Face of Applications Programming", Daniel McCracken, President of the ACM, defined procedural versus non-procedural languages. He says that "despite improvements the productivity of today's programmers is no more than two of three times the productivity of programmers a quarter of a century ago. In the same period, the price performance ratio of the computer hardware has improved by a factor of perhaps a million. People wanting to use this low cost hardware are frustrated by the handicaps imposed by writing programs in...procedural languages." He goes on to state that "by the mid-80's more than half of all computer time will be spent running applications programs constructed with non-procedural oriented languages." (Many companies have already become aware of the cost benefits of non-procedural languages and are already using them. Schering-Plough was to be one of these astute companies). The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Applications of complex cobordism to equivariant maps
#@John Duane O'Neill
#t1968
#c
#index196411


#*Cookbook
#@
#t1972
#cComputer
#index349974


#*Computer scientists' responsibility to educational research: A dynamic medium for creative thought
#@Alan C. Kay
#t1974
#cProceedings of the fourth SIGCSE technical symposium on Computer science education
#index546188
#!A computing engine of sufficient power can both simulate existing media and provide new framewords for creative ideas. It must be personal, portable, and inexpensive. Movies of such a (hard) system/(soft) language designed and built for &ldquo;children of all ages&rdquo; will be shown.


#*Analysis, Decomposition, Synthesis, and Applications of Higher RankRelations
#@S. Y. Bang
#t1974
#c
#index197255


#*Data processing personnel career development program
#@L. Roy Cottrell
#t1979
#cProceedings of the 1979 annual conference
#index550142
#!Data processing personnel career development implies the exercising of a specific plan within a structured environment. Career development should allow an individual to start as a programmer trainee or anywhere in the hierarchy of the group and progress to appropriate levels of responsibility, authority, and pay that are commensurate with that individual's abilities and desires. Career development is &ldquo;GOOD BUSINESS&rdquo; for the company and for the individual, as it provides for the development and optimal use of existing potential. It can provide significant contributions to productivity improvement and at the same time reduce retention problems. If a career development program is to work, it must be pragmatic. First it has to be developed and implemented within the environment of each individual company. Second, it has to have sufficient flexibility to allow for the specific career requirements of each individual. This &ldquo;tall order&rdquo; has been met with varying degrees of success. This case study is intended to provide one example of how career development can and does work for the Missouri Pacific Railroad computer professional.


#*The generative approach to software development
#@Gary L. Hill
#t1977
#cProceedings of the 1977 annual conference
#index548477
#!The National Institute of Child Health and Human Development (NICHD/NIH) provided funding to DUALabs for the analysis of unique data processing problems posed by large statistical data files. One mechanism that resulted from this activity was the CENTS-AID II system, which reduces the cost of accessing large data files by as much as 80%. The generative programming techniques designed into the system are responsible for this significant cost reduction. CENTS-AID is currently being used in over 50 computer sites around the world including the Belgian Archives, University of Heidelberg, Prudential Insurance Company, Congressional Budget Office, Social Security Administration, National Institutes of Health, and the New York State Workmen's Compensation Board. The system is operational on the IBM 360/370 under OS and DOS. A Honeywell 6000 Series version will be available in the near future.


#*Further evidence for the analysis of algorithms for the zero-one programming problem
#@L. G. Proll
#t1971
#cCommunications of the ACM
#index324274
#%315781
#%318806
#%324525
#!The purpose of this note is to report computational experience additional to that recently summarized by Gue et al., with two algorithms for the zero-one linear programming problem. An error in Gue's paper is corrected. The utility of one of the algorithms as a suboptimizer is indicated.


#*ACM president's letter: unfinished business: III
#@Walter M. Carlson
#t1972
#cCommunications of the ACM
#index334571


#*Problems, prospects, and an alternative approach in simulation modeling
#@Robert B. Fetter
#t1979
#cACM SIGSIM Simulation Digest
#index575130
#!Early work (1950's) in simulation and first attempts at modeling of health care facilities utilization are described. Lessons learned from this work are given together with perceived limitations of available technology, the development of the Conversational Modelling Language and its implications for OR in general and simulation in particular are described.


#*Object Migration and Authentication
#@V. D. Gligor
#t1979
#cIEEE Transactions on Software Engineering
#index353965
#!When typed objects migrate in virtual memory, onto off-ine storage, or among the nodes of a network, the type managers must relinguish control over the object representation and state. In this paper we present a mechanism which allows a type manager to authenticate and reinstantiate migrated objects. This mechanism also solves some problems stemming from the hierarchical structure of the system itself. The mechanism is based on a combination of cryptographic techniques using (nondistributable) centralized, secret keys, and data redundancy which characterizes the object representation and state.


#*An accurate time delay model for large digital network simulation
#@C. Chicoix,J. Pedoussat,N. Giambiasi
#t1976
#cProceedings of the 13th Design Automation Conference
#index549954
#%548547
#%553819
#!The authors propose a three valued model for temporal simulation of logic system. This model is well suited for analysis of hazards and high frequency rejection phenomenas. By using a new temporal model, we avoid backtracking or anticipation techniques (generally used in other models) and allow very simple implementation. The model and the mains algorithms are presented in detail in the paper and some examples including hazards are given.


#*Computer simulated effects of non-normality on the f ratio in analysis ofvariance
#@Gary Warren Womble
#t1970
#c
#index186006


#*Dynamic computation of derivatives
#@Arthur M. Lesk
#t1967
#cCommunications of the ACM
#index324373
#%333093


#*Current systems implementation languages: One user's view
#@John Slimick
#t1971
#cProceedings of the SIGPLAN symposium on Languages for system implementation
#index546165
#%313683
#%329080
#!One user's experience with five current systems implementation languages is outlined stressing virtues and vices of each; the five are: FORTRAN, PASS, GOGOL, XPL, and PL360. Some criteria for future systems implementation languages are suggested; the most crucial features of a systems implementation language are (1) access to the &ldquo;real&rdquo; machine, (2) compatibility with existing software, (3) linguistic structure, and (4) predictability of code generator and storage management.


#*MDSL: a microcomputer design and simulation language
#@Michael Adamowicz,Jamshed Mirza
#t1977
#cACM SIGMICRO Newsletter
#index11817
#!MDSL, which stands for Microcomputer Design and Simulation Language, is one of an ever growing number of computer hardware design (or description) languages or CHDL's. The introduction of any new language, particularly a new CHDL, is accompanied by a number of WHYs. Why should anyone bother to develop a CHDL? Why did we bother to develop a new one? Why did MDSL take the form it did?


#*A system for automatic software evaluation
#@B. C. Hodges,J. P. Ryan
#t1976
#cProceedings of the 2nd international conference on Software engineering
#index549919
#%240173
#%316233
#%321876
#%329737
#%333809
#%552136
#%552816
#!The production of consistently executable and dependable software demands a thoughtful systematic implementation&mdash;with clear documentation at each production stage. Recognizing this, the Data Systems Laboratory, at Marshall Space Flight Center, NASA, began a research effort to help discover and institute sound engineering principles into a methodology for the production of software. The design of this methodology is based upon five principal stages of software development: 1. Feasibility: Can software be written to solve the initial problem? 2. Requirements/Design: Are software requirements and design clear, complete, traceable, and testable? 3. Coding: Is use being made of reliable high level coding practices? 4. Testing: Is testing sufficiently thorough to instill initial user confidence? 5. Maintenance: has the software and its design been explicitly documented?


#*Computer-aided synthesis of matching networks for microwave amplifiers.
#@Douglas Jay Mellor
#t1975
#c
#index196473


#*Recursive unsolvability of a complex of problems proposed by post
#@Wilson Eugene Singletary
#t1964
#c
#index189465


#*A behavioral approach to implementation of computer based management information systems.
#@Michael Allan Kole
#t1979
#c
#index202148


#*Programmed methods for printer graphical output
#@David Garfinkel
#t1962
#cCommunications of the ACM
#index321600
#!It is frequently desirable to display the results of computation in a graphical form. This is often done through the use of special hardware such as digital X,Y-plotters. Programmed graphical output for standard printers is preferable in several situations: (1) when economic considerations do not justify the expense of special hardware for the purpose, (2) when a combination of graphical output with some other kind, such as explanatory material, is desired, and (3) when some special variety of graphical output is needed which cannot readily be drawn by an analog device. A number of routines have been prepared (primarily by users rather than manufacturers) to convert numerical data into graphical form for printing by output typewriters or line printers. Virtually nothing on this subject has been published, and this report represents an admittedly incomplete attempt to describe this technique and suggest possibilities for its use. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Logic Design Automation of Fan-In Limited NAND Networks
#@D. L. Dietmeyer,Yueh-Hsung Su
#t1969
#cIEEE Transactions on Computers
#index343158
#!Factoring techniques are incorporated in computer-oriented algorithms for the synthesis of fan-in limited NAND switching networks. Tree networks with reduced gate count or levels of logic are sought. While example FORTRAN programs emphasize computer execution of the algorithms, they are also efficient for hand execution.


#*A New Algorithm for Generating Prime Implicants
#@J. R. Slagle,Chin-Liang Chang,R. C. T. Lee
#t1970
#cIEEE Transactions on Computers
#index344470
#!This paper describes an algorithm which will generate all the prime implicants of a Boolean function. The algorithm is different from those previously given in the literature, and in many cases it is more efficient. It is proved that the algorithm will find all the prime implicants. The algorithm may possibly generate some nonprime implicants. However, using frequency orderings on literals, the experiments with the algorithm show that it usually generates very few ( possibly none) nonprime implicants. Furthermore, the algorithm may be used to find the minimal sums of a Boolean function. The algorithm is implemented by a computer program in the LISP language.


#*Workshop Report Computer Packaging
#@J. W. Balde
#t1976
#cComputer
#index346637
#!On May 19-21, the Computer Packaging Committee of the IEEE Computer Society held its biennial workshop at Split Rock Lodge in the Poconos. Following the same format as in the past, the meeting featured a keynote speech and five technical sessions. Some 60 people from 14 states plus England and Japan were in attendance.


#*Direct connection between Compiling Techniques and Databases courses
#@Nadia Thalmann
#t1978
#cProceedings of the ninth SIGCSE technical symposium on Computer science education
#index547040
#%170184
#%178659
#%240173
#%321318
#%326368
#%552881
#!Two of the most demanding subjects in a Computer Science Curriculum are Compiling Techniques and Databases. In both courses, a major problem is: what should be the main project in the laboratory?. Since 1974, we have had students at various universities write compilers (2) in such a course. In each case, a complete compiler has been implemented. We have tried to establish a direct connection between the Compiling Techniques Course and the Databases Course because both can be selectively chosen by the same students. This paper is divided into three parts: first, we outline the content of each course and the relationship existing between them; secondly, we analyze the criteria for language selection with regards to both courses (also with respect to methodology and to structured programming); third, we discuss the language and illustrate it using some examples.


#*An answer to a user's plea?
#@D. E. Morgan,J. A. Campbell
#t1973
#cProceedings of the 1973 ACM SIGME symposium
#index546070
#%330385
#%331945
#!An era of consumer awareness and power is upon us. Although the great &ldquo;Silent Majority&rdquo; of computer system users (or consumers) may not be aware of it yet, the dawn of their era of awareness and power is near! With the development of multiaccess computer systems and networks of computers, the user is beginning to get the opportunity to employ his choice of system to execute his programs. Even now, some fortunate users are no longer constrained to use the possibly inefficient services of the neighborhood computer monopoly, their organization's local computer center. They are able to run their programs at installations that give them the most for their money, merely by punching the buttons of their telephone. As this era dawns, directors of inefficient computer centers must be wary lest their empires wither from lack of users. But alas, the poor user! A few problems must be solved even as his era dawns! How does he know that computing at his local computer centre costs too much? How can he determine which system gives him the &ldquo;biggest bang for his buck&rdquo;?


#*Numerical integration with complex exponential kernels
#@Meyer Mike Kaplan
#t1969
#c
#index203007


#*Software aids for microprogram development
#@Christopher Vickery
#t1974
#cConference record of the 7th annual workshop on Microprogramming
#index552922
#%545921
#%549474
#!Debugging of microprograms can be approached in three ways: (1) with the aid of hardware test sets and monitors, (2) through interactive debugging programs, and (3) through simulation techniques. This paper discusses these three methods and describes an interactive debugging program and a simulator developed for debugging microprograms for the Interdata model 85 minicomputer.


#*Computer aids to medical diagnosis&mdash;problems and progress
#@Stephen R. Yarnall,Richard A. Kronmal
#t1966
#cProceedings of the 1966 21st national conference
#index550399
#%327766
#!Computers are increasingly being used in medicine for a variety of applications, as outlined below: 1. Business&mdash;patient billing, record-keeping 2. Retrieval&mdash;patient records, medical literature 3. Laboratory control systems 4. Statistical data processing 5. Simulation&mdash;physiologic models 6. Teaching programs 7. Medical diagnosis and decision-making In this paper we will restrict our discussion to the use of computers as an aid to diagnosis and decision-making. We will consider the question, &ldquo;Why use computers as an aid to diagnosis?&rdquo;, and review in general terms what progress has been made in this application. We will then discuss some of the methods and problems in current approaches to computer-aided diagnosis, and conclude with a few speculations and suggestions for the future.


#*Algorithmic and computer code developments for combinatorial and network problems.
#@Richard Stuart Barr
#t1978
#c
#index195955


#*Review of "Mathematical Modeling for Water Pollution Control Processes, by Thomas M. Keinath and Martin P. Wanielista", Ann Arbor Science Publishers
#@
#t1976
#cACM SIGSIM Simulation Digest
#index578515
#!This volume dealing with dynamic and steadystate simulation and mathematical models focuses on process performance models in water pollution control. According to the author, the volume has three major purposes: (1) establishment of the current status of these models, with special attention given to model development, data requirements, simulation techniques and applicability; (2) identification of models possessing actual design and operation applications; and (3) defining simplied models and mathematically simulate the ecosystems discussed. The authors of the various chapters have done much to help the editors achieve their goals. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*The Hyperplane Method for an Array Computer
#@Leslie Lamport
#t1974
#cProceedings of the Sagamore Computer Conference on Parallel Processing
#index278768


#*Message communication protocol and operating system design for the Distributed Loop Computer Network (DLCN)
#@Ming T. Liu,Cecil C Reames
#t1977
#cProceedings of the 4th annual symposium on Computer architecture
#index554976
#%190051
#%554599
#!The Distributed Loop Computer Network (DLCN) is envisioned as a powerful, unified distributed computing system which interconnects midi/mini/micro-computers, terminals and other peripherals through careful integration of hardware, software and a loop communication network. Research concerning DLCN has concentrated on the loop communication network, message protocol and distributed network operating system. For the loop communication network, previous papers [2,3] reported a novel message transmission mechanism, its hardware implementation, and its superior performance verified by GPSS simulation. This paper presents an overview of the design requirements and implementation techniques for DLCN's message protocol and network operating system. Firstly, a bit-oriented distributed message communication protocol (DLMCP) which handles four message types under one common format is proposed. Besides user information transfer, this protocol supports automatic hardware-generated message acknowledgment, error detection and recovery, and network control and distributed operating system functions, Secondly, the network operating system (DLOS) is described which provides facilities for interprocess communication by process name, global process control and calling of remote programs, generalized data transfer, alterable multi-linked process control structures, distributed resource management, and logical I/O transmission in a distributed file system.


#*Transmission line models, a unified physical network approach
#@Sergio Bernstein
#t1976
#cProceedings of the 13th Design Automation Conference
#index546417
#%554088
#!Digital signals in high-speed computers and communications systems require that even short interconnections be treated as transmission lines, and existing circuit analysts programs (ECAP-II, ASTAP, SCEPTRE, I/TRAC-II) have been used effectively to model lossless and non-dispersive lines. Now, simple networks have been developed which can model accurately the effects of dispersion due to resistance and skin effect, of homogeneous, linear, transmission lines and cables. They can be used with any presently available circuit analysis program, to obtain efficient and accurate simulations. Theoretical responses of lines having large resistance and/or skin effect losses can be approximated to an accuracy of &plusmn;2% over a range of 0.1 to 500 time constants, and a single network configuration can be used to model any type of losses, simply by changing the component values.


#*Mathematical Work of Charles Babbage
#@J. M. Dubbey
#t1978
#c
#index623664


#*Innovative applications of computer science: innovative applications of computer science in education
#@
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index56356


#*Closure of families of languages under substitution operators
#@David J. Lewis
#t1970
#cProceedings of the second annual ACM symposium on Theory of computing
#index548131
#!This paper treats the closure of families of formal languages under operators which may be viewed as substitution into a particular language. A language L over alphabet {a1,...,an} induces an n-place operator on languages by substitution of the n arguments Li for the symbols ai. For example, if L is regular, it induces an operator under which any full AFL is closed. In section two we find a large class of full AFL's which are closed under no other such operators than those induced by regular languages. Also, for any full AFL @@@@', let @@@@ be the class of languages which @@@@' is closed under substitution into. Then @@@@ is itself a full AFL and is closed under substitution. Finally we show that any substitution-closed full AFL @@@@ is obtained in this manner from some non-substitution-closed full AFL @@@@ (except when @@@@ is the universal family). The study is based on the concept of a full AFL, and in section one considerable effort is devoted to a novel approach to the subject. A full AFL is taken to be a family of languages closed under finite-state transducer mappings and substitution into regular sets. By replacing the family of regular sets with more general families we obtain some broad results about canonical forms for derivations of languages from other languages using transducers and substitution. These forms yield several known forms as special cases, and provide tools needed for the study of full AFL's in section two.


#*The Next Three Generations
#@C. C. Foster
#t1972
#cComputer
#index339956
#!In the beginning there was ENIAC. Then there was the 650, then the 7090 and then the 360. By any reasonable mathematics that makes four generations, but by judicious use of zero- origin indexing, we can come out with the present day machinery belonging to the third generation. In this paper, we will try to look at the next three generations of computers.


#*An improved illumination model for shaded display
#@Turner Whitted
#t1979
#cProceedings of the 6th annual conference on Computer graphics and interactive techniques
#index553240
#!To accurately render a scene, global illumination information that affects the intensity of each pixel of the image must be known at the time the intensity is calculated. In a simplified form, this information is stored in a tree of &ldquo;rays&rdquo; extending from the viewer to the first surface encountered and from there to other surfaces and to the light sources. The visible surface algorithm creates this tree for each pixel of the display and passes it to the shader. The shader then traverses the tree to determine the intensity of the light received by the viewer. Consideration of all of these factors allows the shader to accurately simulate true reflection, shadows, and refraction as well as the effects simulated by conventional shaders. Anti-aliasing is included as an integral part of the visibility calculations. Surfaces displayed include curved as well as polygonal surfaces.


#*Computer simulation of computer system performance
#@Norman R. Nielsen
#t1967
#cProceedings of the 1967 22nd national conference
#index549621
#%317974
#%323727
#%324537
#%325486
#%327067
#%329508
#%546056
#!As the usage of some computer systems became more specialized and complicated, there became a need to study the performance of the software as well as the hardware. Thus, simulations were developed to assist in the design and in the improvement of the overall performance of these systems. The categories covered by such simulations ranged from batch processing direct couple systems to time-sharing systems to more specific systems such as those for message processing and switching. It is the intent of this paper to examine the circumstances which have led to the existing state of affairs and to illustrate the benefits which appropriate system performance simulations of some of the newer systems could bestow.


#*Metalanguage and syntax specification
#@Walter H. Burkhardt
#t1965
#cCommunications of the ACM
#index320821
#%318812
#%321034
#%329080
#%328541


#*A design aids data base for digital components
#@Daniel J. Sucher,Donald F. Wann
#t1979
#cProceedings of the 16th Design Automation Conference
#index554452
#%329675
#!A data base containing pertinent information about the components used in a design is a central part of all digital design aids systems. This paper outlines a data base that has been developed for accomodating a wide variety of integrated circuits (IC's) as well as discrete components. A detailed description of the file structure and access subroutines is included, along with a discussion of the design decisions made during their construction.


#*A computer system to aid insurance company investment portfolio management
#@William Engel Millner
#t1970
#c
#index195988


#*Design rule verification based on one dimensional scans
#@P. Wilcox,H. Rombeek,D. M. Caughey
#t1978
#cProceedings of the 15th Design Automation Conference
#index544527
#%548058
#%550139
#%548089
#%544616
#%551855
#!Bell-Northern Research has developed a program for design rule checking of integrated circuit masks, based on a one-dimensional scanning technique using a novel data coding scheme for efficient processing of large volumes of geometric data. The rule checking concept is very simple and the program is small and easily implemented. The technique is also extremely economical, costing less than &dollar;100 to apply 25 design checks to a high density 5200 &micro;m square silicon gate n-channel mask. CPU time varies approximately as the power 1.2 of the amount of data in the mask.


#*&ldquo;INSTANT CAI&rdquo;
#@R. F. Conklin
#t1974
#cProceedings of the sixth international conference on APL
#index547512
#!This paper describes four simple APL functions which allow an author to quickly create a sequence of computer-aided instruction (CAI) questions, answers, and responses. Rather than requiring knowledge of a computer language or programming logic, the author needs only to type four lines of input for each question in a drill sequence: 1) the question, 2) the correct answer, 3) the correct answer response to the student, and 4) a hint in case of a wrong answer. Each student needs only to enter the name of a drill and follow instructions. At the end of a class session, the teacher can retrieve a set of statistics, providing student and class averages.


#*Determination of the fittest number of truth-values and canonical forms of logical functions for a many-valued axiom set by a computer
#@Motinori Goto,Shinji Kao,Tomoko Ninomiya
#t1978
#cProceedings of the eighth international symposium on Multiple-valued logic
#index553534
#!Usually the number of truth-values and the meanings of operators in a given axiom set for many-valued logic are not defined explicitly but done implicitly by many formulas derived from the set. However, it is very laborious to determine them. In this paper, axioms and undefined operators are treated as logical equations and unknown logical functions respectively. General solutions of those equations give general truth tables for undefined operators. For example, M. Wajsberg's axiom set is solved by a computer. The fittest number of truth-values are determined in relation to the construction of the canonical form of logical functions.


#*Towards a simulation model of motivation and adjustment
#@F. Paul Wyman,John W. Slocum, Jr.,Richard R. Reed
#t1973
#cProceedings of the 6th conference on Winter simulation
#index545759
#!A model of human motivation is formulated on the basis of Maslow's need theory. Additionally, behaviors are selected by degree of tension and are reinforced by environmental reactions which facilitate or frustrate reduction of tension according to the aggressiveness of behavior. Comparisons of alternative environments support the internal consistency of the model. Recommendations are made to improve the stability of the model and for behavioral research that would be necessary for validation.


#*Experience with Module-Level Specification Methods
#@J. W. Braken
#t1975
#cComputer
#index339937
#!During the past three years, SofTech has been developing design and specification methods with the goals of improving design quality, reducing integration problems, increasing software portability, and enhancing project control and estimating methods. In particular we wanted to increase the visibility of the detailed design process in order to facilitate design reviews and design iterations. We also hoped to improve the description and management of all module interfaces in order to reduce integration problems and to allow alternative implementations of a module to be "plug-to-plug" compatible-an important consideration when software systems requiring several man-years to build are designed to be portable. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Linkers and Loaders
#@Leon Presser,John R. White
#t1972
#cACM Computing Surveys (CSUR)
#index321122
#%316426
#%334930
#%333166


#*A minicomputer based Interactive Graphics System as used for electronic design and automation
#@Philippe Villers
#t1978
#cProceedings of the 15th Design Automation Conference
#index548000
#!Described in this paper is the use of a commercially available Interactive Graphics System for electronic design, drafting and documentation. The system is used starting from a rough schematic and ending with a tested, manufactured printed circuit board. Discussed in the paper are major aspects and quantitative results obtained in a range of computer aided tasks. These range from initial P.C. design and prototyping to final production, documentation and testing as performed in a relatively small engineering department. The turnkey system employed is Computervision's Designer TM System, with output to Computer Automation's Capable TM printed circuit board tester. Major uses of the system include its use in a novel way at the prototyping stage to produce P.C. prototype circuit boards. Others include the use of its integral minicomputer based P.C. board routing programs supplemented by interactive graphics as well as the use of a series of computer based design verification features both for checking physical constraints and for ensuring data integrity and consistency within the entire documentation package. These verifications eliminate many forms of manual checking. Actual examples are presented.


#*Graphics for data analysis
#@Roy E. Welsch,Helge Bjaaland
#t1974
#cProceedings of the 1st annual conference on Computer graphics and interactive techniques
#index245362
#!In recent years, graphics has become an essential part of modern data analysis. It is particularly useful for interactive data analysis. This paper describes a system called CLOUDS which is designed to make available on inexpensive storage tube terminals a wide range of graphic tools related to data analysis, economics, and management science. The system can be accessed nationwide by non profit organizations via the National Bureau of Economic Research computer network.


#*A linguistic approach to mechanical pattern recognition
#@Peter John Knoke
#t1968
#c
#index185762


#*Database management systems
#@B Shneiderman
#t1976
#c
#index175053


#*SIGNUM (Tutorial Session)
#@John Rice,Wayne Cowell,Edward Battiste
#t1976
#cProceedings of the 1976 annual conference
#index544944
#!This tutorial session is intended to gave the audience an overview of current and possible future mathematical software activities and outlets. The three speakers will cover the academic, government and private sector aspects of mathematical software. The effectiveness of certain journals, textbooks that include software, and conferences will be considered. Various government sponsored research activities will be reviewed and the problems of establishing a financially viable company in this area will be discussed.


#*Privacy issues in the private sector: a commissioner's perspective
#@Willis H. Ware
#t1978
#cACM SIGCAS Computers and Society
#index301943


#*Computing and mathematics in society
#@Donald L. Thomsen, Jr.,Warren J. Ewens,James S. Coleman,John J. Donovan,Warren E. Walker
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index63291
#!The Panel will address selected areas of current interest where computing and mathematics have been successfully applied to societal problems. Those societal fields which have been chosen are biological systems, sociology, energy, and urban emergency services. Although interrelated each area has quite different characteristics. In biology we examine long term evolutionary phenomena; in sociology we review through the techniques of simulation and surveys those human relations which are of concern day by day, month by month, and year by year; in energy we discuss problems both short and long range having to do with basic sources and distribution; and in emergency urban services we address very immediate activity related to what happens when that fire alarm box is pulled down the street. In these four areas the Panel will present examples of noteworthy past successes and conjectures as to where future progress very likely will be made.


#*Partitions and Principles for Secure Operating Systems
#@Gregory R. Andrews
#t1975
#c
#index111449
#!As part of the general goal of providing secure computer systems, the design of verifiably secure operating systems is one of the most important tasks. This paper addresses the problem by defining security in terms of a model and proposing a set of principles which we feel should be satisfied in a secure operating system. Informally, an operating system is secure if its users completely control the use of all information which they introduce. Four key partitions are identified: user interface functions, user invoked services, background services, and the security kernel. Principles are then defined to insure that interface functions provide a safe initial environment for executing user programs, user called services are confined, background services have no access to user information, and the security kernel adequately protects information storage.


#*Anomalous behavior of the fifty-percent rule in dynamic memory allocation
#@John E. Shore
#t1977
#cCommunications of the ACM
#index330952
#%79620
#%185387
#%315236
#%316426
#%319077
#%325027
#%326158
#%330511
#%331803
#%335384
#!This paper reports simulation data showing that, in dynamic memory allocation, the average free-to-allocated-block ratio can differ considerably and in both directions from the predictions of the 50 percent rule. A new derivation is given, and it is shown that previous derivations make an assumption that may be violated frequently. On the basis of the simulation data and the derivation, it is hypothesized that the anomalous behavior results from the combined effects of systematic placement and the statistics of the release process. Additional simulations support this hypothesis. Systematic placement, which refers to the natural convention of always allocating storage requests against the same end of the free block selected by the allocation strategy, tends to order blocks within contiguous groups according to their allocation time. The degree of anomalous behavior depends on the extent to which allocated blocks are released in the order of their allocation. For non-Markovian release processes, the extent of the correlation between allocation order and release order varies approximately inversely with the coefficient of variation of the memory residence time distribution. The simulations show that allocation efficiency depends strongly on the residence time distribution; efficiency decreases as the distribution's coefficient of variation increases. Some practical implications are briefly discussed.


#*Engineering A Program Optimizer
#@John H. Crawford,Mehdi Jazayeri
#t1978
#cProceedings of the 1978 annual conference
#index552717
#%320395
#%321876
#%329737
#!We describe our work in formally specifying an extension to an existing, large software system. In particular, we were interested in adding a global optimization phase to an operational cross-compiler. We describe the module decomposition of the optimizer and how the modules were formally specified. The resulting modules constitute a set of tools and a framework which promote the rapid and efficient implementation of porgram optimizers. The information hiding strategy of Parnas was followed in the module decomposition. A specification technique proposed by Parnas was intended to be used for specifying the modules. During the course of specification, however, we found Knuth's attribute grammars a much more convenient specification technique for some aspects of the design, espcially the syntax dependent parts. In the final design, these two different techniques were combined to produce a complete specification which is superior to any we found using either technique alone. The use of attribute grammars also shows an interesting application of language theory to program specification and design.


#*Communication nets in transportation
#@Dan E. Couchenour,C. F. Norton,Donald LePorte,J. Swartz,Dan E. Couchenour
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index60529
#!Through development and application of combined computer and communications technology the transportation telecommunication network provides the optimum facility utilization. Standardization of data interchange formats, computer-to-computer interfaces, and network control procedures are today a reality. Topics will include: (1) Communication network planning and implementation, (2) Standardization of data interchange, (3) Network consolidation, (4) Computer-to-computer line control procedures used to provide assurance of data interchange, and (5) A panel discussion: Questions and Answers.


#*Developing a user services professional
#@Lois J. Secrist
#t1975
#cProceedings of the 3rd annual ACM SIGUCCS conference on User services
#index544926
#!It is scarcely possible to develop a new professional category without determining just what this new profession is to deliver. Given a User Services professional, what is he or she expected to accomplish? To examine the need for a new profession and to determine what technical expertise might he needed, we first must set some goals for the User Services function in a university computer center.


#*A survey of the literature in computer science education since curriculum '68
#@Richard H. Austing,Bruce H. Barnes,Gerald L. Engel
#t1977
#cCommunications of the ACM
#index315296
#%232655
#%250727
#%254482
#%314782
#%552201
#%552323
#%545053
#%547546
#%553617
#%320517
#%316004
#%551592
#%552453
#%319577
#%548522
#%547020
#%326004
#%549200
#%547376
#%553650
#%548639
#%552489
#%550075
#%552312
#%547109
#%554636
#%551867
#%550345
#%323936
#%548380
#%551328
#%549732
#%552293
#%552999
#%548753
#%551393
#%551333
#%331591
#%554978
#%550604
#%544961
#%549485
#%550835
#%317150
#%579038
#%546724
#%548732
#%549788
#%554815
#%552331
#%554175
#%553585
#%547388
#%324682
#%552247
#%547517
#%549011
#%554405
#%332573
#%554264
#%549885
#%553547
#%323530
#%334753
#%549735
#%550905
#%553139
#%316178
#%551318
#%553707
#%554687
#%549721
#%546331
#%549972
#%554525
#%549340
#%553750
#%552234
#%334770
#%325914
#%327127
#%552411
#%549589
#%552239
#%545926
#%553638
#%544925
#%553329
#%545640
#%326637
#%334754
#%551672
#%551439
#%548907
#%549442
#%545409
#%546089
#%548307
#%549922
#%551275
#%549593
#%318784
#%554319
#%552530
#%550488
#%551327
#%549622
#%547687
#%544759
#%551588
#%549756
#!A bibliography of approximately two hundred references in computer science education appearing in the literature since the publication of &ldquo;Curriculum '68&rdquo; is presented. The bibliography itself is preceded by brief descriptive materials organizing the references into the categories of survey reports, activities of professional organizations, philosophy of programs, description of programs, description of courses and other materials.


#*A Technique for Parsing Ambiguous Languages
#@Cornelis H. A. Koster
#t1974
#cGI - 4. Jahrestagung
#index275283


#*Operating systems for microcomputers: good, bad, and non-existant
#@Greg. L. Weinstein
#t1979
#cProceedings of the 17th annual Southeast regional conference
#index618075
#!Microcomputers are becoming an important area of study in computer science, as their quantities in-crease, their prices decrease, and they become more common and distributed throughout society. Yet perhaps the least considered and developed area of microcomputer systems is that of their operating systems.In this paper will be an attempt to classify currently available operating systems into three categories. First is the machine without any specific group of software known as an operating system. However, key firmware packages contain services something akin to OS primitives. Second is the primitive system usually readily available, perhaps at no charge, with an OEM hardware device. This type of operating system typically supports this OEM device, some system console device, and a limited set of commands, and it also manages some basic file structure. The third type is also the most advanced type available -- the full-scope operating system, such as Digital Research CP/M. This type provides both a software standard compatible across machines and a full set of features including expandability, a complex file structure, and an ability to support many devices.Besides describing the categories involved, this paper will also cite typical examples, describe current problems, and suggest areas for future improvement as this field advances. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*An "intelligent" on-line assistant and tutor: NLS-scholar
#@Mario C. Grignetti,Catherine Hausmann,Laura Gould
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index56971
#!NLS-SCHOLAR is an experimental system that uses Artificial Intelligence techniques to teach computer-naive people how to use the powerful and complex editor of NLS. This teaching is accomplished by presenting a sequence of lessons. During each lesson the student may interact with the system by asking and answering questions, performing tasks which are posed by the system, and performing tasks of his own choosing. Tasks are actually executed using our own implementation of NLS EDIT. Those tasks which have been posed are evaluated by the system, and the student is given encouragement, advice, and assistance.


#*Newsletter for Computer-Aided Design
#@
#t1971
#cComputer
#index342717


#*Free access at UW-Madison
#@Fred M. Jacobson
#t1976
#cProceedings of the 4th annual ACM SIGUCCS conference on User services
#index241602


#*A letter from the ACM treasurer: ACM financial highlights
#@Aaron Finerman
#t1975
#cCommunications of the ACM
#index321902


#*Primitive functions for graphics in APL
#@D. S. Galbraith
#t1976
#cACM SIGAPL APL Quote Quad
#index232418


#*Software for Nonlinear Partial Differential Equations
#@Richard F. Sincovec,Niel K. Madsen
#t1975
#cACM Transactions on Mathematical Software (TOMS)
#index330143
#%319676
#%321200


#*Marker automata
#@Pei Hsia
#t1972
#c
#index192193


#*The recognition of Series Parallel digraphs
#@Jacobo Valdes,Robert E. Tarjan,Eugene L. Lawler
#t1979
#cProceedings of the eleventh annual ACM symposium on Theory of computing
#index547103
#%79620
#!We present an algorithm that recognizes the class of General Series Parallel digraphs and runs in time proportional to the size of its input. To perform this recognition task it is necessary to compute the transitive reduction and transitive closure of any General Series Parallel digraph. Our analysis is based on the relationship between General Series Parallel digraphs and a class of well known models of electrical networks.


#*Der Datex-Dienst mit Paketvermittlung (DATEX-P)
#@Friedhelm Hillebrand
#t1979
#cKommunikation in Verteilten Systemen - Workshop der Gesellschaft f&uuml;r Informatik e.V.
#index367219


#*A simulation model for strip mining
#@D. W. Sifferd
#t1968
#cProceedings of the second conference on Applications of simulations
#index548688
#!The purpose of this paper is to present concepts and approaches for implementing a strip mining production planning system. Submodels within this system use FORTRAN IV, GPSS/360, MPS/360, and MARVEL languages.


#*Review of "Notes on Linear Programming by M. Sakarovitch", Van Nostrand-Reinhold, 1971
#@Claude-Alain Burdet
#t1973
#cIssue 14 (May 1973)
#index2540


#*A syntax for solving linear equations
#@C. L. Lawson
#t1972
#cACM SIGNUM Newsletter
#index98516
#!There are a number of well known reasons to prefer solving a system of linear equations, Ax = b, directly rather than first computing C = A-1 and then computing x = Cb. Nevertheless some programming languages provide a special operator for matrix inversion but no equally convenient way to request the direct solution of Ax = b. This situation probably has the effect of reinforcing in the user the unfortunate idea that since x = A-1b is a convenient mathematical notation for the solution of Ax = b it is also the appropriate operational prescription.


#*Traffic considerations in switched data networks
#@G. J. Clowes,C. S. Jayasuriya
#t1973
#cProceedings of the third ACM symposium on Data communications and Data networks: Analysis and design
#index544837
#%552410
#!Based on a model for the data traffic between major Canadian cities, different types of switched networks are compared chiefly on the basis of channel miles. Circuit switched, packet switched and combined circuit/packet switched networks are compared. Attention is given to the internodal grade of service and the significant network design parameters such as the distribution of message lengths and the selection of packet sizes. Different network topologies, with fixed routing strategies, are analyzed.


#*Eingliederung des rechnerunterst&uuml;tzten Unterrichts in die klinische Ausbildung
#@H. E. Renschler,K. Recht
#t1974
#cRechner-Gest&uuml;tzter Unterricht, RGU '74, Fachtagung-ACU-Arbeitskreis Rechner-Gest&uuml;tzter Unterricht
#index566349


#*The science of datalogy
#@Peter Naur
#t1966
#cCommunications of the ACM
#index322726


#*Implementation aspects of the symbol hardware compiler
#@T. A. Laliotis
#t1973
#cProceedings of the 1st annual symposium on Computer architecture
#index547722
#!One of the most outstanding features of the SYMBOL computer is its high level hardware compiler. This paper presents some aspects of the hardware implementation including the network characteristics of the communication scheme between compiler, system supervisor, and Memory Controller, the functional breakdown into distinct sections for implementation, the support hardware (registers, tables, etc.,), the Name Table structure, and some of the linking techniques for the structured output of the compiler.


#*Gaining production rules for a MARKOV Braille translation algorithm
#@Hermann Kamp
#t1975
#cIssue 15 (March 1975)
#index301981


#*Griphos as a relational data base system.
#@Scott Abbey
#t1975
#c
#index198712


#*Speech analysis and recognition for computer-administered instruction
#@Herman Levin
#t1972
#c
#index191832


#*Internal procedure parameters in structured Fortran precompliers
#@Menachem Malkosh
#t1977
#cACM SIGPLAN Notices
#index312725
#%306853
#%313344
#%323067
#%317259


#*Computer representation of planar regions by their skeletons
#@John L. Pfaltz,Azriel Rosenfeld
#t1967
#cCommunications of the ACM
#index314542
#%329436


#*A Preliminary Evaluation of the Critical Path Method for Scheduling Tasks on Multiprocessor Systems
#@W. H. Kohler
#t1975
#cIEEE Transactions on Computers
#index353669
#!The problem of scheduling tasks on a system of independent identical processors is discussed and the performance of a suboptimal method is evaluated. The computation is modeled by an acyclic directed graph G(T,


#*Big trees in a lambda - calculus with lambda - expressions as types
#@Roel C. de Vrijer
#t1975
#cProceedings of the Symposium on Lambda-Calculus and Computer Science Theory
#index259508


#*Die Realisierung von Architekturprinzipien f&uuml;r Methodenbank-Systeme im Modellbanksystem MBS
#@Willi Klösgen,W. Schwarz
#t1979
#cGI - 9. Jahrestagung
#index269910


#*Production systems: or can we do better than BNF
#@Henry F. Ledgard
#t1974
#cCommunications of the ACM
#index335296
#%321433
#%329080
#%330864
#!Since the development of BNF, the definition of the syntax of programming languages has been almost universally associated with context-free requirements. Yet numerous interesting and difficult issues in syntax stem from the context-sensitive requirements, notably the compatibility between the declaration of an identifier and its uses, the correspondence between actual and formal parameters, and issues arising from block structure. This paper explores the use of a formal notation called Production Systems in providing a readable and complete formal definition of syntax. As a practical illustration, a small but significant subset of PL/I is considered. A more detailed presentation, as well as the application to define abstract syntax and translations between languages, is given in a previous paper by the author.


#*Interaction, interfaces and design
#@John S. Gero,Warren G. Julain,W. Neville Holmes
#t1974
#cProceedings of the 11th Design Automation Workshop
#index554993
#!Many planning problems cannot be formulated in such a manner t h a t a well developed optimizing technique can be applied to them to arrive at a satisfactory solution. This may be because of the structure of the problem itself, it may be because objectives and even parameters cannot be adequately described or it may be due to the need to include subjective factors. Additionally there is a class of problems for which the cost of the computation required to reach an optimum is not warranted by the expected gains. When we examine the tools available to a problem solver who wishes to use interactive computing, we find that the languages currently used to achieve interaction are both clumsy and restrictive.


#*Standard COBOL: A Problem-Solving Approach
#@Marilyn Z. Smith
#t1974
#c
#index609433


#*Geometric modelling in ALGOL 68
#@I. C. Braid,R. C. Hillyard
#t1977
#cProceedings of the Strathclyde ALGOL 68 conference
#index553785
#%326284
#!The paper describes the experiences of a small team in writing a substantial ALGOL 68 program to model the shapes of engineering components. The application derives much advantage from structures, operators and the heap. It includes a command interpreter, graphics package, vector and matrix routines, and procedures for moving data structures on the heap to and from disc. A system has been devised to ensure safe, selective compilation of program segments.


#*Regular Events in Stochastic Sequential Machines
#@A. Paz
#t1970
#cIEEE Transactions on Computers
#index346877
#!Events representable in stochastic sequential machines, as defined previously by several authors, are shown to be regular in certain cases. The construction of deterministic machines representing those events is implicit.


#*An investigation of a small high-level language direct execution computer.
#@Nagi M. Abo El Naga
#t1978
#c
#index196160


#*Computer design of temperature desensitized integrated selective amplifiers
#@William Joseph Walsh
#t1969
#c
#index190919


#*Robustness and power studies of some multivariate tests in classical and complex gaussian distributions.
#@Yu-Sheng Hsu
#t1975
#c
#index191229


#*Principles for producing computer animated motion pictures
#@Don Deily
#t1968
#c
#index185874


#*A Modification to the SHR-Optimal State Assignment Procedure
#@P. S. Noe
#t1974
#cIEEE Transactions on Computers
#index347153
#!In a recently published article, Story et al. detailed an organized search process leading to the optimum state assignment for a synchronous sequential machine. Their procedure begins with the calculation of a set of lower bounds (minimum numbers) on the costs of the excitation logic required for each possible distinct partial state assignment.


#*Remark on &ldquo;Algorithm 49: Spherical Neumann Function&rdquo;
#@John P. Coleman
#t1978
#cACM Transactions on Mathematical Software (TOMS)
#index325399
#%316109
#%328489


#*Cubical notation for computer-aided processing of multiple-valued switching functions
#@Stephen Y.H. Su,Peter T. Cheung
#t1976
#cProceedings of the sixth international symposium on Multiple-valued logic
#index553549
#%487502
#%545025
#!In this tutorial paper, cubical notation is introduced for representing multiple-valued switching functions. Various advantages of the cubical notation over other conventional representations are pointed out. The cubical notation is presented in a step-by-step manner and with many different variations. It is general enough to represent any multiple-valued switching functions. Representation of input and output multiple-valued conditions using strings of binary digits are given. Examples are given to show the one-to-one correspondence between the map and the cubical representation of multiple-valued switching functions. The basic set of operators for manipulating arrays of cubes is given. Experience on the computer implementation of cubical notations is reported and the trade-offs between computer execution time, memory spaces and programming effort are given.


#*In defense of the equivalence algorithm
#@Bernard A. Galler,Michael J. Fischer
#t1964
#cCommunications of the ACM
#index328669


#*Design tools for evaluating multiprocessor programs.
#@Philip Howard Mason
#t1976
#c
#index204387


#*A structured beginning COBOL class using structured programming with objectives
#@Ed Keith
#t1976
#cProceedings of the sixth SIGCSE technical symposium on Computer science education
#index548696
#!This paper presents the structure of a beginning class in COBOL which stresses structured programming techniques and is organized as a series of stair-step type objectives. Three topics are stressed in this presentation: the application of student-centered objectives to a COBOL class, structured COBOL examples for commonly encountered logic constructs, and an approach to documenting structured COBOL through an indentation scheme.


#*The concurrent simulation of nearly identical digital networks
#@E. G. Ulrich,T. Baker
#t1973
#cProceedings of the 10th Design Automation Workshop
#index549102
#%323455
#%549253
#!Injecting a single fault into a fault-free digital network creates a &ldquo;bad&rdquo; network which is only slightly dissimilar from the original. Injecting the same stimuli (signals) into both of these networks will produce activity sequences which are often identical, normally almost identical, and rarely substantially different from each other. This similarity between good and bad networks and their activities suggests a method of simulation which avoids the customary duplication of essentially identical good and bad simulations. This method consists of simulating good network activity, and of initiating and performing a concurrent bad network simulation only if bad network activity actually differs from good activity. The run time savings inherent in this method are substantial if hundreds or thousands of bad networks can be simulated in concurrence with a single good network. FANSSIM II is a digital logic simulator under development capable of simulating a 2500 gate network in concurrence with approximately 10,000 single-fault networks. The storage requirements for this simulation are estimated to remain under 450,000 bytes. The effective simulation rate is expected to be above a million signals/dollar, exceeding the real simulation rate of 20,000 signals/dollar for the IBM 360-50 by a factor of 50:1. Some of the techniques and features used are the following: &bull; Fault sources are detected during good network activity and trigger the initiation of concurrent bad network activity. &bull; Fault effects are transmitted piggyback via good signals or separately as independent bad signals. &bull; Fault effects arriving at good gates cause the divergence of bad gates. &bull; Bad gates disappear, or converge, as soon as their inputs and outputs are again in agreement with the associated good gate. &bull; The passage of time is simulated precisely by using assignable rise and fall gate delays. &bull; Feedback, reconvergent fanout, and race detection are handled without special mechanisms. &bull; Economical event handling, desirable here due to accumulation of events of many bad networks, is achieved by using the time mapping6event scheduling technique.


#*Coding Theorems of Information Theory, 3rd edition
#@Jacob Wolfowitz
#t1978
#c
#index610571


#*Computer generation of gamma random variates with non-integral shape parameters
#@N. D. Wallace
#t1974
#cCommunications of the ACM
#index315710
#%551918
#!When the shape parameter, &agr;, is integral, generating gamma random variables with a digital computer is straightforward. There is no simple method for generating gamma random variates with non-integral shape parameters. A common procedure is to approximately generate such random variables by use of the so-called probability switch method. Another procedure, which is exact, is due to J&ouml;hnk. This paper presents a rejection method for exactly generating gamma random variables when &agr; is greater than 1. The efficiency of the rejection method is shown to be better than the efficiency of J&ouml;hnk's method. The paper concludes that when &agr; is non-integral the following mix of procedures yields the best combination of accuracy and efficiency: (1) when &agr; is less than 1, use J&ouml;hnk's method; (2) when 1 is less than &agr; and &agr; is less than 5, use the rejection method; (3) when &agr; is greater than 5, use the probability switch method.


#*Prolog
#@Kenneth A. Bowen
#t1979
#cProceedings of the 1979 annual conference
#index545269
#%148046
#%325466
#%326368
#!Exactly 100 years ago, the first-order predicate calculus was created and defined by Gottlob Frege. In the ensuing century his system was studied and refined by such logicians as Bertrand Russell, David Hilbert, Kurt Godel, Jacques Herbrand, Alonzo Church, and Alan Turing. In the 1950's and 60's attempts were made to use the results of these studies (especially those of Herbrand) in order to program computers to prove theorems automatically. These attempts introduced a new demon to the study of logic: ferocious computational complexity. The investigations of methods to avoid this demon led to the development of new systems of logic which are equivalent to the traditional systems, but are more suited to the efficient mechanical construction of proofs. The most notable among these is the resolution system of J. Alan Robinson [1965],[1979]. Cordell Green [1969] proposed the use of resolution systems in the construction of deductive question-answering systems, and this proposal eventually led Robert Kowalski [1974] to propose the so-called procedural interpretation of logic which forms the basis for the use of logic as a programming language.


#*A decision-set approach to the recognition of handprinted numerals.
#@Soon Kuck Kwon
#t1979
#c
#index194587


#*Comments on a paper by Lowe
#@Kirk Sattley,Robert Millstein
#t1970
#cCommunications of the ACM
#index319045
#!We have read with much interest the paper &ldquo;Automatic Segmentation of Cyclic Program Structures Based on Connectivity and Processor Timing&rdquo; by T. C. Lowe [Comm. ACM 13, 1 (Jan. 1970), 3-6, 9], and we congratulate the author on the clarity of his exposition. However, we're afraid we must question the technique he describes.


#*Proceedings of the second conference on Applications of simulations
#@
#t1968
#cWinter Simulation Conference
#index546760


#*Detection of parallel processable code in computer programs.
#@Ronald Gene Ward
#t1973
#c
#index188397


#*Production Control Packages
#@CORPORATE National Computing Centre, Ltd. Staff
#t1976
#c
#index625948


#*Square Roots and Functional Decompositions of Boolean Functions
#@S. Rudeanu
#t1976
#cIEEE Transactions on Computers
#index347395
#!A square root of an isotone Boolean function f with respect to a variable xi was defined by Reischer and Simovici [10] as a Boolean function s such that holds identically. More generally, given a partition (T,Y,Z) of the set X = (x1,···,xn) of variables, we may be interested in finding a functional decomposition of the form


#*Proceedings of the 1967 22nd national conference
#@Solomon Rosenthal
#t1967
#cACM Annual Conference/Annual Meeting
#index547955


#*Solution characteristics and algorithms for the vertex packing problem.
#@Leslie Earl Trotter, Jr.
#t1973
#c
#index190290


#*Implemented techniques for handling spikes in an assignable delay simulator
#@S. A. Szygenda,A. Lekkos,J. Fike
#t1974
#cProceedings of the 7th conference on Winter simulation - Volume 2
#index546327
#%545616
#%550250
#!The needs for Digital Logic Simulation to analyze design timing problems, such as spike and hazards, has been shown previously (1). In this paper, methods for detecting timing problems are investigated and analyzed. A technique is developed to perform spike and hazard analysis in a less pessimistic approach than has been used previously. It was implemented as an extension of the TEGAS2 simulation system (2) and is capable of associating different turn-on and turn-off propagation delays with an element.


#*Panel on military data networks: Present plans and future requirements
#@Irwin Lebow,Robert E. Lyons,Chris N. Wilcox,Thomas Bartee
#t1979
#cProceedings of the sixth symposium on Data communications
#index553732
#!In the first talk, Dr. Lebow will discuss DoD plans for providing secure voice for three disparate communities within DoD: 1. Narrowband Tactical (datarate: up to 2.4 KB), 2. Wideband Tactical (16 and 32 KB) and 3. Long-haul Strategic (DCS-based, up to 9.6 KB). Dr. Lebow will compare advantages and deficiencies of the three systems and will discuss the evolution of these systems into a two-rate architecture in the 1990's., In the second paper, Dr. Lyons will discuss the DoD system architecture concept for the evolutionary growth of defense data networks: the Integrated AUTODIN System Architecture (IASA). The third paper, presented by Lt. Col. Wilcox will discuss DoD plans for the integrated development of standard Automated Message Handling (AMH) systems for military end-user applications. The final paper, by Dr. Bartee, is a discussion of protocol standardization requirements for the interconnection of present and future DoD data networks such ARPANET, AUTODIN I II, and other DoD data handling networks such as Intelligence community's COINS II (Community On-line Intelligence Network System), and IDHSC II (Intelligence Data Handling System Communications). Bartee will conclude his talk with a discussion of database management problems in computer networks. The discussion will emphasize the data acquisition problem. The session will conclude with a panel discussion among the authors, with questions from the session chairman and the audience.


#*Database abstractions: aggregation
#@John Miles Smith,Diane C. P. Smith
#t1977
#cCommunications of the ACM
#index317127
#%326368
#%335509
#%332320
#!Aggregation is introduced as an abstraction which is important in conceptualizing the real world. Aggregation transforms a relationship between objects into a higher-level object. A new data type, called aggregate, is developed which, under certain criteria of &ldquo;well-definedness,&rdquo; specifies aggregation abstractions. Relational databases defined as collections of aggregates are structured as a hierarchy of n-ary relations. To maintain well-definedness, update operations on such databases must preserve two invariants. Well-defined relations are distinct from relations in third normal form. It is shown that these notions are complementary and both are important in database design. A top-down methodology for database design is described which separates decisions concerning aggregate structure from decisions concerning key identification. It is suggested that aggregate types, and other types which support real-world abstractions without introducing implementation detail, should be incorporated into programming languages.


#*A user authentication scheme not requiring secrecy in the computer
#@Arthur Evans, Jr.,William Kantrowitz,Edwin Weiss
#t1974
#cCommunications of the ACM
#index328690
#%81323
#%232980
#%622734
#!In many computer operating systems a user authenticates himself by entering a secret password known solely to himself and the system. The system compares this password with one recorded in a Password Table which is available to only the authentication program. The integrity of the system depends on keeping the table secret. In this paper a password scheme is presented which does not require secrecy in the computer. All aspects of the system, including all relevant code and data bases, may be known by anyone attempting to intrude. The scheme is based on using a function H which the would-be intruder is unable to invert. This function is applied to the user's password and the result compared to a table entry, a match being interpreted as authentication of the user. The intruder may know all about H and have access to the table, but he can penetrate the system only if he can invert H to determine an input that produces a given output. This paper discusses issues surrounding selection of a suitable H. Two different plausible arguments are given that penetration would be exceedingly difficult, and it is then argued that more rigorous results are unlikely. Finally, some human engineering problems relating to the scheme are discussed.


#*On sets of numbers recognized by push-down automat
#@Jean Berstel
#t1972
#cProceedings of the 13th Annual Symposium on Switching and Automata Theory (swat 1972)
#index398321
#!A set of positive integers is said to be recognizable by a push-down automaton if its elements, written in k-ary notation for some k ≥ 2, form a context-free language. Some general properties of this type of sets are given. The set of squares is shown not to be recognizable. A necessary condition is proved for a subset of a set defined by a linear recurrence relation of some special form to be recognizable. The set of square-free integers is investigated.


#*Coroutines in a Theory of Programmable Machines
#@J. L. Baker
#t1977
#c
#index200366
#!It is shown that, in the author''s theory of programmable machines, the composition of functions computable by programs is in some important cases computable by a program constructed to use the given programs as coroutines. To illustrate the utility of this result, a characterization of the full AFLs in terms of programmable machines is established with its help. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*An empirical study of the effectiveness of programed instruction and computer-assisted instruction in elementary accounting
#@Sunion Theodore Hong
#t1972
#c
#index187019


#*On-line computer auditing
#@Harvey S. Koch
#t1979
#cProceedings of the 1979 annual conference
#index547082
#!An auditing technique that audits transactions as they are being processed will be introduced. Concurrent and Intermittent Simulation (CIS) is an auditing technique that is very similar to parallel simulation in terms of the amount of work and type of code that must be completed by the auditor. However, in terms of capabilities, CIS is much more advanced than parallel simulation. CIS is an auditing technique that simulates the instruction execution of the application at the time the application is processing a transaction. All data and input to the application is accessible by and shared with the simulation. This means that the simulation knows about each transaction that is entered to the application, all accesses to the data base by the application can be monitored and all working-storage values of the application can be accessed by the simulation. Before any updates are made to the data base or before any output is returned to the users, the simulation can verify the results by executing the appropriate instructions of the simulation by having access to the transaction, working storage values and the data base. If an inconsistency is found, all pertinent information about the system status can be put into the exception log. The simulation then has the choice to allow the results computed by the application to be used, to use the results computed by the simulation or not to use any of the results, as if there was no transaction.


#*Continuing education in information system development
#@Russell M. Armstrong
#t1972
#cProceedings of the ACM annual conference - Volume 1
#index552453
#%318784
#%319577
#!Key issues in continuing education for systems staffs involved in the development of in formation systems are identified and discussed. Perspective is provided by reference to the curriculum development efforts of the ACM Curriculum Committee on Computer Education for Management. Recommendations are made for efforts towards improving the field of counting education.


#*Management Issues in Cooperative Computing
#@Dan Bernard
#t1979
#cACM Computing Surveys (CSUR)
#index323133
#%555257


#*Introduction to simulation modeling
#@J. William Schmidt
#t1978
#cProceedings of the 10th conference on Winter simulation - Volume 1
#index554665
#!Since World War II system modeling has played an increasingly important role in the analysis of complex systems in both the private and public sectors. In the broadest sense, a model may be considered to be a representation of reality without the presence of reality itself. Hence, pictures, graphs, management games, computer programs and mathematical equations may be considered models of those systems which they represent. For the purposes of this discussion we will restrict our attention to that class of models which attempts to capture the relationship between the behavior of a measure or measures of system effectiveness and the behavior of those variables and parameters which influence the measure(s) of effectiveness and includes simulation and mathematical models. The specific focus of our attention will be on simulation models.


#*Conjectures and counterexamples
#@David Gelperin
#t1972
#cIssue 34 (June 1972)
#index99775


#*The software engineering laboratory: Objectives
#@Victor R. Basili,Marvin V. Zelkowitz
#t1977
#cProceedings of the fifteenth annual SIGCPR conference
#index549901
#%544920
#%549716
#%551281
#!A great deal of time and money has been and will continue to be spent in developing software. Much effort has gone into the generation of various software development methodologies that are meant to improve both the process and the product ([MYER, 75], [BAKE, 74], [WOLV, 72]). Unfortunately, it has not always been clear what the underlying principles involved in the software development process are and what effect the methodologies have; it is not always clear what constitutes a better product. Thus progress in finding techniques that produce better, cheaper software depends on developing new deeper understandings of good software and the software development process through studying the underlying principles involved in software and the development process. At the same time we must continue to produce software. A better understanding of the factors that affect the development of software and their interrelationships is required in order to gain better insights into the underlying principles. The Software Engineering Laboratory has been established, in August 1976, at NASA Goddard Space Flight Center in cooperation with the University of Maryland to promote such understanding. The next section gives an overview of the research objectives and experiments being performed at the Laboratory. Section III contains the current list of factors that affect the software development process or product and are to be studied or neutralized. The data collection and data management activities are discussed in Section IV. The last section contains information on the current status and future plans for the Laboratory.


#*Linear decision functions, with application to pattern recognition.
#@Wilbur Hull Highleyman, II
#t1961
#c
#index194138


#*Proceedings of the 16th Annual Symposium on Foundations of Computer Science
#@
#t1975
#cSFCS
#index52794


#*Self-adaptive teleprocessing network design.
#@Harold Edward Livings, III
#t1975
#c
#index198438


#*An algebraic view of protection and extendibility in abstract data types.
#@Jernej Polajnar
#t1978
#c
#index195490


#*Remark on Algorithm: Algorithm 321 [S14] t-test probabilities and Algorithm 344: students t-distribution
#@G. W. Hill,Mary Loughhead
#t1970
#cCommunications of the ACM
#index329700


#*A concept paper on &ldquo;Host&rdquo; vs. &ldquo;Own&rdquo; data manipulation languages in military information systems
#@E. Raichelson
#t1972
#cProceedings of 1972 ACM-SIGFIDET workshop on Data description, access and control
#index551733
#!Although machine/program independent data description languages are difficult to achieve, there is no argument relative to the goals. This agreement as to goals is generally non-existent among those who seek to implement data manipulation languages (DML). The major issues in DML development manifest themselves in the entire spectrum of environment from usage to input/output processing. The SIGFIDET workshop is designed to address problems related to design and implementation of tools to allow logical definition of data, the mapping of this data to physical storage and the processing of data which has both properties, i.e., logical definition and physical residence. The papers presented in this session all address specialized aspects of the data manipulation problem.


#*Design choices for complex APL
#@Paul Penfield, Jr.
#t1978
#cACM SIGAPL APL Quote Quad
#index247655
#%244834
#%253250
#!This is the third and last paper in a series discussing the major design choices for APL to handle complex numbers. These papers are intended to stimulate a discussion in the APL community before the first implementation of complex numbers in APL renders such a discussion academic.


#*Algorithm 48: logarithm of a complex number
#@John R. Herndon
#t1961
#cCommunications of the ACM
#index327595


#*Microsystems Microprogram Assemblers for Bit Slice Microprocessors
#@V. M. Powers
#t1978
#cComputer
#index411969
#!Designers of high-speed microprocessors need good software to help them construct the microprogram, but the seven bit-slice assemblers surveyed here remain essentially low level and even primitive.


#*Solving the Biharmonic Equation on Irregular Regions
#@L. W. Ehrlich
#t1979
#cACM Transactions on Mathematical Software (TOMS)
#index320187


#*Instructional uses of the olin experimental classroom
#@V. K. Kumar,James L. Rogers
#t1976
#cACM SIGCUE Outlook
#index552791
#!The Olin Experimental Classroom at Case Western Reserve University provides a laboratory-like environment in which instructors can assess the results of trying out different teaching methods, techniques, etc. From a hasty look at three of the essential hardware components of this facility as shown in Figure 1 - keyset response units for each student, a process-control computer which scans the response units, and a display for the instructor - one could easily conclude that the Olin Experimental Classroom is simply another &ldquo;student response system&rdquo; or &ldquo;wired classroom&rdquo;. In fact, the differences between the traditional student response systems and the Olin Experimental Classroom begin with the very purposes for which these facilities are intended, and the differences extend to every aspect of t h e i r respective operation.


#*A start on automatic storage assignment
#@Robert L. Patrick
#t1960
#cCommunications of the ACM
#index331368
#!This technique outlines a method whereby equation sets can be ordered in computational order and checked for compatibility. The technique also allows one to note what equations can be computed in parallel (provided one has parallel arithmetic capabilities) or can be considered a logical entity, i.e., segment. Furthermore, the technique will assist one to intelligently allocate high-speed memory (HSM) so that memory is reassigned to other duties as soon as its present duties are fulfilled. Last, the technique appears to be simple and fast to implement.


#*Conference Report: Eleventh Annual Simulation Symposium
#@
#t1978
#cComputer
#index346294


#*Completion problem and its solution for context-free languages (algebraicapproach)
#@Takayuki Kimura
#t1971
#c
#index189252


#*Campus computer centers: and technical writers
#@Patricia Durr
#t1975
#cACM SIGDOC Asterisk Journal of Computer Documentation
#index6608
#!Michigan Technological University has a UNIVAC 1110 2x1 which serves the academic and administrative community. We have approximately 2,000 to 3,000 users in the faculty, staff, and student areas. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Computing in Crystallography
#@Henk Schenk
#t1978
#c
#index626985


#*A preliminary system for the design of DBTG data structures
#@Rob Gerritsen
#t1975
#cCommunications of the ACM
#index313668
#%196297
#%326368
#!The functional approach to database design is introduced. In this approach the goal of design is to derive a data structure which is capable of supporting a set of anticipated queries rather than a structure which &ldquo;models the business&rdquo; in some other way. An operational computer program is described which utilizes the functional approach to design data structures conforming to the Data Base Task Group specifications. The automatic programming technology utilized by this program, although typically used to generate procedure, is here used to generate declaratives.


#*Cohomology conditions for piecewise linear embeddings of complexes in euclidean space
#@Peter Alan Laszlo
#t1971
#c
#index202989


#*The ACM and standardization
#@T. B. Steel, Jr.
#t1964
#cProceedings of the 1964 19th ACM national conference
#index549185
#!The complexities of standardization procedures and the interlocking multiplicity of Sectional Committees, Subcommittees, and Working Groups comprising the formal standardization organizations are undoubtedly bewildering to the uninitiated. The author can assert from experience that it requires about a year of heavy involvement in the process before one begins to have a clear understanding of how it all works. Upon observing this, one is tempted to view the whole complex as a classical example of Parkinsonism; concurrently one develops the wish to cut the structure apart and proceed toward attaining standardization goals in a simple and direct manner. Let me assure you that the obvious, straightforward approach will not work. There are too many interrelated questions to answer and too many conflicts of interest to resolve. It is not clear that the standardization structure which has evolved is the optimum one but, just as in the case of the Congress - which may not be the optimum legislative configuration - it is the best one we know. Further, it seems to work. American Standards in information processing are beginning to appear and, once published, they have not caused any violent or widespread dismay. Despite all this, the computing man in the street generally feels that his opinions are not considered and his technical problems given little, if any, weight. There i s substantial justification for this view. To take one example, the preliminary work in the preparation of proposed American Standards in the area of common programming languages, such as ALGOL, COBOL and FORTRAN, i s being done almost entirely by people whose principal occupation is compiler writing. The Subcommittee whose function it is to determine when the work is ready to enter the real standardization mill is largely constituted of peeple who have not written computer programs on a day-te-day basis for some time. Finally, the Board that ultimately decides whether the community Interest is being served through the promulgation of an American Standard has few members who have ever written a program for a stored program computer. One cannot help but notice the absence of those really affected-and-mdash;the users of common programming languages.


#*Faces of Reality: Essays in Science
#@Edmond P. Odescalchi
#t1975
#c
#index618649


#*Contribution to solving the energy crisis: Simulating the prospects for low cost energy through silicon solar cells
#@Alexander Kran
#t1978
#cProceedings of the 11th annual symposium on Simulation
#index545840
#!PECAN (Photovoltaic Energy Conversion Analysis) is a highly interactive decision analysis and support system. It simulates the prospects for widespread use of solar cells for the generation of electrical power. PECAN consists of a set of integrated APL functions for evaluating the potential of terrestrial photovoltaics. Specifically, the system is a deterministic simulator, which translates present and future manufacturing technology into economic and financial terms, using the production unit concept. It guides solar cell development in three areas: tactical decision making, strategic planning, and the formulation of alternative options.


#*Hierarchical geometric models for visible-surface algorithms
#@James H. Clark
#t1976
#cACM SIGGRAPH Computer Graphics
#index242079
#!The research described in this paper addresses the problems associated with the design of systems for efficiently producing computer-generated pictures and picture sequences of very complex, three-dimensional environments. The thesis of the research is that the geometric structure inherent in the definition of the shapes of three-dimensional objects and environments must be used not just to define their relative motion and placement but also to assist in solving many other problems of systems for producing pictures by computer.The implications are that by using an extension of traditional structure information, or a geometric hierarchy, five significant improvements to current techniques are possible. First, the range of complexity of an environment is greatly increased while the visible complexity of any given scene is kept within a fixed upper limit. Second, a meaningful way is provided to vary the amount of detail presented in a scene both according to the screen area occupied by the objects in the scene and according to camera and object motions. Third, by using the geometric hierarchy, "clipping" becomes a very fast logarithmic search for the resolvable parts of the environment within the field-of-view. Fourth, by using this positional hierarchy in conjunction with a storage hierarchy of the sort used in virtual memory computing systems, frame-to-frame coherence and clipping define a graphical "working set", or fraction of the total structure that should be present in primary store for immediate access by the visible-surface algorithms. Finally, the proposed structural framework suggests a new recursive descent visible-surface algorithm in which the computation time grows almost linearly with a scene's visible complexity rather than as a worse than linear function of its object-space complexity.


#*Data base design: object distribution and resource-constrained task scheduling.
#@Mary Elizabeth Loomis
#t1975
#c
#index187707


#*Automatic test-generation and test-verification of digital systems
#@J. P. Verma,D. M. Selove,J. N. Tessier
#t1974
#cProceedings of the 11th Design Automation Workshop
#index548049
#!The widespread use of large scale and medium scale integrated circuits, coupled with the trend towards larger boards, made manual generation of test patterns very expensive, somewhat ineffective, and rather difficult to update for design changes. The advent of MOS LSI's with extremely large gate density made manual test-verification, the process of finding failures detected by a given test pattern, an impossibility. Therefore, a series of programs was developed, over the years, to completely automate the test cycle&mdash;using logic description files as input, the final output for test generation is a test deck compiled in the language of card test equipment and, in the case of test-verification, lists of detected and undetected failures. All this is accomplished within the global constraint of complete (nearly 100%) coverage and prevailing test floor practices.


#*The Axiomatization Problem of a Theory of Linear Languages
#@Gerd Wechsung
#t1974
#cProceedings of the 3rd Symposium on Mathematical Foundations of Computer Science
#index380962


#*A real time priority scheduler
#@Karl Ramsay,Jon C. Strauss
#t1966
#cCommunications of the ACM
#index323178


#*Asynchronous network of specific microprocessors
#@François Dromard,Gérard Noguez
#t1973
#cConference record of the 6th annual workshop on Microprogramming
#index552902
#!The present state of the LSI technology enables the integration of sophisticated functions, such as control functions. However, these functions are still simple. A present micro-computer set offers a low parallelism and a low flexibility in interruption handling. Thus, the typical application of micro-computer sets is the development of inexpensive satellite processors. Two techniques become available: -the dynamic microprogramming, - the multiplication of control organs. The efficient use of the dynamic microprogramming supposes the concept of the &ldquo;host machine&rdquo; which can emulate a number of virtual machines (cf B1700). The multiplication of control organs actually needs asynchronous communication procedure and requires specific microprocessors. This paper investigate such a machine. The computer is a collection of specific microprocessors. The communications are handled by an auto-regulating principle. A paged working storage and a communication mechanism are cyclicly shared between the microprocessors. The communication mechanism allows the garbage collecting and the flag locking of the common pages.


#*A translation algorithm for morse systems.
#@Robert Arthur Alps
#t1979
#c
#index197602


#*Recent Developments in Design Automation
#@M. A. Breuer
#t1972
#cComputer
#index353345
#!In this paper we review some of the recent developments in the automated design and analysis of digital systems. The areas of gate level simulation, synthesis, partitioning, interconnection and fault test generation are discussed, and new algorithms in each of these areas are presented and compared. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Software engineering-as it is
#@Barry W. Boehm
#t1979
#cProceedings of the 4th international conference on Software engineering
#index551234
#%250122
#%312853
#%318766
#%325067
#%330862
#%458820
#%548279
#%619912
#%577319
#!This paper presents a view of software engineering as it is in 1979. It discusses current software engineering practice with respect to lessons learned in the past few years, and concludes that the lessons are currently not heeded roughly half of the time. The paper discusses some of the factors which may account for this lag, including rapid technological change, education shortfalls, technology transfer inhibitions, resistance to disciplined methods, inappropriate role models, and a restricted view of software engineering. The paper also updates a 1976 state of the art survey of software engineering technology, including such topics as requirements and specifications, design, programming, verification and validation, maintenance, software psychology, and software economics. It concludes that the field is making solid progress, but that it is growing more complex at a faster rate than we can put it in order.


#*Life is universal!
#@Robert T. Wainwright
#t1974
#cProceedings of the 7th conference on Winter simulation - Volume 2
#index548250
#%574808
#!The game of Life1 involves forms built out of simple birth and death rules which a computer puts through a series of rapid transformations. This game was invented by John Horton Conway and recently introduced in Scientific American by Martin Gardner. Many computers have been programmed to play the game of Life. In this paper we shall show how to return the compliment by making Life forms that can imitate computers. Then we shall see that many remarkable consequences follow from the existence of such constructions. Further we shall see that in Life there exists the possibility of organisms with the ability to duplicate themselves, to reproduce. It has even been suggested that the universe itself is space-time granular and that the future although completely deterministic is unpredic-table, being its own fastest simulation.


#*Environment primitive operators in programming languages
#@Richard O. Clark,James F. Leathrum
#t1973
#cProceedings of the ACM annual conference
#index546064
#!An extensible language implies that the fundamental semantics of a programming language are included in the base language. Those basic operations which are not so defined cannot be produced by extension. One aspect which has not been decomposed into a set of primitive actions is that of environmental operators. These are operators which describe the binding between a symbol, its value-structure, and a value. As a result, the execution environment of the base language applies to each extension and the style of the language remains fixed. The same remarks also apply to formal semantic descriptions of programming languages. In this paper a value storage mechanism, a value reference mechanism, and a set of binding operators are proposed which permit the execution of a program in the context of a FORTRAN, ALGOL, PL/1, or APL environment.


#*NUFACTS: A tool for the analysis of nuclear development policies
#@Mark B. Triplett,Theodore L. Willke,John D. Waddell
#t1977
#cProceedings of the 9th conference on Winter simulation - Volume 2
#index547427
#!NUFACTS, the Nuclear Fuel Cycle Activity Simulator, is a combined continuous/discrete simulation of the nuclear power economy. This model has been useful in the evaluation of nuclear development policies as it projects the economic and resource impacts attributable to a given policy. A recent application of NUFACTS has involved the economic evaluation of plutonium recycle options in light-water reactors. Based upon the GASP IV simulation language, NUFACTS provides a highly flexible means of simulating a wide variety of nuclear growth scenarios. In its present form most planned reactor concepts can be studied. To achieve this capability a model of the nuclear fuel cycle has been developed that incorporates functions related to the control over the pattern of development of nuclear power as well as to the detailed operation of individual reactors.


#*Report of session on systems programming languages
#@Robert M. Graham
#t1973
#cProceeding of ACM SIGPLAN - SIGOPS interface meeting on Programming languages - operating systems
#index555280
#!Discussion in this session centered around two major topics: experience using a particular language for systems programming and features which are required or desirable in a systems programming language. In general, as one might expect, the users of a particular language were happy with that language and felt they had made the right choice, even though they were not completely satisfied. There seemed to be general agreement that a higher level language than machine language (assembly language) should be used for systems programming. There was considerable difference of opinion as to how high level the language should be. There was a similar difference of opinion as to what features are desirable, and even necessary, in a systems programming language. Although the session was organized so as to discuss the two major topics separately, there was considerable discussion of desirable and necessary language features mixed in with the discussion of experience with specific languages. The session opened with a report by Bob Freiburghouse on the use of PL/I for implementation of Multics. "In general the project was successful. We're not about to switch to some other programming language. But we would like to enforce more discipline. I think we would like to recognize and enforce a subset of all this. He listed a number of key features, the most important of which was external procedures and external variables. Other important features included structured data with controlled packing, recursion, block structure, high level control statements, type checking, pointers and dynamic storage allocation, and % include. A few extensions were made to the language such as pointer valued functions, functions to construct and take apart pointers, P and V operations, and a notation for referencing Multics segments. In addition, a support routine called the binder was implemented. Using this routine one can combine a number of procedure and data segments into a single module. References to this module can be made using only designated names, all other names originally associated with the segments in the module will be hidden, that is, undefined outside the module.


#*ACM president's letter: whither ACM?
#@Anthony Ralston
#t1973
#cCommunications of the ACM
#index322301


#*Asymmetric memory hierarchies
#@John G. Williams
#t1973
#cCommunications of the ACM
#index323986
#%316426
#%317782
#%318912
#%554090
#!A study is presented of some of the system implications of memory hierarchies in which the backing or secondary store has a very small read time, relative to both the time required for writing and to the read time of conventional backing storage devices. Several analytic models are introduced, and it is shown that such hierarchies may operate in ways which differ from those of more conventional hierarchies. In particular, it is shown that it may not be necessary to multiprogram in such a situation. In the past, backing storage devices have been roughly symmetric with respect to their read and write times. This situation may not continue, as several devices are currently under development which may have a very small read-time/write-time ratio. This study places particular emphasis on one such system&mdash;the RCA read/write holographic optical memory.


#*An interactive system for the generation of standardized autopsy protocols.
#@Seymour Fox
#t1977
#c
#index193236


#*Topological techniques for computer analysis of passive and active electrical networks
#@William Ryder Dunn, Jr.
#t1971
#c
#index205141


#*B74-20 Systematic Programming: An Introduction
#@P. J. Denning
#t1974
#cIEEE Transactions on Computers
#index354060
#!This book will become a lethal weapon against skepticism toward the possibility of presenting programming as a precise discipline based on clear and simple principles. It treats what many regard as advanced topics in programming in so straightforward a manner, that there is little doubt that the "advanced topics" are in fact elementary notions. The material is presented simultaneously at many levels: the college sophomore will enjoy a hearty repast of solid conceptual and practical aspects of algorithm design, and the college professor or industrial professional will enjoy many morsels from the philosophy of programming to practical advice on the best uses of each language construction. The material is presented in a fast-moving, unadorned style, reminiscent in places of sketchy lecture notes; indeed, fully fourteen chapters appear in the first 124 pages. Every concept is backed by an example; I counted approximately 45 sample algorithms or programs in the text and about 25 more in the Exercises. The sample programs are masterpieces of clarity, exemplifying how invariant assertions can be embedded in comments to make understanding and verifying the programs as simple as possible. Wirth leaves little doubt as to the power of this technique, not merely by disoussing it but by doing it.


#*Session 6a: statistical packages
#@
#t1976
#cProceedings of the 4th annual ACM SIGUCCS conference on User services
#index251328


#*Compact complex homogeneous manifolds.
#@Hugh Norton Albright
#t1959
#c
#index197394


#*Node-Visit Optimal 1-2 Brother Trees
#@Thomas Ottmann,Arnold L. Rosenberg,Hans-Werner Six,Derick Wood
#t1979
#cProceedings of the 4th GI-Conference on Theoretical Computer Science
#index563955


#*Design characteristics of the WATFOR compiler
#@D. D. Cowan,J. W. Graham
#t1970
#cACM SIGPLAN Notices
#index549692
#%320760
#%329092
#%580589
#!About 1960, it became fashionable to introduce computer techniques into many of the courses being taught at the university level. These courses tended to be technically oriented (Engineering, Science, Mathematics), and the language most often used was one of the versions of FORTRAN. Students were introduced to computing by a brief course in FORTRAN, and then were expected to apply their newly-discovered knowledge to the solution of numerous problems related to some discipline. Introducing large numbers of students to computing in this manner created an entirely new type of demand for computer services. These new demands for computer services had to satisfy the following needs. (i) The programmers were not professionals; thus, the proportion of errors in a given number of written statements was higher than usual. (ii) The programs themselves were often quite short, usually 30 to 50 statements in length. (iii) The volume of submitted programs was very high, in the order of hundreds of thousands per day. (iv) The debugged program tended to be run in production only once, and was set aside as a completed assignment.


#*The provision and use of environmental information in a multiprogramming system
#@Tomlinson G. Rauscher
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index59533
#!In a modern multiprogramming system a user, who is competing for system resources, may desire to optimize himself relative to his environment. The environment includes not only the physical machine and attached devices but also system software and the programs of other users which are sharing and competing for resources. As most modern systems provide little environmental information to users, we describe facilities for querying the system to ascertain environmental information. The user, in dynamically querying the environment, can use information on the status of hardware and software (both system and other user) to improve the status and performance of his program according to some cost function he selects. Several examples demonstrate the utility of these environmental inquiry facilities. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*An approach to systems correctness
#@Gilles Kahn
#t1972
#cACM SIGOPS Operating Systems Review
#index113213
#%199366
#%203125


#*The use of Monte Carlo simulation to reflect the impact human factors can have on systems performance
#@Gerald P. Chubb
#t1971
#cProceedings of the 5th conference on Winter simulation
#index551467
#!Man-machine simulation is one approach to determining system effectiveness as a function of subsystem performance, but often man has not been treated as a viable element in system effectiveness studies. The model discussed here is an example of how human factors can be explicitly dealt with in mission simulation. The application discussed also demonstrates the feasibility of a new, systematic method for integrating multidisciplinary biological research data into a composite description of performance degradation in a nuclear attack environment. The approach, however, appears to be generalizable to other threat environments and mission conditions. Besides being a potentially useful design evaluation method, the model has served to focus attention on critical problem areas for future laboratory investigations.


#*On Eliminating Unit Productions from LR(k) Parsers
#@David Pager
#t1974
#cProceedings of the 2nd Colloquium on Automata, Languages and Programming
#index381950


#*The history of FORTRAN I, II, and III
#@John Backus
#t1978
#cACM SIGPLAN Notices
#index546358
#%250122
#%313666
#%320995
#%330084
#%580589
#!Before 1954 almost all programming was done in machine language or assembly language. Programmers rightly regarded their work as a complex, creative art that required human inventiveness to produce an efficient program. Much of their effort was devoted to overcoming the difficulties created by the computers of that era: the lack of index registers, the lack of built- in floating point operations, restricted instruction sets (which might have AND but not OR, for example), and primitive input- output arrangements. Given the nature of computers, the services which &ldquo;automatic programming&rdquo; performed for the programmer were concerned with overcoming the machine's shortcomings. Thus the primary concern of some &ldquo;automatic programming&rdquo; systems was to allow the use of symbolic addresses and decimal numbers (e.g., the MIDAC Input Translation Program [Brown and Carr 1954]). But most of the larger &ldquo;automatic. Programming&rdquo; systems (with the exception of Laning and Zierler's algebraic system [Laning and Zierler 1954] and the A-2 compiler [Remington Rand 1953; Moser 1954]) simply provided a synthetic &ldquo;computer&rdquo; with an order code different from that of the real machine. This synthetic computer usually had floating point instructions and index registers and had improved input-output commands; it was therefore much easier to program than its real counterpart.


#*Selecting a Military Computer Architecture
#@W. E. Burr
#t1977
#cComputer
#index352543
#!Selecting or even designing a computer architecture is at best as much a black art as a science. The problem is particularly difficult when one tries to choose an architecture meant to serve a very broad range of users whose present and future requirements are poorly understood. This article describes the activities of a joint Army/Navy Selection Committee, which was charged with the task of selecting a single computer architecture to be used as the basis for a new military computer family. The range of applications for military computers is broad and ill defined; how the committee tried to cope with this problem should be of interest to others who are interested in measuring, designing, or selecting computer architectures.


#*CASS: computer-assisted stereotaxic surgery
#@P. A. Hawrylyshyn,R. R. Tasker,L. W. Organ
#t1977
#cProceedings of the 4th annual conference on Computer graphics and interactive techniques
#index237137
#!An interactive computer graphics system has been developed for online use with a two-stage stereotaxic technique in man. The computer plots sagittal sections approximating the region of the brain being stimulated on a display screen located in the operating room. When responses are elicited by electrical stimulation, they are graphically illustrated on the template, accurately positioned at the brain site being stimulated. If such evoked responses do not fit the template, they can be replotted on a modified template in a manner prescribed by the neurosurgeon. Such a system allows optimal localization of subcortical lesion sites.


#*The GRE advanced test in computer science
#@Richard H. Austing
#t1977
#cCommunications of the ACM
#index324123
#!This report describes the Advanced Test in Computer Science which was recently introduced in the Graduate Record Examination Program. The GRE program is described in general, and, the events leading to the establishment of the Advanced Computer Science Test are discussed. Content specifications and their rationale are given. A set of sample questions is included.


#*Derivation of Minimal Complete Sets of Test-Input Sequences Using Boolean Differences
#@P. N. Marinos
#t1971
#cIEEE Transactions on Computers
#index347548
#!This paper deals with a fault detection and diagnosis technique based on Boolean differences. A brief review of the notion of a Boolean difference is presented, and the concept of partial Boolean difference is introduced. An algorithm for obtaining minimal, complete sets of test-input sequences based on the partial Boolean differences of a switching function is formulated, and illustrations demonstrating the use of the technique are presented.


#*Automating analog circuit diagrams using a list processing language
#@Richard C. Jaffe,Joseph P. Young
#t1977
#cProceedings of the 14th Design Automation Conference
#index550425
#!An interactive method of analog computer circuit diagram generation is described which utilizes symmetric list processing techniques as a basis for its data structure. The resultant program, known as DISPLAY, permits generation, maintenance, and modification of analog circuit diagrams from a graphics terminal, with the added capability of directly generating a set of differential equations which can link to an analysis program known as Equation Verification (EV), to obtain static and dynamic solutions of the time response of the analog circuit elements. The program was developed to aid simulation engineers to maintain up-to-date documentation, storage, and retrieval of schematic information in a list processing formulation which simplifies the programming effort considerably. Examples of the input and graphical output are given, along with typical state equations used as input to the analysis program. DISPLAY is written in Fortran IV, and currently interfaces with a 4012 Tektronix Graphics Display Storage Terminal.


#*The specification of program flow in Madcap 6
#@James B. Morris, Jr.,Mark B. Wells
#t1972
#cProceedings of the ACM annual conference - Volume 2
#index554495
#%79620
#%317062
#%321318
#%327006
#%331066
#%334877
#%335365
#!The control structures of the Madcap language have evolved to a point where today those of Madcap 6 have obviated programmer defined labels and go-to statements. The benefits of the removal of these concepts are discussed in detail. Madcap has a powerful class of data structures, including sets, sequences, and expressions, along with a full array of operators for manipulating these structures. These operators include important facilities for forming sets and for forming and concatenating sequences, based on very general iterative expressions. Procedures in Madcap are expressions whose evaluation is deferred; characteristics of this approach are discussed. Also described is a notation which facilitates backtrack programming.


#*Why James G. Miller's &ldquo;decider&rdquo; lets simulation harden the &ldquo;SOFT&rdquo; biological sciences
#@G. Arthur Mihram
#t1978
#cProceedings of the 10th conference on Winter simulation - Volume 2
#index553339
#!James C. Miller's compendium, LIVING SYSTEMS, just released by McGraw-Hill (1977), notes that every living system, from the cell through the society, undertakes change by means of its intrinsic 'decider'. The paper shows that the application of this result, by constructing simulation models (one algorithm for each 'decider' or deciding process), will permit us simulationists to provide what biologists have long sought: a modelling methodology deemed as 'hard', as scientifically credible, as mathematics has been for physics and chemistry. Biologists have typically provided, as their explanations for the naturally occurring phenomena which they have observed, a model of the descriptive category. Indeed, Konrad Lorenz (NATURWISSENSCHAFTEN, 1973) takes considerable issue with what he terms contemporary biologists' &ldquo;fashionable fallacy&rdquo; of dispensing with natural-language descriptions of biological systems in favour of writing mathematical models of the phenomena confronting them. Mellanby (Nature, 1976) has rather belittled the contemporary concern of &ldquo;modelling,&rdquo; despite the fact that, like M. Jourdain (Moliere's character, who spoke prose for 40 years without really knowing it), scientists have been writing models (descriptions) since at least the time of da Vinci. However, both Lorenz and Mellanby share the same concern: that biologists currently are over-emphasizing the &ldquo;fitting&rdquo; of mathematical curves to recorded data rather than the reflective evaluation of one's observations in order first to arrive at an understanding of some biological phenomenon and then to describe one's conclusion (i.e., to author one's descriptive or mathematical model). Both Lorenz and Mellanby may well be decrying the intensive use of computerised models, but what each appears to have overlooked is the fact that not all computerised models need be strictly mathematical. Indeed, the distinguishing characteristic between computerised models which are of the more general (simular) variety permits the contemporary biol&fgr;gist to regain what both Lorenz and Mellanby seem to fear has been lost: the intense mental reflection on observations before constructing the model. The proper simulation, or simular variety of model, consists of a set of event routines, each of which is an authored algorithm. The distinguishing characteristic of the algorithm is that it is a second-person &ldquo;formula&rdquo; or instructuin, much like the cook's recipe, for making a decision. The computerised algorithm becomes, then, a &ldquo;paragraph&rdquo; in a model, the paragraph being a set of instructions to the computer (a robot). The biologist, reflecting upon his observations of some natural phenomenon (or some system of natural phenomena) is required to &ldquo;describe&rdquo; in a simular model his understanding of the observed phenomenon (-a) in terms of a &ldquo;recipe&rdquo; which the robot must follow if he (the robot) were to himself act as the &ldquo;director&rdquo; of the natural system being modelled; i.e., the robot (the computer) is provided an executive routine (its &ldquo;mind&rdquo;) with which to keep track of all the pertinent information (&ldquo;entities&rdquo; and their &ldquo;attributes&rdquo;, or &ldquo;state variables&rdquo;) within and about the system, and through which to command a particular &ldquo;state variable&rdquo; to alter its value if, when, and only when, the conditions among those ever-dynamic variables would require a change in the natural system being modelled. Thus to author a model of the truly simular variety for a biological phenomenon requires that a considerable greater mental reflexion shall have taken place by the biologist than would be the case for the biologically-minded entrepreneur who seeks merely to find some hastily-conceived differential equation which &ldquo;adequately&rdquo; fits some data observed and recorded for the purpose. The truly similar model of a biological system requires that its author has painstakingly reflected on the decision-making qualities which reflect the many observed changes taking place in the system at hand. General systems theorists (cf., e.g., James C. Miller, PROCEEDINGS OF THE 1975 ANNUAL NORTH AMERICAN JOINT MEETING OF THE AMERICAN ASSOCIATION FOR THE ADVANCEMENT OF SCIENCE AND THE SOCIETY FOR GENERAL SYSTEMS RESEACH) have noted that every level of biological systems, whether cell, organ, organism, group, organization, or society, possesses a &ldquo;decider&rdquo;, its &ldquo;executive subsystem which receives information inputs from all other subsystems and transmits to them information outputs that control the entire system.&rdquo; Thus, no matter at what &ldquo;level&rdquo; one is modelling biological systems, simular models, with their emphasis on the algorithm, are ideally suited. The analogies between individual animals and social animals also serve to illustrate the importance of simular, as opposed to strictly mathematical, models. For example, the Mind is an individual's &ldquo;Neural Librarian&rdquo; while the Brain is his personal &ldquo;Library&rdquo; of experiences; whereas, seen by the biologist of social systems (e.g., the sociologist), Man's archival respositories (libraries, museums) are merely his &ldquo;Brain&rdquo; and their controller (conscientious editors, publishers, and librarians) is Man's &ldquo;mind,&rdquo; storing for generations his collective observations for survival. The paper therfore underscores the distinctive characteristics of simulation, characteristics which will permit biologists to model, with scientific credibility, biological systems. In this context, the pertinence of Thom's &ldquo;catastrophe theory,&rdquo; particulary as accounted by Zeeman (SCIENTIFIC AMERICAN, 1976) and in other popular accounts (e.g., NEWSWEEK, 1976), is questioned. Every biological system requires its own &ldquo;decider,&rdquo; or deciding sub-system. The algorithm is a recipe for decision making. Thus, the paper reveals the value of computerized simulation to the modelling of biological systems.


#*Proceedings of the 6th annual Design Automation Conference
#@
#t1969
#cAnnual ACM IEEE Design Automation Conference
#index548154


#*Groups with solvable word problems.
#@Christine Semeniuk
#t1979
#c
#index194409


#*FORTRAN IV in Chemistry: An Introduction to Computer-Assisted Methods, 99th edition
#@Graham Beech
#t1975
#c
#index618174


#*Stability analysis of certain Runge-Kutta procedures for Volterra integral equations
#@Christopher T. H. Baker,Malcolm S. Keech
#t1978
#cACM Transactions on Mathematical Software (TOMS)
#index327799


#*Review of "A Guide to Models in Governmental Planning and Operations, by Saul I. Gass and Roger L. Sissons", Sauger Books
#@
#t1976
#cACM SIGSIM Simulation Digest
#index576854
#!This is the hard copy version of the report prepared for the Office of Research and Development of the Environmental Protection Agency. The volume contains 12 chapters in addition to any introductory preface. Each chapter is selfcontained and, on the whole, each is a very good presentation. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Uses of general arrays and operators
#@J. E. Mezei
#t1974
#cProceedings of the sixth international conference on APL
#index550548
#!This paper introduces basic definitions for general arrays and operators in the context of illustrative examples of their uses. Most examples are rendered in two versions, one that uses general arrays and operators, and one that foregoes their use.


#*Some inference problems associated with the complex multivariate normal distribution
#@John Coleman Young
#t1971
#c
#index193103


#*A new algorithm for the numerical solution of ordinary stiff differential equations of the n-th order
#@Karl Strehmel
#t1977
#cACM SIGNUM Newsletter
#index104125


#*A SIMSCRIPT-FORTRAN case study
#@Arla E. Weinert
#t1967
#cCommunications of the ACM
#index324099
#%314624
#!Two programs for a vehicle dispatching model, one written in 7040 SIMSCRIPT and the other in 7040 FORTRAN IV are compared. The comparison is made in terms of basic program design decisions, storage requirements, computer time used, and the ease of making changes. In the SIMSCRIPT program, the primary design considerations center around the choice of model variables, model changing events, and model testing. In the FORTRAN program, basic design problems relate to the representation of the passage of time, the allocation of storage, and the organization of input data. The comparison of these differently designed programs shows that the SIMSCRIPT program uses more computer storage and more computer time, but requires fewer program changes to introduce model revisions.


#*Application of statistical methods to number theory (Clustering of Primes)
#@Michael E. Neyer
#t1973
#cProceedings of the ACM annual conference
#index554479
#!For the purposes of this paper I will define clusters of N primes in M numbers, as the occurrence of N prime numbers in a range of M consecutive numbers. The maximum clustering K in a range of L consecutive numbers is defined as, the number of integers in the range which are not eliminated by any prime number less than (M+1)/2. If M and N can satisfy two conditions, then there are an infinite number of such clusterings (i.e. prime pairs). First, for all J, the maximum clustering K for the range (aJ+b to aJ+b+M&minus;l) is greater than or equal to N. Second, there exists a range L such that for all I for the maximum clustering K in the range (IL+d to IL+d+L&minus;1), the ratio of K/L is less than or equal to 1/N. Due to the complexity of the notation for the proof, I could not fully explain the basic equation in this abstract.


#*A technique for optimizing a function of many variables: determining the minimum energy configuration of a crystal lattice
#@D. R. Winner,L. L. Marsh
#t1966
#cCommunications of the ACM
#index332124


#*Student response behaviors in an instrumented feedback environment
#@V. K. Kumar,James L. Rogers
#t1978
#cACM SIGCUE Outlook
#index353603
#%552791
#!Three sessions of an Educational Statistics course were taught in an instrumented feedback environment which allowed students to register up to twelve responses (e.g. "Repeat", "Please Summarize") at their initiative, or in response to instructor's queries. Comparison between instrumented and non-instrumented settings indicated no significant difference in overall response rate. However, it was observed that keysets did serve as <u>another mode</u> of responding, particularly for responses which need not be accompanied by oral responses, and for students who had difficulty with the course. Some software and hardware refinements are suggested to study the effects of student responses on systematically shaping instructor's behavior.


#*Even Data Bases That Lie Can Be Compromised
#@R. A. Demillo
#t1978
#cIEEE Transactions on Software Engineering
#index342790
#!Users can compromise data bases by asking a series of questions, even when the data bases are allowed to lie.


#*Project FIND: an integrated information and modeling system for management
#@John S. McGeachie,Donald L. Kreider
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index55692
#!Project FIND (Forecasting Institutional Needs for Dartmouth) has been established at Dartmouth College to make institutional data readily accessible to administrative officers and faculty members through the facilities of the Dartmouth Time-Sharing System (DTSS). A concomitant goal is to develop models of the operation of the institution to facilitate long-range planning by providing quantitative estimates of the effects of policy changes.


#*Simulation methods for response times in networks of queues
#@Donald L. Iglehart,Gerald S. Shedler
#t1979
#cProceedings of the 11th conference on Winter simulation - Volume 1
#index549753
#!We describe theoretically sound and computationally efficient estimation methods for &ldquo;passage times&rdquo; in certain closed networks of queues. Informally, a passage time is the time for a job to traverse a portion of the network. Such quantities are important in computer and communication system models where they represent job response times, and in this context, quantities other than mean values are of interest. From a single simulation run, the methods described here provide both point estimates and confidence intervals for general characteristics of response times.


#*On Memory Usage Under Microprogramming
#@G. W. R. Luderer
#t1972
#cComputer
#index339153
#!The issue of quantitative determination of memory usage and utilization is central to multiprogramming computer systems. In such systems, one tries to improve the system performance by loading a set of independent jobs together into main memory. If the jobs have complementary resource requirements and the system is capable of parallel resource operation, the total time required to complete all jobs is less than if they were processed serially, i.e., in a uniprogramming mode. The situation is illustrated in Figure 1 showing a space-time diagram of memory occupancy, where the available memory space is dynamically covered with jobs. The term "job" is used in the sense of "process" as defined in [1], which also gives an excellent survey of related subjects. However, we restrict jobs to keep a fixed amount of memory until they are completed. Generalization of the concepts to be developed to include systems with dynamic allocation, swapping, paging is possible but not attempted here.


#*A design for a community/junior college curriculum with options for two neighboring institutions
#@Iva Helen Lee,Claudia Elizabeth Plog
#t1978
#cProceedings of the 1978 annual conference - Volume 2
#index553808
#!This paper presents a curriculum design for applications programmers in two neighboring community/junior colleges in the state of Texas. McLennan Community College serves a rural area with predominantly small DP shops environments whereas E1 Centro serves an urban area with a wide range of installation sizes. Despite their differing student bodies and environments, a common curriculum has been designed based on the draft of the ACM C3S-CAJC model curriculum in computer programming (1). The authors have designed a flexible curriculum in which the language emphasis is based on community needs. The curriculum includes a second major language because the knowledge of two business programming languages greatly enhances the job prospects of students in the Southwest area.


#*Algorithms for scientific computation
#@George E. Forsythe
#t1966
#cCommunications of the ACM
#index315018


#*Linear Time Simulation of Multihead Turing Machines with Head-to-Head Jumps
#@Walter J. Savitch,Paul M. B. Vitányi
#t1977
#cProceedings of the Fourth Colloquium on Automata, Languages and Programming
#index357610


#*The Test Support Program (TSP) a real-time interactive simulation system
#@Edward G. Ries,Donald J. Harmon
#t1976
#cProceedings of the 1976 ACM SIGMETRICS conference on Computer performance modeling measurement and evaluation
#index552525
#!The Test Support Program (TSP) is a real-time interactive computer-based simulation model that provides the environment for testing and verifying the operation of netted air control systems. It provides computer-to-computer simulation of data link timing; message interpretation, response, and transmission; and on-line data analysis and recording for up to nine interfaced systems of various types. Event execution and timing is performed in accordance with a time-ordered pre-stored scenario and operator-initiated console inputs. Live and simulated system interfaces and data may be used. The simulation model can accept and use data from live systems. Event and data inputs are structured in a special language and are validated by a pre-processor to aid in test design and error-free execution. Event control and data entry during program execution are from a CRT/keyboard or magnetic tape. TSP permits earlier and more effective verification of program performance, easier design of complicated tests, and reduces reliance on establishment and operation of large complexes of operational and test bed systems. Program operation can be verified in advance of the availability of interfacing hardware and software in a controlled environment.


#*Suggestions for improvements to ALGOL 68
#@S. R. Bourne,M. J. T. Guy
#t1972
#cIssue 33 (March 1972)
#index101622


#*Asynchrone Schaltwerksimulation mit SSM, einer Simulationssprache f&uuml;r Schaltwerke mittels mehrwertiger Logik
#@Winfried Görke
#t1975
#cGI - 5. Jahrestagung
#index262477


#*Complex differentiation theory by power series methods.
#@France Maurice Evans
#t1975
#c
#index203314


#*Repeated additions
#@Eldon Hansen
#t1970
#cACM SIGNUM Newsletter
#index108589
#!The recent note by Morris [1] prompts me to describe the following process for doing repreated floating point additions. It seems certain that the process is not new; but I have not seen it described elsewhere. It has perhaps been ignored because of its limited practical value. However, it serves as an interesting example for the classroom.


#*A next step in data structuring for programming languages
#@Jim Mitchell,Ben Wegbreit
#t1976
#cACM SIGPLAN Notices
#index551423
#!An abstraction provides a statement of the properties of a data type without any commitment to a specific implementation. Programs which use abstractions can be developed and verified without regard to how the abstraction will be realized. Any type which fulfills the requirements of the abstraction can be bound in its place without affecting the program's correctness or its proof. In [4], the notion of a scheme as a model for a set of types is developed. A scheme is written as a module which takes normal values plus types as formal parameters. Instantiating a scheme with actual parameters yields a scheme instance which is a data type. For example, one can write a scheme for AVL trees [5] which takes the type of the keys in the tree as a parameter. An instance of this scheme, for example, AVL trees of strings, is a normal data type.


#*A practical method for constructing LR (k) processors
#@A. J. Korenjak
#t1969
#cCommunications of the ACM
#index327887
#%187307
#%315280
#%329080
#!A practical method for constructing LR(k) processors is developed. These processors are capable of recognizing and parsing an input during a single no-backup scan in a number of steps equal to the length of the input plus the number of steps in its derivation. The technique presented here is based on the original method described by Knuth, but decreases both the effort required to construct the processor and the size of the processor produced. This procedure involves partitioning the given grammar into a number of smaller parts. If an LR(k) processor can be constructed for each part (using Knuth's algorithm) and if certain conditions relating these individual processors are satisfied, then an LR(k) processor for the entire grammar can be constructed for them. Using this procedure, an LR(1) parser for ALGOL has been obtained.


#*A Note on Atrubin's Real-Time Iterative Multiplier
#@L. N. Goyal
#t1976
#cIEEE Transactions on Computers
#index348652
#!This correspondence presents a new multiplication algorithm for Atrubin's one-dimensional real-time iterative multiplier such that all the cells including the first cell in the array are identical in all respects, for the no-delay case.


#*Speedup in parallel algorithms for adaptive quadrature.
#@James Milton Lemme
#t1976
#c
#index195225


#*Computer Choice; A Manual for the Practitioner
#@R. J. McQuaker
#t1978
#c
#index439431


#*The influence of productions on derivations and parsing (Extended Abstract)
#@Benton L. Leong,Detlef Wotschke
#t1976
#cProceedings of the 3rd ACM SIGACT-SIGPLAN symposium on Principles on programming languages
#index551397
#%159845
#%579380
#!The concept of grammar forms [4,5] provides evidence that there seems to be no way to base the definitions of many grammar types used in parsing and compiling solely on the concept of productions. Strict interpretations, as introduced in [3,5], of unambiguous or LR(k) grammar forms generate unambiguous or LR(k) languages, respectively. This is not true in the LL(k) case. It is decidable whether a strict interpretation of an unambiguous grammar form is unambiguous. For any two compatible strict interpretations G1 and G2 of an unambiguous grammar form it is decidable whether L(G1)@@@@L(G2), L(G1)@@@@L(G2)&equil;&thgr;, finite, or infinite. For every grammar form F1 there exists a grammar form F2 such that the grammatical family of F1 under unrestricted interpretations is equal to the grammatical family of F2 under strict interpretations.


#*A method for the formal derivation of programs and its applicability to automatic program synthesis.
#@Jeffrey Stanley Gishen
#t1978
#c
#index201345


#*Solution plans and interactive problem solving
#@William E. Howden
#t1974
#cProceedings of the 1st annual conference on Computer graphics and interactive techniques
#index242617
#!The concept of a "solution plan" is used to characterize the structure of interactive systems in which the user guides the solution process. A formalism for describing and analyzing solution plan structures is presented. The formalism can be used to define the role of the user in an interactive system. The solution plan approach to interaction is particularly applicable to problems which have an obvious graphical representation. An interactive graphics system for solving a class of routing problems is described. Suggestions for the application of the approach to other problems are included.


#*A design study on graphics support in a Fortran environment
#@R. G. Loomis
#t1966
#cProceedings of the SHARE design automation project
#index550854
#!Some of my colleagues in IBM and myself have been jointly studying and discussing the problems involved in providing future graphics support in a FORTRAN environment. In this presentation I will attempt to summarize the major assumptions that have influenced this design study and report on some of the tentative conclusions reached as well as some, as yet, unanswered critical questions. This report is being made at this time in the hope that it will stimulate a critical evaluation on your part and provide us with some useful feedback. Your first opportunity for responding will be provided by the discussion session scheduled for later this afternoon. We hope you will participate by informing us about your own views and experiences with respect to graphical data processing.


#*Computer facilities and secondary school mathematics
#@Walter J. Koetke
#t1971
#cACM SIGCUE Outlook
#index309089


#*A new grammatical transformation into LL(k) form (Extended Abstract)
#@Michael Hammer
#t1974
#cProceedings of the sixth annual ACM symposium on Theory of computing
#index545578
#!For some time, it has been recognized that left-to-right deterministic top-down parsing has a number of features to recommend it. The logic of such a parser is easily expressed as a one-state pushdown machine, and very flexible translations can readily be performed in conjunction with top-down processing. The major difficulty with this style of parsing is that there are relatively few grammars which satisfy the rather restrictive requirements to admit of top-down parsing (the LL(k) grammars), in comparsion with grammars that can be parsed deterministically bottom-up (the LR(k) grammars). There has been some research along the lines of trying to apply transformations to non-LL(k) grammars in order to convert them into equivalent LL(k) form [1,2,3]; the most successful approach has been that of Rosenkrantz and Lewis [4]. They define class of grammars, the LC(k) grammars, which can be parsed in a mixed hybrid of top-down bottom-up techniques; this class strictly includes the LL(k) grammars, as well as many interesting but non-LL(k) grammars. They then provide a deterministic algorithm for converting any LC(k) grammar into an equivalent LL(k) grammar. This work is a generalization of, and in the same spirit as, the Lewis and Rosenkrantz program. We investigate a new hybrid parsing method, basically bottom-up in character, but which contains a minimal infusion of top-down ideas. We consider the class of grammars which can be parsed by this method, and observe that it strictly includes the class of LC(k) grammars. Then we exhibit an algorithm for deriving from any such grammar an equivalent LL(k) grammar; this derived grammar is also as &ldquo;useful&rdquo; as the original one in directing compilation activities, for it can support translations equivalent to those supportable by the original grammar.


#*Simulation methods for Poisson processes in nonstationary systems
#@Peter A.W. Lewis,Gerald S. Shedler
#t1978
#cProceedings of the 10th conference on Winter simulation - Volume 1
#index547106
#%81323
#!The nonhomogeneous Poisson process is a widely used model for a series of events (stochastic point process) in which the &ldquo;rate&rdquo; or &ldquo;intensity&rdquo; of occurrence of points varies, usually with time. The process has the characteristic properties that the number of points in any finite set of nonoverlapping intervals are mutually independent random variables, and that the number of points in any of these intervals has a Poisson distribution. In this paper we first discuss several general methods for simulation of the one-dimensional non-homogeneous Poisson process; these include time-scale transformation of a homogeneous (rate one) Poisson process via the inverse of the integrated rate function, generation of the individual intervals between points, and generation of a Poisson number of order statistics from a fixed density function. We then state a particular and very efficient method for simulation of nonhomogeneous Poisson processes with log-linear rate function. The method is based on an identity relating the nonhomogeneous Poisson process to the gap statistics from a random number of exponential random variables with suitably chosen parameters. This method can also be used, at the cost of programming complexity and some memory, as the basis for a very efficient technique for simulation of nonhomogeneous Poisson processes with more complicated rate functions such as a log-quadratic rate function. Finally, we describe a simple and relatively efficient new method for simulation of one-dimensional and two-dimensional non-homogeneous Poisson processes. The method is applicable for any given rate function and is based on controlled deletion of points in a Poisson process with a rate function that dominates the given rate function. In its simplest implementation, the method obviates the need for numerical integration of the rate function, for ordering of points, and for generation of Poisson variates. The thinning method is also applicable to the generation of individual intervals between points, as is required in many programs for discrete-event simulations.


#*A variational approximation for sturm-liouville problems
#@C. C. Farrington, Jr.
#t1956
#cProceedings of the 1956 11th ACM national meeting
#index555022


#*A combinatorial problem which is complete in polynomial space
#@Shimon Even,R. Endre Tarjan
#t1975
#cProceedings of seventh annual ACM symposium on Theory of computing
#index545954
#%544896
#%555061
#%611356
#!We consider a generalization, which we call the Shannon switching game on vertices, of a familiar board game called HEX. We show that determining who wins such a game if each player plays perfectly is very hard; in fact, it is as hard as carrying out any polynomial-space-bounded computation. This result suggests that the theory of combinatorial games is difficult.


#*Algorithms for tree source coding with a fidelity criterion
#@John Bailey Anderson
#t1972
#c
#index200274


#*Program behavior and control in virtual storage computer systems
#@Tad Brian Pinkerton
#t1968
#c
#index197933


#*The architecture of a database computer - a summary
#@David K. Hsiao,Krishnamurthi Kannan
#t1977
#cACM SIGARCH Computer Architecture News
#index547195
#!The motivation for seeking hardware solutions to database management functions traditionally carried out by software has been apparent to data-base designers for sometime now. Firstly, database management software has grown in complexity and size over the years. This growth is prompted by the increase in user requirements, by the formulation of sophisticated models and by the change in data processing mode from an off-line, batched, single user environment to an on-line, concurrent and multi-user environment. Large and complex software systems tend to be failure-prone. Further-more, practical verification methods for software systems are still not in sight. On the other hand, methods for verifying hardware functionality, design and production have long been available. Advanced technology has also overcome some of the problems of the logic complexity and capacity requirements, making the construction of relatively large and complex computers viable. By incorporating basic database management functions into hardware, not only can we provide more reliable basic functions, but we can also improve the software reliability since the software requirements will be less complex and the system software will be smaller in size.


#*A course description for teacher education in computer science
#@J. L. Poirot
#t1976
#cProceedings of the ACM SIGCSE-SIGCUE technical symposium on Computer science and education
#index547415
#%301744
#%309225
#%312865
#!This paper describes the content of a course entitled &ldquo;Computers in Education&rdquo; offered within the teacher certification program at Southwest Texas State University. This course, designed specifically for teacher education has several objectives including the following: (1) to cover material which would be most likely included in a secondary school curriculum, (2) to give adequate motivation for covering this material in the secondary school, (3) to list objectives to be reached in the secondary school classroom for each topic, (4) to present teaching techniques for topics in the secondary school, (5) to present computer related topics designed to aid the teacher in instruction, (6) to present computer related topics designed to aid the teacher in school administrative work.


#*XL: a language structure
#@R. A. Nelson
#t1978
#cACM SIGPLAN Notices
#index303040
#%325067


#*Report on selected readings on digital computer simulation
#@Vladimir Bazjanac
#t1973
#cACM SIGSIM Simulation Digest
#index580968
#!The title of this text immediately reveals who it is written for: architects who are interested in computer applications. The author is assuming that the general reader in the field of architecture has absolutely no background in the field of computing and the text is therefore written on a very low level of sophistication, at which the simplicity is exaggerated. Though the text as a whole is probably helpful for an uninformed reader to learn about applications of computers to architecture, a more sophisticated reader will find reading of all but a few sections a waste of time. For a person with specific interests in the field of architecture and computer applications, those few more successful parts are probably quite worth reading, if for nothing else, then just for exposure to what is actually being done in that area. Besides that, an uninformed reader may find it interesting to get exposure to British hardware and ALGOL-based programming practice, as well as British terminology.


#*Hierarchical implementation of operations research models using a conversational modelling language.
#@Ronald Eugene Mills
#t1978
#c
#index200112


#*More on an IF statement for bed comparison
#@R. E. Dickie
#t1962
#cCommunications of the ACM
#index316389


#*Picture naming and modification: An overview
#@James D. Foley
#t1976
#cACM SIGGRAPH Computer Graphics
#index548161
#!The purpose of this paper is to review and organize the basic concepts involved in naming and modifying images presented on a graphics display, and to indicate the advantages and disadvantages of the various techniques currently used by graphics languages. We will not consider the syntactic questions of how the semantic capabilities are presented to the language users. A number of extant graphics programming languages are categorized according to their naming and modification capabilities.


#*ACM forum
#@Robert L. Ashenhurst
#t1979
#cCommunications of the ACM
#index313981
#%320527


#*Cohen-macaulay complexes and group actions.
#@Peter Freedman Garst
#t1979
#c
#index198942


#*Constructing Call-by-Value Continuation Semantics
#@Ravi Sethi,Adrian Tang
#t1979
#cProceedings of the 6th Colloquium, on Automata, Languages and Programming
#index364038


#*Session 8c: data archives and data file services
#@
#t1976
#cProceedings of the 4th annual ACM SIGUCCS conference on User services
#index234702


#*Logic and programming languages
#@Dana S. Scott
#t1977
#cCommunications of the ACM
#index314791
#%611343
#%317475
#!Logic has been long interested in whether answers to certain questions are computable in principle, since the outcome puts bounds on the possibilities of formalization. More recently, precise comparisons in the efficiency of decision methods have become available through the developments in complexity theory. These, however, are applications to logic, and a big question is whether methods of logic have significance in the other direction for the more applied parts of computability theory. Programming languages offer an obvious opportunity as their syntactic formalization is well advanced; however, the semantical theory can hardly be said to be complete. Though we have many examples, we have still to give wide-ranging mathematical answers to these queries: What is a machine? What is a computable process? How (or how well) does a machine simulate a process? Programs naturally enter in giving descriptions of processes. The definition of the precise meaning of a program then requires us to explain what are the objects of computation (in a way, the statics of the problem) and how they are to be transformed (the dynamics). So far the theories of automata and of nets, though most interesting for dynamics, have formalized only a portion of the field, and there has been perhaps too much concentration on the finite-state and algebraic aspects. It would seem that the understanding of higher-level program features involves us with infinite objects and forces us to pass through several levels of explanation to go from the conceptual ideas to the final simulation on a real machine. These levels can be made mathematically exact if we can find the right abstractions to represent the necessary structures. The experience of many independent workers with the method of data types as lattices (or partial orderings) under an information content ordering, and with their continuous mappings, has demonstrated the flexibility of this approach in providing definitions and proofs, which are clean and without undue dependence on implementations. Nevertheless much remains to be done in showing how abstract conceptualizations can (or cannot) be actualized before we can say we have a unified theory.


#*Polynomial real root isolation using Descarte's rule of signs
#@George E. Collins,Alkiviadis G. Akritas
#t1976
#cProceedings of the third ACM symposium on Symbolic and algebraic computation
#index548899
#%205529
#%544529
#!Uspensky's 1948 book on the theory of equations presents an algorithm, based on Descartes' rule of signs, for isolating the real roots of a squarefree polynomial with real coefficients. Programmed in SAC-1 and applied to several classes of polynomials with integer coefficients, Uspensky's method proves to be a strong competitor of the recently discovered algorithm of Collins and Loos. It is shown, however, that it's maximum computing time is exponential in the coefficient length. This motivates a modification of the Uspensky algorithm which is quadratic in the coefficient length and which also performs well in the practical test cases.


#*Digital control simulation system
#@H. Rex Hartson
#t1969
#cProceedings of the 6th annual Design Automation Conference
#index554737
#%553515
#!Today there is widespread application of digital control circuitry in a wide range of products. This paper describes a simulation system in which the designer of these control circuits can interact with his design ideas before they are implemented in hardware. The Digitial Control Simulation System (DCSS) is a digital design description language with a set of programs to generate and execute a simulation program. The main use of this system (with an appropriate hardware interface) is the testing of, and possibly on-line simulation of, the control of a system being designed and constructed.


#*Product Profile
#@
#t1973
#cComputer
#index340510
#!Information on the products and services advertised in PRODUCT PROFILE may be obtained by writing the product listing's number (in parenthesis at the beginning of each listing) on the postage-paid reader service card this issue. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Proposals for revision of the transput sections of the Report (Fontainebleau 10)
#@C. H. Lindsey
#t1972
#cIssue 34 (July 1972)
#index98957


#*Mathematische Logik und Informatik
#@Konrad Zuse
#t1975
#cGI - 5. Jahrestagung
#index262611


#*The QMESH mesh generation package (abstract)
#@Rondall E. Jones
#t1975
#cACM SIGNUM Newsletter
#index97189
#!A package of five programs centering around the highly flexible, powerful, two-dimensional mesh generation program, QMESH, is presented. Together, the five programs provide a tool for generation, bandwidth minimization and display of meshes with Q4 or Q8 elements. The package's primary purpose is generation of input for finite element analysis programs.


#*Klassifikation von Lehrprogrammen
#@Peter Ripota
#t1974
#cRechner-Gest&uuml;tzter Unterricht, RGU '74, Fachtagung-ACU-Arbeitskreis Rechner-Gest&uuml;tzter Unterricht
#index561187


#*Product type two-point Gauss-Legendre-Simpson's integration [D1]
#@W. Robert Boland
#t1972
#cCommunications of the ACM
#index317749


#*On sharing of pages in CP-67
#@P. N. Wahi
#t1973
#cProceedings of the workshop on virtual computer systems
#index544964
#!Sharing of procedure code among user-programs is a controversial concept in computer systems operating in a virtual machine and a time-sharing environment. In some systems the sharing can be effected at a segment level while in others it is effected at a page level. A model for sharing of pages in a CP-67/360 environment is developed and the results of experiments are presented.


#*An image restoration technique: applications to nuclear medicine images
#@Virginio Cantoni,I. De Lotto,A. Favino,F. Valenziano
#t1977
#cDigital Bildverarbeitung - Digital Image Processing, GI/NTG Fachtagung
#index555854


#*Uniform random number generator by shift register method
#@Harold Joseph Highland
#t1973
#cACM SIGSIM Simulation Digest
#index578266
#%81323
#!The quixotic quest for the perfect random number generator has been an overriding factor for a group of simulation purists. Although we have developed a series of tests for the evaluation of random number generators, only a few of us engaged in modeling and simulation have actually taken the time to analyze the generators we use; most are willing to accept the random number generators available on the system -- just because it is there!


#*Computers in the study of learning: namer&mdash;A pattern-recognition system for generating sentences about relations between line drawings
#@D. L. Londe,R. F. Simmons
#t1965
#cProceedings of the 1965 20th national conference
#index545947
#!THIS PAPER reports on a series of experimental programs which are used to recognize line drawings and the spatial relationships between them. At the pattern-recognition level the programs learn to associate a name with a generalized bit pattern representing a line drawing. At the relation-learning level, the programs abstract characteristics which relate to such spatial concepts as &ldquo;above,&rdquo; &ldquo;left,&rdquo; &ldquo;thicker than,&rdquo; etc. The names that have been learned in association with a drawing, and relation names which the program selects as true for the spatial relations between two drawings, are substituted into a simple generation grammar; variations of sentences that are true for the picture are then generated.


#*A character-oriented context-addressed segment-sequential storage
#@Leonard D. Healy
#t1976
#cProceedings of the 3rd annual symposium on Computer architecture
#index547465
#%191727
#%305945
#%550081
#!The Context-Addressed Segment-Sequential Storage (CASSS) described in this paper provides a solution to the problem of data retrieval from a large, nonpreorganized file. It provides this capability entirely by hardware, eliminating the need for special data structuring solely for the purpose of reducing search time. The major features of the architecture of a character-oriented CASSS system are described, including the basic hardware configuration selected to implement such a system and the set of search instructions chosen to provide a wide variety of search operations useful in information retrieval. Of particular importance in this application is the method of quasi-parallel instruction execution, which allows a full string search of the entire data base in a single cycle of the sequential storage device used.


#*Ein Rechnerkonzept mit assoziativem Arbeitsspeicher - Programmorganisation
#@W. Lawrenz
#t1974
#cFachtagung Struktur und Betrieb von Rechensystemen
#index564804


#*Methods for teaching program verification
#@Susan L. Gerhart
#t1975
#cProceedings of the fifth SIGCSE technical symposium on Computer science education
#index548732
#%79620
#%316592
#%320995
#%545453
#%546623
#!&ldquo;Program verification&rdquo; is generally defined as the process of ascertaining and demonstrating that a program is correct, i.e., that a program satisfies a given set of specifications. The most common method of verifying a program is by testing, the process of executing a program for a set of selected inputs and inferring from the results of those executions that the program is correct for all possible inputs. In practice today, a few programs are being proved correct but the most common method of program verification is still testing. Both methods are unreliable in different ways, but when combined, their complementary relationship can provide a high degree of assurance that programs are correct. The purpose of this paper is (1) to review the state of the art of these two approaches to program verification and the relationship between them, and (2) to suggest a number of ways in which program verification can be introduced into the computer science curriculum.


#*Spelling correction in systems programs
#@Howard L. Morgan
#t1970
#cCommunications of the ACM
#index329166
#%315621
#%331499
#%334014
#%333859
#!Several specialized techniques are shown for efficiently incorporating spelling correction algorithms into compilers and operating systems. These include the use of syntax and semantics information, the organization of restricted keyword and symbol tables, and the consideration of a limited class of spelling errors. Sample 360 coding for performing spelling correction is presented. By using systems which perform spelling correction, the number of debugging runs per program has been decreased, saving both programmer and machine time.


#*Symbolic-Numeric Interface: a review (in absentia)
#@Edward W. Ng
#t1979
#cProceedings of the International Symposiumon on Symbolic and Algebraic Computation
#index271484


#*An Algebraic Construction for q-ary Shift Register Sequences
#@F. Hemmati
#t1978
#cIEEE Transactions on Computers
#index350561
#!Using the Euclidean Algorithm for polynomials over GF(q), an algebraic technique for the generation of q-ary shift register sequences of arbitrary length l, 1 = l = qm, is obtained, where q is a power of a prime number, q = pn, and m is the number of shift register stages.


#*Using a Microprocessor in an Intelligent Graphics Terminal
#@J. Raymond
#t1976
#cComputer
#index340921
#!Graphic terminals allow on-line interaction between the user and his program, thereby enabling him to alter the displayed picutre according to his requirements. However, a major problem with the use of a graphic terminal is the cost associated with it. There is no doubt that low-cost graphic terminals are available, but their utility is very limited since they have no processing capability (or intelligence) and must depend on a host processor attention, while at the same time putting additional strain, on the resources of the host machine. This naturally degrades the response time, depending on the processor load at that time, On the other hand, graphic terminals which have local processing capability are very expensive. With the availability of microprocessors, it is now possible to resolve this delemma: a reasonable amount of intelligence can be added to the terminal at a very reasonable cost. Such a terminal has been developed at the University of Ottawa.


#*Numerical computation of electromagnetic scattering by inhomogeneous dielectric bodies of revolution.
#@Michael Allen Morgan
#t1976
#c
#index199106


#*IEEE Computer Society Technical Committees
#@
#t1976
#cComputer
#index352388


#*Facilities and programs in support of education in computer science at minority institutions (Panel Discussion)
#@
#t1976
#cACM SIGCSE Bulletin
#index545214
#!The panel will address the area of education in computer science from the standpoint of minority institutions. Panelists will present views from the standpoint of individuals who have developed programs at the two and four year levels, individuals who have utilized portions of such programs as service offerings, and from the standpoint of funding agencies. Also considered by the panel will be questions of problems unique to the minority institutions, and projected future developments in computer science education at the institutions. Finally, the area of appropriate resources in support of computer science education will be considered.


#*Recent abstracts
#@Stanley Habib
#t1974
#cACM SIGMICRO Newsletter
#index11006
#%335595


#*Universal computer-oriented language
#@W. B. Dobrusky,T. B. Steel
#t1961
#cCommunications of the ACM
#index317045
#!The basic idea of UNCOL Universal Computer-Oriented Language&mdash;is to introduce a language between problem-oriented languages, POLs, and machine languages, MLs. This third level consists of a single language, UNCOL, which has the character of a generalized machine-line language.


#*Multi-tape and infinite-state automata&mdash;a survey
#@Patrick C. Fischer
#t1965
#cCommunications of the ACM
#index327461
#%576727


#*Own concept and ALGOL X
#@J. N. Merner
#t1966
#cIssue 22 (February 1966)
#index100269


#*An interference matching technique for inducing abstractions
#@Frederick Hayes-Roth,John McDermott
#t1978
#cCommunications of the ACM
#index324890
#!A method for inducing knowledge by abstraction from a sequence of training examples is described. The proposed method, interference matching, induces abstractions by finding relational properties common to two or more exemplars. Three tasks solved by a program that uses an interference-matching algorithm are presented. Several problems concerning the description of the training examples and the adequacy of interference matching are discussed, and directions for future research are considered.


#*SALOGS-IV-A program to perform logic simulation and fault diagnosis
#@Glenn R. Case,Jerry D. Stauffer
#t1978
#cProceedings of the 15th Design Automation Conference
#index553159
#%545616
#%549027
#%549265
#!The simulation algorithm for multiple logic levels modeling considerations and the network and simulation languages used in SALOGS, Version IV, are discussed. Also presented is the method for fault diagnosis and test sequence generation and the philosophy used in the code development.


#*A Hybrid Iterative-Numerical Method for the Solution of a General Queueing Network
#@Raymond A. Marie,William J. Stewart
#t1977
#cProceedings of the Third International Symposium on Measuring, Modelling and Evaluating Computer Systems
#index272136


#*Rules for reducing calculate time and conservation of storage space
#@J. H. Allen
#t1956
#cProceedings of the 1956 11th ACM national meeting
#index546532
#!Two of the most costly commodities of a computing machine are calculate speed and amount of storage space. It makes good economic sense to be able to utilize the machine so that both of these commodities are effectively increased. Here are presented some of the most frequently used functions, and some of the means whereby their computation is faster, and/or the amount of required storage is reduced. Except for the four basic arithmetic operations: add, subtract, divide and multiply, the most frequently used operation in general problems is square root. Hence, if this one operation can be minimized in calculate time, considerable saving may be realized in the overall operating speed.


#*A general personnel information retrieval system in APL
#@K. K. Wing,Y. K. Wong
#t1976
#cProceedings of the eighth international conference on APL
#index552052
#!This paper describes an information retrieval system originally conceived for use in a personnel management environment. However, it is perfectly general and readily applicable to other areas. The data are stored in the form of an inverted file. Laymen with no prior exposure to APL can use the system for automatic report generation, frequency distributions and other information retrieval routines as well as simple statistical calculations. Ease of use is achieved via the construction of a simple syntactic structure.


#*The dynamics of a general aviation pilot promotion campaign
#@Michael A. Duffy
#t1978
#cProceedings of the 11th annual symposium on Simulation
#index549915
#!The General Aviation Dynamics (GAD) model is the result of a series of research programs conducted by Battelle's Columbus Laboratories (BCL). It is a dynamic simulation model built upon the causal interactions displayed between the various sectors of the general aviation system; viz, the pilot supply sector, the aircraft demand sector, and the aircraft utilization sector. Previous applications of the GAD model have addressed the impact on GA activity of proposed regulatory changes which would result in increased user costs. This paper is an evaluation of the General Aviation Manufacturers' Association's three-year Takeoff program which is attempting to double the expected private pilot population by 1980. If the Takeoff program is successful, the GAD model indicates that there will be approximately 50,000 additional active general aviation aircraft by 1985.


#*Speech synthesis under APL
#@Donald B. Rueter
#t1974
#cProceedings of the sixth international conference on APL
#index546298
#!Electronic speech synthesis is new a reality. Within the past few years there have been developed a number of devices having the capability of producing remarkably understandable speech electronically. Digital speech devices are of basically two types: they either withdraw prerecorded speech sounds from some direct-access storage device and connect them into words and phrases; or they electronically synthesize speech sounds using tone generators and appropriate shaping and filtering circuits. This paper discusses the second type. For a few years, now, there has been available from the Federal Screw Works of Troy, Michigan, a device called the Votrax voice synthesizer. This device may be connected to a computer, among other things, and digital codes can be entered into its internal buffer. The device is then instructed to speak the contents of its buffer through a loudspeaker. Coast Community College District obtained its first of the current two Votrax devices late in the 1972-73 school year and spent several months using a keyboard to load the buffer in a manual mode. In September, 1973, it became possible to connect the device to the computer in parallel with a Tektronix 4010 graphic display terminal under APL, which was then done as shown in Figure 1. Using this convention the Votrax sees all characters sent to the terminal, and does not transmit any data or line control voltages back to the terminal controller.


#*Compiling matrix operations
#@Bernard A. Galler,Alan J. Perlis
#t1962
#cCommunications of the ACM
#index331703
#%328020
#!It is unfortunate that almost all of the presently used algebraic languages do not provide the capability of linear algebra. Operations such as the inner product of vectors, the product of two matrices, and the multiplication of a matrix by a scaler must inevitably be written out in detail in terms of the individual components. The reasons usually given for avoiding linear algebra in these languages are (1) the difficulties which would arise in scanning linear algebraic expressions, and (2) the uncertainty involved as to the amount of temporary storage needed during the evaluation of linear algebraic expressions when the program is executed. The purpose of this paper is to show how these two types of difficulties can be overcome. Although suggestions have been made for even further increasing the general capability of ALGOL such as including the ability to form a matrix from a collection of vectors, we shall be content here to consider the ordinary operations of linear algebra. Even if this much becomes available in algebraic languages, considerable progress will have been made. The following remarks constitute a suggestion for the addition to ALGOL of linear algebraic expressions.


#*Proximity and reachability in the plane.
#@Der-Tsai Lee
#t1978
#c
#index190735


#*On program control structure
#@Peter M. Neely
#t1973
#cProceedings of the ACM annual conference
#index554375
#%332108
#%333809
#!The syntax of the DO-WHILE is revised so as to distinguish the semantics of logical control of iteration from those of site of test within the scope of the DO. The corresponding control graph (flowchart subdiagram) is shown to be a combination of previously used alternative forms. An indentation scheme is proposed in which the indentation rules are identical for both iterative and conditional statements. Furthermore the rules as given are identical for any programming language, whether it is a lower level language which requires hand coded book-keeping statements or some ideal language in which all loop control is provided for in the syntactic forms. The minimal sufficient set of program control structures is augmented with forms for the convenience of human program writers and readers. These forms all share common indentation rules corresponding to those used for the DO-WHILE and IF-THEN-ELSE. Last a form is provided for handling error conditions, POSIT-QUIT-ADMIT in which multiple QUITs are permitted. The indentation rules are compatible with the preceding rules.


#*Tape splitting
#@Donald P. Moore
#t1961
#cCommunications of the ACM
#index327992


#*Human extrapolation of strings generated by ordered cyclic finite state grammars.
#@James Lewis Beug
#t1974
#c
#index193759


#*Towards a unified approach to 2-D picture manipulation
#@Richard G. Shoup
#t1977
#cProceedings of the 4th annual conference on Computer graphics and interactive techniques
#index245763


#*Computing in the 1980's
#@
#t1979
#cProceedings of the 7th annual ACM SIGUCCS conference on User services
#index445548


#*The control of congestion in packet switching networks
#@D. W. Davies
#t1971
#cProceedings of the ACM second symposium on Problems in the optimizations of data communications systems
#index549264
#%549911
#!Any communication network has a limit to the traffic it can carry. If there is more than a certain traffic demand, some of the traffic must be rejected. Both the nature of the limitation and the reaction of the network to excess demand depend on the design of the network. The network in a condition where it must reject traffic is called 'congested'.


#*On Restrictions to Ensure Reproducible Behavior in Concurrent Programs
#@Fred B. Schneider,A. J. Bernstein
#t1979
#c
#index110885
#!One of the major difficulties encountered when dealing with concurrent programs is that reproducible behavior may not be assumed. As a result, it is difficult to validate and debug such systems. In this paper, structural restrictions are presented that ensure that reproducible behavior will occur in concurrent programs. The application of this to system design is discussed. Keywords: time dependent behavior, concurrency, synchronization, monitors, Concurrent Pascal.


#*Social aspects and responsibilities (A Panel Session): Computer investigations of intention to attack
#@E. C. Berkeley
#t1962
#cProceedings of the 1962 ACM national conference on Digest of technical papers
#index544595
#!ONE OF THE SOCIALLY important questions which can be studied with aid from computers is the question: &ldquo;Is any country really preparing to attack any other country?&rdquo; In other words, is it possible, using computers, to distinguish between the absence and the presence of intention to attack, committing obvious and flagrant aggression?


#*Architectural implications of abstract data type implementation
#@Virgil D. Gligor
#t1979
#cProceedings of the 6th annual symposium on Computer architecture
#index553947
#%201080
#%323836
#%324042
#%326150
#%329899
#%334254
#%334270
#%553281
#%554522
#!Some protection mechanisms support the implementation of abstract type objects. The &ldquo;separation of privilege&rdquo; and the &ldquo;least privilege&rdquo; principles define several requirements that must guide the design of such protection mechanisms. Some of these requirements can be used to eliminate inadequate or unnecessary mechanisms. Type protection mechanisms and some of the requirements of the least privilege principle have either practical theoretical limitations. To mitigate these limitations, a capability-based architecture must support (1) the migration of abstract type objects outside the control of their type manager, and (2) inexpensive, small segments. To meet the requiements of the &ldquo;separation of privilege&rdquo; and &ldquo;least privilege&rdquo; principles, a capability-based architecture only needs to support (1) protected procedures and (2) &ldquo;explicit&rdquo; mechanisms for separating access privileges to objects and to object representations.


#*The notions of consistency and predicate locks in a database system
#@K. P. Eswaran,J. N. Gray,R. A. Lorie,I. L. Traiger
#t1976
#cCommunications of the ACM
#index317485
#%552437
#%547167
#%326368
#!In database systems, users access shared data under the assumption that the data satisfies certain consistency constraints. This paper defines the concepts of transaction, consistency and schedule and shows that consistency requires that a transaction cannot request new locks after releasing a lock. Then it is argued that a transaction needs to lock a logical rather than a physical subset of the database. These subsets may be specified by predicates. An implementation of predicate locks which satisfies the consistency condition is suggested.


#*Estimation of manpower forecast variation by GPSS simulation
#@Philip Hicks
#t1968
#cProceedings of the second conference on Applications of simulations
#index555343
#!Traditionally, manpower estimation has been done on an expected value basis. Such estimates, although providing an estimate of the mean of manpower requirements, provide no indication of the probable spread about the mean. Manpower solution plans, however, often implicitly assume an estimate spread based upon experience gained from previous projects. This paper is concerned with estimation of manpower forecast variations, both in the aggregate and by skill level.


#*Neighborhood search algorithms for finding optimal traveling salesman tours must be inefficient
#@P. Weiner,S. L. Savage,A. Bagchi
#t1973
#cProceedings of the fifth annual ACM symposium on Theory of computing
#index552750
#%194879
#%198448
#!search In this paper, we explore the use of neighborhood search techniques for finding optimal solutions to the symmetric Traveling Salesman Problem. These techniques have been dramatically successful in obtaining near-optimal solutions to this problem for a reasonable expenditure of effort (1,2,3,4,5,6,9,10,12). Extensions of these techniques can be used to obtain the globally optimum solution, but the effort involved is at least an exponential function of the number of cities, n. Indeed, as this paper demonstrates, all local search algorithms that are capable of finding the optimal solution to an arbitrary n-city problem must grow at least as fast as equation !. Thus for large problems, these algorithms are computationally inefficient. In following section we show that any exact neighborhood search algorithm for the Traveling Salesman Problem must inspect a prohibitively large number of feasible solutions. We begin with a brief discussion of the Traveling Salesman Problem (TSP) and neighborhood search techniques in section II. In section III we develop a necessary condition for neighborhood search to converge to an optimal solution. We use this result in sections IV and V to obtain a lower bound on the effectiveness of neighborhood search as applied to the TSP.


#*Review of "Statistical Quality Control Methods, by Irving W. Burr", Marcel Dekker, Inc., 1976
#@
#t1976
#cACM SIGSIM Simulation Digest
#index577940
#!Although most of us are not directly involved with quality control in computer systems, it is highly recommended that those who are rusty take the time to read this clear and concise volume. The emphasis is on data analysis and decision making. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Algorithm 94: Combination
#@Jerome Kurtzberg
#t1962
#cCommunications of the ACM
#index319360


#*Cold-start vs. warm-start miss ratios
#@Malcolm C. Easton,Ronald Fagin
#t1978
#cCommunications of the ACM
#index331266
#%329097
#%551615
#!In a two-level computer storage hierarchy, miss ratio measurements are often made from a &ldquo;cold start&rdquo;, that is, made with the first-level store initially empty. For large capacities the effect on the measured miss ratio of the misses incurred while filling the first-level store can be significant, even for long reference strings. Use of &ldquo;warm-start&rdquo; rather than &ldquo;cold-start&rdquo; miss ratios cast doubt on the widespread belief that the observed &ldquo;S-shape&rdquo; of lifetime (reciprocal of miss ratio) versus capacity curve indicates a property of behavior of programs that maintain a constant number of pages in main storage. On the other hand, if cold-start miss ratios are measured as a function of capacity and measurement length, then they are useful in studying systems in which operation of a program is periodically interrupted by task switches. It is shown how to obtain, under simple assumptions, the cache miss ratio for multiprogramming from cold-start miss ratio values and how to obtain approximate cold-start miss ratios from warm-start miss ratios.


#*A New Concept in Impact Printing
#@J. Tschinkel
#t1975
#cComputer
#index353003
#!While the impact printer has been developed to a very high level of performance in terms of printing quality and speed, no fundamental changes have been made to the printed format. All printing is currently done, as it has been for years, on the "standard" computer form measuring 11 inches high and 14-7/8 inches wide. Typically, a line is 132 characters long; there are 6 lines per inch and the characters are generally upper case only. The paper is fan fold, available in various thicknesses or weights, and is multi-formed with interlaced carbon. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*The design of computer architectures to enhance software reliability.
#@Glenford James Myers
#t1977
#c
#index191539


#*Music and computer composition
#@James Anderson Moorer
#t1972
#cCommunications of the ACM
#index315469
#!The problem discussed is that of simulating human composition of Western popular music by computer and some relevant theories of music and harmony are given. Problems with this kind of program and several schemes that are known not to work are discussed. Several previous computer compositions are discussed, including the ILLIAC Suite. A program to generate short melody fragments was written to simulate some of the aspects of human composition. Five samples of its output are presented and discussed. It was discovered that although the fragments show many of the characteristics of popular melodies, they have a strangely alien sound. It is theorized that this is because the relevant probabilities which would discriminate against unfamiliar sequences were not used.


#*An organizational approach to routing printed circuit boards
#@Barry D. Heller,Robert S. Fisher
#t1976
#cProceedings of the 13th Design Automation Conference
#index553069
#!Many attempts have been made to create better routers by developing new algorithms or modifying existing ones, the results of which have been published (sometimes). At Raytheon, an experiment was undertaken to increase the percentage of signals routed (in a batch router). The improvement technique consisted of modifying the order and manner in which connections were routed. This was accomplished by splitting the signal networks into parts, and using different rules for routing the different parts.


#*A self documenting technique for systems analysis
#@Lois A. Rose
#t1978
#cACM SIGDOC Asterisk Journal of Computer Documentation
#index10920
#!Probably the biggest, messiest, most onerous task in systems analysis is documentation. Typically, we produce enormous amounts of highly detailed narrative, together with some fairly general flowcharts. If anybody ever actually reads these documents, they often find redundant and contradictory information. Even though the documents are laden with all the detail we could think of to include, the reader typically walks away muttering, "But what's the system supposed to do?" The feeling is something like expecting floor plans and renderings of your new custom house from the architect, and instead receiving an accounting of the barrels of nails, board-feet of lumber, reels of copper wire, and a carpentry manual. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*File Assignment in Memory Hierarchies
#@D. V. Foster
#t1975
#c
#index186450


#*Information Retrieval: Easy English, a language for information retrieval through a remote typewriter console
#@M. Rubinoff,S. Bergman,F. Rapp,H. Cautin
#t1968
#cCommunications of the ACM
#index334761
#%323641
#!Easy English is a natural command language designed to simplify communication between man and machine through remote typewriter console. It has been developed for retrieval of documents from a computerized data base, the Moore School Information Systems Laboratory files. Requests are formulated in a standardized syntactical form (examples of which are presented), and this form is then transformed into an equivalent query expressed in the retrieval system's original Symbolic Command Language, which is briefly described. Operation of Easy English is detailed by illustration of the transformations performed upon a sample request up to the point at which the request string is sent to the system. A macro flowchart of Easy English is included, and an Appendix provides the printout of a retrieval demonstration.


#*Operating system enhancement through microprogramming
#@George E. Brown,Richard H. Eckhouse, Jr.,Robert P. Goldberg
#t1976
#cACM SIGMICRO Newsletter
#index12635
#%316233
#%335280
#!Microprogramming support for the enhancement of operating system design is described briefly, organization structure of real-time operating systems are examined, and criteria proposed for determining which functions are best candidates for implementation in firmware. A suitable microprogrammed computer is selected and avenues for additional research are recommended.


#*The optimization of analog computer programming by digital computer techniques
#@William Sanders Adams
#t1963
#c
#index201590


#*Bounded context syntactic analysis
#@Robert W. Floyd
#t1964
#cCommunications of the ACM
#index321844
#%331118
#%327973
#!Certain phase structure grammars define languages in which the phrasehood and structure of a substring of a sentence may be determined by consideration of only a bounded context of the substring. It is possible to determine, for any specified bound on the number of contextual characters considered, whether a given grammar is such a bounded context grammar. Such grammars are free from syntactic ambiguity. Syntactic analysis of sentences in a bounded context language may be performed by a standard process and requires a number of operations proportional to the length of sentence analyzed. Bounded context grammars form models for most languages used in computer programming, and many methods of syntactic analysis, including analysis by operator precedence, are special cases of bounded context analysis.


#*The HP 3000 computer system
#@Joel F. Bartlett
#t1973
#cProceedings of a symposium on High-level-language computer architecture
#index302091


#*A new approach to an adaptive computer&mdash;an automatic recovery mechanism to prevent the occurrence of subtract errors
#@Ken Sakamura,Koichi Nakano,Yoshio Kato,Hideo Aiso
#t1979
#cProceedings of the 6th annual symposium on Computer architecture
#index547541
#%79620
#!This paper deals with an automatic recovery mechanism designed to prevent the occurrence of subtract errors at the computer architecture level. This mechanism always detects the occurence of subtract errors whenever addition or subtraction is performed. If a subtract error is detected, backtracking to a certain location is carried out, and from there recomputing is performed in order to realize the required precision. An adaptive algorithm required for this mechanism is described in detail. An experimental adaptive computer was implemented on a Burroughs B1700. The evaluation of the experiments proves that the inherent possibilities of dynamic microprogramming play a very important role in realizing this mechanism, and that the proposed mechanism will be useful for the development of future high-level computer systems.


#*On the Minimization of the Width of the Control Memory of Microprogrammed Processors
#@J. -L. Baer
#t1979
#cIEEE Transactions on Computers
#index348740
#!A branch and bound method to minimize the width of the control memory of microprogrammed processors is given. Although it is exponential in the worst case, it appears much more effective than previous enumerative solutions. Furthermore, it can lead quickly to near-optimal solutions representing "good engineering" reductions.


#*The tricotyledon theory of system design
#@A. Wayne Wymore
#t1974
#cProceedings of the Proceedings of the First International Symposium on Category Theory Applied to Computation and Control
#index275379


#*&Dgr;Editor APL function and data maintenance system
#@R. G. Germain,J. W. Burgeson
#t1976
#cProceedings of the eighth international conference on APL
#index555167
#!&Dgr;EDITOR IS AN APL WORKSPACE CONTAINING A SET OF HIGHLY USEFUL APL FUNCTIONS FOR USE IN THE CONSTRUCTION, DEBUGGING, MODIFICATION AND MAINTENANCE OF APL WORKSPACES. FEATURES OF &Dgr;EDITOR: A POWERFUL COMMAND SET, INCLUDING ADD, DELETE, CHANGE, MOVE, COPY, MERGE, BUILD AND FIND FUNCTIONS. EDITING OF BOTH APL FUNCTIONS AND DATA ARRAYS. FLEXIBILITY - THREE LEVELS OF FUNCTION AND STORAGE REQUIREMENTS, GROUPED FOR EASY COPYING INTO AND DELETING FROM USER WORKSPACES. DOCUMENTATION - USER MANUAL, HELP FUNCTION AND STORAGE REQUIREMENTS TABLE. EASE OF USE - TERSE, EASY TO REMEMBER COMMAND NAMES WITH CONSISTENT SYNTAX.


#*Homogeneous complex manifolds and representations of semisimple lie groups
#@Wilfried Schmid
#t1967
#c
#index204542


#*The Concurrency Control Mechanism of SDD-1: A System for Distributed Databases (The Fully Redundant Case)
#@P. A. Bernstein
#t1978
#cIEEE Transactions on Software Engineering
#index352588
#!SDD-1, A System for Distributed Databases, is a distributed database system being developed by Computer Corporation of America (CCA), Cambridge, MA. SDD-1 permits data to be stored redundantly at several database sites in order to enhance the reliability and responsiveness of the system and to facilitate upward scaling of system capacity. This paper describes the method used by SDD-1 for updating data that are stored redundantly.


#*Efficient computation and data structures for graphics.
#@Gregory Michael Hunter
#t1978
#c
#index185853


#*Proving theorems by pattern recognition I
#@Hao Wang
#t1960
#cCommunications of the ACM
#index321810


#*Failure-Tolerant Sequential Machines with Past Information
#@Y. Tohma,S. Aoyagi
#t1971
#cIEEE Transactions on Computers
#index342030
#!A sequential machine must have certain redundant information in order to be capable of correcting error. As past inputs and past states are redundant, a sequential machine with error correction capability is constructable by making use of these elements of past information. This paper describes conditions of state assignments, numbers of required redundant state variables, and estimation of reliability of failure-tolerant sequential machines.


#*Solving Boundary Value Problems with a Spline-Collocation Code
#@Uri Ascher
#t1978
#c
#index205811


#*The characterisation of the derivation trees of context free sets of terms as regular sets
#@T. S. E. Maibaum
#t1972
#cProceedings of the 13th Annual Symposium on Switching and Automata Theory (swat 1972)
#index386747


#*Segmentierung in digitalen Chromatogrammbildern mit abgestufter Rastergr&ouml;&szlig;e
#@Harald Kronberg,Hans-Georg Zimmer,Volker Neuhoff
#t1979
#cAngewandte Szenenanalyse, DAGM Symposium
#index559021


#*Elementare Steuerknoten in Datenflu&szlig;modellen
#@Hans-Jürgen Gottschalk
#t1974
#cGI - 4. Jahrestagung
#index256384


#*Algorithm 156: algebra of sets
#@Charles J. Mifsud
#t1963
#cCommunications of the ACM
#index316130


#*Official Notices: Location changes for JCC conferences
#@
#t1962
#cCommunications of the ACM
#index324985


#*Picture Processing by Computer
#@Azriel Rosenfeld
#t1969
#cACM Computing Surveys (CSUR)
#index315776
#%313913
#%314542
#%549959
#%322663
#%320503
#%316058
#%333153
#%329436
#%545852
#%323284
#%328161
#%545947


#*Data base abstraction
#@John M. Smith
#t1976
#cACM SIGPLAN Notices
#index548994
#!Real-world systems modelled by data bases are often quite complex. It is essential that the data base be structured in a way which supports a users abstractions about the real-world system. The &ldquo;relation&rdquo; data type is introduced as a structuring primitive for relational data bases The relation data type has similar abstraction properties to the &ldquo;record&rdquo; data type of PASCAL. A data base defined via relation data types is structured as a hierarchy of n-ary relations. It is shown that the consistency of this hierarchic structure can be preserved during update operations by two simple rules. A top-down methodology for data base design with relation data types is developed. This methodology minimizes the number of details with which a designer must contend at one time. In particular, the methodology allows the separation of decisions concerning abstract structure from decisions concerning key identification. The separation simplifies both types of decision making for the data base designer.


#*SIAL/74 - an APLSV analog-logical block-diagram simulator
#@M. Alfonseca
#t1975
#cProceedings of seventh international conference on APL
#index545932
#!SIAL/74 is an APL-based, block-oriented, analog-logical continuous simulation language, allowing block diagram simulations. 56 different blocks are recognized by the compiler, although new block types may be included at will. The SIAL/74 compiler is written in APLSV. The language is an extension of former versions,(SIAL/70, SIAL/71, SIAL/72), described elsewhere (refs. 1-4). The result of compilation is a pair of APL functions: the object program, and an initiator needed to assign initial values to several global variables.


#*A Human Movement Language for Computer Animation
#@Don Herbison-Evans
#t1979
#cProceedings of a Symposium on Language Design and Programming Methodology
#index364476


#*Scattering theory and non linear systems
#@F. Joanne Helton,J. William Helton
#t1974
#cProceedings of the Proceedings of the First International Symposium on Category Theory Applied to Computation and Control
#index271422


#*Regular multivalued functions and algorithmic applications.
#@Javier Maguregui
#t1976
#c
#index194944


#*Using plans to understand natural language
#@Robert Wilensky
#t1976
#cProceedings of the 1976 annual conference
#index550764
#!Our ability to build a natural language understanding system is limited by the degree to which we can organize and apply world knowledge. This paper describes a program, called PAM, that has knowledge about people's intentions. PAM uses its knowledge to infer the relationships between sentences in a text. A sample run of the program is presented and is described in detail. The inference mechanisms of PAM are compared to those of other knowledge-application programs.


#*Abstracts in software engineering: part 6
#@Software Engineering Notes Staff
#t1978
#cACM SIGSOFT Software Engineering Notes
#index436204
#%434822


#*Dynamic scheduling with preemption: a deterministic approach.
#@Zaw-Sing Su
#t1975
#c
#index186587


#*Algorithms for shortest paths.
#@Donald Bruce Johnson
#t1973
#c
#index195119


#*A generalized system for university mathematics instruction
#@Robert L. Smith,Lee H. Blaine
#t1976
#cProceedings of the ACM SIGCSE-SIGCUE technical symposium on Computer science and education
#index550739
#!EXCHECK is a system for developing mathematically-based CAI courses. It is currently being used at Stanford University to teach a college-credit course in axiomatic set theory The design of this system had several goals. First, we wanted an instructional system that would provide a semantic base for our work on processing natural language and computer-generated audio. Axiomatic mathematics fits this description in that the underlying semantics is relatively well understood, but many of the interesting problems of natural language are also involved in the informal language of mathematics and the informal expression of mathematical proofs. Second, we recognized that traditional proof checkers were inadequate for teaching mathematics, or for that matter, introductory logic. People understand mathematical concepts and arguments at a level much higher than the traditional formal systems of mathematical logic. Finally, we designed the EXCHECK system to be an extensible system in which other curricula could be implemented with incrementally less work.


#*Additional comments on a problem in concurrent programming control
#@Donald E. Knuth
#t1966
#cCommunications of the ACM
#index319561


#*Decomposition programming: an analysis of matrix substructure
#@Earl J. Bell
#t1967
#cCommunications of the ACM
#index326126


#*Structural inference and identification of discrete time systems.
#@Anna Sylwia Zalecka-Melamed
#t1977
#c
#index191931


#*A systems approach to software design representation
#@Leon John Mekly
#t1979
#c
#index199524


#*Letters to the editor: Boolean rings
#@George Mealy
#t1961
#cCommunications of the ACM
#index331958


#*Algorithms
#@
#t1976
#cACM SIGAPL APL Quote Quad
#index241820


#*IFIP Document - Report on the Standard Hardware Representation for ALGOL 68
#@Wilfred J. Hansen,Hendrik Boom:
#t1976
#cIssue 40 (August 1976)
#index106277
#%103927


#*A hierarchical net-structure learning system for pattern description.
#@Harold Addison Williams, Jr.
#t1974
#c
#index189418


#*An analysis of traffic handling capacity of packet switched and circuit switched networks
#@Kazuo Itoh,Takao Kato,On Hashida,Yutaka Yoshida
#t1973
#cProceedings of the third ACM symposium on Data communications and Data networks: Analysis and design
#index545163
#%549262
#!This paper reports the results of a study on traffic handling capacity of switching nodes and transmission lines in the circuit and packet switched networks, and on cost evaluation methods for the two types of networks. The two types of networks were compared by setting various parameters, including the communication density defined in the paper. The comparison results show that there are application regions favorable for each type of network.


#*Proceedings of the sixth international conference on APL
#@
#t1974
#cInternational Conference on APL
#index555307


#*Computer preparation of a poetry concordance
#@James A. Painter
#t1960
#cCommunications of the ACM
#index324146
#!A concordance is an alphabetical index of the words used by a major writer, or group of writers, showing each word in its context. It is one of the basic research tools for scholars in the Humanities. Concordances are very useful in studies of language, vocabulary, and the history of ideas in literature and philosophy. Use of a concordance is probably the only way to interpret critically, or sometimes even to understand, a symbolist writer. It can also be used to help determine the age or even the author of a piece of anonymous writing.


#*A finite primal integer programming algorithm using facial cuts.
#@Graham Links
#t1976
#c
#index189268


#*Optimal simultaneous flow in single path communication networks
#@Robert Martin Siegmann
#t1971
#c
#index202656


#*Eliminating monotonous mathematics with FORMAC
#@Robert G. Tobey
#t1966
#cCommunications of the ACM
#index323030
#%321176
#%544757
#%332695
#!The FORMAC (FORmula MAnipulation Compiler) programming system provides a powerful tool for performing mathematical analysis. It is an extension of FORTRAN IV which permits the use of the computer to perform the tedious algebraic computations that arise in many different fields. Among the areas in which it has been successfully used are: differentiation of complicated expressions; expansion of truncated power series, solution of simultaneous equations with literal coefficients, nonlinear maximum likelihood estimation, tensor analysis, and generation of the coefficients of equations in Keplerian motion. These types of analysis&mdash;which arose in the solution of specific practical problems in physics, engineering, astronomy, statistics and astronautics&mdash;are discussed in the paper. In addition to its usage for specific problem solutions, FORMAC can also be used to automate the analysis phase in certain production programming. Several such applications are presented.


#*A hybrid paradigm for computer programming and its investigation in the context of electronic circuit simulation by means of an extensible language.
#@William Seabrook Beckett, Jr.
#t1978
#c
#index201489


#*Heuristic analysis of large trees as generated in the game of 'go'
#@Jonathan Leonard Ryder
#t1971
#c
#index203439


#*IEEE Computer Society Publications
#@
#t1979
#cIEEE Transactions on Computers
#index349681


#*Random variable generators
#@Robert E. Wheeler
#t1976
#cACM SIGSIM Simulation Digest
#index578880


#*Proceedings of the 3rd international conference on Software engineering
#@
#t1978
#cInternational Conference on Software Engineering
#index545242


#*Walsh-hadamard transformations in image processing
#@Nikitas Anestis Alexandridis
#t1971
#c
#index189906


#*Simulation von Zielfolgesystemen nach dem Reticle-Prinzip
#@S. Craubner
#t1979
#cAngewandte Szenenanalyse, DAGM Symposium
#index571248


#*Concurrency Control and Consistency of Multiple Copies of Data in Distributed Ingres
#@M. Stonebraker
#t1979
#cIEEE Transactions on Software Engineering
#index340070
#!This paper contains algorithms for ensuring the consistency of a distributed relational data base subject to multiple, concurrent updates. Also included are mechanisms to correctly update multiple copies of objects and to continue operation when less than all machines in the network are operational. Together with [4] and [12], this paper constitutes the significant portions of the design for a distributed data base version of INGRES.


#*Some comments on structured Fortran
#@Stuart W. Rowland
#t1976
#cACM SIGPLAN Notices
#index310381


#*Representation and perception: an essay in computational metaphysics.
#@Arthur John Thomas
#t1978
#c
#index186432


#*Considerations for future programming language standards activities
#@John A. N. Lee
#t1977
#cCommunications of the ACM
#index314345
#%318564
#%324621
#%330452
#%335296
#%550776
#%331016
#!This paper reviews the current state of programming language standards activities with respect to the anomalies which exist between the various published and proposed standards for Fortran, Cobol, PL/I, and Basic. Proposals are made for the inclusion of formalisms within future standards and the extension of the standards to include additional items such as error conditions and documentation.


#*An Analysis of Swapping Policies in Virtual Storage Systems
#@We-Min Chow
#t1977
#cIEEE Transactions on Software Engineering
#index348892
#!An important resource allocation mechanism in virtual storage operating systems is the maintainence of the multiprogramming level in main storage, especially when some form of working-set storage management strategy is employed. Swapping of programs in and out of main memory occurs when sufficient storage becomes available and when total storage demand exceeds capacity. In this paper, we propose a class of swapping algorithms that couples storage management parameters with swapping decisions. An analytic model is developed and numerical results are presented to compare the performance of these algorithms.


#*An efficient algorithm for computing powers of triangular matrices
#@C. P. Huang
#t1978
#cProceedings of the 1978 annual conference - Volume 2
#index553771
#!An efficient algorithm for the computation of powers of a square arbitrary lower triangular matrix is presented. A comparison of the algorithm with the standard matrix multiplication method in terms of maximum number of multiplications is included. A numerical example is used to show some of the computational details.


#*Letters to the editor: The go to statement reconsidered
#@John R. Rice,Edsger W. Dijkstra
#t1968
#cCommunications of the ACM
#index325267


#*A formalization for modelling structures and the generation of efficient implementation structures.
#@Lawrence Arnold Rowe
#t1976
#c
#index186510


#*Resource allocations and other managerial uses of a general simulation model for outpatient clinics
#@Edward F. Stafford, Jr.,F. Paul Wyman
#t1977
#cProceedings of the 9th conference on Winter simulation - Volume 1
#index547997
#!This paper demonstrates certain managerial uses of a general simulation model for multifacility outpatient clinics. A major experiment involving the allocation of scarce funds is described; this experiment involved either adding more staff or converting a clinic to an appointments system. Cost/benefit ratios were determined for each possible decision in the experiment. A variety of other model uses is also presented, and future directions for outpatient clinic modeling research are suggested.


#*Writing an interactive psychiatric information system
#@Dietolf Ramm,Daniel T. Gianturco
#t1972
#cProceedings of the ACM annual conference - Volume 1
#index230597
#!We report on our experiences in the use of C.P.S. PL/1 for writing a medical information system. This system involves the use of I.B.M. 2741 terminals in a clinical psychiatric setting. A collection of programs is described which is used to set goals for patients and which stores this set of goals for subsequent ratings of progress for the patient. A global "T" scorer, similar to the one used by Kiresuk, is employed. The use of linked file organization is discussed as it pertains to the flexibility of the system. Upward and downward compatibility of programs and files is assured by the use of the rules presented. Problems of confidentiality are solved by the use of a scrambler routine using the C.P.S. pseudo-random number generator. Measures to prevent the deterioration of data base integrity due to teleprocessing disconnects and other interruptions are discussed. The use of a message level parameter with all of the programs and other techniques which make the programs easier to use are also presented.


#*Software: program verification in 1980
#@
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index67153


#*Research on Advanced Assembly Automation
#@J. L. Nevins
#t1977
#cComputer
#index343698
#!The advancement and application of any manufacturing technique require two research issues to be resolved. First, the technique must be understood. That is, there must exist mathematical models of the technique's performance which have been experimentally verified. Second, the relation between the technique and other manufacturing processes with which it will work must be understood so that the new technique can be integrated with the rest of the factory. As these steps are accomplished for more processes, integrated factories of a new kind will emerge.


#*Statistical software in APL: Bibliography
#@Richard M. Heiberger
#t1979
#cACM SIGAPL APL Quote Quad
#index545845
#%545120
#%545224
#%545713
#%555082
#%551836
#%546084
#%553884
#%546580
#%547283
#%548893
#%552032
#!High quality, state-of-the-art statistical software is not yet widely available in APL. However, many individuals and groups have developed collections of functions and some have begun the distribution of workspaces. This bibliography lists many of the available publications using APL in statistics including Analysis of Variance, Data Analysis, Probability, Regression, Statistical Analysis, and Time Series Analysis. A panel discussion on statistical software in APL is scheduled for this meeting. The panelists will include some of the authors listed in the bibliography.


#*Wave: interactive color graphics for waveform analysis
#@Fred E. Robbins,William G. Green
#t1975
#cProceedings of the 2nd annual conference on Computer graphics and interactive techniques
#index231979
#!WAVE, an interactive color graphics software system for Waveform Analysis Visualization and Edification, is an evolving software interface between an Anagraph Color Graphics System, a CDC 6400/7600 computer configuration, and User Application programs coded in standard FORTRAN source language.WAVE, when mated with the user application modules provides a complete specialized interactive graphical analysis system. The system features:&bull; Full interaction of user with program operation via keyboard/trackball inputs;&bull; A large repertoire of viewing and display options for interactive selection;&bull; Interactive storage and retrieval of displays and off-line or job-to-job capabilities available through magnetic tape;&bull; A variety of methods for the retrieval of analytical information;&bull; Automatic adjustment of scaling, centering, and other detailed viewing parameters to maximize user convenience;&bull; Application program options displayed in user terminology to minimize learning time;&bull; Modular construction to facilitate addition of new application modules.The WAVE program is readily modified to meet specialized user requirements. Several applications of the WAVE system are currently operational at the Ballistic Missile Defense Advanced Technology Center's (BMDATC) Advanced Research Center (ARC) in Huntsville, Alabama. The WAVE technique has been applied comprehensively to the problem of radar ambiguity analysis and clutter rejection. Other applications of WAVE are currently in progress or have been less comprehensively developed.


#*Assisting network users with a network access machine
#@Robert P. Blanc
#t1974
#cProceedings of the 1974 annual conference - Volume 1
#index554926
#%544530
#!Accessing networks of heterogeneous computer systems can often be cumbersome due to differences in command languages and conventions. Approaches toward improving these conditions are identified and a specific solution - a &ldquo;Network Access Machine&rdquo; - is described in detail. The &ldquo;Network Access Machine&rdquo; is a mini- computer-based system that acts as a network access point for a user at his terminal and assists the user through the automatic execution of access procedures. This minicomputer facility allows the user to specify (or to have specified) his own network commands. The minicomputer expands these commands into command sequences executable on a specified network and host connected to that network. Further, system and network responses are analyzed to assure agreement with those anticipated for specific commands. Conditional and parameterized expansions allow the use of the same commands on different host computers and different networks.


#*Association of American railroad's network model
#@Wayne K. Minger,John N. Cetinich
#t1969
#cProceedings of the third conference on Applications of simulation
#index554540
#!Major U.S. railroads are investing over $200,000 to develop a model capable of simulating a railroad network. The model will be capable of determining the effect of major changes in facilities, train schedules and priorities, classification strategies, levels and mix of traffic. The model is in SIMSCRIPT for three different computers with primary emphasis on flexibility, efficiency, and user convenience.


#*Sixth Texas Conference on Computing Systems
#@
#t1977
#cComputer
#index341846


#*The Assignment Statement in Hardware Description Languages
#@H. F. Jordan
#t1977
#cComputer
#index338999
#!The basic character of a programming language or a hardware design language is determined by the data types on which it operates and how changes in their values are made. Few of the papers on specific hardware design languages have included a discussion of this basic part, of the languages' semantics. Often a heuristic discussion based on examples is taken as the most rapid way of conveying the flavor of a new language. Since the range of language applications is often limited by the available data types and the transformations which may be applied to them, a careful analysis of this area of language structure is essential. It is not the intent of this paper to define another hardware description language. Instead, we want to propose a basic set of data types and assignment statements which should be available in any general-purpose hardware description language.


#*A methodology for LISP program construction from examples
#@Phillip D. Summers
#t1976
#cProceedings of the 3rd ACM SIGACT-SIGPLAN symposium on Principles on programming languages
#index548771
#%199774
#!This paper reports on a system, THESYS, that synthesizes LISP recursive programs from examples of what they do. There has been recent interest in this form of program specification[1,4,8]. The theory of such inductive systems has been investigated by Blum and Blum[2], Kugel[5] and Summers[10]. In this paper we describe the practical results of an investigation into the problem of program synthesis from examples. The methodology to be presented is based on a firm theoretical foundation which may provide a basis for generalizing the results to other kinds of program synthesis systems. The various theoretical models for computation and data that comprise the theory are not described in detail in this paper but may be found in [10]. As part of the methodology we describe two processes used in constructing LISP recursive programs from examples. The first is a method for discovering and encoding the relationships or differences between pairs of examples used to specify a program. Unlike systems that synthesize programs from a single example[8], we feel that it is crucial to the process of program synthesis to discover these implicit relationships rather than inferring them from a single example. The multiple example approach permits the construction of a greater variety of programs than does the single example approach. If the algorithm for difference discovery is successful, the relationship between examples is encoded as a kind of recurrence relation. Derivation of such relations effectively determines the program to be constructed as one may prove equivalence between certain recurrence relations and various program schemata.


#*A comment
#@Conrad H. Weisert
#t1964
#cCommunications of the ACM
#index314457
#%326195
#%330796


#*Programming performance: Monitoring, maximization, and prediction
#@Rudolph E. Hirsch
#t1972
#cProceedings of the tenth annual SIGCPR conference
#index550697
#!Non-technical management persists in its 1950's attitude toward data processing. The unfamiliar is often held in awe, and management frequently considers all of its programmers to be highly gifted and thus not manageable by conventional management tools. This attitude is flattering to us but not justified. There are indeed many highly gifted programmers (and for that matter highly gifted engineers, accountants, etc.), but most programmers are people of average ability who turn out average-quality work. Therefore, programmers should be supervised and encouraged as are other kinds of employees. They should be directed to work toward explicit output targets and be evaluated by the results in relation to those targets, i.e., the way in which everyone else is evaluated. The purpose of this paper is to present some methods by which that can be done.


#*On a measure of program structure.
#@Robert Noyes Chanon
#t1974
#c
#index205932


#*Simulation von Turingmaschinen mit logischen Netzen
#@Martin Fürer
#t1976
#cKomplexit&auml;t von Entscheidungsproblemen, Ein Seminar
#index568912


#*Algorithm 182: nonrecursive adaptive integration
#@W. M. McKeeman,Larry Tesler
#t1963
#cCommunications of the ACM
#index335492


#*A model for a multifunctional teaching system
#@K. J. Engvold,J. L. Hughes
#t1967
#cCommunications of the ACM
#index334247


#*Programmable formatting of program text: Experiences drawn from the TAMPR system
#@Kenneth W. Dritz
#t1978
#cProceedings of the SIGNUM Conference on the Programming Environment for Development of Numerical Software
#index554765
#%258364
#!The TAMPR System originated as an approach to the problem of automating the routine modifications of Fortran source programs required to adapt them to a variety of uses or environments [1]**. Overall, the system accomplishes such modifications by applying transformations to Fortran programs at the source level. But the process differs markedly, in detail, from string-based editing or macro expansion. Three steps are involved: (1) A Fortran source program is processed by the TAMPR Recognizer, yielding essentially a parse tree called the abstract form. (2) The Transformation Interpreter applies IGT's (Intragrammatical Transformations) to the abstract form as tree operations [2]. (3) The abstract form is then reconverted to source program form by the Formatter. By ensuring that the transformations are applied only to the correct syntactic entities and only in the intended contexts, the use of the abstract form greatly simplifies establishing the reliability of the overall process.


#*&ldquo;The simple internal procedure as an effective tool in the teaching and practice of structured PL/I&rdquo;
#@David R. Levine
#t1977
#cProceedings of the seventh SIGCSE technical symposium on Computer science education
#index553095
#%552963
#!This paper reports on two successful curricular innovations made in the first-year PL/I programming course at Rutgers. Simple internal procedures are introduced at an early point, and used extensively thereafter; and fairly long, large programming projects are undertaken. The combined effect significantly reinforces the presentation of structured programming methodology, as well as enhancing the general educational effectiveness of the course.


#*Decision rules and measurement selection in pattern recognition theory.
#@Jian Kong Chang
#t1973
#c
#index192123


#*Circular automata
#@Charles Zaiontz
#t1976
#cProceedings of the 14th annual Southeast regional conference
#index619763
#!We define a finite-state machine called a circular automata (CA) which processes information in a queue; we show that any function computed (or any language recognized) by such a machine is computable (recognizable) by a Turing machine and vice versa. Space and time bounds are given for the needed simulations. Furthermore, the class of languages recognized by (non-) deterministic linear bounded automata is equal to the class of languages recognized by (non-) deterministic CA which don't expand the length of the contents of the queue. Whether every language recognized by such a non-expanding CA is recognized by a deterministic one is equivalent to the famous LBA problem.CA can be viewed as generalizations of ordinary finite automata and as a Shepherdson-Sturgis single register machine programming language. An interesting model of a non-expanding CA is that of a finite-state machine which process tapes in the form of a loop. This appears to be a very natural way to process magnetic tape which circles back on itself.


#*Remark on algorithm 323 [G6]
#@Mohit Kumar Roy
#t1973
#cCommunications of the ACM
#index329154
#%317369


#*Workshop Report: The Science of Design
#@M. J. , Jr. Gonzalez
#t1979
#cComputer
#index339782
#!Design can be approached scientifically. However, before a formal science of can be developed, several principles must be established, including the continuous nature of the design verification process.


#*A minisystem programming language
#@Robert Lechner,William Stallings
#t1973
#cProceedings of the ACM annual conference
#index546880
#%316592
#%327006
#%331066
#!TRAIL is a block-structured language and programming system for the development of programming support systems and translators for problem-oriented languages on minicomputers. The programming system includes an interpreter for an intermediate language (IL) into which various source languages (including TRAIL itself) may be translated. The interpreter size is about 1400 bytes. The choice of an interpreted target language was guided by the objectives of minimum object code size and machine independence of the developed software. Both of these have been achieved, at the expense of a 20:1 slowdown of execution speed relative to directly assembled code. The interpreted object code is at least 50% smaller than assembly code. The source language was designed to match the requirements of language translator software; software design directly models syntax checking, context-free translation, and context-sensitive translation aspects, in ascending order of complexity. Anticipated benefits include greater productivity in design and debug phases, and enhanced communication between programmers via simplified documentation procedures.


#*A computer model of the total emergency health care system
#@J. T. Ryan,C. N. Dillard, Jr.
#t1967
#cProceedings of the 6th annual Southeastern regional meeting of the Association for Computing Machinery and national meeting of Biomedical Computing - Volume 1
#index609214


#*Operating efficiencies and characteristics of the computing machines at aberdeen proving ground
#@Homer W. Spence
#t1952
#cProceedings of the 1952 ACM national meeting (Toronto)
#index548885
#!The Computing Laboratory of the Ballistic Research Laboratories at Aberdeen Proving Ground has greatly expanded its computing facilities during the past year. The ORDVAC now has taken its place with the EDVAC, ENIAC, and the Bell Relay Computers. The ORDVAC is a general purpose machine built by the University of Illinois for the Ballistic Research Laboratories. After reassembling at the Aberdeen Proving Ground during the latter part of February 1952, only five days of testing was required before satisfactory acceptance tests were completed. Since that time the ORDVAC has made a very commendable record. Additions have already been made to this machine in order to reduce the reading and printing time. A tape reader, approximately five times as fast as the original, and a punched card system for reading and printing have been installed


#*Effective planning for and justification of the extension of data processing in hospitals
#@Richard B. Freibrux
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index55106
#!Starting with the basic premise that: There is a significant role for data processing as a viable tool to assist in patient care and administrative management of hospitals, then we can dispense with the assumption that it should no longer be necessary to convince administrators of the need for computerization in hospitals. This premise seems to be substantiated by the significant increase in the application of computer technology over the last several years as documented by a 1972 American Hospital Association Survey that indicated that of 552 hospitals sampled, 81 percent had one or more in-house computers and an additional 5 percent used out-of-house computer services. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A class of unambiguous computer languages
#@John B. Johnston
#t1965
#cCommunications of the ACM
#index326232
#%328020
#%328083


#*Reversible execution as a diagnostic tool
#@Marvin Zelkowitz
#t1971
#c
#index201292


#*Design of an aerospace computer for direct HOL execution
#@William C. Nielsen
#t1973
#cProceedings of a symposium on High-level-language computer architecture
#index310284
#%314049


#*A comparison of simulation event list algorithms
#@Jean G. Vaucher,Pierre Duval
#t1975
#cCommunications of the ACM
#index319101
#%550250
#%323455
#%547769
#!Four algorithms are considered which can be used to schedule events in a general purpose discrete simulation system. Two of the algorithms are new, one is based on an end-order tree structure for event notices, and another uses an indexed linear list. The algorithms are tested with a set of typical stochastic scheduling distributions especially chosen to show the advantages and limitations of the algorithms. The end-order tree algorithm is shown to be an advantageous, immediate replacement for the algorithm in use with current simulation languages. The most promising algorithm uses the indexed list concept. It will require an adaptive routine before it can be employed in general purpose simulators, but its performance is such that further study would be fruitful.


#*Microcode implemented General Modular Redundancy
#@F. P. Mathur,P. T. de Sousa
#t1974
#cConference record of the 7th annual workshop on Microprogramming
#index546239
#!First the concepts of protective redundancy are described in the unified framework called General Modular Redundancy (GMR). GMR is a unified framework which synthesizes all the major redundancy techniques known. An alternative to an exclusively hardware implementation is by means of an extension to the Wensleyian Software Implemented Fault-Tolerance (SIFT) approach. A more attractive alternative, an implementation in microcode, is proposed and described here.


#*Small computers (Panel Discussion): The information gap
#@
#t1979
#cProceedings of the 1979 annual conference
#index548046
#!The numbers and uses of small computer systems have grown so rapidly over the past decade that we, in the industry, are faced with a serious lack of information about them and now they can or should be used. They are cropping up in different places among business and industry, where computers were never anticipated. Long time, &ldquo;veteran&rdquo; segments of industry are using them in ways they never dreamed would be possible. Many laymen heretofore completely unacquainted with the computing process, are now using it in their day-to-day work. Many experienced computer specialists are now using machines in rather &ldquo;unorthodox&rdquo; ways. The results are a good deal of confusion, and a serious void of information about computers and their usability, or lack thereof. This condition is enhanced by the rate at which the industry is growing and the low cost for which systems are selling. Hardware is inexpensive and readily produced. Documentation, on the other hand, is very expensive and time-consuming. The manual that is well-done is almost a sure sign that the product it describes has either become out dated, or was purchased at an exhorbitant price. The purpose of this panel will be to identify some key aspects of this information gap and, hopefully, to suggest some potential solutions, or trends toward solution, of this problem.


#*Algorithm 383: permutations of a set with repetitions [G6]
#@Phillip J. Chase
#t1970
#cCommunications of the ACM
#index321973
#%314633
#%318538
#%334171
#%327054


#*Decompilation of object programs
#@Clifford Roy Hollander
#t1973
#c
#index195502


#*Measurement and analysis for computer performance evaluation.
#@Clifford Allison Rose, Jr.
#t1975
#c
#index194915


#*Generalized procedure calling and content-directed invocation
#@Randall Davis
#t1977
#cProceedings of the 1977 symposium on Artificial intelligence and programming languages
#index547764
#%545628
#%548982
#!We suggest that the concept of a strategy can profitably be viewed as knowledge about how to select from among a set of plausibly useful knowledge sources, and explore the framework for knowledge organization which this implies. We describe meta rules, a means of encoding strategies that has been implemented in a program called TEIRESIAS, and explore their utility and contribution to problem solving performance. Meta rules are also considered in the broader context of a tool for programming. We show that they can be considered a medium for expressing the criteria for retrieval of knowledge sources in a program, and hence can be used to define control regimes. The utility of this as a programming mechanism is considered. Finally, we describe the technique of content-directed invocation used by meta rules, and consider its use as a way of implementing strategies. It is also considered in historical perspective as a knowledge source invocation technique, and its advantage over some existing mechanisms like goal-directed invocation is considered. This work was supported in part by the Bureau of Health Sciences Research and Evaluation of HEW under Grant HS-01544 and by the Advanced Research Projects Agency under ARPA Order 2494. It was carried out on the SUMEX Computer System, supported by the NIH under Grant RR-00785. The views expressed are solely those of the author.


#*RTL - The firmware Design Automation system
#@Robert L. Hasterlik
#t1974
#cProceedings of the 11th Design Automation Workshop
#index553415
#%550351
#!The development of firmware controlled devices poses several new requirements on Design Automation. Because firmware is central to system design and reflects heavily on system speed and cost, the basic assembly parameters change after during the early design phases. It is necessary to have an automation system which is able to react to design changes without reprogramming of system components. Thus the standard approach of simulating firmware with a special purpose language and a special purpose assembler or assembler/simulator is no longer practical. This paper discusses a general solution to the several requirements of firmware design.


#*The logical approach to programming
#@N. N. Nepeivoda
#t1979
#cProceedings on Algorithms in Modern Mathematics and Computer Science
#index263289


#*An analysis of mini-computer configurations to fulfill hospital information system requirements
#@Robert D. Drummond
#t1979
#cProceedings of the 17th annual Southeast regional conference
#index613984


#*Algorithm 106: Complex number to a real power
#@Margaret L. Johnson,Ward Sangren
#t1962
#cCommunications of the ACM
#index327423


#*On step control criteria
#@J. C. Butcher
#t1973
#cACM SIGNUM Newsletter
#index105230
#!Programs for the numerical solution of ordinary differential equations generally use one of two alternative criteria for step size control, these are, the error per step criterion and the error per unit step criterion. The purpose of this note is to present a trivial example which illustrates an argument favouring the error per unit step criterion.


#*Models for assignment of 911 emergency telephone operators
#@Peter Kolesar,Albert Pedrinan,Peter Stein
#t1976
#cProceedings of the 76 Bicentennial conference on Winter simulation
#index554132
#!We discuss the design and implementation of a SIMSCRIPT simulation of the 911 emergency telephone system in New York City. The simulation was created to aid the New York City Police Department in scheduling operators and controlling the flow of calls through the system so that delays could be kept to tolerable levels while the system was run economically. A second goal was to use the simulation to validate an approximate analytic queueing model of the complex system. The queueing model based on the M/M/C queue can be used to provide quick responce to management questions.


#*n-dimensional codes for detecting and correcting multiple errors0
#@Morris Rubinoff
#t1961
#cCommunications of the ACM
#index315677
#!The paper introduces a new family of codes for detecting and correcting multiple errors in a binary-coded message. The message itself is arranged (conceptually) into a multidimensional rectangular array. The processes of encoding and error detection are based upon parity evaluations along prescribed dimensions of the array. Effectiveness of the codes is increased by introducing a &ldquo;system check bit&rdquo;, which is essentially a parity check on the other parity bits. Only three-dimensional codes are discussed in this paper, with parity evaluations along the horizontal, the vertical, and one main diagonal. However, the family of codes is not restricted to three dimensions, as evidenced by the discussion by Minnick and Ashenhurst on a similar multidimensional single-bit selection plan used for another purpose [6]. A four-dimensional code, correcting three and detecting four errors, has been developed; the extension to higher-dimensional codes with greater correction power is straightforward.


#*Remark on algorithm 235 [G6]: random permutation
#@M. C. Pike
#t1965
#cCommunications of the ACM
#index329741


#*The D-Calculus: A System to Describe the Semantics of Programs Involving Complex Data Types (Summary)
#@Peter Raulefs
#t1974
#cGI - 4. Jahrestagung
#index276527


#*Engineering Data Management System (EDMS) for computer aided design of digital computers
#@Masakazu Soga,Chiyozi Tanaka,Kinya Tabuchi,Katsuhiko Seo,Michiko Kunioka,Hiroo Tsuji
#t1974
#cProceedings of the 11th Design Automation Workshop
#index549744
#!The current technology lets a DA system handle the data on various design levels such that pure logical, logical and physical and pure physical information are mixedly used on a PCB design. The design process has not been uniformly carried out, such that the simulation of digital system, the routing and a PCB and a unit design has been carried out at the same time, and made the operation and the management be more difficult and complicated. Therefore, only extention of traditional DA systems tends to be difficult to cope with these situations. We have studied these problems and developed Engineering Data Management System - EDMS - so as to be open-ended general purpose DA system which can meet with the future innovation of the technology.


#*Official Notices: Leaders for 1963 SJCC picked
#@
#t1962
#cCommunications of the ACM
#index315225


#*Monte carlo simulation of nonlinear radiation induced plasmas
#@Benjamin Shaw-Hu Wang
#t1972
#c
#index189153


#*Auswertungsnetze als Hilfsmittel zur Modellbildung: Probleme und deren L&ouml;sungen
#@L. Stewen
#t1975
#cGI - 5. Jahrestagung
#index261876


#*The visualization of computer simulation
#@Antonio E. Gibson
#t1974
#cACM SIGSIM Simulation Digest
#index577536
#!The giant red helicopter sits in the center of a stark, surreal runway. Its rotors turn, slowly at first, then whirl into a flashing arc as the helicopter lifts off to sweep out over the ocean and hover over a ship's deck. The helicopter picks up a cargo container, turns toward the audience and fades as the short film clip ends. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Locating traveler support facilities along the interstate system--a simulation using general systems theory.
#@James Charles Heckman
#t1973
#c
#index199861


#*Deformations of branched coverings of complex manifolds
#@John Joseph Wavrik
#t1966
#c
#index197321


#*Certification of algorithm 153: GOMORY
#@B. Lefkowitz
#t1963
#cCommunications of the ACM
#index331665


#*A computer adaptation of lattice theory.
#@Patricia Mary Moore
#t1975
#c
#index196861


#*Automatic Steno translation
#@Raoul N. Smith
#t1973
#cProceedings of the ACM annual conference
#index553792
#%318506
#!The first preliminary computer translation of machine produced stenographic notes was described in Salton 1959. Since then other approaches have been suggested but none seem to have succeeded. In the meantime the need for a solution becomes more and more pressing. The impetus for a solution is coming from two user areas&mdash;court reporting and speech recognition. The purpose of this paper is to describe the problems and solutions to the problems of automatic Steno-English translation.


#*Documentation: a growing need ... a new tool
#@Marcia A. Metcalfe
#t1979
#cACM SIGSIM Simulation Digest
#index576995
#%458820
#%546410
#%547890
#%622903
#!The Software Design and Documentation Language (SDDL) has proven to be an effective, automated documentation tool. This paper presents the purpose, timing, and components of documentation. SDDL is introduced and related to the different timing scenarios; its capability to provide reasonable documentation is discussed and demonstrated by the use of several examples.


#*Information access at the data file level: documentation prerequisites on the file-level data base inquiry process
#@Per Nielsen
#t1974
#cACM SIGSOC Bulletin
#index577330
#!In the mid-sixties, political and social science was theory-rich and data-poor. [1] In the decade following this statement, the ever-increasing holdings of machine-readable datasets in a growing chain of data repositories throughout the world have made the social science community much more wealthy. But, the vast scientific potential buried in data repositories is being transformed only at a slow pace. In the mid-seventies, quantitative data generated by empirical political and social science research are still heavily underexploited.


#*Some New Error Bounds and Approximations for Pattern Recognition
#@J. T. Chu
#t1974
#cIEEE Transactions on Computers
#index350872
#!For the average error probability Pe associated with the Bayes recognition procedures for two possible patterns, using no context, new upper and lower bounds and approximations are obtained. Results are given in terms of simple functions of feature "reliability" and a priori probabilities of the patterns. Two kinds of feature "reliability" are considered, i.e., distance between probability distrib


#*Letters to the editor
#@Francis V. Wagner Paolo Ercoli,Roland Silver
#t1960
#cCommunications of the ACM
#index317065


#*Stochastic modeling as a means of automatic speech recognition.
#@James K. Baker
#t1975
#c
#index193246


#*A communication structure to implement a multi-microprocessor computer architecture
#@George N. Arnovick,Robert L. Britton
#t1975
#cProceedings of the 1975 annual conference
#index545953
#!From the results of research dealing with the overall system architecture of a nodal processor system, a major problem was the way in which nodes (individual) processors can effectively communicate with each other. This paper presents a proposed communications method for a set of interconnected micro-processors. The proposed communication system provides for a multitude of communication buses and the ability for simultaneous direct communication between all microcomputers connected to the same communication bus, which would be a single wire. Also any microcomputer within this structure can select to communicate over three different orthogonally arranged buses. To make this possible a special transmitter receiver circuit must be associated with each microcomputer. Although only one physical wire makes up an individual communication path, simultaneous direct communication is possible among any combination of microcomputers connected to a bus by phase modulation of individually selected binary orthogonal waveforms (Walsh Functions) generated by the special communications circuit. The information is separated in sequency [@@@@] instead of in space. Each microcomputer must be programmed with the information as to what sequencys of Walsh Functions are to be used to transmit or receive information at specific times. The general geometric arrangement for this communication structure would be somewhat similar to that of a three-wire three-dimensional core memory, where in this case microcomputers and their associated memorys would be located geometrically analogous to where the cores are located in a core memory. Such a computer structure is completely homogenous thus offering high reliability and also provides the capability for a high degree of parallelism when computing.


#*Riemannian Integral of Set-Valued Function
#@E. S. Polovinkin
#t1974
#cProceedings of the IFIP Technical Conference
#index571162


#*SLIP
#@L. D. Yarbrough,J. Weizenbaum
#t1964
#cCommunications of the ACM
#index318362


#*Character string manipulation in APL
#@Charles R. Moore
#t1974
#cProceedings of the sixth international conference on APL
#index545754
#!Use of the NMSU EXECUTE enhancement at PCS (since September 1973) has opened the way to many new applications and programming techniques, Most of these applications have been in the area of packages where the user communicates indirectly with APL through a higher-level 'language' tailored to a specific task. One such program is the PCS APL/RJE system. In the RJE system the user is under firm program control with all his inputs in the character input mode. These inputs are scanned with the APL character handling primitives and program control paths are altered to satisfy the request. As the interface languages become more sophisticated, it often becomes useful to create or modify APL programs under program control and cause them to be executed. The enhancement of APL character string manipulation and some programming application areas are the subject of this paper.


#*Computer-Aided Synthesis or Multiple-Output Multilevel NAND Networks witk Fan-in and Fan-out Constraints
#@S. Y. H. Su,Chong-Woo Nam
#t1971
#cIEEE Transactions on Computers
#index337233
#!A straightforward efficient computer algorithm for synthesizing multiple-output NAND (NOR) switching networks is presented which takes practical fan-in and fan-out limitations of logic gates into account. The algorithm is highly iterative and hence is very suitable for realizing large-size switching functions by a digital computer. The algorithm has been programmed in Fortran and a great deal of statistical data has been obtained to demonstrate its efficiency in terms of gate count as well as computing time. It is also efficient for hand execution


#*Polynomial Separation of Ternary Functions
#@Claudio Moraga
#t1975
#cGI - 5. Jahrestagung
#index260376


#*Backtracking in a Generalized Control Setting
#@Gary Lindstrom
#t1979
#cACM Transactions on Programming Languages and Systems (TOPLAS)
#index332917
#%318638
#%325466
#%330438
#%551259
#%547001
#%549488
#%546372
#!Backtracking is a powerful conceptual and practical programming language control structure. However, its application in general has been limited to global control over recursive programs. In this paper we explore the coherence and utility of applying backtracking in a more general control setting, namely, block-structured coroutines. The following criteria are proposed for such a control combination to be judged successful: (i) retention of each control form's individual semantics; (ii) coherent semantics for each legal application of the combination; (iii) nonpreeminence of either control form, and (iv) facilitation of genuinely novel programming effects. The attainability of these criteria is assessed, with the aid of an informal language design and three illustrative applications: (i) a dual tree walk program using coroutine-managed backtracking subsystems; (ii) a context-free language intersection tester using bilevel hierarchical backtracking, and (iii) an optimizing computer job scheduler using backtracking in a simulation language context. Full programs are given for each example, phrased in a Pascal extension offering both coroutines and backtracking (expressed through nondeterministic control).


#*The Cheap Video Cookbook
#@Donald Lancaster
#t1978
#c
#index613792


#*A Universal Cellular Array
#@Jung-Chang Huang
#t1971
#cIEEE Transactions on Computers
#index341681
#!A new type of fixed-cell fixed-interconnection homogeneous cellular array that is capable of realizing any switching network is developed. The array is composed of identical combinational logic cells with three inputs and three outputs. The logic cells are arranged in a rectangular array with uniform interconnection structure. The signal flow is unilateral in the vertical direction and bilateral in the horizontal direction. Each n-column array is capable of realizing any set of n functions of n variables. The functional capabilities of the array can be changed by appropriately setting the parameters on the edges of the array. Algorithms for the realization of a set of n functions of n variables by using this type of array are presented.


#*Compcon79 Spring Wrap-up
#@W. Myers
#t1979
#cComputer
#index343050
#!A record 930 attendees met February 27-March 1 in San Francisco, where they explored the conference theme of "Exploding Technology, Responsible Growth." The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*An analysis of consumer usage of computer consoles for credit cards, an empirical exploration of retail customer behavior.
#@Steven White Straw
#t1976
#c
#index200880


#*Interactive graphics and the computer-aided design of digital systems
#@Harry Meyer Taxin
#t1970
#c
#index195141


#*NCC '79
#@
#t1979
#cComputer
#index348937


#*A Comparison of Term Value Measurements for Automatic Indexing
#@Gerard Salton
#t1975
#c
#index117864
#!A number of automatic theories have been proposed over the last few years leading to the assignment of significance values to linguistic entities in accordance with their importance for purposes of content representation. Among these are methodologies based on decision theory, information theory, communication theory, vector space transformation and others. An attempt is made to compare these theories by exhibiting the formal frequency characteristics which underlie them. The effectiveness of the various approaches is also evaluated in experimental situations by using collections of documents in the areas of aerodynamics, medicine and world affairs.


#*SIGDA 1 - Generation of automatic logic test data
#@
#t1972
#cProceedings of the ACM annual conference - Volume 1
#index232965


#*A steady&mdash;state enzyme kinetics modeling system
#@Nancy Schatz,Chan F. Lam
#t1974
#cProceedings of the 7th conference on Winter simulation - Volume 2
#index547748
#!A technique is presented to generate rate equations for random enzymatic mechanisms in a systematic manner. The generation of constraint equations arrived from the principle of detailed balance is also discussed. The rate constants of the reaction mechanisms are then estimated by a stepwise least squares algorithm.


#*Simulation in surgery, anesthesia and medical interviewing
#@Augustine O. Esogbue
#t1979
#cACM SIGSIM Simulation Digest
#index575855
#!In this paper, we present a bird's-eye view of our work in health systems involving the applications of simulation to the surgical department, anesthesia, and medical diagnosis. Through all these models, an attempt is made to provide the reader with appropriate insights into the process of problem selection, language choice, analysis, interpretation and implementation of results, as well as the limitations of simulation in health systems.


#*Proceedings of the seventh SIGCSE technical symposium on Computer science education
#@
#t1977
#cTechnical Symposium on Computer Science Education
#index555312


#*Some observations on modular design technology and the use of microprogramming
#@D. P. Siewiorek
#t1974
#cConference record of the 7th annual workshop on Microprogramming
#index545392
#!As modules become more complex the advantages and disadvantages of modularity have become more pronounced. The cost of modularity is measured not only in added hardware but also in a loss of flexibility. Functions that are easy to implement at a submodule level may be very difficult, or even impossible, to duplicate at the modular level. We term this a loss of transparency. PMS (Processor-Memory-Switch) level modules could be available in the next four-six years. Their existence will open many significiant areas of research. It appears that the overhead for PMS modular systems will be on the order of 30%-50% but with decreasing hardware costs this will be tolerable. The expendable components will be processors and there will be no effort to obtain a high utilization factor for the individual processors in a system. An 80%-90% idle time may be acceptable. The high sales volume required by the semiconductor industry suggests that, in the foreseeable future, PMS level components will be oriented towards mass market applications like personal calculators and intelligent terminals. It is interesting to note that as the cost per digital function has decreased the design time and cost per system has remained relatively constant. So instead of obtaining a cheaper system with the same functions a user gets a more complex system at the same cost. This is best exemplified by observing the evolution of minicomputers and noting that the cost per system of a 1965 vintage minicomputer (e.g., PDP-8) is about as costly as a ]974 minicomputer (e.g., the PDP-]I)*. Finally, microprogrammed modules are an attractive control element for PMS level modules from both an economic and a transparency point of view.


#*Recognizable sets of trees with multiplicity.
#@Ch'Eng San Wu
#t1974
#c
#index189589


#*Simple Programs and Their Decision Problems
#@Amir Pnueli,Giora Slutzki
#t1977
#cProceedings of the Fourth Colloquium on Automata, Languages and Programming
#index376581


#*A queueing-theoretic analysis of third-generation computer systems
#@Thomas Walford Johnson
#t1974
#c
#index188994


#*A Medical Information System and Data Language for Ambulatory Practices
#@P. D. Beaman
#t1979
#cComputer
#index347026
#!The COSTAR system keeps medical records and does accounting and administrative tasks for group practices. It also offers clinical researchers a useful query language for manipulating medical data.


#*Executive Support For Urban Technology: The case of computing
#@William H. Dutton,Kenneth L. Kraemer
#t1978
#cProceedings of the 1978 annual conference
#index550289
#!This paper describes the high level of support for computer technology among local government chief executives and suggests that this support is explained, in large part, by a generalized &ldquo;faith in technology.&rdquo;


#*Interarrival statistics for time sharing systems
#@E. G. Coffman, Jr.,R. C. Wood
#t1966
#cCommunications of the ACM
#index326348


#*On reducing the profile of sparse symmetric matrices.
#@Joseph Wai-Hung Liu
#t1976
#c
#index191272


#*Performance monitoring for multiprocessor networks
#@Rebecca E. Adams
#t1979
#cProceedings of the 17th annual Southeast regional conference
#index620617


#*Another approach to service courses
#@William Mitchell
#t1979
#cProceedings of the tenth SIGCSE technical symposium on Computer science education
#index552283
#%546581
#%546908
#%546993
#%547109
#%547388
#%548218
#%549011
#%549756
#%550363
#%550750
#%551672
#%551982
#%553071
#!This paper discusses the issues surrounding service offerings by Computer Science departments and focuses specifically on the first programming course. The approach described by the author has been developed to serve business students who seek an introduction to programming, but it applies also to most non-majors. The popularity of computer applications in the various disciplines as well as the widely publicized vocational opportunities in data processing induce ever more students to try their hand at programming. The embarrassment of riches in enrollment, however, brings with it multiple problems of staffing, machine resources, and curricular balance. Less obviously it also brings the pressure for instant success in serving this new population and thereby avoiding the splintering of programming education among interested disciplines, as happened with statistics instruction. Various viewpoints on solutions to these problems have been published, but little understanding of the nature and goals of the students involved has been evidenced. What follows is an explanation of a student-oriented approach to service course instruction which has been instituted at the University of Evansville(Mitchell 78).


#*Virtual memory systems for closed applicative language interpreters
#@Geoffrey Alson Frank
#t1979
#c
#index202594


#*Decisions for "type" in APL
#@W. E. Gull,M. A. Jenkins
#t1979
#cProceedings of the 6th ACM SIGACT-SIGPLAN symposium on Principles of programming languages
#index252748
#%241681
#%315351
#!The meaning of "type" in an APL extended to contain nested arrays is discussed. It is shown that "type" is closely related to the variety of empty arrays of the same shape and to the possible fill values needed in the "expand" and "take" functions. Choices for fill functions are systematically presented. They are classified according to the possibility of maintaining important identities involving level-manipulating functions in the case of empty arguments, to their effect on other design choices still to be made (the restriction to homogeneous arrays and the definition of the nature of basic data), and to their ability to express "type" in a natural way.


#*LISP books
#@
#t1978
#cIssue 2 (July 1978)
#index386551
#%157764
#%534189


#*Designing simulation experiments to completely rank alternatives
#@Thomas A. Bishop
#t1978
#cProceedings of the 10th conference on Winter simulation - Volume 1
#index547403
#%287232
#%550785
#!Many of the problems of selecting the t-best of k populations with respect to a given parameter have been successfully solved for some time. Important applications, including applications to the design and analysis of simulation experiments, have been demonstrated and the tables required for implementation of solutions are easily available (e.g. in Gibbons, Olkin and Sobel (5)). Solutions to the companion problem of completely ranking k populations have been scarce due to their mathematical complexity. This paper discusses examples of complete ranking problems, some recent advances made towards their solution, and cites sources of tables needed for their implementation.


#*Some Parametric Techniques in the Analog Solution of Ordinary Differential Equations
#@T. A. Newton
#t1975
#cIEEE Transactions on Computers
#index349314
#!The direct analog simulation of an ordinary differential equation over an interval for the independent variable is not possible whenever on that interval there is division by a variable which tends to zero, or there is a dependent variable such as a derivative which is represented by an integrator output and which becomes large without bound. Also, the raising of time dependent variables to fractional powers can require considerable analog equipment and introduce further error into a simulation.


#*Specifications in a Data Independent Accessing Model
#@E. B. Altman,M. M. Astrahan,P. L. Fehder,M. E. Senko
#t1972
#cProceedings of 1972 ACM-SIGFIDET workshop on Data description, access and control
#index549824
#%553631
#!The Data Independent Accessing Model (DIAM) Project of the Information Sciences Department of IBM Research is directed towards developing an architectural basis for an advanced data base system - a data base system which, in addition to providing advanced functional capabilities and a new level of data independence, is not limited either in the access paths which can be declared (in order to support the user-specified information collections) or in the encodings which are possible for those access paths. We have already been presented with a general overview of the basic system (1). In that overview, DIAM was seen to be composed of 4 basic levels of description: the Entity Set Model the String Structure Model the Encoding Model the Physical Device Model. In this paper we shall concentrate on the middle two of these levels - the String Structure and the Encoding Models.


#*Stylitism, Synergism, And Syncretism: The interface of computer science and operations research
#@Richard E. Nance
#t1978
#cProceedings of the 1978 annual conference
#index552990
#%314695
#%328860
#%554469
#!In 1970 I authored a paper dealing with the interface of Operations Research and Computer Science, which was presented at the 37th Meeting of ORSA on April 20-22, 1970. [NANCR70]. That paper, which included the thoughts and opinions of several eminent computer scientists, has proved to be interesting reading some eight years later. My view of the interface between the two disciplines has changed but slightly in that time; nevertheless, certain intersections of the two disciplines are now more clearly defined. Nevertheless, the belief that I have a better picture of the computer science and operations research interface is probably as illusory now as it was in 1970.


#*Evaluation of Policy Simulation Models: A Conceptual Approach and Case Study
#@Robert E. Pugh
#t1977
#c
#index618388


#*Record Handling
#@C. A. R. Hoare
#t1965
#cIssue 21 (November 1965)
#index98300


#*Trends in Computer Science Education
#@Peter Naur
#t1974
#cGI - 4. Jahrestagung
#index276145


#*Computer Magazine Annual Index Volume 10, 1977
#@
#t1978
#cComputer
#index352808


#*Suggestions on ALGOL 60 (ROME) issues
#@R. E. Utman
#t1963
#cCommunications of the ACM
#index326359


#*On the size of programs in subrecursive formalisms
#@Robert L. Constable
#t1970
#cProceedings of the second annual ACM symposium on Theory of computing
#index550535
#%183108
#%550323
#%554609
#!This paper gives an overview of subrecursive hierarchy theory as it relates to computational complexity and applies some of the concepts to questions about the size of programs in subrecursive programming languages. The purpose is three-fold, to reveal in simple terms the workings of subrecursive hierarchies, to indicate new results in the area, and to point out ways that the fundamental ideas in hierarchy theory can lead to interesting questions about programming languages. A specific application yields new information about Blum's results on the size of programs and about the relationship between size and efficiency.


#*A Direct Numerical Method for Queueing Networks
#@William J. Stewart
#t1979
#cProceedings of the Third International Symposium on Modelling and Performance Evaluation of Computer Systems: Performance of Computer Systems
#index276515


#*A microprogrammed minicomputer for the efficient execution of high-level language programs.
#@Bradford Warren Wade
#t1975
#c
#index199408


#*Formalization and automatic derivation of code generators.
#@Roderic Geoffrey Galton Cattell
#t1978
#c
#index203250


#*The current state of research in job shop scheduling
#@Carter L. Franklin, II
#t1969
#cProceedings of the third conference on Applications of simulation
#index553614
#%554363
#!The state of the art of job shop research is investigated via the development of a framework within which problems and results may be described. The bulk of the paper is devoted to the development of the framework and the research which arises from it. Few explicit references are made to the large body of published research on the problem.


#*A System For Office Automation Research
#@Howard Lee Morgan
#t1978
#cProceedings of the 1978 annual conference
#index548832
#!The Wharton Office Automation System, developed by Professor David Ness, along with the author and several other collegues in the Department, originated from a lack of support services in the traditionally support poor academic environement. The managers in the department (all of the faculty, as well as some administrators), were having difficult time getting papers out on time, preparing budgets and grant proposals, and handling correspondence. About this same time, the school received a new DECSystem 1&Oslash; computer. Dave Ness set about implementing a text editing facility suitable for faculty writing research papers. This included bibliography handling, cross indexing, footnoting, and automatic reference numbering features, as well as the traditional formatting software already provided by DEC. At the same time, several research projects which the author was managing were attempting to develop sophisticated software for man/machine communication, and for dealing with very large databases. The management to this project, involving about 15 people, was becoming a complex task. In particular, the communications among team members was difficult to arrange, resulting in too many meetings.


#*A lesson in recursion and structured programming
#@Moshe Augenstein,Aaron Tenenbaum
#t1976
#cProceedings of the ACM SIGCSE-SIGCUE technical symposium on Computer science and education
#index548037
#!Students in middle level courses in data structures and programming languages often do not have a full appreciation of recursion. The study of the simulation of recursion can be an excellent tool in improving this situation. It is shown how to construct a nonrecursive routine to solve a problem whose solution is naturally recursive. This nonrecursive routine is then used as a foundation from which one can construct a simpler and better structured program than the original version. The advantages of this activity are also discussed.


#*Computer-aided analysis and design of information systems
#@J. F. Nunamaker, Jr.,Benn R. Konsynski, Jr.,Thomas Ho,Carl Allen Singer
#t1976
#cCommunications of the ACM
#index334723
#%332554
#!This paper describes the use of computer-aided analysis for the design and development of an integrated financial management system by the Navy Material Command Support Activity (NMCSA). Computer-aided analysis consists of a set of procedures and computer programs specifically designed to aid in the process of applications software design, computer selection and performance evaluation. There are four major components: Problem Statement Language, Problem Statement Analyzer, Generator of Alternative Designs, and Performance Evaluator. The statement of requirements was written in ADS (Accurately Defined Systems) and analyzed by a Problem Statement Analyzer for ADS. The ADS problem definition was supplemented with additional information in order to create a complete problem definition. The analyzed problem statement was translated to the form necessary for use by the SODA (Systems Optimization and Design Algorithm) program for the generation of alternative specifications of program modules and logical database structures.


#*Design of an Adaptive, Parallel Finite-Element System
#@Pamela Zave,Werner C. Rheinboldt
#t1979
#cACM Transactions on Mathematical Software (TOMS)
#index324549


#*An experimental program in computer usage for secondary students
#@Joan Platt,Jeanne Curran
#t1976
#cProceedings of the ACM SIGCSE-SIGCUE technical symposium on Computer science and education
#index546942
#!This paper presents an experimental program designed to introduce high school students to the use and interpretation of computer data. The program has evolved from a model research center in the Department of Sociology at California State College, Dominguez Hills. The Center is operated and administered by undergraduates and graduates as a part of their curricular experience in research methods.


#*Nonparametric selection procedures applied to state traffic fatality rates
#@Gary C. McDonald
#t1978
#cACM SIGSIM Simulation Digest
#index577217
#!This article reviews the practical aspects of several nonparametric subset selection rules useful in block design problems, and discusses advantages and disadvantages of these methods. The populations are assumed stochastically ordered by the parameter of interest. Rules based on ranked observations are given for selecting a subset of populations which contains, with a specified confidence level, the population characterized by the smallest (or largest) parameter value. These procedures are applied to state traffic fatality rates recorded yearly (1960-76). New England states and Middle Atlantic states comprise most of the subset asserted, with a 90% confidence level, to contain the state with the smallest fatality rate; whereas, Southern states, Southwestern states and Rocky Mountain states generally comprise the subset for the state with the largest fatality rate. Note that while this example is not based on simulation data, such data would be analyzed in exactly the same fashion.


#*Advanced LILAC - an Automated Layout Generation system for MOS/LSIs
#@Tokinori Kozawa,Hiroshi Horino,Tadakatu Ishiga,Junya Sakemi,Shoji Sato
#t1974
#cProceedings of the 11th Design Automation Workshop
#index553224
#%548360
#%551977
#%552115
#%554897
#!This paper describes the layout model and algorithm applied to an advanced LILAC system which is capable of automatically designing MOS/LSI chip layouts containing PLAs. The system, which is a fully automated design system, inputs logic description and outputs layout drawing.


#*Experience with a microprogrammed Interlisp system
#@L. Peter Deutsch
#t1978
#cProceedings of the 11th annual workshop on Microprogramming
#index546043
#%316203
#%332054
#%334666
#!This paper presents the design of an Interlisp system running on a microprogrammed minicomputer. We discuss the constraints imposed by compatibility requirements and by the hardware, the important design decisions, and the most prominent successes and failures of our design, and offer some suggestions for future designers of small Lisp systems. This extended abstract contains only qualitative results. Supporting measurement data will be presented at MICRO-11.


#*Analog subroutines for the finite-element method.
#@Om Prakash Singla
#t1972
#c
#index202142


#*Versatile mask generation techniques for custom microelectronic devices
#@Robert P. Larsen
#t1978
#cProceedings of the 15th Design Automation Conference
#index550307
#!A paramount attribute for any computer-aided design methodology, involving custom microelectronic devices, is a rapid and cost effective mask generation technique. The microelectronic device can be characterized as a discrete topological schematic which has been geometrically scaled to imply a grid structure. This topological schematic is constructed from a set of symbols which explicitly define the electrical and logical functions of the device while implying the geometrical relationships related to the process technology. Each layout symbol can be mapped into specific geometrical shapes (layer by layer) which can be defined by sizing data and subsequently subjected to appropriate modification, depending on contextual relationships with the adjacent orthogonal and diagonal layout symbols. These symbol-to-geometrical mappings can be easily comprehended by device designers and the requisite algorithms are amenable to computer implementation. These mask generation techniques provide a cost-effective means of generating mask sets for custom microelectronic devices while also providing device design portability and is ideally suited for process experimentation.


#*COBOL batching problems
#@J. W. Mullen
#t1962
#cCommunications of the ACM
#index326113


#*On Scolnik's proposed polynomial-time linear programming algorithm
#@David M. Gay
#t1974
#cIssue 16 (April 1974)
#index7223
#%113986
#!At the Eighth International Symposium on Mathematical Programming (August 1973 at Stanford), Hugo Scolnik suggested a line of reasoning leading to an algorithm which he thought might solve the linear programming problem in polynomial time. The algorithm which Scolnik contemplated would construct an optimal basis one column at a time, in such a way that once a column is selected to be in this basis, it need never be thrown out later; after t basic columns had been selected, the algorithm would first use two rejection criteria (a) and (b) to reduce the number of candidates for the (t+1)st column and would then use a selection criterion (c) to choose one of the remaining candidates.


#*Steps toward an APL compiler
#@Clark Wiedmann
#t1979
#cProceedings of the international conference on APL: part 1
#index554183
#%235464
#%244592
#%248841
#%546156
#%549933
#%550899
#!Compilation of APL programs could yield a dramatic improvement in performance for some kinds of programs, provided that the compiler could simplify the processing to the actual requirements of the particular algorithm. Other optimization approaches have been unable to achieve the performance improvements that seem to be possible. Compilation aided by declarations has been demonstrated, but it is undesirable to require declarations if most of the information they contain can be deduced by inspection of the program. Certain changes and restrictions to the language would make such deduction feasible by simplifying the analysis of control flow and removing apparent interfaces between programs that are not actually used as interfaces. Some of the proposed language changes are regarded as improvements because they facilitate deductions about programs by humans and therefore contribute to program readability and reliability. The other restrictions are inconvenient when debugging a program, but the impact is minimal because compilation of APL would be appropriate mainly for production programs that already have been tested.


#*Differential geometry of complex hypersurfaces
#@Brian Brendan Smyth
#t1966
#c
#index190604


#*Discrimination in the employment of women in the computer industry
#@Richard E. Weber,Bruce Gilchrist
#t1975
#cCommunications of the ACM
#index318471
#!It has been more than ten years since the passage of the Equal Pay Act and Title VII of the 1964 Civil Rights Act, which were intended to end employment and wage discrimination against women. Thus it seems an appropriate time for the computer industry to examine its own employment practices with respect to women.


#*An interactive debugger for software and firmware
#@Morrie Gasser
#t1973
#cConference record of the 6th annual workshop on Microprogramming
#index549474
#!A program for interactively debugging software and firmware on an Intercomputer 1-50 minicomputer is described. Two processors sharing a common memory are used. The debugger is controlled by standard firmware in one processor, and the firmware and software to be debugged run under the other processor. By inserting a small defined routine into the firmware to be debugged, the debugger has control of the other processor, yet is practically invisible to it.


#*Real-time algorithms for string-matching and palindrome recognition
#@Zvi Galil
#t1976
#cProceedings of the eighth annual ACM symposium on Theory of computing
#index554384
#!We give a sufficient condition when an on-line algorithm can be transformed into a real-time algorithm. We use this condition to construct real-time algorithms for string-matching and palindrome recognition problems by random access machines and by Turing machines.


#*Control Data 480 Series Microprogrammable Computer Family
#@R. E. Pollmann
#t1977
#cComputer
#index345066
#!The Control Data 480 series microprogrammable computer family, designed to emulate a wide range of general-purpose computers, consists of a number of standard modules that are pluggable in a variety of configurations for emulating small, medium, or large computer systems. This building block approach permits the configuration of a specific computer system which is microprogrammed to emulate a specific computer architecture. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Range reduction and infeasibility testing using surrogate equalities
#@Ron S. Dembo
#t1975
#cIssue 19 (August 1975)
#index10040
#!Methods are given for combining linear equalities in integer variables into surrogate equalities in such a way as to obtain the strongest information regarding the implicit bounds on these variables. Testing for infeasibility of the original system is also discussed and the strongest such tests identified. The tests given here may be used as part of a preprocessing routine for linear integer programming problems.


#*Conditional Interpretation of Operation Codes
#@C. C. Foster,R. Gonter
#t1971
#cIEEE Transactions on Computers
#index344947
#!A method, called conditional interpretation, is proposed which will allow small computers to have as large a set of instructions as may be desired without using a large number of bits to hold the operation code. The method is based on the redundancy of machine language instruction sequences. Most machine language instructions have a limited number of "reasonable" successors. For example "load accumulator" hardly ever follows "enter accumulator." It turns out that if each instruction is allowed seven successors plus an "escape instruction," only about one out of every five instructions needs to be an "escape" to get to one of the less usual successors. Seventy-five percent of the time the desired "next instruction" is among the seven permitted successors. Since each instruction has its own, possibly unique, set of successors, the interpretation of the stored op-code is conditional upon the state of the machine.


#*Panel on &ldquo;computer science graduates-industry/university gap?&rdquo; (Panel Session)
#@Russell M. Armstrong,Robert Benson,Peter Calingaert,Aaron Finerman,Pat McGee,D. O. Thomsen, Jr.
#t1972
#cProceedings of the second SIGCSE technical symposium on Education in computer science
#index548428
#!One of the interesting aspects of the first SIGCSE Technical Symposium was the discussion generated by the question of how large a gap there was between what Computer Science Departments were offering and the expectations of industry concerning computer science graduates. There definitely seemed to exist some differences. On the one hand the university seemed to be interested in turning out well-rounded students who were as familiar with basic principles and fundamental theoretical concepts in computer science as they were with programming techniques. On the other hand industry representatives seem to feel that the students did not have enough practical knowledge and had to be retrained upon entering the business world. The topic has been debated for some time. Therefore, the organizers of this Second SIGCSE Technical Symposium decided that a panel should be organized to discuss this issue. The following abstracts represent the main theses which will be elaborated on by the four representatives from industry who were invited to give 10-15 minute papers. After the presentation of these papers, Drs. Aaron Finerman and Peter Calingaert have been allotted 10-15 minutes each to comment on the ideas and topics presented in the papers. Since both Drs. Calingaert and Finerman have worked in industry, as well as in a university, their viewpoints will hopefully tie together the central themes of the panelists. This will help focus the ensuing discussion on the one or two key points which seem to be the primary cause of the gap between what industry sees as its needs and what the university perceives as well educated computer science graduates. Following these presentations, the panelists and the audience will have an opportunity to discuss the issues raised by the panelists. This format will allow anyone interested in participating in the conference to have a chance to listen to industry's point of view on this very important matter as well as to contribute his own thoughts during the discussion session. This issue has been informally discussed for some time. This panel was organized in an attempt to give formal recognition to the problems. The dialog among university/industry representatives will hopefully open communication channels that will bridge this gap.


#*An interesting LISP function
#@J. McCarthy
#t1979
#cIssue 3 (December 1979)
#index387892
#%200702


#*Reliability of electrolytic capacitors in computers
#@Mark VanBuskirk
#t1953
#cPapers and discussions presented at the Dec. 8-10, 1953, eastern joint AIEE-IRE computer conference: information processing systems---reliability and requirements
#index391462
#!If any person would ask ten different electronic manufacturers whose equipments cover a wide variety of electronic circuits for their opinions of electrolytic capacitors, it is possible there would be ten different answers. These answers might range from: "We use them all the time, and never have any trouble," to the extreme: "We wouldn't use them under any circumstance. They are not reliable." The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*An investigation of communications methods for mini-computer systems withmultiple low speed terminals
#@James Edwin Vander Mey
#t1970
#c
#index198157


#*FORTRAN Programming for Civil Engineers
#@Richard H. McCuen
#t1975
#c
#index611786


#*The design, development and applications of the astrac computer
#@Thomas Allen Brubaker
#t1963
#c
#index195594


#*Nondeterminism and the size of two way finite automata
#@William J. Sakoda,Michael Sipser
#t1978
#cProceedings of the tenth annual ACM symposium on Theory of computing
#index545227
#%544896
#%549043
#%548177
#%545954
#%550746


#*Processes in Structures
#@Andrea Maggiolo-Schettini,Józef Winkowski
#t1978
#cProceedings of the International Workshop on Graph-Grammars and Their Application to Computer Science and Biology
#index273108


#*The Cookbook
#@
#t1971
#cComputer
#index337031


#*Digital calculus: ss
#@Samuel C. Lee,Yousef M. Ajabnoor
#t1978
#cProceedings of the eighth international symposium on Multiple-valued logic
#index551142
#%607848
#!This paper attempts to establish a mathematical foundation for the variational analysis of multivalued switching systems. The mathematics in question is termed digital calculus, which includes Boolean calculus and binary vector Boolean calculus as special cases. In this paper the concept of Boolean difference (Boolean derivative) has been extended to multivalued (m-valued) switching algebra, where m need not be an integer power of 2. The derivatives of multivalued switching functions of potentially implementable multivalued algebras and their properties are presented. It is shown that every multivalued switching function of these algebras has a MacLaurin series expansion and a Taylor series expansion. As an example of the applications of digital calculus to multivalued switching systems design, the derivation of tests for fault detection of stuck-type faults in multivalued combinational circuits is presented and illustrated by an example.


#*Computational complexity and numerical stability
#@Webb Miller
#t1974
#cProceedings of the sixth annual ACM symposium on Theory of computing
#index546238
#%176377
#%607602
#!Limiting consideration to algorithms satisfying various numerical stability requirements may change lower bounds for computational complexity and/or make lower bounds easier to prove. We will show that, under a sufficiently strong restriction upon numerical stability, any algorithm for multiplying two n&times;n matrices using only +, &minus; and &times; requires at least n3 multiplications. We conclude with a survey of results concerning the numerical stability of several algorithms which have been considered by complexity theorists.


#*Foundations of Coding Theory
#@William E. Hartnett
#t1974
#c
#index619983


#*A man/machine workload model
#@Ronald R. Willis
#t1976
#cACM SIGSIM Simulation Digest
#index581888
#%328910
#%546683
#%547907
#%548766
#%549943
#%551130
#%552639
#%553904
#%554196
#!The fundamental nature of computer systems is to serve the user. If we wish to evaluate the performance of a computer system, we must therefore seek to characterize its responsiveness to those actions initiated by the user. It is this responsibility that isolates accurate workload distributions as an imperative ingredient in computer systems evaluation, and it is this ingredient that the man/machine workload model addresses.In particular, the model presented here simulates human activity at a terminal in real-time or time-share computer system environments. The use of flowcharts to represent human decision making and a variable language definition capability to code flowchart actions are key to the approach. The techniques described stress automatic and manual verification as well as the ability to accurately represent workloads at the point where workloads originate, the human.With this representative approach, accurate workload generation is a natural outcome. In addition, experience has shown that the man/machine workload model serves to enhance computer system simulation credibility, provide a tradeoff tool for human factors and operations design "what-if" questions, and most importantly, to provide a validation methodology for front-end system design efforts.


#*User behavioral patterns and requirements and their effect on the possible applications of data processing and computer techniques in a university library
#@Richard William Trueswell
#t1964
#c
#index202251


#*Non- determined algorithm schemata or R- schemata
#@R. I. Podlovchenko
#t1972
#cProceedings of the International Sympoisum on Theoretical Programming
#index257420


#*Overcoming computerese: some linguistic considerations for more effective user communications
#@William E. Knabe
#t1976
#cProceedings of the 4th annual ACM SIGUCCS conference on User services
#index253133


#*Storage CRT Display Terminals: Evolution and Trends
#@R. B. Preiss
#t1978
#cComputer
#index351214
#!Storage-tube display technology and costs will continue to attract new users and new applications, especially where very high information density is needed. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*B74-8 Design of Man-Computer Dialogues
#@R. Elschlager
#t1974
#cIEEE Transactions on Computers
#index337529
#!It might be said that this book points in the direction of our society's current renewed emphasis on the human. In order to make dialogues that people will use, the systems designer should become aware of the user, who is not a machine but a human being, and become aware, too, of the user's particular needs, sensitivities, and psychological reactions to conversing with a computer. For as Martin states in his introduction, "the future growth of the computer industry and the acceptance of computer methods will depend largely on the successful establishment of effective man-machine communications." The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A Nonimpact Page Printing System
#@R. F. Borelli
#t1975
#cComputer
#index345241
#!For a number of years computer peripherals have been recognized as bottlenecks in the computer performance race, and computer output hardcopy devices have been leading offenders.


#*An investigation of the protection requirements for programming language objects.
#@John Joseph Mcglothlin, Jr.
#t1976
#c
#index188567


#*Efficient digital transform algorithms and architectures for signal processing and error-correcting codes.
#@Kuang Yung Liu
#t1977
#c
#index206228


#*Design of a multi-level distribution system using simulation analysis
#@Leland Blank
#t1979
#cProceedings of the 12th annual symposium on Simulation
#index554311
#!A digital inventory management simulation model is described and its use in a supply project to design and plan the operations of a multi-level inventory distribution system is explained. An overview of the project objectives, the actual system, and the purposes and general design specifications of the simulator are discussed. Details of the simulated events are described as are the user inputs and the output reports. The simulation is written in SIMSCRIPT for general application to large-scale inventory system design involving many products and storage facility locations. Manufacturing capacity limitations may be specified by the user to evaluate the effect on service levels at all points of the distribution system.


#*Conversion of complex contour line definitions into polygonal element mosaics
#@H. N. Christiansen,T. W. Sederberg
#t1978
#cACM SIGGRAPH Computer Graphics
#index550346
#!A simple algorithm is presented for processing complex contour arrangements to produce polygonal element mosaics which are suitable for line drawing and continuous tone display. The program proceeds by mapping adjacent contours onto the same unit square and, subject to ordering limitations, connecting nodes of one contour to their nearest neighbors in the other contour. While the mapping procedure provides a basis for branching decisions, highly ambiguous situations are resolved by user interaction. The program was designed to interface a contour definition of the components of a human brain. These brain data are a most complex definition and, as such, serve to illustrate both the capabilities and limitations of the procedures.


#*An inquiry into the computer automation of super markets
#@Ronald R. Segel
#t1961
#cProceedings of the 1961 16th ACM national meeting
#index548457
#!In this day of automation, one fertile field has barely been scratched and it is strange because of the fact that it is in an area used by all of us. I have reference to the checkout systems in today's supermarkets. Stores are losing customers because of the long and annoying wait for service at the checkout counter. Since supermarkets make their money on a high-volume low-net business, a reduction in customer flow can be disastrous. A computer automated system is being discussed in this paper. Its ultimate goal is; to eliminate the checker who looks at the merchandise and operates the cash register, to automatically place the merchandise in bags, and to keep a running inventory for ordering and auditing. The first section considers what may be called the philosophical part of the problem. It considers such questions as, &ldquo;Who will unload carts as the customer enters the checkstand? After the automatic machine rings up and tabulates the bill, who will put the merchandise in bags? Where will the customer pay for his merchandise? Will pilfering increase? Will customers think that they are being pushed around and will they resent the loss of the human touch?&rdquo; The non-food items carried in today's supermarkets and the very large and very small packages, as well as wet and fragile items, will all have to be carefully handled and considered.


#*Simulation of the Coast Guard search and rescue process
#@Gerald L. Underwood
#t1979
#cProceedings of the 12th annual symposium on Simulation
#index548358
#!The Search and Rescue Simulation (SARSIM) is a management tool that is being used by U.S. Coast Guard decision makers to assist in the allocation of limited resources with the goal of achieving desired levels of performance. SARSIM is an event oriented digital computer simulation that is programmed in SIMSCRIPT II.5 and is operational on CDC (CYBERNET) remote computing service.


#*Programming in natural language: &ldquo;NLC&rdquo; as a prototype
#@Bruce W. Ballard,Alan W. Biermann
#t1979
#cProceedings of the 1979 annual conference
#index548062
#%205626
#%315326
#%318506
#!The state of the art in computational linguistics has progressed to the point where it is now possible to process simple programs written in natural language. This report describes a natural language programming system called NLC which enables a computer user to type English commands into a display terminal and watch them executed on example data shown on the screen. The system is designed to process data stored in matrices or tables, and any problem which can be represented in such structures can be handled if the total storage requirements are not excessive.


#*The graphics symbiosis system--an interactive mini-computer animation graphics language designed for habitability and extensibility
#@Thomas Albert De Fanti
#t1973
#c
#index197898


#*Effects of distributed processing in a data processing environment
#@Fred J. Maryanski,Daniel E. Kreimer
#t1978
#cProceedings of the 11th annual symposium on Simulation
#index551525
#%334566
#%547363
#!Most data processing installations utilize a single large mainframe computer to execute their three principal software functions - data base management, teleprocessing, and batch processing. Recently, distributed processing systems composed of a network of minicomputers have been proposed as alternatives to the single large mainframe. The study described herein determines the conditions under which it is feasible, in terms of performance, to distribute the data base, teleprocessing, and batch functions to configurations of two or three processors. The simulation results indicate that distributing a software data processing function provides performance benefits if the demands for that function are heavy.


#*The Anomalous Behavior of Flip-Flops in Synchronizer Circuits
#@W. Fleischhammer
#t1979
#cIEEE Transactions on Computers
#index337697
#!Quantitative results of the observations of oscillatory and metastable behavior of common flip-flops in response to logically undefined input conditions, such as those that occur in synchronizers and arbiters, are presented. The results are obtained with the help of a circuit developed for this purpose which measures the failure rate for a certain flip-flop and frequency. It is found that the obtained results are in good correlation with observed failure rates of a synchronizer with both short and long flip-flop resolution times allowed.


#*Proceedings of the 7th conference on Winter simulation - Volume 1
#@Michael F. Morris,Harold Steinberg,Donald Walter,Fred Silver,Susan L. Solomon,Joseph Annino,Dennis M. Gilbert
#t1974
#cWinter Simulation Conference
#index547845


#*Communication In X-TREE, A Modular Multiprocessor System
#@C. H. Séquin,A. M. Despain,D. A. Patterson
#t1978
#cProceedings of the 1978 annual conference
#index546181
#%144640
#%565454
#%547049
#%552219
#!A communication network for a tree-structured assembly (X-TREE) of single-chip processors is described, and considerations for selecting this particular approach are discussed. The communication links between the processors are high-speed, byte-parallel connections with an asynchronous handshaking protocol. Each node of X-TREE consists of a powerful processor, a switching network and a dedicated communications controller. The latter checks the availability of the links terminating in this node, supervises the creation and elimination of message channels and controls the routing and time multiplexing of concurrent messages over the same link. The switching network inside each X-NODE connects the external links with the internal processor via a fast multiplexed bus which is interfaced to each input/output port through fifo message buffers. Network topology, routing algorithm, addressing scheme, message format and communication hardware are discussed.


#*Calculation of complex modes and analysis of tapered coupling in optical waveguides.
#@Robert Brubaker Smith
#t1978
#c
#index194249


#*A Survey of Resource Directive Decomposition in Mathematical Programming
#@Francisco Walter Molina
#t1979
#cACM Computing Surveys (CSUR)
#index324253
#%327000


#*Microprogramming of signal processors
#@W. D. Ashcraft
#t1973
#cACM SIGMICRO Newsletter
#index17992
#!This paper is concerned with the hardware and architecture of microprogrammed equipment intended primarily for real time signal processing applications. Principles and structural types are discussed rather than a specific structure. There are numerous advantages to microprogrammed as contrasted to hardwired signal processing equipment. People in different positions view microprogramming as having different advantages. This paper presents some of these advantages together with hardware structure, microinstruction format, diagnostic techniques for both hardware and software, and various methods of control of a microprogrammed processor. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*General purpose emulation using the Hewlett-Packard 2100 minicomputer
#@Daniel W. Lewis
#t1979
#cACM SIGMICRO Newsletter
#index11601
#%315820
#!A taxanomy of methods for the implementation of general-purpose emulation projects on the Hewlett-Packard 2100 minicomputer is presented. The HP2100 is intended to be microprogrammed for instruction set extensions rather than general emulation. Problems encountered and solutions found through experience are discussed.


#*Analysis of Multiprocessor Control Organizations with Partial Program Memory Replication
#@A. A. Covo
#t1974
#cIEEE Transactions on Computers
#index349812
#!In certain real-time multiprocessor controllers the program memory must be at least partly replicated to reduce queuing delays and meet throughput requirements. In these organizations the program memory is a common pool consisting of K sections servicing m CPU's. The jth section is of size Xi and is replicated ni times (ni = m); j = 1,...-, K. Dynamic programming is used to find optimal values of the number of replications ni relative to given fixed values of m, K, and Xi. This solution satisfies throughput requirements at minimum cost, relative to the given m, K, and Xi. The process is repeated for several values of the last three parameters, using a systematic search procedure described herein, until reaching the first local minimum. This usually provides a satisfactory suboptimal solution. Partial replication (n, = m) is economically attractive in a wide class of real-time control systems in which the CPU's access a relatively small portion of the program store most of the time. Quantitative examples indicate that partial replication may cause 30 to 40 percent cost reduction compared to full replication.


#*SIGCAS (Panel Session)
#@Barry W. Boehm,Harry D. Huskey,Alan B. Kamman,Michael R. Lackner
#t1976
#cProceedings of the 1976 annual conference
#index554222
#!There is great potential impact of computers on any nation. Well-used, computers can increase the utility of human and material resources. Poorly-used, they provide a further drain on already strained resources. It is therefore imperative that developing nations learn from our mistakes and do not repeat them. This panel will discuss, and hopefully encourage others to discuss, the problems of introducing and applying computers in developing nations, the solutions which appear to be feasible, and the contributions we may make to these solutions.


#*A methodology for supporting existing CODASYL databases with new database machines
#@Jayanta Banerjee,David K. Hsiao
#t1978
#cProceedings of the 1978 annual conference - Volume 2
#index552574
#%547195
#%547315
#%551791
#%554150
#%555136
#!In this paper, an attempt is made to show that conventional database management system software, in particular those of CODASYL type, can be effectively replaced by database machines with good performance. The replacement of CODASYL system software involves two main steps: (i) In order to preserve the notions of CODASYL records, sets,-areas, and others, we need a methodology for database transformation so that an existing CODASYL database may be transformed into suitable formats for storing and retrieving in the database machine. (2) For the purpose of allowing existing application programs written in a CODASYL data sublanguage to store, retrieve and manipulate CODASYL data in the new environment without reprogramming, we need to be able to translate the data sublanguage calls dynamically into the commands of the database machine. Such process is termed query translation. In this paper, a database transformation methodology and a query translation process are presented which ensure that the content-addressability and parallel read-out capability of the database machine are used to advantage. The machine in consideration is known as the database computer (DBC) and is also briefly reviewed. DBC is one of the 'typical' new back-end machines for database management which utilize the emerging hardware and the modification of existing hardware for performance gain and capacity increase.


#*Formal translation of phrase-structure languages.
#@Arthur Bruce Pyster
#t1975
#c
#index193487


#*On Effective Speed-up and Long Proofs of Trivial Theorems in Formal Theories
#@Juris Hartmanis
#t1975
#c
#index118599
#!In this note we give a very simple proof which shows that in many interesting formal mathematical theories, axiomatizable as well as decidable ones, for every given formalization we can effectively find infinite subsets of trivially true theorems which require as long proofs in the given formalism as the hardest theorems of the theory. Thus showing that for these theories every formalism is doomed to be blind to the triviality of infinite sets of theorems, which can be found effectively. Furthermore, it follows that for all (sufficiently large) constructable tape and time bounds there exists sets whose recognition can be effectively speeded up on infinite subsets and that such sets appear naturally, thus showing that for many concrete problems, every algorithm can be effectively sped-up on infinite subsets.


#*A model for human faces that allows speech synchronized animation
#@Frederic I. Parke
#t1974
#cProceedings of the 1st annual conference on Computer graphics and interactive techniques
#index242387
#!A parametric model for human faces is described which is capable of expression and lip animation. With this model speech synchronized animation is reduced to varying parameters in accordance with a timed speech sequence.


#*Statistical programs at the University of North Carolina
#@Norman Bush
#t1961
#cCommunications of the ACM
#index325117
#!The Research Computation Center at the University of North Carolina has access to a UNIVAC 1105 general purpose digital computer for use in connection with data processing problems, theoretical studies, and computer research. With respect to data processing problems, three major statistical programs have been written: General Contingency Table Analysis for Questionnaire Data Analysis of Variance (ANOVA) Multiple Regression and Correlation Some of the concepts and ideas in these programs are new and may be of interest to other computation centers. Hence they are described below. The programs were written in the Remington Rand UNICODE language. Thus it would not be difficult to translate them into any other algebraic language, such as ALGOL, FORTRAN, or IT.


#*The Computer Center's potential as a community educational resource tool: from the instructor's point of view
#@John Dowling, Jr.
#t1976
#cProceedings of the 4th annual ACM SIGUCCS conference on User services
#index241582


#*Remark on algorithm 412 [J6]
#@Richard P. Watkins
#t1973
#cCommunications of the ACM
#index326436


#*A Restructurable Computer System
#@S. S. Reddi
#t1978
#cIEEE Transactions on Computers
#index345133
#!This paper presents an architecture for a restructurable computer system which reconfigures its resources according to the problem environment for efficient performance. It converts the user's program into an intermediate level language called Realist which is capable of specifying arbitrary resource structures such as an array or a pipeline and the computation to be performed upon these structures. An architectural design for the system is presented with special attention to bus units. It is shown how APL, a vector processing language, can be implemented on the system. Some storage schemes are considered for organizing vectors and matrices to facilitate efficient retrieval and manipulation. The paper is concluded with a comparison of the proposed system to existing high speed architectures.


#*Logic Design for Behavioral Scientists
#@Roy Udolf
#t1973
#c
#index447918


#*Staffing the MIS Function
#@Theodore C. Willoughby
#t1972
#cACM Computing Surveys (CSUR)
#index317950
#%578223
#%548655
#%554422
#%546521
#%555021


#*An image matrix for accessing files
#@Stanley T. Schuyler,Jonathan A. Soule,Patrick F. Turchetta,Malcolm H. Gotterer
#t1972
#cProceedings of the ACM annual conference - Volume 1
#index243547
#%327682
#%324107
#%331163
#%329291
#%317208
#!The efficiency of a file management system using direct access storage depends to a large extent upon the efficiency of its file access algorithm, the extent to which the operating environment influences file manager performance, and the effectiveness of primary storage utilization. One way to increase a system's efficiency is to reduce the number of probes necessary to access a record. Such a reduction may be accomplished by storing a small portion of a record's key in a bit matrix within primary storage. This method is effective when a section of primary storage is not used by the file management package, or when a section is occupied by component modules which are used infrequently enough to allow overlays or swapping. The effectiveness of this technique has been established through an experimental investigation.


#*Proceedings of the eighth SIGCSE technical symposium on Computer science education
#@
#t1977
#cTechnical Symposium on Computer Science Education
#index546901


#*Reflections on Ljubljana
#@Walter M. Carlson
#t1971
#cCommunications of the ACM
#index332103


#*Regulatory control and modeling of responsive behavior in autonomous systems.
#@David Earl Sundstrom
#t1973
#c
#index202271


#*Simulation tools (Paper Session)
#@
#t1972
#cProceedings of the ACM annual conference - Volume 2
#index553628
#!The emphasis in this session is on the tools which are available for use in simulation.


#*Minimal solutions for binary identification problems with inconclusive questions
#@Anumongkol Sirivedhin
#t1972
#c
#index200983


#*Development of educational software using the DEC PDP-11
#@D. D. Cowan,P. H. Dirksen,J. W. Graham,J. W. Welch
#t1976
#cACM SIGPLAN Notices
#index553798
#%320760
#%329092
#!During the past two years, the Waterloo Foundation for the Advancement of Computing (WATFAC) and the University of Waterloo have been developing educational software in a number of projects using DEC PDP-11 mini-computers. These projects include the development of WATFOR-11 (a load-and-go FORTRAN compiler), WATBOL-11 (a load-and-go COBOL compiler), and WIDJET (a student editing and job-entry system). This paper presents a survey of these projects and discusses several problems encountered during their implementation.


#*Study of multistage SIMD interconnection networks
#@Howard Jay Siegel,S. Diane Smith
#t1978
#cProceedings of the 5th annual symposium on Computer architecture
#index549076
#%549696
#%554555
#!Four SIMD multistage networks - Feng's data manipulator, STARAN flip network, omega network, and indirect binary n-cube&mdash;are analyzed. Three parameters - topology, interchange box, and control structure&mdash;are defined. It is shown that the latter three networks use equivalent topologies and differences in their capabilities result from the other parameters. An augmented data manipulator network using a modified control structure to perform more single pass interconnections than the other networks is presented. Some problems may be solved more efficiently if the 2n processing elements of an SIMD machine can be partitioned into submachines of size 2r. Single and multiple control partitioning are defined. The capabilities of these multistage networks to perform in these partioned environments are discussed.


#*Design and application of electronically programmable LSI arrays
#@D. Hampel,R. L. Barron,D. Cleveland
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index63103
#!It has been shown that arrays of calculating elements, providing various functions of their input variables, can be used as general-purpose signal processors. Such elements could, in general, operate on binary, analog, or numerical inputs. Networks or arrays composed of elements in each of these domains have advantages in particular applications. The numerical processing element and its use in programmable arrays is the subject of this paper.


#*Computer graphics as an aid to teaching geometric transformations
#@Joseph K. McAdams,Arlan R. DeKock
#t1976
#cProceedings of the ACM SIGCSE-SIGCUE technical symposium on Computer science and education
#index551649
#!During the past several years, there has been much discussion and controversy over what should be taught in high school mathematics, in general, and in high school geometry, in particular. Numerous mathematicians have encouraged the teaching of transformations as part of the standard high school mathematics curriculum[l-4,6-9]. The results of a recent survey of high school teachers of mathematics indicate that 19% have taught geometric transformations, 26% feel adequately prepared to teach such a topic, and 50% would like to teach the topic if materials were available for the average college prep student[5]. The topic of transformations is important because transformations are a unifying factor in algebra and geometry. Algebra and geometry are essentially the same material taught from different approaches. In particular, the abstract algebraic concept of a group can be conveyed in purely geometric terms by groups of transformations.


#*Discrete simulation applied to Mars lander
#@Edward M. Morgan,Jon I. Fellers
#t1969
#cProceedings of the third conference on Applications of simulation
#index554392
#!NASA plans for a sophisticated Mars lander mission during the 1973 opportunity present a rigorous deceleration system design problem due to uncertainties in the environment in which the retardation must be effected. Selection of design characteristics such as ballistic coefficient, aeroshell diameter, parachute size and deployment altitude, and propulsion thrust level and initiation altitude is critical, for if a &ldquo;worst case&rdquo; design philosophy is adopted for all parameters, weight is not available to perform an interesting science mission. To establish a proper design, a certain risk with respect to environment must be accepted; this paper discusses a digital simulation tool as it has been applied to parameter trades to specify retardation design.


#*Additional APL generators: geometric, PORDER and WEIBULL
#@David G. Halmstad
#t1976
#cACM SIGSIM Simulation Digest
#index576998
#!The following are some additional generator routines to supplement those published by Robert E. Wheeler. The first is the (usual?) straight-forward routine for the geometric distribution. The second is for the generation of the highest (or lowest) variates in ordered samples (from the uniform distribution). When one has the inverse of the distribution function being used, this routine is rather useful. A self-explanatory demonstration of the use of the PORDER generator is shown in conjunction with the use of WEIBULL distribution generator.


#*The Multics Input/Output system
#@R. J. Feiertag,E. I. Organick
#t1971
#cProceedings of the third ACM symposium on Operating systems principles
#index547550
#!An I/0 system has been implemented in the Multics system that facilitates dynamic switching of I/0 devices. This switching is accomplished by providing a general interface for all I/O devices that allows all equivalent operations on different devices to be expressed in the same way. Also particular devices are referenced by symbolic names and the binding of names to devices can be dynamically modified. Available I/0 operations range from a set of basic I/0 calls that require almost no knowledge of the I/O System or the I/0 device being used to fully general calls that permit one to take full advantage of all features of an I/O device but require considerable knowledge of the I/0 System and the device. The I/O System is described and some popular applications of it, illustrating these features, are presented.


#*Promoting computer literacy: a search for cost-effective alternatives
#@Michael A. Steinberg
#t1979
#cProceedings of the 7th annual ACM SIGUCCS conference on User services
#index444485
#!The use of computers in society today is growing at a startling rate. Consequently, it is becoming increasingly important that today's well-educated college graduates have knowledge about computing. This knowledge, which not only includes exposure to the use of computing but the ability to manipulate computers for one's own individual needs, is what might be termed computer literacy. It is becoming essential that the educational institutions in this country provide students with the opportunity to become computer literate by promoting the use of computing in education. Unfortunately, this has not been done as rapidly as we would like to see. It then becomes an important responsibility for the computer professional in general and the User Services organization in particular to provide both the environment and the motivation for development of computer literacy.There are a number of reasons why instructional computing has grown slowly in the past. One reason is that faculty either do not have the time or do not receive rewards for developing and implementing instructional materials. Another reason is that there is often very little funding available for the acquisition of computing hardware. Making this problem worse is the trend toward tightening of computing budgets at many academic institutions. Fortunately, within recent years, a number of hardware and software alternatives have been developed and are beginning to address these problems.This session will be an examination of some of the alternatives that are available for providing instructional computing facilities at a reasonable cost, thus paving the way for our efforts to promote computer literacy. The hardware alternatives range from the large to small, centralized to decentralized. While inexpensive technology is now available, there are many factors, including logistical, technical, administrative, and political that prevent us from moving immediately to the most modern equipment. The intent of this paper is to suggest alternatives that are viable despite these constraints, and thereby provide a model for those who are evaluating available alternatives.


#*Legal aspects of computer management
#@
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index73082


#*The quadratic congruential method of random-number generation.
#@Claude Lee Overstreet, Jr.
#t1973
#c
#index205982


#*1971 IEEE Computer Society Conference
#@
#t1971
#cComputer
#index344859


#*The construction of recognizers
#@A. E. Roberts, Jr.
#t1966
#cCommunications of the ACM
#index322197


#*Database sharing: A study of interference, roadblock and deadlock
#@J. E. Shemer,A. J. Collmeyer
#t1972
#cProceedings of 1972 ACM-SIGFIDET workshop on Data description, access and control
#index547004
#%314206
#%314331
#%316233
#%319434
#%322720
#!It is the purpose of this paper to examine the problems of contention which arise naturally when a number of programs are granted simultaneous access to a database for the purpose of update as well as inquiry. A LOCK-UNLOCK mechanism, applied at the group (or record) level is assumed. Incremental allocation of groups is permitted; hence deadlocks are possible. Of particular interest are the frequencies of three events: 1) Interference 2) Roadblock 3) Deadlock While none of these events constitutes a threat to the integrity of the database, each is a potential contributor to degraded performance. The justification of a LOCK-UNLOCK mechanism is thus predicated on acceptably low frequencies for each of the foregoing events. To measure these frequencies, a simulation study was undertaken. The results of this study, together with a description of the simulation, are presented.


#*Analysis of a new method for microprocessor solution of differential equations.
#@Dan Ioan Moldovan
#t1978
#c
#index201968


#*Algorithmic progress in solving partial differential equations
#@John R. Rice
#t1976
#cACM SIGNUM Newsletter
#index103699
#!This is an attempt to document the progress that has been made over the past 30 years in computational methods for solving partial differential equations. Hopefully the assumptions made in this study are clear, but they may well be disputed. Some computational efforts are quickly estimated here, but others are taken from the literature without an independent check that the same definition of effort is used. There are probably some computational methods which I have overlooked which should be included. Note that this study shows up some obscure methods as being very attractive, which suggests that there are other lesser known methods which are also attractive.


#*Book review of The structure of computers and computations: volume one by David J. Kuck. John Wiley & Sons 1978.
#@
#t1979
#cACM SIGARCH Computer Architecture News
#index120872


#*A theory of general machines and functor projectivity
#@David Craig Rine
#t1970
#c
#index205828


#*Programming in an Interactive Environment: the ``Lisp'' Experience
#@Erik Sandewall
#t1978
#cACM Computing Surveys (CSUR)
#index333675
#%79620
#%153456
#%318506
#%546083


#*Comments on computers in banking
#@Millard H. Perstein
#t1964
#cCommunications of the ACM
#index335206


#*A mathematical modeling approach to the automatic selection of database designs
#@Salvatore T. March,Dennis G. Severance
#t1978
#cProceedings of the 1978 ACM SIGMOD international conference on management of data
#index621699
#%186409
#%200199
#%316308
#%316426
#%329105
#%330186
#%330505
#%332110
#%334723
#%613033
#%614103
#!This paper provides an overview of a methodology developed to support systems analysts in the process of database design. The design approach is built upon an analytic model composed of (1) parametric descriptions for components of a generalized database organization, (2) costing equations which can evaluate a proposed modular database design, (3) an analyst interface which accepts an arbitrary database organization for evaluation, and (4) search procedures which automatically generate and compare thousands of alternative designs. Performance is measured as the sum of storage, retrieval, and maintenance costs and is estimated from parameters of the proposed design, the problem description and the storage environment. A virtual, record-frame view of secondary storage has been developed in which data records are added, deleted and modified with minimal effect on existing data structures. Application of the modeling approach to a realistic design problem is described, and modeling accuracy to within four percent is claimed.


#*Parallel graph processing using depth-first search and breadth-first search.
#@Denise Marie Eckstein
#t1977
#c
#index203683


#*Structured organization of clinical data bases
#@Gio Wiederhold,James F. Fries,Stephen Weyl
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index57414
#%329737
#%326368
#!The health care delivery system is under strong pressures from several sides. Many of these pressures derive from the demand for a more comprehensive range of health services and from the increased complexity of disease and treatment patterns. Since medical science has provided tools to manage many of the once common diseases, it now has to cope with problems of less well understood origin and course. The practicing physician is faced with an information explosion of major dimensions and a gap between scientific knowledge in a basic form and its practical application at the bedside.


#*Recognition of patterns with syntactic and semantic deformations
#@Wen-Hsiang Tsai
#t1979
#c
#index191563


#*Policy/mechanism separation in Hydra
#@R. Levin,E. Cohen,W. Corwin,F. Pollack,W. Wulf
#t1975
#cProceedings of the fifth ACM symposium on Operating systems principles
#index544708
#%315247
#%316426
#%323836
#%329737
#%330178
#%332957
#%555060
#%548311
#!The extent to which resource allocation policies are entrusted to user-level software determines in large part the degree of flexibility present in an operating system. In Hydra the determination to separate mechanism and policy is established as a basic design principle and is implemented by the construction of a kernel composed (almost) entirely of mechanisms. This paper presents three such mechanisms (scheduling, paging, protection) and examines how external policies which manipulate them may be constructed. It is shown that the policy decisions which remain embedded in the kernel exist for the sole purpose of arbitrating conflicting requests for physical resources, and then only to the extent of guaranteeing fairness.


#*COKO III: the Cooper-Koz chess program
#@Edward W. Kozdrowicki,Dennis W. Cooper
#t1973
#cCommunications of the ACM
#index323193
#%544780
#%445001
#!OKO III is a chess player written entirely in Fortran. On the IBM 360-65, COKO III plays a minimal chess game at the rate of .2 sec cpu time per move, with a level close to lower chess club play. A selective tree searching procedure controlled by tactical chess logistics allows a deployment of multiple minimal game calculations to achieve some optimal move selection. The tree searching algorithms are the heart of COKO's effectiveness, yet they are conceptually simple. In addition, an interesting phenomenon called a tree searching catastrophe has plagued COKO's entire development just as it troubles a human player. Standard exponential growth is curbed to a large extent by the definition and trimming of the Fisher set. A clear distinction between tree pruning and selective tree searching is also made. Representation of the chess environment is described along with a strategical preanalysis procedure that maps the Lasker regions. Specific chess algorithms are described which could be used as a command structure by anyone desiring to do some chess program experimentation. A comparison is made of some mysterious actions of human players and COKO III.


#*Two-dimensional sequential algorithms for image restoration and enhancement.
#@John Andrew Jesudoss Rajan Ponnusamy
#t1979
#c
#index199090


#*An extendable approach to computer-aided software requirements engineering
#@Thomas E. Bell,David C. Bixler,Margaret E. Dyer
#t1976
#cProceedings of the 2nd international conference on Software engineering
#index551616
#!The development of system requirements has been recognized as one of the major problems in the process of developing data processing system software. We have developed a computer-aided system for maintaining and analyzing such requirements. This system includes the Requirements Statement Language (RSL), a flow-oriented language for the expression of software requirements, and the Requirements Engineering and Validation System (REVS), a software package which includes a translator for RSL, a data base for maintaining the description of system requirements, and a collection of tools to analyze the information in the data base. The system emphasizes a balance between the use of the creativity of human thought processes and the rigor and thoroughness of computer analysis. To maintain this balance, two key design principles&mdash;extensibility and disciplined thinking&mdash;were followed throughout the system. Both the language and the software are easily user-extended, but adequate locks are placed on extensions, and limitations are imposed on use, so that discipline is augmented rather than decreased.


#*Partially separable functions
#@Thomas Andrew Slivinski
#t1967
#c
#index187835


#*A computer method for radiation treatment planning
#@William Siler,John S. Laughlin
#t1962
#cCommunications of the ACM
#index318417
#!Automatic computation methods were first developed and applied to the problem of radiation therapy treatment planning by the Physics staff at Memorial Hospital and Sloan-Kettering Institute in 1954 and reported in 1955 [1]. The field of radiation from a single port was stored as a matrix in a library of punched cards, and a sorter and accounting machine were used to combine various fields for rotation, cycling and multi-port therapy. This system was in continuous routine use from then until 1961, when the equipment was replaced by a Bendix G15-D digital computer. Subsequent work by Sterling [2] followed essentially the same method of describing the radiation field as used by the Physics staff at Memorial Hospital [1], except that more powerful equipment has been used. An analytic expression for the dose distribution produced by rotation had been previously applied successfully in 1951 to treatment planning with high-energy X-rays [3].


#*A Signal-Dependent Error Arising in Digitally Processed Images Due to Quantization
#@W. H. Carter
#t1972
#cIEEE Transactions on Computers
#index346563
#!A troublesome error has been found in digital data which represents an image renormalized by a computer. The error, which takes the form of anomalous patterns in the switching sequence of certain bits, contributes unnecessary, signal-dependent noise to the-data. Experimental results illustrating this phenomenon are shown and a theoretical model is derived. The model shows that the phenomenon results from a qtiantization or roundoff error inherent in digital renormalization and describes its detailed behavior. A method for rescaling the data which does not lead to the introduction of noise is described.


#*A management approach to the development of computer-based systems
#@R. Turn,M. R. Davis,R. N. Reinstedt
#t1976
#cProceedings of the 2nd international conference on Software engineering
#index551270
#%593112
#!Many organizations have experienced serious difficulties in developing complex computer-based systems, especially their software components. The problems include large cost overruns, schedule slippages, inadequate performance, and inability to use the system as originally envisioned. One major reason for such lack of success has been the inability of the management of the organization or the development effort to understand the need for a total-system management approach. In particular, acquisition of software and hardware separately with the hope of integrating them later does not work in complex systems. This paper outlines a management approach to acquiring computer systems which encompasses the whole system, with emphasis on the software, from the initial concept formulation to the support of the operational system. Expected improvements in the development process and organizational implications of this management approach are discussed.


#*A computerized traffic control algorithm to determine optimal traffic signal settings.
#@Kurt Seldner
#t1977
#c
#index189285


#*Preliminary investigation of techniques for automated reading of unformatted text
#@George Nagy
#t1968
#cCommunications of the ACM
#index320503


#*Automatic error recovery for LR parsers
#@M. Dennis Mickunas,John A. Modry
#t1978
#cCommunications of the ACM
#index332577
#%114741
#%189791
#%194698
#%205883
#%319281
#%319747
#%321744
#%322533
#%323844
#!In this paper we present a scheme for detecting and recovering from syntax errors in programs. The scheme, which is based on LR parsing, is driven by information which is directly and automatically obtainable from the information that is already present in an LR parser. The approach, which is patterned after that of Levy and Graham and Rhodes, appears to provide error recovery which is both simple and powerful.


#*A hierarchical structure for concurrency control in a distributed database system
#@H. Yamazaki,S. Hikita,I. Yoshida,S. Kawakami,Y. Matsushita
#t1979
#cProceedings of the sixth symposium on Data communications
#index549545
#!This paper focuses on the concurrency control problem for a distributed database system. A new control philosophy called hierarchical processing structure is proposed. Two different types of the consistency are clearly defined, and the hierarchical processing structure is derived from these consistency types. This structure provides the following features; 1) The centralization of processing load on a particular site can be avoided. 2) Two distinct types of updating mechanism are defined according to two aspects of data consistency. 3) A comprehensible philosophy for the concurrency control is established.


#*Certification of algorithm 203 [E4]: STEEP1
#@J. M. Varah
#t1965
#cCommunications of the ACM
#index329323


#*Chebyshev series expansion of the solution of kepler's equation and its numerical computation.
#@En Jui Lin
#t1974
#c
#index186896


#*Proceedings of the 1979 annual conference
#@Arvid L. Martin,James L. Elshoff
#t1979
#cACM Annual Conference/Annual Meeting
#index550700


#*Fault-detection experiments for sequential machines
#@Daniel Eugene Farmer
#t1970
#c
#index196805


#*Algorithm 386: Greatest common divisor of n integers and multipliers
#@Gordon H. Bradley
#t1970
#cCommunications of the ACM
#index326529
#%320378


#*Cooperative government utilization of information processing systems
#@
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index68701


#*A Recursive Relation for the Determinant of a Pentadiagonal Matrix
#@Roland A. Sweet
#t1968
#c
#index114656
#!A recursive relation is developed for the determinant of a pentadiagonal matrix $S$ which satisfies $s_{i,j} \neq 0$ for $|i-j|=1$. When $S$ is symmetric, one has a six-term recursive relation. An example is given to illustrate its use in the computation of eigenvalues.


#*Generalization of Tee's matrix
#@Gerhard Zielke
#t1974
#cACM SIGNUM Newsletter
#index108916
#%107752


#*PC board layout techniques
#@David R. Johnson
#t1979
#cProceedings of the 16th Design Automation Conference
#index548755
#%551464
#!This paper discusses general concepts and sample results of printed circuit board layout techniques involving the use of a general purpose, interactive graphics, computer aided design and manufacturing system. Employed is a balance of automatic processes and manual techniques proven to be effective for addressing a wide range of board sizes and types.


#*Organizational change and educational computing
#@John A. Sonquist
#t1976
#cProceedings of the 1976 annual conference
#index544814
#%577967
#!Sociological theories of change in formal organizations are brought to bear on acceptance of computer technology in support of social science research and teaching in colleges and universities. The paper employs theory based on general studies of organizational change to sensitize organizational planners to issues and problems specifically related to computing.


#*Future of design automation (Position Paper)
#@P. Losleben
#t1979
#cProceedings of the 16th Design Automation Conference
#index553249
#!In a field which is at least two decades old, one phenomenon remains constant. It appears that none of us can objectively describe our current status without sprinkling a little of &ldquo;what might be&rdquo; into the discussion. While we all complain about the day-to-day fire fights, we are basically forward looking, if only incrementally. Let us drop all pretense about the present then, and talk strictly about the future. It is useful to think of the future in terms of specific challenges (instead of problems).


#*A synthesis rule for concurrent systems
#@Tilak Agerwala,Yong-Chai Choed-Amphai
#t1978
#cProceedings of the 15th Design Automation Conference
#index554550
#%192823
#%193442
#%321015
#%324964
#%330765
#%332514
#%335107
#%545041
#%552259
#%553888
#!Concurrent (hardware and software) systems can become extremely complex due to the existence of multiple loci of control. Posteriori analysis of such systems is very difficult. This paper presents a systematic bottom-up modular approach to synthesis. The synthesis procedure at each stage yields all invariants (of a certain kind) of the system. These invariants can be used as an aid to proving certain properties of the system such as boundedness, conservativeness, mutual exclusion, absence of deadlock, etc. The use of the synthesis rule and the utility of the invariants are illustrated by examples.


#*A token flow model applied to computer networks.
#@Kenneth Clair Larson
#t1977
#c
#index188708


#*Design of assembly level language for horizontal encoded microprogrammed control unit
#@R. H. Evans,L. H. Moffett,R. E. Merwin
#t1974
#cConference record of the 7th annual workshop on Microprogramming
#index554659
#%233701
#%244680
#%552132
#!Microprogramming in its most elementary form involves determination of the required bit patterns for a set of control words which express some desired computer instruction. The bit patterns, stored as words in a control word memory, selectively and in time sequence activate the control lines of a computing element. In its simplest form, each control line for the computing element corresponds to a bit in the control word. In addition the control word may contain bit fields to determine the sequence of execution of control words. The first proposals for microprogrammed control systems [1,2,3] were essentially of this type. Specification of these bit patterns was exceedingly tedious since the number of control lines runs to over one hundred for a typical computing element and several hundreds of control words must be specified. The first step to alleviate this situation was the development of encoded [4] control where groups of control lines which are never activated simultaneously, e.g., the controls to an adder/subtractor unit, are encoded where k bits in the control word selectively activate one of up to 2Kcontrol lines. While this reduces the number of bits that must be specified for each control word, it doesn't reduce the number of control words that must be generated and microprogramming is still an error prone procedure. Because of this situation, microprogramming is considered by most programmers to be analogous to or worse than machine language programming. The development of assemblers and compilers to simplify the process of coding microprograms has proceeded slowly in contrast to the situation for conventional application programming. Available design systems [5,6] for microprogrammers feature simple languages composed of orders or operations which are associated with specific encoded control word bit patterns. There are three principal causes for this situation. First, most microprogrammers have a design engineering background and are not familiar with assemblers and compilers and do not request such facilities from the design automation developers. Second, logic design of digital systems involves largely register to register transfers and bit manipulations with associated timing constraints which are not efficiently expressed in terms of programming languages like FORTRAN. Third, user microprogrammable computers have not been widely available until recently, therefore fewer people have been concerned about the situation. To address the problem of designing a language to simplify the specification of microprograms for horizontally encoded control units, an assembly level language, HALL (HYRMAN Assembly Level Language), was designed. A brief description of the language and a two pass translator is presented with special emphasis on the design of the control sequence technique. As background, the major features of the HYRMAN [7] simulator are presented along with a sample case of simulation to illustrate the usage of HALL. The paper concludes with some comparisons of this approach to other attempts [8,9,10,11] of a similar nature.


#*Welcoming remarks
#@George E. Forsythe
#t1966
#cCommunications of the ACM
#index314616


#*Information processing and computerized business games.
#@Jay Hartwell Coats
#t1975
#c
#index196214


#*Have you Heard James Martin Lately?
#@
#t1979
#cComputer
#index339096


#*Supporting a flourishing language culture
#@Peter Wegner
#t1978
#cACM SIGPLAN Notices
#index309846


#*Generalizations of the b spline approximation and their applications to geometric problems in computer aided designs.
#@Kam-Fook Tse
#t1975
#c
#index191747


#*The programming language EFL
#@S. I. Feldman
#t1979
#cACM SIGNUM Newsletter
#index552068
#%178360
#!EFL is a comprehensive language designed to make it easy to write portable, understandable programs. It provides a rich set of data types and structures, a convenient operator set, and good control flow forms. The lexical form is easy to type and to read. EFL was originated by A. D. Hall. The current author completed the design of the language and wrote the current compiler. Whenever possible, EFL uses the same forms that Ratfor [1] does; in this sense EFL may be viewed as a superset of Ratfor. EFL is a well-defined language; this distinguishes it from most &ldquo;Fortran preprocessors&rdquo; which only add simple flow of control constructs to Fortran.


#*The use of logo in a "computers and society" course
#@Ronald Baecker
#t1972
#cProceedings of the ACM annual conference - Volume 1
#index254482


#*4th Conference on Local Computer Networks
#@
#t1979
#cComputer
#index346966


#*In support of users
#@Roger W. Watt
#t1975
#cProceedings of the 3rd annual ACM SIGUCCS conference on User services
#index550128
#!SHARE Inc. is an IBM users' group; it is a non-profit international organization whose members are organizations which make use of large-scale IBM computing systems. Today, in its 20th year, SHARE's members number almost 1300 installations spread over six continents. Computing personnel from these member installations meet at two major and two interim SHARE conferences each year. The participants at these conferences (called SHAREs) discuss common problems, exchange ideas and solutions to problems, and attempt to influence the directions IBM takes in its technological and business decisions. The two major SHARE conferences each year are attended by several thousand people from the member installations. The computing interests of these individuals and the installations they represent encompass the entire spectrum of the computing environment. SHARE offers its members a forum in which to pursue and expand personal, professional, and installation objectives through interaction with others. Its stated purpose is to foster the research, development, exchange, and public dissemination of information and techniques pertinent to computing technology, in the best scientific tradition.


#*Conversion of a d17b (minuteman-i) guidance computer to acquire and process evoked response information.
#@Harry Steven Warford
#t1974
#c
#index193561


#*Automatic coding: choice of data structures.
#@James Richard Low
#t1974
#c
#index200129


#*Reproductive adaptive plans
#@Daniel J. Cavicchio, Jr.
#t1972
#cProceedings of the ACM annual conference - Volume 1
#index548673
#%517247
#!This paper traces the experimental development of a new class of powerful and flexible adaptive plans, called reproductive plans. Adaptive plans are formally presented as search procedures for locating superior devices in an extremely large space. Reproductive adaptive plans operate by treating the search procedure as an evolutionary process of finding the best organism in a certain environment. Devices are represented as strings or chromosomes. At each &ldquo;generation&rdquo; or time step a population of devices is tested and each device is copied (rewarded) according to its performance. Then the copies &ldquo;mate&rdquo; using a number of genetic-like operators to produce a modified population of devices. In this particular study devices are pattern recognition programs although they could be any set of modifiable procedures. Much of the work is concerned with experimentally testing and improving the general reproductive plan to achieve fast and continuous adaptation.


#*Implementierbarkeit attributierter Grammatiken
#@Robert Giegerich,Reinhard Wilhelm
#t1977
#cGI - 7. Jahrestagung, N&uuml;rnberg
#index277540


#*Algorithms for sparse matrix eigenvalue problems.
#@John Gregg Lewis
#t1977
#c
#index199212


#*Two Subroutine Packages for the Efficient Updating of Matrix Factorizations
#@A. K. Cline
#t1977
#c
#index192032


#*The analysis of double hashing(Extended Abstract)
#@Leo J. Guibas,Endre Szemeredi
#t1976
#cProceedings of the eighth annual ACM symposium on Theory of computing
#index554190
#%324207
#%331163
#!In this paper we analyze the performance of a well known algorithm known as double hashing [Knuth]. In this method we probe the hash table along arithmetic progressions, where both the initial element and the increment of the progression are chosen randomly and independently depending only on the key K of the search. We prove that double hashing is asymptotically equivalent to uniform probing, an idealized hashing technique that exhibits no clustering and is known to be optimal in a certain sense. Between steps of the extension process we can show that the effect of clustering is negligible, and that we therefore never depart too far from the truly random situation.


#*Statistical models and methods for measuring software reliability.
#@Ernest H. Forman
#t1975
#c
#index205461


#*Computer source language optimizing utilizing a visual display
#@Ralph Edwin Love, Jr.
#t1967
#c
#index201460


#*The coordination of multiple processes in computer operating systems
#@John Hayes Howard, Jr.
#t1970
#c
#index189525


#*Algorithm 482: Transitivity sets
#@John McKay,E. Regener
#t1974
#cCommunications of the ACM
#index325671


#*A simulation model for data base system performance evaluation
#@Fumio Nakamura,Ikuzo Yoshida,Hidefumi Kondo
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index69132
#%325094
#!Performance evaluation represents one of the most critical and also most complex aspects of the design of a data base system for operation in an on-line environment.


#*A computer study of permanents of n-square (0,1) - matrices in the class u(k, k)
#@Jesse Cornelius Lewis
#t1966
#c
#index205037


#*Time-bounded random access machines
#@Stephen A. Cook,Robert A. Reckhow
#t1972
#cProceedings of the fourth annual ACM symposium on Theory of computing
#index544917
#!In this paper we introduce a formal model for random access computers and argue that the model is a good one to use in the theory of computational complexity. Results are proved which compare run times for recognizing sets using this model (which has a fixed program) with a stored program model and with Turing machines. The main result, theorem 3, shows the existence of a time complexity hierarchy which is finer than that of any standard abstract computer model. An Algol-like programming language is introduced which facilitates proofs of the theorems.


#*The development and application of a digital computer simulation of the rake concept as related to tropospheric scatter measurement
#@Robert Harold Pool
#t1972
#c
#index189485


#*A computer graphics system for macromolecular model building
#@James Ross Miller
#t1979
#c
#index190020


#*Reconfigurable Modular Computer Networks for Spacecraft On-Board Processing
#@D. A. Rennels
#t1978
#cComputer
#index395507
#!Standardized fault-tolerant microcomputers in a reconfigurable distributed network promise to meet spacecraft reliability requirements at low cost.


#*Algorithm 497: Automatic Integration of Functional Differential Equations [D2]
#@Kenneth W. Neves
#t1975
#cACM Transactions on Mathematical Software (TOMS)
#index321019
#%315763


#*Positivity and norms
#@F. L. Bauer
#t1975
#cCommunications of the ACM
#index322442
#!Following some lines of joint work with A.S. Householder, the character and use of algebraic methods in the theory of norms is demonstrated. New results concerning norms with values in an Archimedian vector lattice (not necessarily being totally ordered) are given, in particular for the generalization of order unit norms, L-norms and M-norms. An example of application to operator norms is given concerning contraction properties of positive operators.


#*Keynote address
#@Howard T. Engstrom
#t1953
#cPapers and discussions presented at the Dec. 8-10, 1953, eastern joint AIEE-IRE computer conference: information processing systems---reliability and requirements
#index404138
#!I speak to you this morning as Chairman of the Technical Program Committee for the AIEE-IRE-ACM Joint Computer Conference. At the first of these conferences, in December 1951, at Philadelphia, a program was devoted to a description of existing electronic computers or those under development. The second conference, at New York, in December 1952, was devoted to a review of input-and-output equipment necessary for efficient usage of computer systems. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Sprachwissenschaft und CUU
#@K. H. Deutrich,P. Pauly,J. Wilbs
#t1974
#cRechner-Gest&uuml;tzter Unterricht, RGU '74, Fachtagung-ACU-Arbeitskreis Rechner-Gest&uuml;tzter Unterricht
#index569971


#*Interactive data entry and com output
#@
#t1979
#cProceedings of the 7th annual ACM SIGUCCS conference on User services
#index449467


#*A spline package in APL
#@Robert J. Korsan
#t1974
#cProceedings of the sixth international conference on APL
#index551904
#!Interpolation is the fundamental numerical technique used for approximating the operations of the calculus. Polynomial interpolation is the most often used form of interpolation. The past twenty five years nave seen the development of spline interpolation. Spline interpolation theory has become synonomous with many aspects of numerical analysis. The question is &ldquo;Why?&rdquo; It has not been generally recognized that polynomial interpolation has many defects when used to represent physical data. Polynomials are beautiful examples of analytic functions. This implies that their local behavior determines their global behavior. Anyone dealing with real world phenomena can tell you that phase changes, resonance properties, modal systems, etc. have precisely the opposite behavior. The simplest form of a spline is a collection of polynomials patched together so as to be smooth. The &ldquo;best approximation&rdquo; property of splines is responsible for their leading role in numerical analysis. This paper will, provide a very brief introduction to spline theory and in particular cubic splines. It will also describe a package which has been developed on the Scientific Time Sharing Corporation's APL PLUS (registered trade mark) system. The areas of application to be discussed include mathematics, statistics, engineering, simulation and finance.


#*Renamings in program schemas
#@Luigi Logrippo
#t1972
#cProceedings of the 13th Annual Symposium on Switching and Automata Theory (swat 1972)
#index398008


#*Polytechnic Institute of New York MRI Symposium on Computer Software Engineering
#@
#t1976
#cComputer
#index345591


#*General purpose problem solving using simulated human judgement
#@Cathy Jo Thompson Linn
#t1978
#cProceedings of the 16th annual Southeast regional conference
#index615964
#%197130
#!This paper presents an alternative or possible addition to techniques used in general purpose problem solvers. A technique described by Jeffrey and Ossorio to simulate human judgment is applied to general problem solving. Human judgments on the degree to which objects are important to processes, (solution methods,) are factor analyzed and formed into a judgment space of orthogonal vectors. This space is consulted to choose a solution method based on the attributes of the available objects. The result is a system which decides "how" to solve a problem in much the same way a person would.


#*Automation of the radioisotope accountability system
#@Elaine L. Lahners
#t1965
#cCommunications of the ACM
#index334517


#*Division and square root in the quarter-imaginary number system
#@Morton Nadler
#t1961
#cCommunications of the ACM
#index329917
#%323591


#*Version spaces: an approach to concept learning.
#@Tom Michael Mitchell
#t1979
#c
#index204500


#*Projective coordinates and rigid motions in the plane of two complex variables interpreted in argand four-space
#@Wilbur Carrington Whitten, Jr.
#t1961
#c
#index200837


#*An environment for research in microprogramming and emulation
#@Robert F. Rosin,Gideon Frieder,Richard H. Eckhouse, Jr.
#t1972
#cCommunications of the ACM
#index321707
#%331310
#!The development of the research project in microprogramming and emulation at State University of New York at Buffalo consisted of three phases: the evaluation of various possible machines to support this research; the decision to purchase one such machine, which appears to be superior to the others considered; and the organization and definition of goals for each group in the project. Each of these phases is reported, with emphasis placed on the early results achieved in this research.


#*Vector computations in an array computer.
#@Tomas Lang-Korpel
#t1974
#c
#index195929


#*Supplementary terminology for nonlinear iterative methods
#@J. E. Dennis,R. A. Tapia
#t1976
#cACM SIGNUM Newsletter
#index99930
#%115501
#%283978
#!The purpose of this note is to suggest a supplement to the terminology of [7] and [9] for nonlinear iterative methods for solving F(x) = 0. We feel such a supplement is needed because it is now clear that the so-called <u>quasi-Newton</u> [1], or <u>variable metric</u> [2], or <u>modification</u> [7] methods are here to stay. Furthermore, the current working terminology for these methods is separate, non-standard and not sufficiently suggestive of their proper place in an overview of nonlinear iterative methods. This is borne out by the comments one always encounters when explaining the subject to the uninitiated. One explanation for this dilemma could be that these methods have essentially arrived after the last systematic attempt to standardize nomenclature [7].


#*Community memory: a public information network
#@Ken Colstad,Efrem Lipkin
#t1975
#cACM SIGCAS Computers and Society
#index303457
#!This brief summary of an article by Colstad and Lipkin is exerpted from the full length article which appeared in an IEEE proceedings. It is included here as an introduction to the next paper, Implications of Community Memory. Both papers illustrate a paradox which may be seen in many "people's computing" groups. While attempting to bring the computer into useful daily interaction with a variety of citizens for a variety of applications, such groups often unwittingly reinforce myths about computers which, as Berk notes, are a primary obstacle to social acceptance of the technology as a tool for society. Although the experiment and its acceptance are interesting, the myths of the computer as brain and the computer as question answering machine have not been dispelled by operation of the public information network. Perhaps the myths have been strengthened by the enthusiasm of the proponent groups.


#*Predicting fault detectability in combinational circuits - a new design tool?
#@John L. Fike
#t1975
#cProceedings of the 12th Design Automation Conference
#index550186
#%197705
#!This paper examines procedures for estimating the probability of detecting a logical fault in a combinational network. The prediction methods are based upon the characteristics of the circuit element, the interconnections, and the faults; they do not require generation of any test patterns or simulation of the network. The procedures are developed through the use of existing switching algebra and fault collapse techniques, combined with elementary probability theory. While the goal was to derive a general procedure for accurately predicting fault detectability networks, subsequent analysis indicated that detection probabilities would only be estimated without resorting to simulation. The results have been verified using an existing test generation and simulation system. Extensions to sequential circuits are discussed. This approach may improve the cost-effectiveness of existing test generation systems, and may provide a means of estimating the difficulty of production testing of a proposed logic design.


#*Thick film substrate (Micropackage) design utilizing interactive Computer Aided Design systems
#@Freddie M. Christley
#t1977
#cProceedings of the 14th Design Automation Conference
#index549481
#!Honeywell Information System, Inc. in Phoenix, Arizona utilizes Computer Aided Design (CAD) systems with graphics capabilities and online data bases to design, build and test thick film substrates. The thick film substrate is enclosed in a metal housing with edge connections and is called a Micropackage.


#*Random access file organization for indirectly addressed records
#@Charles A. Olson
#t1969
#cProceedings of the 1969 24th national conference
#index544722
#%317208
#!Random access file organization is discussed for the case of indirect addressing and a high rate of additions and deletions. The equations derived for this special situation are substantially different from those usually used in estimating file requirements. Graphs are included which make it possible to estimate file utilization and overflow, as shown in several simple examples.


#*Les Algorthmes de Coordination dans la M&eacute;thode Mixte d'Optimisation &agrave; Deux Niveaux
#@G. Grateloup,A. Titli,T. Lefèvre
#t1973
#c5th Conference on Optimization Techniques, Part 1
#index562398


#*Signal corps research and development on automatic programming of digital computers
#@William F. Luebbert,Percy W. Collom, Jr.
#t1959
#cCommunications of the ACM
#index318292


#*Delay test generation
#@E. R. Hsieh,R. A. Rasmussen,L. J. Vidunas,W. T. Davis
#t1977
#cProceedings of the 14th Design Automation Conference
#index548491
#%544869
#%545701
#%554333
#%553243
#%553430
#!Conflicting needs complicate the task of testing LSI chips. As system designs come to require better and more predictable performance, it becomes increasingly difficult to develop tests for application at the product I/O pins to verify that each internal device has been manufactured correctly. Any of numerous kinds of random manufacturing defect, though allowing correct dc operation, can cause a device to perform at a speed below that specified for it. This type of defect has led to the development of several testing methods that have become conventional. For numerous reasons, however, the conventional methods cannot be extended to LSI without certain design constraints. For the LSSD&mdash;level-sensitive scan design&mdash;constraints, dc fault-oriented testing has been extended to delay faults. The strategy is to delay-test each block input and/or output in both its longest and its shortest sensitizable delay paths. An algorithm for automatic generation of such delay tests has been developed, and extended to generate delay tests for designer-specified critical paths.


#*State Assignments for Asynchronous Sequential Machines
#@Chung-Jen Tan
#t1971
#cIEEE Transactions on Computers
#index339381
#!In this paper, a heuristic state assignment algorithm for asynchronous sequential machines is presented. Machines realized by this assignment scheme will result in circuits having a small amount of gate inputs and operating in single transition time. It is also shown that for a flow table having m1input columns, m input variables, and d stable states, the number of gate inputs required


#*The chip layout problem: A placement procedure for lsi
#@K. H. Khokhani,A. M. Patel
#t1977
#cProceedings of the 14th Design Automation Conference
#index547565
#%554378
#%553101
#!This paper presents a placement technique for allocation of logic gates to locations. The placement technique involves four different procedures, namely, constructive placement, linear assignment of signal I/Os, pairwise interchange, and wirability evalution. The constructive procedure generates an initial placement configuration by adjoining logic gates (vertices) to a subset (nucleus) of already placed gates on a chip. This is followed by linear assignment of signal I/Os. A neighborhood-biased pairwise interchange procedure improves the initial placement by minimizing the total conductor length, and also utilizes wirability evaluation as a placement selection criterion.


#*Knotted list structures
#@J. Weizenbaum
#t1961
#cProceedings of the 1961 16th ACM national meeting
#index548040
#%318294
#%324059
#%334426
#!In (3) Perlis and Thornton describe a list structure language the central innovation of which is that the last word of each list specifies the location of the head of the list of which it is the terminal word. They call such list structures threaded lists. Beyond this, however, they hypothesize Sequencing Tables and associated sequencing modes (e, l, and w). The sequencing modes make possible forms of traversing list structures which leave the lists themselves undisturbed in memory. Since the Sequence Table can contain true names as well as aliases for particular list structures and since lists are undisturbed by sequencing, many programs may sequence through lists in different manners, at various rates, but still simultaneously. This partially mitigates against the need to store many copies of a list and becomes critical in multiple computer systems in which it may be expected that a number of sub-programs operate on a single list structure (under various aliases) independently. This note describes a generalization of the threaded list. The name given to such generalized threaded list structures is knotted list structures (KLS). The generalization consists essentially of replacing the thread link which Perlis and Thornton place in the R or link position of the last list cell of a list (or sub-list with a Control List (CL) which is attached to the list structure and which contains, among other information, a push down list capable of storing many thread links. The chief advantage of this scheme is that it permits a sub-list to be a sub-list of many lists, something which ordinary threaded lists do not permit. All other advantages of threaded lists are kept.


#*Implementation of a tagged architecture for block structured languages
#@L. N. McMahan,E. A. Feustel
#t1973
#cProceedings of a symposium on High-level-language computer architecture
#index312137
#!This paper describes the implementation of a tagged architecture for a block structured language. First a model for the environment of block structured languages based on an extension to MADCAP VI is developed. Then the implementation of the model in hardware is described.


#*A linear algebraic theory of complexes
#@Lloyd Wayne Johnson
#t1941
#c
#index192455


#*The evaluation of periodic functions with large input arguments
#@J. Y. Wang
#t1978
#cACM SIGNUM Newsletter
#index103230
#!The argument reduction scheme plays an important role in the evaluation of periodic functions. In this report we discuss the criteria for determining the domain of computer routines that evaluate periodic functions, and apply the results to the widely used sine and cosine functions.


#*Molecular stochastics: a study of direct production of stochastic sequences from transducers.
#@James Roland Cutler
#t1975
#c
#index186888


#*Analysis of a multiprocessor system with a shared bus
#@L. L. Kinney,R. G. Arnold
#t1978
#cProceedings of the 5th annual symposium on Computer architecture
#index552987
#!An analysis for a multiprocessor system with a shared bus is given. The analysis applies to application areas where the task to be performed can be partitioned into largely independent subtasks. Each subtask requires cyclic execution on continuous data input. The objective is to determine the processing power of such a system as the number of subtasks or, equivalently, as the number of processors is increased. First, it is assumed that the partitioning of the task can be done without incurring any overhead in processor execution time (E) or bus usage time (I). Upper bounds on the processing power are determined that are independent of the bus type and bus allocation scheme. The upper bounds are functions of the number of processors and the ratio (E/I). The upper bound on processing power increases linearly with the number processors until it reaches the value E/I. Secondly, it is assumed that the partitioning causes an overhead in processor execution time and bus usage time that increases linearly with the number of processors. If the processor execution overhead predominates, then the number of processors required to obtain maximum processing power is greatly increased and the maximum processing power attainable is limited by the overhead factor for any E/I. If the bus usage overhead predominates, then the maximum attainable processing power is reduced and is reached with fewer processors, i.e., the bus is saturated with fewer processors. Thirdly, a specific bus allocation scheme is analyzed namely FIFO, assuming randomly distributed processor execution and bus usage times with average values E and I, respectively. In this case, the processing power is lower than what is ideally attainable (partitioning without overhead) for any value of n. As n becomes large, the maximum approached is the same as in the ideal case.


#*Programmed error recovery for APLSV
#@Richard Grossman
#t1976
#cACM SIGAPL APL Quote Quad
#index239166
#!This paper describes a facility for programmed error recovery, comparable to PL/I ON conditions, which has been implemented in APLSV.


#*Algorithm 300: Coulomb wave functions
#@J. H. Gunn
#t1967
#cCommunications of the ACM
#index319207


#*An optimal control algorithm applicable to real-time river basin management.
#@Quentin Ware Martin
#t1974
#c
#index196311


#*An attribute description of a subset of Algol 68
#@M. Simonet
#t1977
#cProceedings of the Strathclyde ALGOL 68 conference
#index554886
#%324137
#%331016
#%550024
#!Among the formalisms used for the definition of programming languages, context-free grammars are widely and satisfactorily used, but their power is limited. Augmented with attributes they can express context sensitive aspects of a language. In this paper a subset of Algol 68 is described by an attribute-grammar. This is done in a way which suggests that the attribute point of view may also help reading and writing W-grammars.


#*Vector representation of switching and three-valued functions
#@Ytzhak Levendel,Melvin A. Breuer
#t1978
#cProceedings of the eighth international symposium on Multiple-valued logic
#index555311
#!In this paper we present a new vector representation for switching functions, where two or three-valued logic systems are employed. Using this representation, rules for carrying out numerous operations are presented such as vector AND, OR and complementation; Boolean difference; vector reduction; and substitution of 0, 1 or u for the variables. Hence complex operations classically carried out over large Boolean expressions can now be more easily carried out using simple algorithms which operate over the components of these new vector representations.


#*Optimal checkpointing in real-time multiprogramming systems.
#@Nadim Fauzi Daouk
#t1979
#c
#index188167


#*Another method of converting from hexadecimal to decimal
#@M. V. Kailas
#t1970
#cCommunications of the ACM
#index315769
#%81323
#!There is a simple paper-and-pencil method of converting arithmetic a hexadecimal number N to decimal.


#*Performance Evaluation of the BASIS System
#@Reind P. van de Riet
#t1979
#cProceedings of the Third International Symposium on Modelling and Performance Evaluation of Computer Systems: Performance of Computer Systems
#index255521


#*A Program Generator Package For Management Of Data Files&mdash;The Input Language
#@Lewis M. Norton
#t1978
#cProceedings of the 1978 annual conference
#index553712
#%316195
#%549845
#!After a brief discussion of the use of existing program generators, this paper discusses a new, integrated package of generators of programs which perform manipulation of sequential data files. The generated programs create, update, validate, and reformat data sets, invert textual data, and produce reports. Emphasis in the paper is placed on the semantics and syntax of the statements used as input to the generators. Alternatively, this may be viewed as the design of a new, non-procedural, special-purpose, high-level language for data manipulation. The term conceptual record is defined to be the set of logical records pertaining to a subject. Input and output in the generated programs is done in terms of conceptual records. A detailed example of a conceptual record description is given and discussed to illustrate the flavor of the new package. Brief remarks on individual generators in the package conclude the presentation.


#*Improving the Efficiency of Matrix Operations in the Numerical Solution of Stiff Ordinary Differential Equations
#@W. H. Enright
#t1978
#cACM Transactions on Mathematical Software (TOMS)
#index316936
#%331454
#%322467
#%457304


#*Machine generation of assignments for a mass education introductory programming course
#@Leonard H. Weiner
#t1973
#cProceedings of the third SIGCSE technical symposium on Computer science education
#index549068
#%198708
#%326215
#%328080
#%335559
#%552312
#!In any classroom, students vary in their background and aptitudes. It has long been recognized [6] that, ideally, each student should receive instruction and assignments geared to his own particular ability to perform: Weaker students should receive additional instruction and less demanding assignments; stronger students should be challenged by more complex or thought-provoking problems. In practice, however, many classes, especially in the introductory courses, have too many students for the instructor to provide such individualized attention. The slower students must struggle, often without much success, to keep up with the others, while some of the brighter ones become bored by it all.


#*Technical market analysis using a computer
#@John Hansen
#t1956
#cProceedings of the 1956 11th ACM national meeting
#index546412
#!The subject of this paper is the use of an electronic computer for the technical analysis of stock charts. No new methods for prediction of stock fluctuations will be presented; but merely procedures currently being developed for speeding up the use of some well-known methods. These procedures are being developed under contract with one of the large New York brokerage houses as an initial step in the use of electronic computation for accomplishing day-to-day market analysis.


#*On the experience of riding two horses in programming
#@Anatoly Buda
#t1979
#cProceedings on Algorithms in Modern Mathematics and Computer Science
#index267024


#*The minuteman communication network simulator
#@W. V. Neisius,E. D. Katz
#t1968
#cProceedings of the second conference on Applications of simulations
#index546458
#!This is a case history of a very versatile and complex Simscript simulation which has been completed and successfully used since December 1965. Several points are of interest: first, the original approach took maximum advantage of Simscript by concentrating upon the development of a quick and simplified model which could be expanded as additional system details were made available; second, the analysis reports went through a number of versions as experimentation goals were modified; and, finally,the simulation was responsible for uncovering potentially significant system problems.


#*The residue calculus in several complex variables
#@Gerald Leonard Gordon
#t1968
#c
#index187521


#*Microsystems Interview with an Entrepreneur
#@
#t1977
#cComputer
#index339362
#!Not too long ago, Bob Moody's idea of a computer store was a warehouse full of used 360's. At least, that's what first came into his mind when Paul Terrell suggested they pool their resources to open shop. Now just two years after the two of them founded the original Byte Shop (there are currently over 40 individually owned Byte Shops across the country), Moody is, one of the most seasoned entrepreneurs in the personal computing movement. He and Terrell parted company in 1976, "because of capitalization problems." With Bob Spitler, another computer enthusiast, Moody today owns the Byte Shop in Palo Alto, California. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*An ALGOL compiler: construction and use in relation to an elaborate operating system
#@J. C. Boussard
#t1966
#cCommunications of the ACM
#index326787
#%328020
#!An ALGOL translator has been prepared and integrated into the IBSYS Operating System. Assembly and &ldquo;go&rdquo; features of IBSYS permit immediate execution with optional listings, decks and debugging information. Using the chain feature of IBSYS, links written in MAP or FORTRAN as well as ALGOL may be called by the ALGOL main program. In addition, procedures coded in MAP may be included in any ALGOL program. Although assembly plus loading time exceeds compilation time, the total time is satisfactory and the user gets ease and facility which are fully compensating.


#*A structured specification of a hierarchical operating system
#@Ashok R. Saxena,Thomas H. Bredt
#t1975
#cProceedings of the international conference on Reliable software
#index551975
#%316233
#%332514
#!This paper applies the concepts of hierarchical levels of abstraction and structured programming to the design of a large program system. An operating system for a multi-processor installation is specified that supports a large number of concurrently active processes and provides a virtual store for them. The specification is in an extended version of PASCAL, a high-level language.


#*Hierarchical properties of flows, and the determination of inner loops.
#@Bernard Marcel Mont-Reynaud
#t1978
#c
#index199441


#*Complex Disjunctive Decomposition of Incompletely Specified Boolean Functions
#@S. L. Hight
#t1973
#cIEEE Transactions on Computers
#index347967
#!In this paper the Ashenhurst-Curtis theory of complex disjunctive decompositions is extended to the realm of incompletely specified Boolean functions. A compatibility relation on the column vectors of the decomposition chart is introduced, which is applied to identify all possible simple disjunctive decompositions for each input partition. The assignments of the DON'T CARE (f) conditions that are required to realize these simple decompositions are described by a vector listing the constraints on these f's by new Boolean variables caled constrained DON'T CAREs. A compatibility relation is introduced on these vectors, caled constrained Boolean vectors, which is applied to form complete decompositions. A Complete decomposition is one for which al possible simple decompositions have been combined into a complex decomposition. Throughout the procedure, the freedom of choice implied by the f's is maintained as far as is alllowed by the choices that have been made to achieve the decompositions.


#*Sixth Data Communications Symposium 1979
#@
#t1979
#cComputer
#index346050


#*Some Design Features of a Sparse Matrix Code
#@I. S. Duff,J. K. Reid
#t1979
#cACM Transactions on Mathematical Software (TOMS)
#index334541
#%317092
#%457404


#*Activities of the DOE Advanced Computing Committee Language Working Group
#@Rondall E. Jones
#t1978
#cProceedings of the SIGNUM Conference on the Programming Environment for Development of Numerical Software
#index554187
#!The Language Working Group is a technical arm of the DOE Advanced Computing Committee. The purpose of the Group is to work toward providing a compatible Fortran environment at the ACC sites. A brief history of the efforts of the Group is given, and the general features of the language the group will recommend are discussed. This language is a multi-level Fortran with Fortran 77 as the core.


#*"SGP": a simple graphics package
#@Richard E. Putnam,Ralph L. Carmichael
#t1976
#cACM SIGGRAPH Computer Graphics
#index254012
#!This paper presents a simple scheme for manipulating graphical information. The basic idea is to generate a user-readable, and therefore editable, file of device-independent picture descriptions. This file would typically be created by a set of FORTRAN-callable subroutines, each having a specific function (draw a vector, draw an axis, write text), but could be created in more direct ways by a user sufficiently familiar with the file structure. Once such a file has been created and perhaps examined and edited, a postprocessor may be selected to translate the file into the device-dependent instructions necessary to produce a picture on a specific device. If the file is saved, a different postprocessor could obviously be used later to generate the same picture on another device.


#*The application of computer simulation techniques to glassware production
#@J. A. Runner,W. Hand,O. J. Meyers
#t1979
#cProceedings of the 11th conference on Winter simulation - Volume 2
#index551675
#!Rising costs, changing product mix, and expanding technology have left engineers with a perplexing problem; how should we design and run the manufacturing system of the early 1980's? This was indeed the question posed for the production of a well known brand name of glassware. Rising production costs were eating away at profits and changing product mix was contributing to the problem through a reduction in productivity efficiencies. Further, expanding technology developed new processes that somehow had to be efficiently added to the manufacturing process. This paper describes how simulation was used to identify the key variables which were used to determine the best operating strategy and equipment design. In addition, and more importantly, a synopsis is presented explaining why simulation was chosen as the analysis technique (along with its advantages and disadvantages) and the problems encountered throughout the analysis.


#*SIGACT (Tutorial Session)
#@Michael Harrison,Susan Graham,Kenneth Kennedy
#t1976
#cProceedings of the 1976 annual conference
#index546446
#!This session surveys some advances in theoretical computer science and their impact on the design of programming language compilers. The emphasis is on three major areas: the analysis of program syntax, the detection of errors at compile time, and the optimization of compiled code. The tutorials presented here do not purport to summarize all the work that has been done, but they will capture its flavor and demonstrate its practical importance.


#*Innovative applications of computer science
#@Bertram Raphael
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index63975
#!For many years much of the research frontier of computer science as represented, for example, by the activities of artificial intelligence laboratories, seemed preoccupied with esoteric mathematical studies (such as self organizing systems, algebraic theory of machines, or resolution theorem proving), "toy" systems (such as games, puzzles, children's blocks), or far-out science fiction goals (such as robots for space exploration). Now many of these same laboratories are applying the techniques they have developed in the past to important, short term, real world tasks---and uncovering significant new research problems in the process. By working in new interdisciplinary teams, the computer scientists and the applications specialists have begun to develop an evolving series of novel systems whose potential value to our society is tremendous.


#*Computers help solve problems in multinational corporations
#@E. Jane Powanda
#t1979
#cProceedings of the 1979 annual conference
#index546060
#!A broad picture is presented of the ways that computers have been and can be utilized by companies dealing in international business. Emphasis is placed on the use of the computer as a management tool, the use of the computer to bring corporate headquarters and foreign subsidiaries closer together, and on some of the new problems created by international computer usage that will require resolution in the next decade.


#*Special control structures for APL
#@A. P. Reeves,J. Besemer
#t1978
#cACM SIGAPL APL Quote Quad
#index252645
#%553871
#%554218
#%547036
#%551440
#!The problem of consolidating the block control structures of conventional programming languages such as ALGOL within the framework of APL is discussed. A novel partial solution is proposed by the introduction of special new basic functions to APL. One of the main design considerations of these functions is to maintain the current structure of APL as far as possible.A preprocessor to enable simple implementation of these structures without modification to existing APL interpreters is described. Some program examples using these new functions are given.


#*Symmetric solutions of the modified no-three-in-line problem for even boards
#@Jainendra K. Navlakha
#t1979
#cProceedings of the 17th annual Southeast regional conference
#index621481
#!An algorithm for generating symmetric solutions of the modified no-three-in-line problem for the square boards of even size is presented. The correctness of the algorithm for arbitrarily large square boards is established. A computer program in PL/I was written and executed on the UNIVAC 1108 computer to generate the solutions for some boards of even size.


#*Interactive simulation with GASP IV on a minicomputer
#@Mark A. Fox,A. Alan B. Pritsker
#t1975
#cACM SIGSIM Simulation Digest
#index580514
#%580984
#!In this paper, the implementation of an interactive version of GASP IV, a FORTRAN-based discrete/continuous simulation language (1,2,3) is described. Interactive GASP IV was implemented on a General Automation SPC 16/65 mini-computer configured with 16K words of core memory and operating under the control of a disk based operating system (4). All features of GASP IV are included in the interactive version. A list of the subprograms of GASP IV is presented in Figure 1 (5). In addition, four forms of real-time man-computer interaction have been designed into Interactive GASP IV:1) online presentation of simulated system status on requests through the use of clearly formatted reports and plots;2) free formatted online data input of GASP variables and model parameters;3) programmed decision events requiring online responses as part of the discrete event structure; and4) user intervention in an executing program through keyboard interrupts.


#*Remark on &ldquo;Algorithm 528: Framework for a Portable Library [Z]&rdquo;
#@Phyllis Fox
#t1979
#cACM Transactions on Mathematical Software (TOMS)
#index316808


#*A system model for computer performance evaluation
#@D. J. Kuck,B. Kumar
#t1976
#cProceedings of the 1976 ACM SIGMETRICS conference on Computer performance modeling measurement and evaluation
#index550777
#!A framework for the study of computer capacity is given by means of a definition of capacity in terms of speeds of various parts of a computer as well as memory size. In addition to these machine parameters, we also include certain parameters of the programs to be run on a given machine. The calculation of theoretical capacity is given for several combinations of processor, memory, and I/O bandwidth for overlapped machines. The tradeoff between primary memory size and I/O bandwidth is discussed in terms of the new definition.


#*SIGACT (Paper Session)
#@George T. Ligler William C. Nylin, Jr. Patrick Wang Patrick C. Fischer,Robert L. Probert
#t1976
#cProceedings of the 1976 annual conference
#index548789
#!These papers indicate the diversity of the theoretical area of computer science. The first explores programming language concepts in terms of Hoare's formal assignment axiom. The second is well described by its title. The third is a contribution to formal language theory, and the last paper adapts a &ldquo;divide and conquer&rdquo; technique to a paging environment.


#*Depth-first digraph algorithms without recursion
#@
#t1977
#cACM SIGCSE Bulletin
#index553331
#%79620
#%170184
#%552803
#!After having taught the design of algorithms for more than ten years I still find that recursive algorithms are much too difficult for most computer science students. There seem to be two problems: the students are unable to grasp the essence of an algorithm in a recursive setting, and they rarely have any knowledge of the mechanisms underlying recursive calls. In view of the above it was thought useful to translate a number of recursive algorithms into nonrecursive form for classroom use. Tarjan's depth-first search algorithms for digraphs (4,5) were selected because they are sufficiently important to require their study in some computer science course or other. The translation consists of making the depth-first search tree of the digraph explicit, and letting tree traversals take over the role of recursion. The nonrecursive algorithm for topological ordering of an acyclic digraph will be our example here. This algorithm is used to preprocess a scheduling network before it is subjected to critical path analysis.


#*Pseudochaining in hash tables
#@Constantine Halatsis,George Philokyprou
#t1978
#cCommunications of the ACM
#index334115
#%315947
#%317208
#%324107
#%324207
#%331163
#!This paper presents pseudochaining as a new collision-resolution method. Pseudochaining is half way between open addressing and chaining. It owes its name to the fact that link fields are present in each cell of the hash table which permits &ldquo;chaining&rdquo; of the first overflow items in the table. The efficiency of the method is derived and a tradeoff analysis is given.


#*The development of the MU5 computer system
#@R. N. Ibbett,P. C. Capon
#t1978
#cCommunications of the ACM
#index329396
#%315887
#!Following a brief outline of the background of the MU5 project, the aims and ideas for MU5 are discussed. A description is then given of the instruction set, which includes a number of features conducive to the production of efficient compiled code from high-level language source programs. The design of the processor is then traced from the initial ideas for an associatively addressed &ldquo;name store&rdquo; to the final multistage pipeline structure involving a prediction mechanism for instruction prefetching and a function queue for array element accessing. An overall view of the complete MU5 complex is presented together with a brief indication of its performance.


#*Selected annotated bibliography on software engineering
#@Karl Kleine
#t1978
#cACM SIGSOFT Software Engineering Notes
#index437651


#*The configurational optimization of computer systems.
#@Swatantra Kumar Kachhal
#t1974
#c
#index190080


#*Coming changes in system analysis and design
#@Richard G. Canning
#t1966
#cProceedings of the 1966 21st national conference
#index552841
#%330721
#!System analysis has been defined as &ldquo;the examination of an activity, procedure, method, technique or a business to determine what must be accomplished and how the necessary operations may best be accomplished&rdquo;.1 The definition really covers both system analysis and design&mdash;determining what is required and how best to accomplish it. In business data processing, a number of levels of system analysis have been observed. Table 1 lists several of these levels, starting at the lowest level&mdash;for the conversion of applications to a computer. The highest level of system analysis deals with the missions and goals of the whole enterprise; this type of system analysis might be compared with that performed at the highest levels in the Department of Defense.


#*On-line index term predictions using bigram-term associations
#@Jon T. Rickman,Harry W. Gardner
#t1973
#cProceedings of the ACM annual conference
#index551540
#%186311
#%323425
#!Predicting index terms (or keywords) by examining a word's component letter strings is investigated. The weights or string-term associations for the letter strings are determined by using relative frequencies computed from a representative sample of the total abstract (or document) collection. The experimental results indicate that the terms predicted by using bigrams (letter pairs) are effectively the same as those predicted by using bigrams and longer letter strings.


#*The computation of connected regions in interactive graphics
#@Janice R. Lourie
#t1969
#cProceedings of the 1969 24th national conference
#index550248
#!This paper addresses the problem of automatically identifying and labeling the connected regions formed by sets of closed curves. This is a general problem encountered in interactive computer graphics, where an arbitrary pattern is transmitted via a digitizing device such as a data tablet and a stylus, or CRT and light pen. Area calculations for these connected regions are also briefly discussed. Two programmed algorithms are presented which accomplish these functions. The first operates on a completed pattern and is most efficiently applied to small patterns. The second is a dynamic generalization of the first. It permits segmentation of the original pattern and does identification and labeling of connected regions of any part of the pattern. It also permits modification of isolated parts of the pattern and accomplishes the necessary reidentification and relabeling. It is applicable to patterns which are many times the size of the original data tablet or screen. The paper also presents a specific application of this generalized algorithm to a problem requiring dynamic data handling.


#*Management and computers
#@
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index72234


#*Simulation of executing robots in imperfectly known environments
#@L. Siklossy,J. Dreussi
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index57634
#!A simulated robot solves tasks in environments which she knows only approximately. The robot is given a description of the environments and of her capabilities. From the latter, she generates procedures that are evaluated to solve tasks. As tasks are solved, the robot improves her knowledge of the environment and the efficiency with which she can solve problems. Unknown, correctly known, and incorrectly known facts are treated in a uniform manner. The design used, that of an executing robot, is contrasted to the design of planning robots. Executing robots may also be used to plan in perfectly known environments and are usually more efficient than planning robots. In imperfectly known environments, planning robots are inadequate.


#*Array reference operations
#@J. B. Hext
#t1975
#cProceedings of the conference on Programming languages and compilers for parallel and vector machines
#index554213
#!An examination is made of the different ways in which APL and ALGOL 68 refer to cross-sections or other subsets of an array. It is noted that APL allows a variety of reference operations but no reference variables; on the other hand, ALGOL 68 has reference variables and parameters, but only one array operation. Two kinds of array reference are distinguished - the linear and the nonlinear - and a proposal is made for representing a linear reference by a simple form of descriptor, suitable for processing in hardware. The reference operations are then divided into those which give linear results and those which give non-linear. By retaining only the linear ones, it is possible to combine the main advantages of the APL and ALGOL 68 operations into a single system. A discussion is given of some of the issues involved, including those of dynamic types and bounds.


#*Microprogramming technology
#@
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index58589


#*Turning on the undergraduate computer science student: A RE-IPL suggestion
#@Edward L. Schulman
#t1977
#cACM SIGCSE Bulletin
#index548356
#!The School of Advanced Technology currently has a number of courses that are used to better acclimate students on the graduate level to an industrial environment. This paper describes a two-course sequence designed for the undergraduate level that serves the same purpose.


#*Link implementation techniques
#@Robert M. Long
#t1978
#cProceedings of the 16th annual Southeast regional conference
#index617540
#%195172
#%330186
#!The physical representation of DBMS data models involves representing logical relationships via connections between data value occurrences. The collection of connections between two sets of data values is said to specify a link. In [D2] three distinct forms of link have been show to exist, each capturing distinct physical characteristics. The purpose of this paper is to extend the concept of a link so as to permit specification of various physical storage schemes. This extension thus enables a more precise definition of the physical representation of data models.


#*Education: Expenditures, sources of funds, and utilization of digital computers for research and instruction in higher education: 1964-65 with projections for 1968-69
#@John W. Hamblen
#t1968
#cCommunications of the ACM
#index324682
#!The Southern Regional Education Board published a complete report on a survey it conducted to determine the funding and characterize the utilization of computers used for research and instruction in institutions of higher education in the United States. The sampling survey is described and the estimates for this total population are presented.


#*Computer Network Architectures
#@S. Wecker
#t1979
#cComputer
#index343902
#!This tutorial analyzes developments in computer network architectures from a top-down design viewpoint starting with user interface requirements, then developing a structure to realize that interface. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Planning for remote users
#@Frances Bardello Craig
#t1979
#cProceedings of the 7th annual ACM SIGUCCS conference on User services
#index443474
#!Technical and economic problems in accessing remote computers have virtually been eliminated. It is now feasible and economical, for a user to access remote computers through private or public data communications networks. From 1966 through the present, administrative issues in the sharing of computing resources among higher education and research institutions have been the topic of conferences, publications and experimentation. EDUCOM, the inter-university consortium of colleges, universities and research institutions, sponsors much of this activity regarding the sharing of computing resources. In 1974 EDUCOM established the Planning Council to more actively experiment with network issues. On July 1, 1979 the Planning Council's experiment in a national educational network, EDUNET, became an operational reality. EDUNET is supported by regular and sustaining membership fees. Carnegie-Mellon University has opted to become a supplier of computing services to the EDUNET network. This paper describes the issues considered in planning to service remote users. The paper uses Carnegie-Mellon as an example of a host site on EDUNET. Administrators in charge of user services organizations and/or computation centers who plan to sell their computing resources to a remote market will find this paper contains a useful checklist of items for consideration. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Review of data base administrators functions from a survey
#@Jean-Paul de Blasis,Thomas H. Johnson
#t1978
#cProceedings of the 1978 ACM SIGMOD international conference on management of data
#index627195
#%175053
#%555038
#!This paper reports some results from a survey of about thirty practicing data base administrators (DBA) in U.S. organizations of warying sizes and commitment to data base technology. From these observations some trends and evolutions of the data base administrator position are outlined. First, basic definitions and organizational considerations are set forth. The functions, interfaces and responsabilities of the DBA are discussed along with the DBMS tools available to carry out their tasks as recommended by various committees including CODASYL, GUIDE/SHARE, etc.Next, results of a survey of organizations staffed with data base administrators are presented. The survey stresses how the various recommendations regarding DBA implementation are reflected in reality and analyzes a number of significant parameters characterizing the DBA teams surveyed. An attempt to rationalize the aspirations and the actual status of the DBA is carried out. Finally, some trends in the evolution of the data base administration function are outlined from the survey results and from projections provided by the DBAs themselves. In light of these observations, some current recommendations are reviewed and others are proposed, especially with respect to the data administrator and data base administrator responsabilities.


#*A minicomputerized automatic layout system for two-layer printed wiring boards
#@Ikuo Nishioka,Takuji Kurimoto,Hisao Nishida
#t1977
#cProceedings of the 14th Design Automation Conference
#index546810
#%547930
#%551340
#%549828
#%551361
#!The requirement for high density packaging is dominant in the design of electronic systems. In the assembly of such systems multi-layer printed wiring boards are often used to provide the necessary connections among functional modules, and as the wiring density for a board ascends, an automatic scheme to realize 100 percent wiring would be more essential to reduce cost and time incurred in laying out wire pattern. Thus, methods to improve the layout of printed wiring boards are still continually under investigation. The present paper proposes an automatic layout system for two-layer printed wiring boards, which operates on a PDP 11/40 computer with 24K 16-bit words of core memory and with 1.2M words of disk storage, coupled with a TEKTRONIX 4014 display terminal in conjunction with a 4953 graphics tablet. This system has been at work, and more than 300 wiring boards of manufacturing use have been already processed automatically by this system, almost all with 100 percent routing realized. A part of such implemented results are also shown.


#*A psychology of learning BASIC
#@Richard E. Mayer
#t1979
#cCommunications of the ACM
#index322607
#!This paper addresses the question: What does a person know following learning of BASIC programming? Several underlying conceptual structures are identified: (1) a transaction is an event that occurs in the computer and involves some operation on some object at some location, (2) a prestatement is a set of transactions corresponding to a line of code, (3) chunks are frequently occurring configurations of prestatements corresponding to several lines of code.


#*A multiprogramming operating system for a minicomputer
#@Terry E. Weymouth,James T. Perry
#t1977
#cACM SIGCSE Bulletin
#index552797
#%553650
#%554687
#!Described in this paper is a small, modular operating system which was written for an Interdata-70 machine. The total operating system is memory resident and occupies 5K bytes. The primary motivation in redesigning the operating system was to structure it so that students and general system users could easily expand or modify the basic services of the supervising system. Towards this end, the following system principles are embodied in the design: (1) clearly defined separation of system functions, (2) separate object modules for each system routine, and (3) simple system design. Although specifics of implementation are discussed, general design concepts are covered which should aid the reader in any similar attempt (either by example or counter example).


#*A note: Top-to-bottom parsing rehabilitated?
#@R. A. Brooker
#t1967
#cCommunications of the ACM
#index329036
#%328874
#%330235


#*Adding capability access to conventional file servers
#@Roger M. Needham
#t1979
#cACM SIGOPS Operating Systems Review
#index117808
#%544652
#%546112


#*Television education in elementary school speech improvement
#@Morton J. Gordon
#t1966
#c
#index197598


#*Call for Papers 1979 Computer Networking Symposium
#@
#t1979
#cComputer
#index351105


#*On orthogonality in programming languages
#@B. T. Denvir
#t1979
#cACM SIGPLAN Notices
#index301315
#%189680
#%250122
#%450764
#%329080
#%335555
#%553246
#%319630


#*New release of BMDP programs
#@
#t1976
#cACM SIGSOC Bulletin
#index580348
#!The August 1976 version of the BMDP programs is now available from the Health Sciences Computing Facility. The new version can be obtained in load module form for IBM 360 and 370 or in source form. For details on ordering the new version, contact:BMD Program LibrarianHealth Sciences Computing FacilityUniversity of CaliforniaLos Angeles, CA 90024One program (P1F) has been rewritten, and four new programs have been added. Abstracts for these five programs follow.


#*Internal communications for external results
#@Rita Seplowitz Saltz
#t1977
#cProceedings of the 5th annual ACM SIGUCCS conference on User services
#index546644
#!(The conference session planned includes some discussion, followed by video-taped selections to prompt problem-solving by session participants. An instrument for evaluating internal communication may be developed. The quality of service and information that a computing facility provides to its computer users depends largely upon the quality of communication among the members of the installation's staff.


#*The accommodation of human characteristics in programming language design.
#@Bruce Hudson Stowell
#t1975
#c
#index187510


#*Algorithm 522: ESOLVE, Congruence Techniques for the Exact Solution of Integer Systems of Linear Equations [F4]
#@S. Cabay,T. P. L. Lam
#t1977
#cACM Transactions on Mathematical Software (TOMS)
#index325507
#%314994


#*APL[LAVAL] used as an interactive tool for the description, simulation and micro-programming of digital computers
#@Louis P.A. Robichaud,Yves Ouellet,Gerard Simian
#t1975
#cProceedings of seventh international conference on APL
#index552025
#%551342
#!This paper presents the use of APL [LAVAL] for the complete study of a digital computer at the micro-programmed control level. For us such a study signifies the description, simulation (i.e. behavorial description), and the creation of a set of micro-programming aids such as: an appropriate micro-programming language, its assembler and its linkage editor. A general and systematic approach will be presented concerning the description and simulation phase. This method has been used to study a number of existing machines and could be applied in the design phase of new machines.


#*Pattern recognition using associative memories.
#@Jeffrey Lynn Altman
#t1977
#c
#index199399


#*Computer expansion of Boolean expressions
#@Y. H. Chuang,C. C. Kao
#t1971
#cProceedings of the 8th Design Automation Workshop
#index545536
#%329080
#%332643
#!A computer oriented algorithm for symbolically expanding Boolean expressions containing &ldquo;and&rdquo;, &ldquo;or&rdquo;, and &ldquo;complement&rdquo; operators into their disjuntive normal form is presented. The algorithm consists of two parts in sequence. The first part applies the DeMorgan's laws, and the second part applies the distributive laws. Each part scans the expression only once, and performs the expansion directly while analysing the syntax. The one-pass feature is achieved through a syntax-oriented recursive approach. The most commonly used symbolic convention is assumed for the input and output expressions. The algorithm is believed to be machine-independent and efficient, and it can be easily implemented even on a small computer. The algorithm is found particulary useful in automation of switching circuit simplification and diagnostic test generation.


#*Reliability experience with Chi/OS
#@W. C. Lynch,J. W. Langner,M. S. Schwartz
#t1975
#cProceedings of the international conference on Reliable software
#index555313
#%199013
#%206277
#%327623
#%330803
#!The Chi/OS operating system, the latest large scale software effort of Chi Corporation, has had an excellent reliability record since its installation in November, 1973. Although the system design is vital to the reliability of Chi/OS, several environmental factors are equally vital. After a brief presentation of the substantial work load supported by Chi/OS, this paper deals with those environmental factors which contribute to the reliability of the software.


#*Conditional Capabilities
#@K. Ekanadham
#t1979
#cIEEE Transactions on Software Engineering
#index343109
#!Protection in capability-based operating systems is comsidered. The concept of a conditional capability, which is a generalization of a conventional capability, is proposed. The conditional capability can only be exercised when certain conditions relating to the context of its use are satisfied. It is shown that such capabilities form a basis upon which features such as domains of protection, revocation, and type extension can be built. The implementation of these features can be isolated into sepuate modules thus leaving the basic protection module uncluttered and simplifying the overall structure of the system.


#*A spatially iterated memory organ patterned after the cerebral cortex
#@Matthew Kabrisky
#t1961
#cProceedings of the 1961 16th ACM national meeting
#index547581
#!On the basis of anatomical explorations reported over sixty years ago, a rather complete block diagram of the &ldquo;wiring&rdquo; of the brain may be drawn. Unfortunately the function or mode of operation of many of the blocks are poorly understood even though we have remarkably accurate pictures of the fine structure. Our task is to fit some hypothetical model of brain operation into the (admittedly incomplete) set of restraints which are formed by the known aspects of structure and performance.


#*An investigation into computerized personnel management information systems: a prescriptive model.
#@Michael Neil Wolfe
#t1977
#c
#index191484


#*Fourier transform communication system
#@J. Salz,S. B. Weinstein
#t1969
#cProceedings of the first ACM symposium on Problems in the optimization of data communications systems
#index548417
#!The development of rapid algorithms for computation of the discrete Fourier transform has encouraged the use of this transform in the design of communication systems. Here we describe and analyze a data transmission system in which the transmitted signal is the Fourier transform of the original data sequence and the demodulator is a discrete Fourier transformer. This system is a realization of the frequency division multiplexing strategy known as &ldquo;parallel data transmission&rdquo;, and it is constructed in this manner so that the data demodulator, after analog to digital conversion, may be a computer program employing one of the fast Fourier transform algorithms. The system appears attractive in that it may be entirely implemented by digital circuitry. We study the performance of this system in the presence of typical linear channel characteristics. It is shown, via computer simulation and computation of the variances of errors, how the system corrects linear channel distortion.


#*Canonical observers in linear control systems
#@Muhammadi Siswosudarmo
#t1969
#c
#index192379


#*Complexity of Monotone Networks for Boolean Matrix Product
#@M. S. Paterson
#t1974
#c
#index197685


#*Affinit&auml;ten und Abstandsma&szlig;e von Verteilungen zur Sch&auml;tzung von Fehlklassifikationswahrscheinlichkeiten
#@Siegfried J. Pöppl
#t1979
#cAngewandte Szenenanalyse, DAGM Symposium
#index568400


#*An approach to optimal partitioning of hypergraphs
#@Giuseppe Alia,Piero Maestrini
#t1974
#cProceedings of the 1974 annual conference - Volume 1
#index552322
#!The problem of determining optimal partitions of hypergraphs (or, more simply of ordinary graphs), is relevant in several areas, such as computer aided design of printed boards, information retrieval and program paging. In many cases there exist optimal or near optimal partitions, subject to the constraint that each block is an LS set. Intuitively, an LS set is a subset of nodes of the given hypergraph, more strongly connected to each other that to the nodes in the complementary subset. This paper presents a polynomial-bounded procedure to determine all the LS sets in a given hypergraph.


#*Swift's technique
#@Millard H. Perstein
#t1961
#cCommunications of the ACM
#index316327


#*A note on variable order strategies for differential equation solvers
#@D. D. Warner
#t1976
#cACM SIGNUM Newsletter
#index96989
#%549235
#!In the design of a step-size and order monitor for the numerical solution of ordinary differential equations, the conventional wisdom holds that the monitor should start with a cautious first-order method. For example, Gear [1], Hindmarsh [2], Schryer [3], and Shampine and Gordon [4] require that the initial successful integration be accomplished with a first-order method. Of course these authors have other good reasons for their design besides mere caution. However, for stiff ODE's we will show that this restriction can lead the monitor to abandon perfectly reasonable problems.


#*System Development Corporation
#@Edward A Nelson
#t1968
#cProceedings of the 1968 23rd ACM national conference
#index551551
#!This paper discusses several comparatively recent contributions by System Development Corporation to the management of computer programming: a planning aid; cost estimation guides; and, a general project reporting and control system. These contributions and the process by which they were developed is considered in the context of traditional management practices, with the intention of establishing the extent to which these practices are, in fact, applicable to the management of computer programming.


#*An optimal real-time algorithm for planar convex hulls
#@F. P. Preparata
#t1979
#cCommunications of the ACM
#index324828
#%317222
#%547743
#!An algorithm is described for the construction in real-time of the convex hull of a set of n points in the plane. Using an appropriate data structure, the algorithm constructs the convex hull by successive updates, each taking time O(log n), thereby achieving a total processing time O(n log n).


#*Algorithm 346: F-Test Probabilities
#@J. Morris
#t1969
#cCommunications of the ACM
#index315490
#%314423
#%315363
#%327969
#%320192
#%333221
#%316143
#%322734
#%316181
#%318870


#*Applicative programming
#@R. M. Burstall
#t1979
#cProceedings of the 4th international conference on Software engineering
#index549792
#!The talk will discuss the advantages and drawbacks of the applicative style of programming, also called non-procedural or functional. This stems from &ldquo;pure LISP&rdquo;, although it is independent of the syntactic peculiarities of LISP, and is well-exemplified by Burge's book &ldquo;Recursive Programming&rdquo;. The idea is to do without assignment and rely on functions which produce results. Developments for this style include PROLOG and the school of logic programming, (Colmerauer,Kowalski), also the functional programming of Backus which avoids variables altogether, rather in the manner of combinatory logic. The author has recently been experimenting with the design of an applicative language, &ldquo;HOPE&rdquo;.


#*Quantitative aspects of software validation
#@Raymond J. Rubey
#t1975
#cProceedings of the international conference on Reliable software
#index554467
#!This paper discusses the need for quantitative descriptions of software errors and methods for gathering such data. The software development cycle is reviewed and the frequency of the errors that are detected during software development and independent validation are compared. Data obtained from validation efforts are presented, indicating the number of errors in 10 categories and three severity levels; the inferences that can be drawn from this data are discussed. Data describing the effectiveness of validation tools and techniques as a function of time are presented and discussed. The software validation cost is contrasted with the software development cost. The applications of better quantitative software error data are summarized.


#*Computer simulation for parameter estimation and target identification of three dimensional poisson processes.
#@Ali Zolfaghari
#t1975
#c
#index199664


#*Practical fast polynomial multiplication
#@Robert T. Moenck
#t1976
#cProceedings of the third ACM symposium on Symbolic and algebraic computation
#index553157
#%315363
#%327408
#%554545
#!The &ldquo;fast&rdquo; polynomial multiplication algorithms for dense univariate polynomials are those which are asymptotically faster than the classical O(N2) method. These &ldquo;fast&rdquo; algorithms suffer from a common defect that the size of the problem at which they start to be better than the classical method is quite large; so large, in fact that it is impractical to use them in an algebraic manipulation system. A number of techniques are discussed here for improving these fast algorithms. The combination of the best of these improvements results in a Hybrid Mixed Basis FFT multiplication algorithm which has a cross-over point at degree 25 and is generally faster than a basic FFT algorithm, while retaining the desirable O(N log N) timing function of an FFT approach. The application of these methods to multivariate polynomials is also discussed. The use is advocated of the Kronecker Trick to speed up a fast algorithm. This results in a method which has a cross-over point at degree 5 for bivariate polynomials. Both theoretical and empirical computing times are presented for all algorithms discussed.


#*Structure of a Polish String language for an Algol 60 language processor
#@Leonard S. Haynes
#t1973
#cProceedings of a symposium on High-level-language computer architecture
#index304578


#*Programmer attitudes and reactions towards programming productivity techniques
#@Edward Yourdon
#t1975
#cProceedings of the thirteenth annual SIGCPR conference
#index554795
#%333809
#%334039
#%458820
#%593112
#!Our purpose in this paper is to describe &ldquo;typical&rdquo; programmer reactions to various elements of PPT. We do this from the vantage point of having conducted well over 100 training seminars around the world, in which approximately 1500 programmers and analysts were exposed to structured programming, structured design, the chief programmer team concept, and so forth. It is our strong belief that if management can anticipate their staff's reaction to these new techniques, they should be able to alter their &ldquo;selling&rdquo; technique so that PPT will be presented in the most favorable possible manner: without doing this, there is a good chance that PPT will ultimately fail in the organization, and die a slow death of atrophy.


#*Session 15a: EDUNET (panel)
#@
#t1976
#cProceedings of the 4th annual ACM SIGUCCS conference on User services
#index248533


#*A Minicomputer Facility for Picture Processing and Pattern Recogniton Research
#@E. Persoon
#t1976
#cComputer
#index343466
#!The laboratory facility for pattern processing and advanced automation research at Purdue University has been specially equipped with hardware and software support for research in picture processing and pattern recognition in general. Fast acquisition and processing of speech signals, pictorial data, and three-dimensional scenes are possible, and the interactive capabilities of the system allow for fast software development.


#*An Approach to the Derivation of Compiler Descrition Concepts from the Mathematical Semantics Concept
#@Harald Ganzinger
#t1979
#cGI - 9. Jahrestagung
#index267554


#*Physical design of database structures
#@Lewis Benjamin Oberlander
#t1979
#c
#index197815


#*The equivalent circuits of shells used in airframe construction
#@R. H. MacNeal
#t1953
#cProceedings of the February 4-6, 1953, western computer conference
#index401767
#!In discussing elastic shells one must be careful to state clearly the type of shell being discussed. Although a complete description together with restrictive assumptions will be given later, it is well to state at the outset that the type of shell discussed in this paper is the type to be found in aircraft fuselage construction. Such a shell has an elongated shape and consists of a thin skin supported by rings and longitudinal members. In analyzing such shells it is the universal practice to replace the elastic supporting rings by rigid bulkheads in order to simplify the analysis. This assumption will not be made in this paper.


#*An information system for the planning and control of a food service operation
#@Albert L. Wrisley, Jr.
#t1971
#c
#index206004


#*Algorithm 349: polygamma functions with arbitrary precision [S14]
#@Georges Schwachheim
#t1969
#cCommunications of the ACM
#index322702


#*Experience with a high level micromachine simulator
#@S. Schleimer,W. J. Meyers
#t1979
#cProceedings of the 12th annual workshop on Microprogramming
#index545716
#%593112
#%546550
#%548291
#!As part of a microcoding project, we developed a simulator that offers a relatively high level view of a micromachine. The simulator supports all out a few features of the hardware, and provides a more friendly environment for the microprogrammer. In addition, the simulator supports a number of microprogramming conventions at a level inaccessible to the hardware. The simulator was implemented in a high level language, which contributed to its timely delivery and flexibility and did not detract from its efficiency. The simulator has been used to validate all of our microcode, with considerable success. Over 98% of microcode bugs have been found during simulation. The credibility of our microcode by the time it reaches hardware has also improved the detection and correction of hardware bugs.


#*Computer-aided logic design
#@Frank William Bliss
#t1971
#c
#index196317


#*Information for Authors
#@
#t1970
#cIEEE Transactions on Computers
#index335769


#*Coding the Lehmer pseudo-random number generator
#@W. H. Payne,J. R. Rabung,T. P. Bogyo
#t1969
#cCommunications of the ACM
#index325239
#!An algorithm and coding technique is presented for quick evaluation of the Lehmer pseudo-random number generator modulo 2 ** 31 - 1, a prime Mersenne number which produces 2 ** 31 - 2 numbers, on a p-bit (greater than 31) computer. The computation method is extendible to limited problems in modular arithmetic. Prime factorization for 2 ** 61 - 2 and a primitive root for 2 ** 61 - 1, the next largest prime Mersenne number, are given for possible construction of a pseudo-random number generator of increased cycle length.


#*QUILT (a.k.a. KWILT): A special purpose instructional language
#@Carl Eckberg
#t1978
#cACM SIGCSE Bulletin
#index555102
#%185213
#!The &ldquo;meaning&rdquo; of KWILT has been lost to etymological history. The K was in honor of D. Knuth, but this gives &ldquo;Knuth WILT&rdquo; which is a bit disconcerting. Indeed, there was a tendency to pronounce the language as &ldquo;kay-wilt&rdquo;, which offended veteran users as much as COBOL programmers would resent &ldquo;cobble&rdquo;. From: QUILT USER MANUAL and REFERENCE GUIDE


#*Microcomputers and the university computer center
#@Richard Stillman
#t1979
#cProceedings of the 7th annual ACM SIGUCCS conference on User services
#index439533
#!Because of current trends in the pricing of computer components, the makeup of the typical computer system is changing radically. Instead of large, multi-user systems built around a single CPU, there is a trend toward single user, dedicated application, and small timesharing systems. The computer center must take an active role in this transition by recognizing and supporting areas in which microcomputers are being introduced.I would like to acknowledge the assistance of Jane Wolin, Head of Programming of the CCIS, in developing the ideas expressed in this paper. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Generalized Inverse Approach to Adaptive Multiclass Pattern Classification
#@W. G. Wee
#t1968
#cIEEE Transactions on Computers
#index346758
#!Abstract In this paper a least-square approach to multiclass pattern classification is undertaken. The generalized inverse computation is used to furnish a quick solution to the problem of fixed training samples. The use of recursive on-line computation is also recommended. Experimental results are presented to illustrate the approach. Both deterministic and statistical interpretations have been given to the approach. The pattern classifier proposed by Chaplin and Levadi [1] and the adaptive pattern classifier proposed by Patterson and Womack [2] are special cases of this approach.


#*Towards a language for the description of IC chips: (part II)
#@Reiner W. Hartenstein
#t1973
#cACM SIGMICRO Newsletter
#index2239
#%7090
#!This paper is continuing as "part II" a paper out of the preceding number of SIGMICRO Newsletter. That preceding paper (for its title see ref. |10|) is referenced as "part I" in the following lines. (As in part I |10|, also in part II some of the ideas are half-baked ideas.) In part I a draft design has been given of a set of register transfer primitives (RTP) and a corresponding symbolic notation, as well as its block diagramm equivalent. Part I particularly aimed at the demonstration of the use of register transfer notations for modelling constructs known from the software field, as seen with the eyes of a hardware man.


#*Datschutz und Gesellschaft
#@Herbert Fiedler
#t1974
#cGI - 4. Jahrestagung
#index274215


#*Application of a logic fault analyzer to the manufacture and maintenance of the CONTROL DATA 7600 computer
#@Lionel C. Bening, Jr.
#t1971
#cProceedings of the 8th Design Automation Workshop
#index554872
#%546274
#!This paper describes the application of a sequential logic fault analyzer computer program to the problem of logic circuit module tests for the CONTROL DATA&reg; 7600 computer. A description of the sequential fault analyzer is provided first. Next, the software system built around this fault analyzer is outlined. The development of test sequences for 231 logic module types used in the 7600 computer is considered. Block diagrams of the test fixtures used at the manufacturing facility and to supplement field maintenance are provided and explained. Preliminary results of the application of fault analyzer developed tests are reported.


#*Preliminary Ada reference manual
#@J. D. Ichbiah
#t1979
#cACM SIGPLAN Notices
#index307288


#*Using Covariance Analysis as an aid to interpret the results of a performance measurement
#@Carlos González
#t1976
#cProceedings of the 1976 ACM SIGMETRICS conference on Computer performance modeling measurement and evaluation
#index552577
#%199076
#%330178
#%551317
#%553510
#!This paper reports on a measurement study of the Scheduler in the PDP-10 TENEX Operating System under normal loads in a Computer Science research environment at Case Western Reserve University. A complete description of the methodology and the results of a Covariance Analysis is presented here. The analysis was made in parallel with the analysis of the collected data, therefore a brief description of the experiments as well as some comments of the most interesting results are also discussed in this report. The complete report of the study is in Gonz&aacute;lez [5] which shall serve as a reference document for this paper.


#*A theory for discrete simulations: an application to major railway systems.
#@Albert Francis Jones
#t1976
#c
#index187709


#*An integrated analytical system for global range planning
#@T. E. Williamson
#t1967
#cProceedings of the 1967 22nd national conference
#index546250
#!The mental image formed upon the first attempt to focus on a problem of the scope involved in systematizing the planning and scheduling functions of a space vehicle tracking range is truly overwhelming (Figure 1). Further investigation, however, while not diminishing the elephantine proportions of the problem, reveals considerable detail of importance. First, there was already at hand at the Air Force Eastern Test Range specific ADP capabilities that could be used almost directly in an integrated analytical system. Examples of such capabilities are those for trajectory and ephemerous computation, geometrical dilution of precision analysis, antenna pattern analysis, ship and aircraft scheduling routines, cost accounting data, and many others. With such assistance identified and the overall dimension of the task in view, the next step was to outline approach and methodology.


#*On the Equivalence of Planar Grammars and Parallel Picture Processing Algorithms
#@Zenon Kulpa
#t1974
#cProceedings of the 3rd Symposium on Mathematical Foundations of Computer Science
#index368575


#*PERT time calculations without topological ordering
#@S. E. Lass
#t1965
#cCommunications of the ACM
#index331759


#*A linear programming system for use on time sharing
#@Bruce O. Larsen
#t1971
#cProceedings of the 1971 26th annual conference
#index549872
#!A linear programming system, NYLPS, designed for batch processing has been adapted for use under time sharing. The new system is called ECLIPS. The system is both conversational, in that it prompts the user for information, and interactive in that the user may interrupt an optimization, change data and continue optimizing without losing the current basis. These features are discussed along with the programming techniques used to accomplish them.


#*Remark on stably updating mean and standard deviation of data
#@Ira W. Cotton
#t1975
#cCommunications of the ACM
#index319455
#%314655
#!Although not published as a numbered algorithm, Hanson's article &ldquo;Stably Updating Mean and Standard Deviation of Data&rdquo; in the January, 1975, issue of Communications, [1] describes an algorithm for sequentially recomputing the mean and standard deviation of a weighted series of numbers when new numbers are added to the series. The procedure requires that only a summary matrix of data be retained, not the entire series, for the new mean and standard deviation to be computed.


#*HOTDAM
#@Gary Berosik
#t1976
#cACM SIGDOC Asterisk Journal of Computer Documentation
#index6840
#!Conventional automated (on-line) documentation usually consists of an unstructured or semi-structured collection of manuals, short information sheets, and user guides. Each of these is retrievable as an all or nothing entity.


#*Hybrid Digital/Analog Computer Systems
#@P. Landauer
#t1976
#cComputer
#index341534
#!In contrast to the crude analog-digital combinations of the 1960's, today's hybrids are true multiprocessors supported by realtime operating systems. Their solid-state analog computing elements loaded digitally in microseconds, together with their equation-oriented compilers, provide efficient, automatic setup and high productivity. Teamed with flexible, low-cost alphanumeric/graphic displays, modern hybrids are being applied over the full spectrum of scientific and engineering studies. Since the average hybrid system has an equivalent digital processing speed of over 10 million operations per second, at less than one-tenth the cost of large digital data processors, typical users realize cost savings of over 100/1. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A stiffly stable integration process using cyclic composite methods
#@Joel M. Tendler,Theodore A. Bickart,Zdenek Picel
#t1978
#cACM Transactions on Mathematical Software (TOMS)
#index330318
#%105956
#%187322
#%322467
#%331454
#%554186


#*Dynamic microprogramming: processor organization and programming
#@Allen B. Tucker,Michael J. Flynn
#t1971
#cCommunications of the ACM
#index324932
#%551097
#%331310
#%334053


#*Instructional psychology and computer science
#@C. Victor Bunderson
#t1971
#cACM SIGCUE Outlook
#index310323


#*A study of closed queueing networks with population size constraints.
#@John Lester Carroll
#t1979
#c
#index203141


#*Algorithms: Algorithm 337: calculation of a polynomial and its derivative values by Horner scheme
#@W. Pankiewicz
#t1968
#cCommunications of the ACM
#index333325


#*An Efficient On-Line Position Tree Construction Algorithm
#@Mila E. Majster-Cederbaum,Angelika Reiser
#t1979
#cProceedings of the 4th GI-Conference on Theoretical Computer Science
#index263650


#*The choice of base
#@W. S. Brown,P. L. Richman
#t1969
#cCommunications of the ACM
#index324530
#%318909
#%333077
#!A digital computer is considered, whose memory words are composed of N r-state devices plus two sign bits (two state devices). The choice of base &bgr; for the internal representation of floating-point numbers on such a computer is discussed. It is shown that in a certain sense &bgr; = r is best.


#*An intelligent analyzer and understander of English
#@Yorick Wilks
#t1975
#cCommunications of the ACM
#index326414
#!The paper describes a working analysis and generation program for natural language, which handles paragraph length input. Its core is a system of preferential choice between deep semantic patterns, based on what we call &ldquo;semantic density.&rdquo; The system is contrasted: with syntax oriented linguistic approaches, and with theorem proving approaches to the understanding problem.


#*Abstract of the proceedings at the SEAS APL Working Committee's meeting Grenoble, Feb. 15th, 16th/71
#@Niels Gellert
#t1971
#cACM SIGAPL APL Quote Quad
#index345958


#*Letters to the editor: construction of school time-tables by a computer
#@J. S. Folkers
#t1963
#cCommunications of the ACM
#index331404


#*The academic/industry gap in systems programming and operating systems
#@William M. Conner,Kenneth A. De Jong
#t1979
#cProceedings of the tenth SIGCSE technical symposium on Computer science education
#index548917
#%544759
#%553783
#%550261
#!The results of a survey of individuals working in the systems programming and operating systems areas are presented in an attempt to characterize the academic/industry &ldquo;gap&rdquo; in this area. The implications of this gap are then presented for both the present curriculum in the Department of Computer Science at the University of Pittsburgh and for college/university curricula in general.


#*Register-transfer level simulation of microprogram controlled processors as a basis for evaluating digital computer system designs.
#@Robert Rainey Little
#t1977
#c
#index186699


#*Segmentierung und Erkennung eines Objektes in nat&uuml;rlicher Umgebung
#@Axel Korn
#t1978
#cBildverarbeitung und Mustererkennung, DAGM Symposium
#index569483


#*A programmed binary counter for the IBM type 650 calculator
#@B. C. Kenny,J. A. Hunter
#t1958
#cCommunications of the ACM
#index327896


#*Fortran Tausworthe pseudorandom number generator
#@W. H. Payne
#t1970
#cCommunications of the ACM
#index332267
#%317911
#%323098
#%333250
#%334105
#!Intermediate computations in an &ldquo;Extremely Portable Random Number Generator&rdquo; by J. B. Kruskal [Comm. ACM 12, 2 (Feb. 1969), 93-94] exceed 15 bits plus sign. This is a severe limitation since the majority of small computers uses a 16 bit (15 bits plus sign) word or less. ASA standard FORTRAN compilers for these machines are readily available. Fortunately, a linearly recurring sequence generator [2] can be written in somewhat &ldquo;portable&rdquo; ASA Standard FORTRAN which will produce maximum length [2** (word size of computer - 1) -1] pseudorandom numbers for common 12, 16, 18, 24, and 32 bit computers, to mention only a few. Following Kendall's algorithm and notation presented by Whittlesey for a p-bit computer: p = 12, N = 11, M = 2; p = 16, N = 15, M = 1, 4, or 7; p = 18, N = 17, M = 3, 5, or 6; p = 24, N = 23, M = 5 or 9; and p = 32, N = 31, M = 3, 6, 7, or 13.


#*Link Segment System
#@James A. Porter
#t1961
#cProceedings of the 1961 16th ACM national meeting
#index553906
#!Our profession, the art of preparing programs for electronic computers, is now experiencing an evolutionary phase similar to that which other professions have experienced from their inception to maturity. In this phase of our professional activity we are attempting to find the most efficient procedures for operating computers and preparing computer programs for our customers. Recognizing these factors, I believe the Link Segment philosophy is our answer for a more economical and efficient approach to the problems than anything we have had in the past. The LSS concept, if implemented adequately has the following potentials: 1) benefiting the programming staff in their preparation of the production programs and the systems programmers preparing the utility routines; 2) aiding the analyst in his design of specifications for these programs; 3) representing a base for management in their estimation of keeping costs as low as possible. By exploring some of the details of the LSS concept we can see how the above problems are solved.


#*A Basic program package for introducing the top-down approach to computer programming
#@Ronald G. Ragsdale
#t1979
#cProceedings of the tenth SIGCSE technical symposium on Computer science education
#index544519
#%552751
#%555209
#!In the summer of 1978, a program package was produced by six members of the class of course 1516, Programming Applications in Ontario Curricula, offered at the Ontario Institute for Studies in Education. The course participants were secondary school teachers of computer science or related subjects.


#*Remark on algorithm 99: Evaluation of Jacobi symbol
#@Ronald W. May
#t1962
#cCommunications of the ACM
#index323698


#*Classes of Functions and Feasibility Conditions in Nonlinear Complimentarity Problems
#@Jorge J. More
#t1973
#c
#index114039
#!Given a mapping $F$ from real Euclidean n-space into itself, we investigate the connection between various known classes of functions and the nonlinear complementarity problem: Find and $x^{*} \geq 0$ such that $ F x^{*} \geq 0$ and is orthogonal to $x^{*}$. In particular, we study the extent to which the existence of a $u \geq 0$ with $F $u \geq 0$ (feasible point) implies the existence of a solution to the nonlinear complementarity problem, and extend, to nonlinear mappings, known results in the linear complementarity problem on P-matrices, diagonally dominant matrices with nonnegative diagonal elements, matrices with off-diagonal non-positive entries, and positive semidefinite matrices.


#*Editor's notes
#@C. H. Lindsey
#t1979
#cIssue 44 (May 1979)
#index108705


#*Accounting rate of return vs. true rate of return considering variability and uncertainty
#@J. V. Baumler
#t1973
#cProceedings of the 6th conference on Winter simulation
#index550375
#!An accounting rate of return and a defined true rate of return were assessed for a simulated firm composed of Independent long-lived investment projects. The parameters of each individual investment project were determined by a Monte Carlo simulation technique. Differing degrees of environmental variability and uncertainty were represented by the simulation techniques used. Accounting rate of return, defined consistent with contemporary accounting practice, and a true rate of return, defined in economic terms, were contrasted. The efficacy of accounting rate of return as a surrogate for true rate of return was found to be a function of the degree of variability and uncertainty represented in the environment.


#*Associative Networks: The Representation and Use of Knowledge by Computers
#@Nicholas V. Findler
#t1979
#c
#index441793


#*A system for typesetting mathematics
#@Brian W. Kernighan,Lorinda L. Cherry
#t1975
#cCommunications of the ACM
#index316812
#%324042
#%322533
#!This paper describes the design and implementation of a system for typesetting mathematics. The language has been designed to be easy to learn and to use by people (for example, secretaries and mathematical typists) who know neither mathematics nor typesetting. Experience indicates that the language can be learned in an hour or so, for it has few rules and fewer exceptions. For typical expressions, the size and font changes, positioning, line drawing, and the like necessary to print according to mathematical conventions are all done automatically. For example, the input sum from i=0 to infinity x sub i = pi over 2 produces &sum;&infin;i=0xi = &pgr;/2 The syntax of the language is specified by a small context-free grammar; a compiler-compiler is used to make a compiler that translates this language into typesetting commands. Output may be produced on either a phototypesetter or on a terminal with forward and reverse half-line motions. The system interfaces directly with text formatting programs, so mixtures of text and mathematics may be handled simply. This paper was typeset by the authors using the system described.


#*Efficient Generation of Statistically Good Pseudonoise by Linearly Interconnected Shift Registers
#@W. J. Hurd
#t1974
#cIEEE Transactions on Computers
#index349820
#!Some new algorithms are presented for efficiently generating pseudorandom noise both in hardware and software. In software, a new word of pseudorandom bits can be generated about every 12 machine cycles, and hardware implementations can generate pseudo Gaussian noise with bandwith of 20 MHz or more. The algorithms generate binary maximal-length linear recursive sequencies of high degree and with many nonzero terms. The ability to efficiently implement high-degree recursions is important because the number of consecutive bits which can be guaranteed to be both linearly and statistically independent is equal to the degree of the recursion. The implementations are by interconnection of several short shift registers in a linear manner in such a way that different widely spaced phase shifts of the same p-n sequence appear in the stages of the several registers. Some specific algorithms have been subjected to extensive statistical evaluation, with no evidence found to distinguish the sequences from purely random binary sequences.


#*A Mathematical Theory of Communication
#@Claude E. Shannon,Warren Weaver
#t1963
#c
#index581170


#*A learning scheme as a possible basis for artificial intelligence
#@Manfred Rudolf Hugo August Hueckel
#t1966
#c
#index199189


#*Sequential Machine Identification
#@J. Kella
#t1971
#cIEEE Transactions on Computers
#index342804
#!A special aspect of sequential machine identification is treated in this paper. Given an input signal sequence to an unknown sequential machine and the resulting output signal sequence of the machine, it is necessary to find a state table or any other description of the machine and all other machines which response to the given input sequence with the given output sequence. The main objective of the research was to develop a fast and efficient state merging method which profits from the special characteristics of the problem at hand.


#*The construction of a selection battery for programmers adapted to South African conditions
#@R. S. Hall
#t1970
#cProceedings of the eighth annual SIGCPR conference
#index547213
#!The project was undertaken after a meeting between N.I.P.R. staff and a subcommittee of the Computer Society for South Africa in March 1968. Doubts had been expressed over the applicability of programmer aptitude tests normalized for a United States population to a South African population&mdash;a fact which accorded with the N.I.P.R.'s experience with other tests. The Society financed the project, and its influence was of great assistance in obtaining the cooperation of the many different organizations that were involved.


#*Predetermining visibility priority in 3-D scenes (Preliminary Report)
#@Henry Fuchs,Zvi M. Kedem,Bruce Naylor
#t1979
#cProceedings of the 6th annual conference on Computer graphics and interactive techniques
#index553529
#%79620
#%319069
#!The principal calculation performed by all visible surface algorithms is the determination of the visible polygon at each pixel in the image. Of the many possible speedups and efficiencies found for this problem, only one published algorithm (developed almost a decade ago by a group at General Electric) took advantage of an observation that many visibility calculations could be performed without knowledge of the eventual viewing position and orientation&mdash;once for all possible images. The method is based on a &ldquo;potential obscuration&rdquo; relation between polygons in the simulated environment. Unfortunately, the method worked only for certain objects; unmanagable objects had to be manually (and expertly!) subdivided into managable pieces. Described in this paper is a solution to this problem which allows substantial a priori visibility determination for all possible objects without any manual intervention. The method also identifies the ( hopefully, few) visibility calculations which remain to be performed after the viewing position is specified. Also diescussed is the development of still stronger solutions which could further reduce the number of these visibility calculations remaining at image generation time. The reduction in overall processing and memory requirements enabled by this approach may be quite significant, especially for those applications (e.g., 3-D simulation, animation, interactive design) in which numerous visible surface images are generated from a relatively stable data base.


#*People-Oriented Computer Systems (Panel Discussion): When, and how?
#@Robert Dunn,Thomas H. Martin,Lawrence Miller,Hugh Smith,Shirley Ward Watkins
#t1978
#cProceedings of the 1978 annual conference
#index550543
#!What will be required in order to accomplish the transition from the current generation of computer-oriented people to people-oriented systems? This session will address various questions relating to the following areas: - How do casual users interact with information processing systems? What do we know about interface characteristics and their effects upon end users? How do users learn the necessary protocols for each host system? - What can we learn from human factors research? Are there some issues that always exist, even when nothing is known about the particular user or the user's tasks? How can system designers learn more about the professed needs of users and their actual behavior? - How will the widespread move towards the use of CRTs rather than printing terminals affect the end user? What changes in system and interface characteristics will be necessitated because of the move towards national networks? - How can we encourage and facilitate collaborative research into the interaction process? How can the findings from such studies be disseminated and implemented? The panelists will describe current work in networking, graphics, interaction monitoring, ergonomics, and the psychology of information system design and discuss the application of such activities to the design and development of people-oriented information systems.


#*SYNARC: A computer - aided model for architectural design
#@Joseph I. Greenberg,San Luis Obispo,Steven A. Siskind
#t1972
#cProceedings of the 9th Design Automation Workshop
#index548620
#!The SYNARC model provides the architect-planner with a series of modular programs which allows him to evaluate and revise conceptual design solutions with a precision that has been heretofore lacking. SYNARC allows the architect to evaluate his conceptual design solution at every level of development from basic land plan to transportation systems location, from land-use and building locations to economic feasibility. It provides objective output data from physical attributes of the conceptual design solution for the architect to interpret. While the negative aspects of speculative investment and rigid financial considerations can never be isolated from solving the problems of the built-environment, the SYNARC model can allow the architect to deal with them in a more integrative, problem-solving process, perhaps producing design solutions which are more sensitive and sympathetic to all human needs.


#*Proceedings of the 10th Design Automation Workshop
#@
#t1973
#cAnnual ACM IEEE Design Automation Conference
#index544881


#*Options and alternatives of the small system user
#@Thalia Kafatou
#t1979
#cACM SIGSMALL Newsletter
#index32998
#!There are no statistical studies concerning the number of the small systems that take the rough road of computerization, every day, but experience has shown that this number is large, and is becoming larger every day. Computers are in fashion. The question, though, is whether the computer solution is the only solution that the small system user has in his disposal to make his working life easier. Even in the case that the computer road is the solution, still there are alternatives concerning the kind, and size of the computer. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A general program for the analysis of square and rectanglar lattice designs
#@K. W. Smillie
#t1963
#cCommunications of the ACM
#index329694
#!This paper describes a general-purpose program that will handle those incomplete block designs known as square and rectangular lattices. Flow diagrams are given so that the method of calculation may be programmed for any digital computer.


#*The computer center newsletter: a struggle for survival
#@Rita Seplowitz Saltz
#t1976
#cProceedings of the 4th annual ACM SIGUCCS conference on User services
#index244288


#*Bildsegementation mittels struktureller Texturanalyse
#@Ludwig Abele
#t1979
#cAngewandte Szenenanalyse, DAGM Symposium
#index558328


#*A method for incrementally compiling languages with nested statement structure
#@Jay Earley,Paul Caizergues
#t1972
#cCommunications of the ACM
#index320846
#%319282
#%326074
#%332030
#!A method of incremental compilation is presented which applies especially to programming languages in which statements can be nested (such as Algol and PL/I). The method permits editing of the source language using a general purpose text editor, and incremental processing of changes without frequent recompilation of entire routines. The essential points of the method are: (1) the syntax of the language is restricted insofar as which constructs may occur on lines; (2) an internal data structure (called the skeleton) is maintained to represent the statement structure; (3) the recompilation is partially batched in the sense that recompilation of modified lines does not occur until the last of a set of editing commands has been received; and (4) the parsing and compilation are factored into two parts, that done on individual lines and that done globally to handle the relationships between the lines.


#*Intersections of linear context-free languages and reversal-bounded multipushdown machines (Extended Abstract)
#@Ronald Book,Maurice Nivat,Michael Paterson
#t1974
#cProceedings of the sixth annual ACM symposium on Theory of computing
#index546233
#!The purpose of this paper is to establish the following result. Theorem 3.1. Let L be a language. The following are equivalent: (i) L is accepted by a nondeterministic multipushdown acceptor which operates in such a way that in every accepting computation each pushdown store makes at most a bounded number of reversals and which runs in linear time; (ii) L is accepted by a nondeterministic multipushdown acceptor which operates in such a way that in every accepting computation each pushdown store makes at most one reversal and which runs in real time; (iii) L is the length-preservlng homomorphie image of the intersection of some finite number of linear context-free languages; (iv) L is accepted by a nondeterministlc acceptro with three pushdown stores which operates in such a way that in every computation each pushdown store makes at most one reversal and which rmls in real time; (v) L is the length-preservlng homomorphic image of the intersection of three linear context-free languages.


#*Proving the Correctness of Multiprocess Programs
#@L. Lamport
#t1977
#cIEEE Transactions on Software Engineering
#index351364
#!The inductive assertion method is generalized to permit formal, machine-verifiable proofs of correctness for multiprocess programs. Individual processes are represented by ordinary flowcharts, and no special synchronization mechanisms are assumed, so the method can be applied to a large class of multiprocess programs. A correctness proof can be designed together with the program by a hierarchical process of stepwise refinement, making the method practical for larger programs. The resulting proofs tend to be natural formalizations of the informal proofs that are now used.


#*Measurement of lawrence livermore laboratory CDC-7600 SYSTEM PERFORMANCE*
#@
#t1973
#cProceedings of the 1973 ACM SIGME symposium
#index551843
#!Performance measures of machine utilization is done on a continuing basis at Livermore. A brief description of the sampling and presentation techniques are given. The impact of timesharing and heavy I/O loading is shown graphically.


#*Digitalisation of pictures and data graphs
#@P. Guichet
#t1977
#cDigital Bildverarbeitung - Digital Image Processing, GI/NTG Fachtagung
#index571235


#*The Time and Tape Complexity of Developmental Languages
#@Ivan Hal Sudborough
#t1977
#cProceedings of the Fourth Colloquium on Automata, Languages and Programming
#index358469


#*The base-data-cluster concept: a cooperative metropolitan approach to computer utilization
#@Leonard Stitelman
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index72829
#!Metropolitan areas across the nation are devoting more attention to the general lack of current and detailed information so necessary for increasingly complex regional and local decision-making by public agencies. In the metropolitan Detroit, Michigan, region several groups have been involved in the attempt to develop a coordinated but voluntary approach to computer utilization which could serve as a model for other multi-jurisdiction metropolitan regions. It is known as the Base-Data-Cluster Information System.


#*Blended Linear Multistep Methods
#@Robert D. Skeel,Antony K. Kong
#t1977
#cACM Transactions on Mathematical Software (TOMS)
#index320494
#%79620
#%105956
#%201801
#%331454
#%322467


#*Specifying queries as relational expressions
#@R. F. Boyce,D. D. Chamberlin,M. M. Hammer,W. F. King
#t1974
#cACM SIGIR Forum
#index301214
#%326368
#!SQUARE (<u>S</u>pecifying <u>Q</u>ueries <u>A</u>s <u>R</u>elational <u>E</u>xpressions) is a set oriented data sublanguage for expressing queries (access, modification, insertion, and deletion) to a data base consisting of a collection of time-varying relations. The language mimics how people use relations or tables to obtain information. It does not require the sophisticated mathematical machinery of the predicate calculus (bound variables, quantifiers, etc.) in order to express simple references to tables. However, the language has been shown to be complete, i.e., any query expressible in the predicate calculus is expressible in SQUARE.


#*Klassifikation mehrdimensionaler Daten bei unbekannter Klassenanzahl mit einem Gradientenverfahren
#@L. Schüler,H. Wolff
#t1978
#cBildverarbeitung und Mustererkennung, DAGM Symposium
#index572568


#*DPL: A Language for Instruction in Concepts Basic to Data Processing and Management Information Systems
#@Howard L. Morgan
#t1968
#c
#index124133
#!NO SUPPLIED


#*Algorithm 17: trdiag
#@C. F. Sprague, III
#t1960
#cCommunications of the ACM
#index320020


#*Design considerations for a heterogeneous tightly-coupled multiprocessor system
#@Kenichiro Noguchi,Isao Ohnishi,Hiroshi Morita
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index67336
#!In a multiprocessor system, processors share main memory and a single copy of the operating system in shared main memory controls the entire system. Basically each processor can execute, any of the programs in the system. (This type of multiprocessor system is sometimes called a tightly-coupled multiprocessor system to distinguish from another type of multiprocessor system in which each processor has its own main memory and operating system. In this paper a "multiprocessor system" means a "tightly-coupled multiprocessor system" unless otherwise noted.) A multiprocessor system usually consists of identical processors, which have same computing speeds as well as the same functional characteristics. In this paper a more general type of multiprocessor system which consists of processors of different computing speeds are discussed. The component processors are equivalent in the hardware functions but have different performance characteristics. This type of multiprocessor system, a heterogeneous multiprocessor system, has the following merits as compared with a homogeneous multiprocessor.


#*Computer simulation: organization and form
#@
#t1966
#cCommunications of the ACM
#index326380


#*Description of a high capacity, fast turnaround university computing center
#@W. C. Lynch
#t1966
#cCommunications of the ACM
#index330803
#!The operating system for the UNIVAC 1107 at Case Institute is reviewed. The system is of interest because of the low turn-around times achieved, the high throughput achieved and the lack of an operating staff. Turnaround times below 5 minutes and job volume above 75,000 per quarter year are reported.


#*APL tools for combinatorics
#@Eduardo Kellerman,William C. Rodgers
#t1974
#cProceedings of the sixth international conference on APL
#index546426
#!This paper is a tutorial devoted to describing how to use some of the tools that APL can provide in the field of combinatorics. Emphasis will be on enumerative combinatorics. The field of combinatorics has undergone tremendous change since the advent of the electronic computer. In the past it has been generally sufficient to answer questions of the sort: &ldquo;In how many ways is it possible to ... ?&rdquo;.Now, in many cases, it is possible to generate each of the ways and to study them further (either manually or through the computer). For example, many books in combinatorics describe how to compute the number of ways a dollar can be changed, now it is a simple task to write a function to enumerate all of the ways. APL is well suited as a tool to aid in the solution of problems in combinatorics. This paper is a tutorial devoted to describing how to use some of the tools that APL provides.


#*Coordinating concurrent access in a distributed database architecture
#@M. J. Stucki,J. R. Cox, Jr.,G. C. Roman,P. N. Turcu
#t1978
#cProceedings of the fourth workshop on Computer architecture for non-numeric processing
#index548981
#%317485
#!A distributed architecture for an interactive information system is described, and a scheme for coordinating concurrent access to its data is presented. The scheme is deadlock free and is carried out without the need for centralized control. Conflicts are detected as they occur, and competing processes are given exclusive access to the data they need.


#*CSP II&mdash;a universal computer architecture simulation system for performance evaluation
#@Harold Y. Iwata,Melvin M. Cutler
#t1975
#cProceedings of the 3rd symposium on Simulation of computer systems
#index552796
#!CSP II is a system through which computers can be quickly and flexibly simulated at the functional level, combining the accuracy of a detailed simulation with the simplicity of a high-level simulation. The simulation experiences which motivated the authors' design of CSP II are described, as are the objectives that CSP II was designed to achieve. Strongest of the latter are the capabilities to vary the workload, instruction set, architecture, and timing without recoding the simulation program. Since simulation languages and systems typically offer complete timing flexibility and some flexibility in specifying architecture and workload, emphasis is placed on how CSP II's table-driven approach achieves this total flexibility without significant inefficiency. The array of statistics-gathering mechanisms built into CSP II is described, from a detailed scoreboard of processor state changes to lumped parameters describing computer performance within a simulation run. The great emphasis placed on workload specification capability by the CSP II design is discussed, concluding with the description of the routines written to support workload specification, measurement, and generation. The advantages of the CSP II approach to workload specification are noted, including the ability to generate a workload synthetically. The use of a single workload specification to compare two or more computers, possibly with different instruction sets, is described-a unique capability of the CSP II system.


#*Three levels of the wiring interconnection problem
#@D. K. Frayne
#t1965
#cProceedings of the SHARE design automation project
#index553635
#!This paper describes a set of computer programs written to aid in the design, documentation, manufacture, and test of electronic hardware. The programs discussed are limited to the areas involved with the problem of wiring interconnection. While it can be said that there are over 10 different levels or types of wiring interconnection, these programs primarily concern the most common three: 1. Interconnection of circuit cards or other modules on a chassis 2. Interconnection of chassis within an electronic unit 3. Interconnection of units within a complex.


#*Software Engineering: Process, Principles, and Goals
#@D. T. Ross
#t1975
#cComputer
#index336316
#!This paper attempts to define the principles and goals that affect the practice of software engineering. Its intent is to organize these aspects of software engineering into a framework that rationalizes and encourages their proper use, while placing in perspective the diversity of techniques, methods, and tools that presently comprise the subject of software engineering.


#*A bonus from van Wijngaarden's device
#@James H. Morris, Jr.
#t1972
#cCommunications of the ACM
#index333108
#%319134
#%319878
#%550835
#!In [1] van Wijngaarden presented a rather remarkable technique for rewriting ALGOL 60 programs to eliminate all labels. The purpose of this note is to point out that the rewriting would also eliminate the use of array returning (procedure returning, label returning, etc.) procedures had they been legal constructs of ALGOL 60. Hence, the many languages which allow such things to be returned as procedure values are not such large extensions of ALGOL 60 as one might think [2, 3, 4, 5].


#*An inversion algorithm for one-dimensional f-expansions
#@Scott Bates Guthery
#t1969
#c
#index186442


#*Introducing the computer at a small liberal arts college
#@Leila de Campo
#t1970
#cProceedings of the first SIGCSE technical symposium on Education in computer science
#index552293
#!Description of a computer course to attract humanities oriented students. Current computer projects in Music, Art, Social Science and English were discussed. PL/I was the language used. In addition to the basic instructions, string manipulation and tape and disk processing were covered. Problems were geared to a non-mathematical group and covered alphabetic arrays and text scanning.


#*Editor's Preview&hellip;
#@William S. Dorn
#t1969
#cACM Computing Surveys (CSUR)
#index320670


#*Research directions in software technology
#@Peter Wegner
#t1978
#cProceedings of the 3rd international conference on Software engineering
#index549846
#!This paper reports on the results of a study, sponsored by AFOSR, ARO and ONR, of current and future research directions in technological areas of computer science. This study is similar in spirit to the NSF-sponsored COSERS (Computer Science and Engineering Research Study) project, but is narrower in scope, emphasizing concepts and research issues relevant to software technology rather than the whole spectrum of research directions in computer science. It was started in the summer of 1975 and has resulted in a book to be published by the MIT press in the summer of 1978. Section 1 of this paper discusses the objectives and organization of the book and introduces a framework for structuring the subject matter of software technology which parallels the structure of the book. Sections 2 and 3 respectively discuss the impact on research of the changing technological environment and the unusual nature of software products. Sections 4-7 present a detailed summary of the contributions of individual chapters. Section 8 enumerates research directions for each of the areas considered. Section 9 briefly considers time horizons and funding philosophies.


#*Experience of using message spooling processors in a non-interactive network
#@D. R. Innes,J. L. Alty
#t1976
#cProceedings of the 1976 annual conference
#index549494
#%335153
#!The use of mini-computer subnets in computer communication networks is now widely established. Such subnets are normally designed for the fast response traffic of interactive computer usage. An alternative design, orientated to the high volume, slow response traffic of non-interactive computing, is described. The mini-computers have local disc based file stores through which the message traffic is spooled. These message spooling processors need not form a conventional communications subnet since only one message spooling processor is needed between any two host computers. This paper examines the advantages derived from message spooling in a variety of modes of operation.


#*Zugriffssicherung in Datenbanksystemen
#@Peter Haberäcker,M. Lehner
#t1974
#cGI - 4. Jahrestagung
#index258035


#*Tendenzen in der Prozessrechnertechnik
#@Heinz Gumin
#t1974
#cGFK-GI-GMR Fachtagung Prozessrechner 1974
#index256455


#*Stiffly Stable Linear Multistep Methods of Extended Order
#@Jim Varah
#t1975
#c
#index197343


#*Singularity in differential optimization theory: differential algorithm for posynomial programs
#@Gintaras Victor Reklaitis
#t1969
#c
#index194304


#*Special Feature: Nanoprogramming vs. Microprogramming
#@G. F. Casaglia
#t1976
#cComputer
#index343778
#!Vertical microprogramming (or, as others say, functional microprogramming or firmware) was introduced in contrast with Wilkes' microprogramming (generally called horizontal or structural microprogramming), and has greatly enhanced the use of microprogramming in control design and implementation. As applied today, the former technique is not yet a way of designing control structures, but an additional software level whose implications in the system are not well clarified. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A characterization of Mal'cev's preiterative algebras
#@I. G. Rosenberg
#t1976
#cProceedings of the sixth international symposium on Multiple-valued logic
#index551057
#!In universal algebras, propositional calculi, combinatorial switching circuits new operations are formed by composition. The process of composing operations is usually described by Menger algebras or by partial or graded algebras (clones). The inherent limitations are due to the preservation of arities. A.I. Mal'cev avoided this by introducing an algebra P@@@@ &equil; <0A,&zgr;,&tgr;,&Dgr;,*> of type <1,1,1,2> on the set 0A of all finitary operations on A such that the subalgebras of P@@@@ (called preiterative algebras) agree with the sets of all polynomials of universal algebras on A. In this paper, we study the abstract structure of these concrete preiterative algebras; that is, we describe the preiterative algebras in terms of the properties of &zgr;, &tgr;, &Dgr;, and * only.


#*Methodology for teaching introductory computer science
#@R. R. Oldehoeft,R. V. Roman
#t1977
#cProceedings of the seventh SIGCSE technical symposium on Computer science education
#index553717
#%546908
#%547094
#%547388
#!In the last few years it has been generally recognized that teaching programming involves more than describing a new FORTRAN statement each day and providing programming problems to be coded. The concepts of disciplined programming and the accompanying interest in the problem solving process, coupled with the increasing economic desirability of constructing correct and maintainable software has resulted in significant attention being focused on what should be taught, and, to a lesser extent, on how this is best accomplished. In order to discuss how an introductory programming course is taught, it is essential to first establish a set of objectives for such a course. Some of these objectives are obvious and generally agreed upon, others are engendered by the academic environment in which this particular course exists. We first state the objectives and then comment on their appropriateness and interrelation.


#*An integrated approach to network protocols
#@Louis Pouzin
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index59953
#!Host-to-host protocols (H-H) for heterogeneous computer networks are still in infancy. So far very few implementations are in existence. Among those on which documentation is available are Arpanet and Cyclades. The former provides only for basic services allowing the transfer of up to 1000 octet messages, with flow control but not error control. The latter allows up to 32 000 octet messages, with error and flow control. Both are similar in the sense that they offer only a message transfer service, which is intended for building higher level protocols more appropriate for specific uses. Since data to be transferred are usually structured in various ways, a traditional approach is to superimpose additional layers of specific protocols, each one dealing with a particular level of structure. While being functionally correct, this approach leads to heterogeneity, redundancy and overhead among the various layers.


#*Spectral characteristics of piecewise polynomial representation of digital signals.
#@George Edward Iddings
#t1978
#c
#index205481


#*On the polyparametric sensitivity of park's equations by computer simulation methods
#@Fred R. Leffler
#t1971
#c
#index194927


#*Minimizing the problem of logic testing by the interaction of a design group with user-oriented facilities
#@Manuel Correia,Donald Cossman,Franco Putzolu,Thomas Snethen
#t1970
#cProceedings of the 7th Design Automation Workshop
#index555269
#!Early design decisions concerning logic packages often make subsequent testing difficult. To minimize such problems, logic designers must maintain close communication with those responsible for testing the finished product. This paper explores a user-oriented system which enables the designer to recognize and correct testing problems in the early stages of design.


#*On channel sharing in discrete-time, multi-access broadcast communication
#@Yechiam Yemini
#t1979
#c
#index186313


#*Allegations as aids to static program testing
#@Leon J. Osterweil
#t1976
#cProceedings of the 1976 annual conference
#index545661
#%316592
#%554610
#%549450
#%552090
#!In static program analysis, a program is examined without execution in an attempt to anticipate possible sources of error. Possible errors detected in this way can rarely be considered certain to occur because of the impossibility of infallibly determining the executability of a given program path. Current heuristic systems for making this determination are costly and uncertain. Hence the use of allegations&mdash;user supplied unverifiable statements designed to provide answers to executability questions&mdash;is suggested.


#*Economies of scale versus specialization - parameters of choice
#@J. H. Weber
#t1977
#cProceedings of the fifth symposium on Data communications
#index548903
#!In this paper the important characteristics of shared and special purpose networks will be examined. The shared networks will include those which are shared among a variety of different types of data services and those which are shared between data services and voice services. Special purpose networks will ordinarily be those which are defined as meeting a particular specialized need for data communications. An attempt will be made to identify the structural differences in such networks, the characteristics of the user's needs which cause one network to be more appropriate than another, and the cost characteristics which lead to a choice of one mechanism or the other. Much of this will be in qualitative terms, although quantitative anslyses of certain situations will be made.


#*Fault-Tolerant Computing: An Introduction and a Perspective
#@C. R. Kime
#t1975
#cIEEE Transactions on Computers
#index340871
#!FAULT-TOLERANT computing has been defined as "the ability to execute specified algorithms correctly regardless of hardware failures, total system flaws, or program fallacies" [1]. To the extent that a system falls short of meeting the requirements of this definition, it can be labeled a partially fault-tolerant system [2]. Thus the definition of fault-tolerant computing provides a standard against which to measure all systems having a degree of fault tolerance. In particular, one can classify systems according to: 1), the amount of manual intervention required in performing three basic functions, and 2) the class of faults covered by three basic functions involved in fault tolerance: system validation, fault diagnosis, and fault masking or recovery. The word "fault" here is used to inclusively describe "failures, flaws, and fallacies" in the original definition. The first function is involved in the design and production of the system hardware and software, while the last two functions are embodied in the system itself. Likewise, the first function is directed to handling faults arising from design and production errors, whereas the last two functions are aimed at faults due to random hardware failures.


#*Corrections to numerical data on Q-D algorithm
#@Richard F. Thomas, Jr.,Peter Henrici
#t1966
#cCommunications of the ACM
#index326507
#%332701


#*Synthesis and complexity of logical systems
#@Hans-Jürgen Hoehnke
#t1974
#cProceedings of the Proceedings of the First International Symposium on Category Theory Applied to Computation and Control
#index258785


#*A Brief Introduction to Quasi-Newton Methods
#@John E. Dennis, Jr.
#t1977
#c
#index123273
#!NO SUPPLIED


#*Papers and discussions presented at the Dec. 10-12, 1951, joint AIEE-IRE computer conference: Review of electronic digital computers
#@
#t1951
#cAFIPS Joint Computer Conferences
#index394597
#!The AIEE-IRE Computer Conference met on December 10-12, 1951, at Philadelphia to discuss the characteristics and performance of working, large-scale, electronic digital computers. The conference was arranged by a joint committee appointed early in 1951 by the Committee on Computing Devices of the American Institute of Electrical Engineers and the Electronic Computers Committee of the Institute of Radio Engineers. It was felt that the development of these machines had reached a point where useful engineering information could be drawn from the experience of the designers and users of these machines and that a published account of these machines, assembled in a report of this meeting, would be of permanent value in the development of engineering knowledge of this new field of activity. The joint committee invited the co-operation of the Association for Computing Machinery, and representatives of that organization joined in the planning of the meeting and participated in the conference. The extent of interest in the subject can be appreciated from the attendance at the conference, which totalled 877 members. Descriptions of ten large-scale electronic computers of varying design and performance were presented, giving a cross-section of the varying designs to date of both parallel and serial types of electronic computers using storage devices including mercury delay lines, magnetic drums, and cathode-ray tubes. Other papers discussed detailed operating and component experience on certain of these calculators, and the final session summarized the present state of computer development and indicated some of the future possibilities of the Transistor in computer design. At the luncheon meeting on the last day of the conference, an inspiring picture of the rapidly expanding use of large-scale computers in engineering design and analysis of our new airplanes, both commercial and military, gave the members of the conference a better understanding of the ultimate usefulness of their efforts, During the conference, inspection trips gave many of the participants an opportunity to view the UNIVAC and the Burroughs Computer, and to visit the computer activities of the Moore School of Electrical Engineering of the University of Pennsylvania and of the Technitrol Engineering Company.


#*Multiprocessor implementations of programs
#@David Lane Carney
#t1972
#c
#index200222


#*Evaluating video tape instruction as a resource for user education
#@William Knabe
#t1977
#cProceedings of the 5th annual ACM SIGUCCS conference on User services
#index544608


#*Programming compatibility in a family of closely related digital computers
#@William F. Luebbert
#t1960
#cCommunications of the ACM
#index315829


#*Computer-aided design of systems with random parameters.
#@Richard Walter Carroll
#t1973
#c
#index205409


#*Graph models of computations in computer systems
#@Jean-Loup E. Baer
#t1968
#c
#index202141


#*A Symposium on Feature Extraction and Selection in Pattern Recognition
#@
#t1970
#cComputer
#index396371


#*Picture generation with a standard line printer
#@Benson Perry,Mortimer L. Mendelsohn
#t1964
#cCommunications of the ACM
#index326704
#!A method is described for producing gray-toned pictures on a line printer by utilizing the different degrees of blackness of standard print characters. Gray scales with 17, 32 and 64 levels have been devised. Scanned images of blood cells are used to display the technique.


#*On the Problem of Finding Natural Computational Complexity Measures
#@Juris Hartmanis
#t1973
#c
#index115378
#!To develop an abstract theory which deals with the quantitative aspects of computing we need a deeper understanding of how to define ``natural'''' computational complexity measures axiomatically. To this end, this paper summarizess the principal properties which hold for some natural complexity measures but not for all measures and which have been proposed as desirable properties of natural measuress. The paper discusses the nature of these properties, studies their interrelations and their possible values towards defining natural computational complexity measures. A number off open problems are discussed and directions for further research are suggested.


#*Context-sensitive immediate constituent analysis&mdash;context-free languages revisited
#@P. Stanley Peters,Robert W. Ritchie
#t1969
#cProceedings of the first annual ACM symposium on Theory of computing
#index554947
#!The ability of context-sensitive grammars to generate non-context-free languages is well-known. However, phrase structure rules are often used in both natural and artificial languages, not to generate sentences, but rather to analyze or parse given putative sentences. Linguistic arguments have been advanced that this is the more fruitful use of context-sensitive rules for natural languages, and that, further, it is the purported phrase-structure tree which is presented and analyzed, rather than merely the terminal string itself. In this paper, a language is shown to be context-free if and only if there is a finite set of context-sensitive rules which parse this language; i.e., if and only if there is a collection of trees whose terminal strings are this language and a finite set of context-sensitive rules which analyze exactly these trees.


#*Algorithms: Algorithm 331: Gaussian quadrature formulas
#@Walter Gautschi
#t1968
#cCommunications of the ACM
#index314645


#*Dealing with loose and redundant constraints and extraneous-variables in a primal all-integer algorithm
#@Michael Woodward Gaffney
#t1973
#c
#index201515


#*Subrecursive Program Schemata I & II I. Undecidable Equivalence Problems and II. Decidable Equivalence Problems
#@Robert L. Constable,S. S. Muchnick
#t1972
#c
#index118500
#!The study of program schemata and the study of subrecursive programming languages are both concerned with limiting program structure in order to permit a more complete analysis of algorithms while retaining sufficiently rich computing power to allow interesting algorithms. In this paper we combine these approaches by defining classes of subrecursive program schemata and investigating their equivalence problems. Since the languages are all subrecursive, any scheme written in any one of them must halt (as long as we assume the basic functions and predicates are all total). Hence equivalence of schemes is the first question of interest we can ask about these languages. We consider schematic versions of various subrecursive programming languages similar to the Loop language. We distinguish between Pre-Loop and Post-Loop languages on the basis of whether the exit condition in an iteration loop is tested before iteration, as in Algol (Pre-), or after iteration, as in FORTRAN (Post-). We show that at the program level all these languages have the same computing power (the primitive recursive functions) and all have unsolvable equivalence problems (of arithmetic degree $\Pi^{0}_{1}$). But at the level of schemes, Pre-Loop has an unsolvable equivalence problem, while at least one formulation of Post-Loop has a solvable equivalence problem. If L is a programming language or scheme language, then we denote by E(L) the equivalence problem in L. The basic languages considered are: Loop ($\equiv$ Pre-Loop) Loop language for primitive recursive functions. Post-Loop Post-Loop language for primitive recursive functions. Loop$_{\Diamond}$ Loop language with restricted conditionals. L [D, ()] Loop schemata over D with identity. L$_{\Diamond}$ [D, ()] Loop schemata with conditionals. PL [D, ()] Post-Loop schemata over D. PL$_{\Diamond}$ [D, ()] Post-Loop schemata with conditionals. P Program (flowchart) schemata. P$_{d}$ Program schemata with DO-statements. In contrast to (pure) Loop schemata studied previously by the first author, some of these languages contain the identity function so that a pure data transfer, $X \leftarrow Y$, is possible. Moreover, the equivalence algorithms given here are for the special case of linear schemes (to be defined below) with monadic function variables. Linear schemes are designated by placing L before the name of the more general class, thus LL for linear Loop, LPL for linear Post-Loop, etc. In all schemes considered here the functions are monadic, so no special designation of function rank is provided. It is well known that E(P) is recursively unsolvable and E(P) $\in \Pi^{0}_{2}$. We show that E(Loop), E(Post-Loop), E(L$_{\Diamond}$) (both with and without the pure data transfer), and E(L) are recursively unsolvable, while E(LPL) is recursively solvable. The extension of the equivalence algorithm for LPL to polyadic functions appears at present to be a tedious but straightforward modification to the monadic algorithm. We are hop


#*APL and its entry into the world (?)
#@Cyrus J. Creveling
#t1974
#cProceedings of the sixth international conference on APL
#index548871
#!The more widespread use of APL is contingent on the solution of a number of technical, psychological, and promotional problems. A separate organization is suggested as the best way to coordinate the solution of these.


#*Simulating a &ldquo;management game&rdquo; with programmed decisions
#@J. A. Bubenko, Jr.
#t1968
#cProceedings of the second conference on Applications of simulations
#index555045
#%323755
#!This game differs from many other management games in that respect that the participants do not make their decisions &ldquo;manually&rdquo; during the game. Instead the model consists of a control module, a market model and an arbitrary number of information compatible and functionally similar firm models, each with an independent and individual decision structure. Each participating group is responsible for the design of its own control algorithms which during the simulation have to allocate the firm s resources and decide its price for the following period. The decisions can be based on global market information and on an arbitrary amount of local information that each firm is free to gather, analyze and use for its forecasting etc. The primary purposes of the above system of models is to provide an experimental tool for studies of automatic control problems concerning complex business-like systems.


#*The subsystem approach to enhancing small processor operating systems
#@Malcolm G. Lane
#t1978
#cProceedings of the first SIGMINI symposium on Small systems
#index551394
#%549833
#%554687
#!Operating systems for small processors often do not take full advantage of a small processor's resources. The implementation of a subsystem to enhance the standard operating system has proved to be an effective method to increase the utilization of a small processor's resources. Several different subsystems for small processors are discussed. The advantages of using the subsystem approach in a small processor environment are given.


#*The CAD-system REGENT
#@G. Enderle,E. G. Schlechtendahl
#t1975
#cProceedings of the 12th Design Automation Conference
#index547261
#!The REGENT-system for the support of computer aided design is being developed at the Institut f&uuml;r Reaktorentwicklung of the Kernforschungszentrum (Nuclear Research Center) Karlsruhe, Germany, from 1973 through 1975. The development aims primarily at providing a socalled &ldquo;system nucleus&rdquo; in the sense of ICES[1,2]. The design concept, though being based upon ICES, shows major improvements in particular in the following respects: -a more powerful base language was chosen (PL/1 instead of FORTRAN) -interactive use has been considered right from the beginning -the base language PL/1 is part of all problem oriented languages within the REGENT system. Since summer 1974 the development of the REGENT nucleus and of one of its first subsystems(GIPSY) for processing graphical information is integrated in the &ldquo;CAD-project&rdquo;, which coordinates all government supported CAD-activities in Germany.


#*Distributive rounding in commercial applications
#@Paul Berry
#t1976
#cProceedings of the eighth international conference on APL
#index545122
#!The elements of an array may be rounded in such a way that their sums along a particular axis are consistent with their sums before rounding. The needed adjustments can be made &ldquo;fairly&rdquo;&mdash;that is, taking into account both the relative accuracy and the serial position of the rounded elements. Using such an algorithm, it is possible to assure that percentages, budget categories, or arrays used in other applications where a given initial amount is partitioned among several components, add to the expected totals.


#*An implementation scheme for a virtual machine monitor to be realized on user - microprogrammable minicomputers
#@B. D. Shriver,J. W. Anderson,L. J. Waguespack,D. M. Hyams,R. A. Bombet
#t1976
#cProceedings of the 1976 annual conference
#index552674
#%195091
#%318696
#%544708
#%545208
#%545849
#%548682
#%549422
#%551447
#%554934
#!A virtual machine monitor allows several different operating systems to run concurrently on the same machine. This paper presents the description of a virtual machine monitor and its support structure which can be implemented on a microprogrammable minicomputer or a distributed network of such machines. In our approach, all storage, transformational, input, and output resources of the system are accessed through a mapping mechanism. The design and implementation methodology for an actual realization of the virtual machine monitor is discussed.


#*PS language definition
#@Portia Isaacson
#t1974
#cACM SIGDA Newsletter
#index107108
#%196835
#%329080
#!The last few years has brought a number of changes to the digital system designer's parts inventory - mainly the addition of large scale integration components such as memories and processors. The solution of an information processing problem involves making the right choices from the variety of components offered and designing the hardware/software interface mechanisms between the components. Methods of simulating this new generation of digital systems are needed as tools. The demands placed on such a tool are great: it must (1) facilitate modeling of a digital system at various levels of architectural detail; (2) allow within a single model two components at quite different specification levels; (3) as a design progresses, allow replacement of models by more detailed models; (4) facilitate modeling of all types of components - hardware, firmware, and software; and (5) have a readily changeable parts library. PS is a tool for simulation of digital systems which meets these demands. In addition PS is designed to case the problem of communicating hardware/software mechanisms between people by automatically producing pictures of a system in its various states. These pictures can be used as a means of describing the system. The models produced by PS are called picture-system models [1, 2, 3].


#*Algorithm 147: PSIF
#@D. Amit
#t1962
#cCommunications of the ACM
#index322847


#*Study of the required degree of numerical complexity of synthetic data generators.
#@Rainer Uwe Jettmar
#t1974
#c
#index195433


#*Author's Reply2
#@P. N. Marinos
#t1975
#cIEEE Transactions on Computers
#index347154
#!I wish to thank Metze et al. for having identified certain sources of difficulty with the algorithm given in my paper.1 The notion of "partial Boolean difference" introduced in my paper and on which the algorithm was based was unfortunately restricted to single path sensitization thus resulting in the well-known limitations of such an approach. The concept of partial Boolean difference, however, is quite general and directly applicable to multiple path sensitization. Such Boolean differences are known as multiple partial Boolean differences, and their utility has been previously recognized in test-code generation [1], [2].


#*Pst (process-selector-tree)--a tree structured operating system.
#@Robert Charles Varney
#t1973
#c
#index190368


#*Computer matching of areas in stereo images.
#@Marsha Jo Hannah
#t1974
#c
#index202029


#*A SAP-like assembly program for the IBM 650
#@A. E. Speckhard
#t1960
#cCommunications of the ACM
#index329938


#*Remark on algorithm 331: Gaussian quadrature formulas [D1]
#@I. D. Hill
#t1969
#cCommunications of the ACM
#index319811


#*An LSI Modular Direct-Execution Computer Organization
#@Yaohan Chu
#t1978
#cComputer
#index405848
#!A potentially low-cost architecture offers both device and linguistic modularity and executes high-level code without compilation.


#*Comments on "Multiple Fault Detection in Combinational Networks"
#@P. Goel
#t1974
#cIEEE Transactions on Computers
#index346410
#!Some comments on a recent contribution on multiple fault detection using test sets for single fault detection are presented. A counter example that shows some defects in generalizing from a tree to an arbitrary network are also included.


#*Certification of algorithm 160: combinatorial of M things taken N at a time
#@Dmitri Thoro
#t1963
#cCommunications of the ACM
#index322513


#*Software reliability: a method that works
#@R. H. Thayer,E. S. Hinton
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index61605
#!Software reliability is receiving increased attention from a broad spectrum of computer users as larger computer programs continue to be implemented in diverse and widespread areas. The reason is fundamental: software reliability has been poor on many large systems and poor on systems which have a high degree of human interaction.


#*TEGAS2&mdash;anatomy of a general purpose TEST GENERATION AND SIMULATION system for digital logic
#@S. A. Szygenda
#t1972
#cProceedings of the 9th Design Automation Workshop
#index545616
#!This paper will attempt to consider requirements and problems encountered in the development of digital logic simulation and test generation systems. The procedure for doing this will be to first consider requirements and general considerations for a particular simulation system (TEGAS2(1,2)TEST GENERATION AND SIMULATION) and then to dissect the system into its major constituent parts with a discussion of adopted techniques and experiences. It is obvious that a detailed discussion of this sort would require far more space than permitted in these proceedings. Therefore, an attempt will be made to discuss the most important considerations for system design and development.


#*Certification of algorithm 20: real exponential integral
#@William J. Alexander
#t1961
#cCommunications of the ACM
#index324292


#*The DRI Motor Vehicle prospects model: an example of econometrics and simulation
#@Edward Matluck
#t1977
#cACM SIGSIM Simulation Digest
#index574346
#!This paper outlines DRI's Motor Vehicles prospect model and presents the results of some sample simulations. The model demonstrates how econometric and simulation techniques can be fruitfully applied at the micro economic level.The model is designed to assess the effects of changes in motor vehicle technology on all facets of the industry. The user first configures the vehicles to be produced over the forecast horizon. Simulation of the model then yields yearly bills of materials, production and investment costs, fuel economy and other fleet characteristics over a forecast horizon. The demand sector of the model forecasts new vehicle sales by market segment as a function of economic and demographic behavior. Final fleet characteristics are thus a function of both the supply and demand for motor vehicles.The model is currently being used by business and government. It is a natural tool for use in making fuel economy estimates and evaluation of motor fuel related energy policy issues. For materials suppliers it is a valuable aid for both long and short term planning. In the automotive after-market it can depict the current and future demand for individual replacement parts with a high degree of accuracy. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Announcements
#@C. H. Lindsey
#t1973
#cIssue 36 (November 1973)
#index101420


#*A Modification Request Control System
#@D. B. Knudsen,A. Barofsky,L. R. Satz
#t1976
#cProceedings of the 2nd international conference on Software engineering
#index549093
#!The Modification Request Control System (MRCS) tracks and reports project change requests and resulting activity through interactive input and extraction of change request data from computer files. MRCS is one of the tools available as part of the Programmer's Workbench (PWB). It was developed to aid in the timely control and coordination of software changes. It provides the capability to: (1) interactively create, update, and print MRS; (2) track and record the flow of the MR through the system development cycle; and (3) provide management with timely MR status information via reports and on-line inquiries. MRCS supports many projects, each project with its own MR data base and commands. It provides, via common control logic, standard operations such as the creation, updating, and printing of MRS, and the extraction of data from them. Each project then defines the fields, validity checks, defaults, prompting sequences, and report formats which satisfy its particular requirements, and these are used to produce an MRCS for that project.


#*Informational report on an international workshop on the use of the computer in the teaching of secondary school subjects
#@Alfred Bork
#t1974
#cACM SIGCUE Outlook
#index342130
#!GNOSIS is a system which makes it very simple for a teacher to produce a computerized lesson. The teacher compiles a lesson containing texts and questions and expected answers to the questions. The teacher can check the student results and adjust the lesson according to the student's achievements, e.g., by prescribing remedial sections for students with difficulties. The teacher can also react in special ways to different expected and unexpected false answers to questions, e.g., by appropriate hints followed by a repetition of the wrongly answered question. Unexpected false answers are saved when a student takes a lesson, and later sent to the teacher to help him improve the lesson. GNOSIS is written in ALGOL for the DEC-system 10 computer, but is probably not too difficult to transfer to another computer which has an ALGOL or preferably a SIMULA compiler.


#*CHAMP code calculations of surface and subsurface explosions
#@L. L. Edwards,R. B. Hickman,J. K. Hobson,T. C. Michels
#t1975
#cProceedings of the SIGNUM meeting on Software for partial differential equations
#index551109
#!The CHAMP (Coupled HEMP and Multifluid Eulerian Program) computer code package solves complex radiation diffusion and hydrodynamics problems. We discuss the structure of the code package and its applications to high-energy explosions on the ground surface and at shallow depths of burial.


#*A method for evaluating the area of the normal function
#@Frank B. Baker
#t1961
#cCommunications of the ACM
#index328887
#!Many statistical procedures require the cumulative area and ordinate of the normal function corresponding to a given deviate. The development of a computer program for the application of probit analysis [1] to bio-assay led to the method described here.


#*Algorithm 107: Gauss's method
#@Jay W. Counts
#t1962
#cCommunications of the ACM
#index332839


#*Miscellaneous calls for papers meeting announcements: Computer representation and manipulation of chemical information
#@
#t1972
#cProceedings of the 1972 SIGGRAPH seminar on Computer graphics in medicine
#index546396


#*Automated Inspection of Electronic Assemblies
#@C. A. Harlow
#t1975
#cComputer
#index346095


#*An approximating transcendental numbers by continued fractions
#@E. Karst
#t1961
#cCommunications of the ACM
#index326548


#*Iron and steelmaking facility planning simulation model
#@David P. Koch
#t1979
#cProceedings of the 11th conference on Winter simulation - Volume 1
#index554551
#!Simulation models of iron and steelmaking facilities have been successfully developed to test the productive capabilities of numerous plants. Representative, critical facilities and events have been selected for discussion.


#*Help for highway maintenance administrators-a highway maintenance simulation model
#@James M. Pruett, Ph.D., P.E.,Rodolfo Perdomo
#t1979
#cProceedings of the 11th conference on Winter simulation - Volume 2
#index549167
#!The functions related to highway maintenance are often conceptually simple (repair the highway) and administratively complex (alternatives related to priorities, approaches, resources, and many others). Highway maintenance administrators are often faced with questions about which little or no definitive information exists and asked to make the proper decision. For example, if some amount of money is available for equipment, which type of equipment should be purchased? How many such equipment units? Where should they be placed and so forth? The dilemma of wanting to do the job well (i.e., make the best decision) and not having sufficient data with which to work is disconcerting at best. The highway maintenance simulation model described in this paper is intended to help alleviate the highway maintenance administrator's problem by providing a flexible highway-maintenance-decision-laboratory in which alternative courses of action may be tested. The simulation model is the result of a two-year project sponsored jointly by the Louisiana Department of Transportation and Development and the Federal Highway Administration, with a scheduled completion date of September, 1979.


#*Information Processing with an Associative Parallel Processor
#@R. M. Lea
#t1975
#cComputer
#index351619
#!Research into new computer structures, which would be better suited to non-numerical information processing tasks, has been in progress for some years.1,2,3The problem has been to design a computing system with high hardware efficiency and low software complexity over a wide range of these applications. Recent research4,5,6has indicated that these apparently conflicting requirements could possibly be achieved by a parallel processing system containing content-addressable storage. Hence there is a revival of interest in associative memories and associative processors.


#*A study of fast transform algorithms.
#@Sun-Maw Yang
#t1975
#c
#index198002


#*Interactive computer graphics for computer aided design in civil engineering
#@John L. Wilson,Charles R. Lansberry
#t1976
#cProceedings of the 3rd annual conference on Computer graphics and interactive techniques
#index233347
#!Interactive computer graphics can be an effective and efficient aid in the analysis/design cycle of engineering problems. The vistas of much engineering research and design can be expanded with the tools and methodology available with the introduction of an interactive computer graphics (ICG) system into an academic or industrial environment. Specific attention is given in this paper to new areas of application of ICG in civil engineering; guidelines for the planning of ICG systems; practical applications in bridge design and shipbuilding; and economic considerations involved in using ICG systems.


#*Remark on &ldquo;Algorithm 496: The LZ Algorithm to Solve the Generalized Eigenvalue Problem for Complex Matrices [F2]&rdquo;
#@L. C. Kaufman
#t1976
#cACM Transactions on Mathematical Software (TOMS)
#index327293


#*New Applications
#@
#t1977
#cComputer
#index349147
#!An integrated package containing all the electro-optical elements of a fiber-optic transmitter has been developed by researchers at IBM. The package contains a semiconductor laser array, a cylindrical lens, and an array of optical fiber light guides. The components are mounted on a silicon wafer, which also contains thin-film drive electrodes for the lasers. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Development of a multivariate process control algorithm
#@John Stephen Tripp
#t1971
#c
#index198563


#*A recurrence scheme for converting from one orthogonal expansion into another
#@Herbert E. Salzer
#t1973
#cCommunications of the ACM
#index325556
#%165289
#%457404
#!A generalization of a scheme of Hamming for converting a polynomial Pn(x) into a Chebyshev series is combined with a recurrence scheme of Clenshaw for summing any finite series whose terms satisfy a three-term recurrence formula. An application to any two orthogonal expansions Pn(x) = &sum;nm=0 amqm(x) = &sum;nm=0 AmQm(x) enables one to obtain Am directly from am, m = 0(1)n, by a five-term recurrence scheme.


#*An approach to a multifaceted student information system in large medical school.
#@F. Clancy,S. Hoke,T. Mullan
#t1975
#cProceedings of seventh international conference on APL
#index545309
#!The Faculty of Medicine of the University of Toronto presently provides a complete undergraduate, postgraduate and speciality curriculum for over 2000 students. The physical facilities of the medical school are located in several buildings on campus as well as eleven teaching hospitals in the surrounding city. It was decided due to the existing size and complexity and an anticipated 28% increase in enrolment (which will bring the number of graduates to 320 per year) that some use would be made of data processing techniques to relieve the administrative workload of both academic and nonacademic staff. The area which seemed most practical was the development of a combined Student Record and Computer Administered Examination System. Here is an overview of the system with the arrows indicating access routes, and interrelationships with the files.


#*Proceedings of the second annual ACM symposium on Theory of computing
#@
#t1970
#cAnnual ACM Symposium on Theory of Computing
#index548322


#*Flowcharting by stepwise refinement
#@O. Ferstl
#t1978
#cACM SIGPLAN Notices
#index300988
#%322271
#%323067
#%306291
#%317887
#%335365
#%331066
#!This paper describes a flowchart technique, which supports the method of program development by stepwise refinement.Flowcharts made by this technique have a tree structure, which simplifies program test and coding the chart into a programming language. For design of the overall control structure the basic forms concatenation, selection, repetition and restricted GOTO statements are available.


#*Consideration in the design of a multiple computer system with extended core storage
#@Kurt Fuchel,Sidney Heller
#t1967
#cProceedings of the first ACM symposium on Operating System Principles
#index549540
#!This paper discusses the recent innovation of the use of large quantities of addressable (but not executable) fast random access memory in order to heighten the multiprogramming performance of a multicomputer system. The general design of the hardware arrangement and the software components and functions of such a system are based on Brookhaven's future configuration of dual CDC 6600's sharing one million words of Extended Core Storage. In the generalization of such a design, special emphasis is placed on estimating expected gains compared to the traditional configuration of separate and independent computers without ECS. An observation is made on the use of conventional slower speed random access storage devices in place of the faster memory.


#*A position paper on computing and communications
#@Jack B. Dennis
#t1967
#cProceedings of the first ACM symposium on Operating System Principles
#index546135
#%322134
#%544606
#%545236
#!The effective operation of free enterprise in creating the envisioned information service industry is dependent on three accomplishments: 1. The restructuring of our information processing industry to provide a clear separation among costs for computing, communications, and the development of information services. 2. The wide use of multi-access system concepts so that information services may share in the use of computer installations, and so their cost of construction is reasonable. 3. The development of public, message-switched communications services with adaquate provisions for information security.


#*Stochastic differential and discrete games: existence of solutions and computational procedures
#@Stanley Greene Chamberlain
#t1969
#c
#index204222


#*A human information acquisition model based on dialog experimentation which incorporates display-effects.
#@Neal Stanley Coulter
#t1974
#c
#index202417


#*President's letter to the ACM membership: the graduate
#@Bernard A. Galler
#t1969
#cCommunications of the ACM
#index316336


#*Certification of algorithm 173: assign
#@R. S. Scowen
#t1963
#cCommunications of the ACM
#index316219


#*Elementary bounds for presburger arithmetic
#@Derek C. Oppen
#t1973
#cProceedings of the fifth annual ACM symposium on Theory of computing
#index550290
#!We consider the first-order theory whose language has as nonlogical symbols the constant symbols 0 and 1, the binary relation symbols &equil; and <, the unary function symbol &minus; and the binary function symbol + This theory of integers under addition is commonly called the 'Presburger Arithmetic' and is known to be decidable for truth [Presburger (1929), Hilbert and Bernays (1968)]. We prove here that there exists a decision procedure for this theory, involving quantifier elimination, for which there is a superexponential upper bound on the size of formula produced when all variables have been eliminated.


#*A flexible environment for program development based on a symbolic interpreter
#@P. Asirelli,P. Degano,G. Levi,A. Martèlli,U. Montanari,G. Pacini,F. Sirovich,F. Turini
#t1979
#cProceedings of the 4th international conference on Software engineering
#index549388
#%307418
#%320204
#%324211
#%330587
#%553465
#!The paper describes an interactive programming system which provides an integrated collection of tools for dealing with the whole process of program development. The pivot tool, the symbolic interpreter, may cover a broad range of applications, from testing to correctness Proving. The aspects in which the symbolic interpreter differs from a conventional interpreter, i.e. the possibility of handling nondeterministic branching at choice points and the presence of a system for manipulating symbolic expressions, are described. Furthermore, the main features of a programming language, around which the programming system is built, are presented.


#*The 1st International Conference on Distributed Computing Systems
#@
#t1979
#cComputer
#index341910


#*Structured systems and their performance improvement through vertical migration
#@John Anthony Stankovic
#t1979
#c
#index195715


#*Problems of program validation in the context of the predicate calculus
#@Terry Gregory Lyons
#t1972
#c
#index192661


#*Software for computers with parallel or pipeline architecture
#@H. Lomax,K. Stevens
#t1975
#cProceedings of the SIGNUM meeting on Software for partial differential equations
#index546949
#!This paper is addressed to those computer users who have the following interests in common. First, they are engaged in the numerical study of a discipline at a level where they wish to write or to understand critical portions of a computer code written in some high-level or scientific language. Second, the amount of numerical manipulations required in their study is large enough to require highly efficient use of the hardware of a major computer facility in order to prevent a calculation from becoming prohibitively costly. Finally, they are willing to accept the responsibility for making the code efficient, but they wish to minimize the amount of their time spent in doing so. At present it is usually difficult to realize the third of these interests in light of the first two. Big problems point to computers with special architectures, and these are usually difficult to program efficiently without devoting a sizable effort to data storage and data management. This paper explores some strategies that can be useful in reducing this difficulty. All of our examples will involve the solution of partial differential equations in three-dimensions by means of numerical algorithms requiring meshes with rectangular topologies. In all cases these &ldquo;big problems&rdquo; are defined to have data bases that are too large to fit in core.


#*Binding time optimization in programming languages: Some thoughts toward the design of an ideal language
#@Neil D. Jones,Steven S. Muchnick
#t1976
#cProceedings of the 3rd ACM SIGACT-SIGPLAN symposium on Principles on programming languages
#index546185
#%176082
#%307575
#%316935
#%319282
#%320964
#%325466
#%546754
#!A new approach to the design of a programming language and its processor is proposed and some of the techniques necessary to realize the design are investigated. The language would have a precisely specified syntax and semantics, with both designed to provide the programmer maximal expressive power and to be as easily understood as possible. The semantics would be based on extremely late binding times, which provide great power to the programmer and are consistent with ease of understanding of the execution process. It would be the responsibility of the processor to implement each program in the most efficient manner consistent with its being correctly executed. Implications of this design philosophy and some of the techniques to be used are discussed in greater detail, focusing particularly on data types and storage allocation.


#*From chaos to credibility
#@Edrice Reynolds
#t1976
#cProceedings of the 4th annual ACM SIGUCCS conference on User services
#index236453


#*Comment on "Pattern Classification Design by Linear Programming"
#@
#t1969
#cIEEE Transactions on Computers
#index337497
#!In a recent paper,1a linear programming method was proposed for finding linear discriminant functions. The dual linear program is a much smaller problem with upper bounded variables, which can be solved efficiently.


#*Design of a multilevel microprogrammable computer and a high-level microprogramming language
#@Masahiro Tsuchiya
#t1972
#c
#index205625


#*Custom Programming/Analysis in the Small Business Environment
#@T. Cary
#t1976
#cComputer
#index351925
#!As has often been stated, a business of any size can be considered as a general system,8,11,13,28,29,20,31with identifiable external inputs and outputs typically consisting of goods, services, energy, money, and information. Internally, a business consists of several interacting parts which may be considered as subsystems, each of which has inputs from external sources or from other subsystems and outputs to external sinks or to other subsystems. Usually, each subsystem requires information as an input and, in turn, generates information as an output. As a business becomes larger and more complex, the need for information becomes greater and more critical. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A Stochastic Model for Closed-Loop Preemptive Microprocessor I/O Organizations
#@J. M. Van Campenhout
#t1978
#cIEEE Transactions on Computers
#index342584
#!A stochastic model of closed-loop priority I/O systems is developed in which request generation is assumed to be exponential but service time distributions are arbitrary. This model reflects the code granularity caused by the implementation. Using this model, an interrupt-driven system is compared to a similar system with polled I/O on the basis of latency times and CPU utilization.


#*Extended fortran algebraic manipulator with applications to linear problems of physics
#@Carl Duane Zimmerman
#t1969
#c
#index193518


#*An investigation of the effects of output variability and output bandwidth on user performance in an interactive computer system.
#@Lawrence Henry Miller
#t1976
#c
#index201219


#*Automatic dimensioning
#@Melvin Klerer,Jack May
#t1967
#cCommunications of the ACM
#index320964
#%334775
#!Examples of algorithms that will accomplish automatic storage reservation without the need for explicit array declarations are described.


#*A simple algorithm for computing the inverse of a matrix
#@S. Sitharama Iyengar,Samuel C. Jordon
#t1976
#cProceedings of the 14th annual Southeast regional conference
#index613191
#!This paper describes an effective technique of finding the inverse of an n x n nonsingular matrix and a solution to a particular system of linear equations simultaneously. The algorithm described in this paper is a simple, direct process one which can be readily used on digital computers.


#*IEEE Computer Society Membership & Publications
#@
#t1972
#cComputer
#index345640


#*A Convention for Explicit Declaration of Environments and Top-Down Refinement of Data
#@E. Towster
#t1979
#cIEEE Transactions on Software Engineering
#index341473
#!Many problems of block structure derive from the remote specification of parts of the local environment. An alternative to block structure is proposed, in which the local environment is described within each program module. Concise environment descriptions are made possible by creating a tree whose terminal nodes are declarations and whose intermediate nodes can represent all of their descendant terminal node declarations. The tree encompasses all of the data used by the program and can thus be thought of as the data structure for the entire program. Each intermediate node of the tree names an abstract data structure that is implemented from the data named in its descendant nodes. Top-down refinement of abstract data structures consists of creating descendant nodes, and terminates when all terminal nodes of the tree have been created. This activity occurs as a normal part of program development, along with the top-down refinement of program modules. The tree can be used in place of a symbol table as a referencing structure for compilation or interpretation. Compilation time wili then increase linearly with the length of the program and the referencing structure can grow dynamically during compilation.


#*Optimal program and data locations in computer networks
#@Howard L. Morgan,K. Dan Levin
#t1977
#cCommunications of the ACM
#index329920
#%204903
#%547478
#!An optimization procedure for the allocation of program and data files in a computer network is presented. This algorithm takes into account the dependencies between files and programs such as occur in real heterogeneous computer networks. Insights into whether or not to convert programs from one computer to another can also be gained from the model. A search procedure for the file location problem is described, along with an example and a possible application of the model.


#*Computer Graphics, Interactive Techniques, and Image Processing 1970-1975: A Bibliography
#@U. W. Pooch
#t1976
#cComputer
#index336881
#!Computer graphics, interactive techniques, and image processing are among the developments in the constantly evolving computer science field that impact the potential user ever more rapidly. This bibliography attempts to compile all articles, books, conference papers, and technical reports about computer graphics and man-machine interaction that have been published in English from 1970 to 1975. Because the literature pertaining to computer graphics and man-machine interaction is immense, this bibliography will no doubt be incomplete. Suggestions and contributions for future supplements to the bibliography should be sent to the compiler.


#*Proceedings of the 3rd SIGCSE symposium on Computer science education
#@
#t1973
#cACM SIGCSE Bulletin
#index304791


#*The implementation of a user-extensible system on a dynamically microprogrammable computer
#@Fergus K. Fung,Willis K. King
#t1977
#cACM SIGMICRO Newsletter
#index549490
#!On a dynamically user-microprogrammable computer the user can tailor the machine to his needs by constructing microprogrammed routines and adding them to the system. If these routines are recognized by the assembler, then using them is no different from using any other basic machine instruction of the computer. The base machine is thus extended. The design and implementation of such a user-extensible system is described. It consists of 2 main parts: a pager which manages a virtual memory for the writable control storage and a user-extensible assembler which accepts microprogrammed routine into the virtual control memory and makes this an integral part of the system.


#*Asynchronous computer simulation of digital networks
#@Robert Warren Leavene, Jr.
#t1972
#c
#index186966


#*INSPECTOR
#@
#t1978
#cProceedings of the 1st annual international ACM SIGIR conference on Information storage and retrieval
#index546795
#!INSPECTOR is a proprietary software system that is designed to be used in an information retrieval environment. Specifically, it is oriented toward the on-line retrieval of microfilmed documents through the indexing of certain key terms relating to the document itself. Items such as date, account number, name, customer name or number, purchase order number, etc. might be considered as key descriptive terms. Thus by indexing these elements on a randomly accessible disk drive, the location of the filmed image of all original documents pertaining to a particular descriptive term may be quickly located by the computer and the location displayed to the operator. Alternatively, if used in conjunction with the Eastman Kodak IC-5/PR-1 microfilm retrieval unit, the computer system will cause the film display unit to automatically advance to the correct frame(s), keeping operator intervention to an absolute minimum.


#*Image transmission and coding based on human vision.
#@Raphael Jona Rom
#t1975
#c
#index189181


#*Review of "A Guide for Software Documentation, by Dorothy Walsh" Published by Advanced Computer Techniques Corp., 1969
#@Patricia Durr
#t1975
#cACM SIGDOC Asterisk Journal of Computer Documentation
#index16698
#!I will begin this critique with an evaluation and description of the book's concepts and contents. Its approach and use will be discussed at the end. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*DASIM 1: A Practical Exercise in Data Abstraction
#@Geoffrey J. Nolan
#t1979
#cProceedings of a Symposium on Language Design and Programming Methodology
#index383743


#*A Globally Convergent Method for Nonlinear Programming
#@Shih Han
#t1975
#c
#index112782
#!Recently developd Newton and quasi-Newton methods for nonlinear programming possess only local convergence properties. Adopting the concept of the damped Newton method in unconstrained optimization, we propose a stepsize procedure to maintain monotone decrease of an exact penalty function. In so doing, the convergence of the method is globalized. Keywords: nonlinear programming, global convergence, exact penalty function.


#*An iterative block lanczos method for the solution of large sparse symmetric eigenproblems.
#@Richard Ray Underwood
#t1975
#c
#index194446


#*Computer Processing of Biomedical Images
#@K. Preston
#t1976
#cComputer
#index337237
#!The 1970's have witnessed two dramatic innovations in the application of computers to image processing in medicine: computerized tomography (CT), a system where data gathered from an x-ray scanner are fed into a computer to produce cross-sectional images of the human body, and white blood cell differentiation (WBCD), a system that uses a television camera and a computer to replace the human eye and brain in the sophisticated task of visually observing and classifying human white blood cells through the microscope.


#*Management of the model development process
#@Igal Ayal,Donald J. Hempel,Philippe Cattin
#t1978
#cProceedings of the 10th conference on Winter simulation - Volume 1
#index547153
#!The purpose of this paper is to present a conceptual framework for managing the development and implementation of decision models. Some of the more critical behavioral factors involved and organizational determinants of model value are discussed. The discussion leads to five points that should deserve special attention in any model development process.


#*Model, Design, and Evaluation of a Compiler for a Parallel Processing Environment
#@J. -L. Baer
#t1977
#cIEEE Transactions on Software Engineering
#index345379
#!The problem of designing compilers for a multiprocessing environment is approached. We show that by modeling an existing sequential compiler, we gain an understanding of the modifications necessary to transform the sequential structure into a pipeline of processes. The pipelined compiler is then evaluated through measurements and simulation. Properties of the model, a generalized Petri Net, are also discussed.


#*IEEE Computer Society
#@
#t1978
#cIEEE Transactions on Computers
#index336366


#*Computer
#@
#t1970
#cComputer
#index352751


#*The Use of Software Science in Evaluating Modularity Concepts
#@A. L. Baker
#t1979
#cIEEE Transactions on Software Engineering
#index338381
#!An investigation is made into the extent to which relationships from software science are useful in analyzing programming methodology principles that are concerned with modularity. Using previously published data from over 500 programs, it is shown that the software science effort measure provides quantitative answers to questions concerning the conditions under which modularization is beneficial. Among the issues discussed are the reduction of similar code sequences by temporary variable and subprogram defmition, and the use of global variables. Using data flow analysis, environmental considerations which affect the applicability of alternative modularity techniques are also discussed.


#*A first order approximation to the optimum checkpoint interval
#@John W. Young
#t1974
#cCommunications of the ACM
#index322618
#!To avoid having to restart a job from the beginning in case of random failure, it is standard practice to save periodically sufficient information to enable the job to be restarted at the previous point at which information was saved. Such points are referred to as checkpoints, and the saving of such information at these points is called checkpointing [1].


#*Performance evaluation of highly concurrent computers by deterministic simulation
#@B. Kumar,E. S. Davidson
#t1978
#cCommunications of the ACM
#index317303
#!Simulation is presented as a practical technique for performance evaluation of alternative configurations of highly concurrent computers. A technique is described for constructing a detailed deterministic simulation model of a system. In the model a control stream replaces the instruction and data streams of the real system. Simulation of the system model yields the timing and resource usage statistics needed for performance evaluation, without the necessity of emulating the system. As a case study, the implementation of a simulator of a model of the CPU-memory subsystem of the IBM 360/91 is described. The results of evaluating some alternative system designs are discussed. The experiments reveal that, for the case study, the major bottlenecks in the system are the memory unit and the fixed point unit. Further, it appears that many of the sophisticated pipelining and buffering techniques implemented in the architecture of the IBM 360/91 are of little value when high-speed (cache) memory is used, as in the IBM 360/195.


#*Letters to the Editors
#@
#t1975
#cComputer
#index337829


#*Certification of Algorithm 30: Numerical solution of the polynomial equation
#@John J. Kohfeld
#t1967
#cCommunications of the ACM
#index324853


#*Computers...by the Millions, for the Millions
#@
#t1976
#cComputer
#index337507


#*Computer science for teachers
#@Judith G. Malkin
#t1972
#cProceedings of the second SIGCSE technical symposium on Education in computer science
#index551521
#!As computing systems in general, and timesharing systems in particular, are becoming less expensive and more reliable, a number of small colleges, junior colleges, and secondary schools are in a position to use computers in the classroom. Immediately this presents the problem of training and education, since many teachers may not have had the opportunity to learn about computers and computer programming when they were in school themselves, or if they had, a lapse of several years would have made much of their knowledge out of date. If a school is obtaining its own computer, the manufacturer may provide training in operation and programming, but this may have several drawbacks. There may be a cost associated with the training, the courses may be at a time prohibiting the attendance of the teacher, and, most importantly, the courses are probably not precisely what the teacher needs to use the computer in the classroom. If the teacher is fortunate enough to be close to a university offering computer science courses, the same drawbacks mentioned above may apply. Many university computer science courses are either pure programming courses or highly theoretical courses. Courses in computer-assisted instruction (lesson design) also do not meet the teacher's needs. With this in mind, and with a growing population of secondary school and small college users, the University of Texas Computer Science department offered a special course, specifically for teachers, in the 1971 summer session.


#*Lower bounds on the size of sweeping automata
#@Michael Sipser
#t1979
#cProceedings of the eleventh annual ACM symposium on Theory of computing
#index550857
#%193168
#%544896
#%545227
#!Establishing good lower bounds on the complexity of languages is an important area of current research in the theory of computation. However, despite much effort, fundamental questions such as P &equil;? NP and L &equil;? NL remain open. To resolve these questions it may be necessary to develop a deep combinatorial understanding of polynomial time or log space computations, possibly a formidable task. One avenue for approaching these problems is to study weaker models of computation for which the analogous problems may be easier to settle, perhaps yielding insight into the original problems. Sakoda and Sipser [3] raise the following question about finite automata: Is there a polynomial p, such that every n-state 2nfa (two-way nondeterministic finite automaton) has an equivalent p(n)-state 2dfa? They conjecture a negative answer to this. In this paper we take a step toward proving this conjecture by showing that 2nfa are exponentially more succinct than 2dfa of a certain restricted form.


#*Minicomputers in the Digital Laboratory Program
#@Taylor
#t1973
#cComputer
#index335923
#!The following article is a condensation of a COSINE task force report. The editing process required to condense the original report for these pages necessarily involves arbitrary judgements, and may have introduced emphases and perspectives that are not held by the authors of the report. All such differences are unintentional. Interested readers should obtain copies of the full report, which are available without charge from: Commission on Education, National Academy of Engineering, 2101 Constitution Avenue, N. W. Washington, D. C. 20418


#*The Data Reduction Laboratory-an aid to the space scientist
#@Barbara A. Walton,Frank A. Keipert,John J. Quann
#t1969
#cProceedings of the 1969 24th national conference
#index548036
#!The data Reduction Laboratory was designed as a system that could be used easily by the space scientist. This system will allow him to interface with his data; it will not only process data in real-time, but be capable of being 'programmed' rapidly. The key to this system lies in the use of a combination of dialog and SYNTAX. Dialog is used where possible&mdash;in those areas that can be preconceived, where the possibilities are finite and either limited or subject to limitations&mdash;SYNTAX where not. The input and output, therefore, are defined through dialog, experiment computation by SYNTAX. Relatively complicated processors can be written, checked out, and operating in terms of hours rather than months. Anomalies in the data can be observed and compensated for; data correlations are facilitated. The time lag between launch and analysis should be considerably shortened.


#*Proceedings of the 11th conference on Winter simulation - Volume 2
#@
#t1979
#cWinter Simulation Conference
#index546925


#*On a program for Ray-Chaudhuri's algorithm for a minimum cover of an abstract complex
#@Dominique C. Foata
#t1961
#cCommunications of the ACM
#index333017


#*Bi-directional tree automata.
#@Aaron David Klappholz
#t1974
#c
#index201141


#*Computational design alternatives with microprocessor-based systems.
#@Sigurd Leland Lillevik
#t1978
#c
#index189863


#*An efficient algorithm of generating fault detection and location test sets for combinational logic circuits.
#@Shiang Ming Wu
#t1974
#c
#index198818


#*Survey of analytic queueing network models of computer systems
#@Martin G. Kienzle,K. C. Sevcik
#t1979
#cACM SIGSIM Simulation Digest
#index554355
#%185447
#%187946
#%200408
#%203231
#%314002
#%319336
#%319426
#%323873
#%327148
#%329878
#%330530
#%331119
#%545622
#%545948
#%551943
#%553985
#!A number of case studies involving the use of queueing network models to investigate actual computer systems are surveyed. After suggesting a framework by which case studies can be classified, we contrast various parameter estimation methods for specifying model parameters based on measurement data. A tabular summary indicates the relationships among nineteen case studies.


#*Handling difficult faults in operating systems
#@R. M. Needham
#t1971
#cProceedings of the third ACM symposium on Operating systems principles
#index549304
#!It is commonplace to build facilities into operating systems to handle faults which occur in user-level programs. These facilities are often inadequate for their task; some faults or incidents are regarded as so bad that the user cannot be allowed to act on them and this makes it difficult or impossible to write subsystems which give proper diagnostics in all cases, or which are adequately secure, or which are adequately robust. This paper looks into why there is a need for very complete facilities and why there is a problem about providing them, and proposes an outline structure which could be used.


#*Organizing matrices and matrix operations for paged memory systems
#@A. C. McKellar,E. G. Coffman, Jr.
#t1969
#cCommunications of the ACM
#index330858
#%318912
#%329636
#%330178
#%554090
#!Matrix representations and operations are examined for the purpose of minimizing the page faulting occurring in a paged memory system. It is shown that carefully designed matrix algorithms can lead to enormous savings in the number of page faults occurring when only a small part of the total matrix can be in main memory at one time. Examination of addition, multiplication, and inversion algorithms shows that a partitioned matrix representation (i.e. one submatrix or partition per page) in most cases induced fewer page faults than a row-by-row representation. The number of page-pulls required by these matrix manipulation algorithms is also studied as a function of the number of pages of main memory available to the algorithm.


#*Report on a microprogramming workshop
#@Helmut K. Berg,Udo Schloms
#t1979
#cACM SIGMICRO Newsletter
#index7971
#%572429
#!In connection with the annual conference of the Gesellschaft f&uuml;r Informatik (the German association of professional computer scientists), GI, a microprogramming workshop was held October 6 in Berlin. The workshop was organized by the GI interest group for Firmware and Microprogrammed Computer Structures. It was intended to provide, in the professional domain, a forum for the exchange of research experiences and results, and to promote, in the public domain, the knowledge of the current status and future trends in microprogramming and firmware engineering. The initiative taken by the GI interest group was honored by an unexpectedly high attendance of over 100 practitioners.


#*On ACM goals
#@Walter M. Carlson
#t1971
#cCommunications of the ACM
#index334328


#*Generating English discourse from semantic networks
#@R. Simmons,J. Slocum
#t1972
#cCommunications of the ACM
#index330460
#%318506
#%323984
#%325037
#%549682
#%553721
#%334070


#*Systematic mistake analysis of digital computer programs
#@Joan C. Miller,Clifford J. Maloney
#t1963
#cCommunications of the ACM
#index314903
#%545523
#%330767
#%316182


#*Anaphoria in natural Language Understanding: A Survey
#@Graeme Hirst
#t1979
#c
#index205337
#!A problem that all computer-based natural language understanding (NLU) systems encounter is that of linguistic reference, and in particular anaphora (abbreviated reference). For example, in a text as simple as: \begin{quote} Nadia showed Sue her new car. The seats were Day-Glo orange. \end{quote} knowing that ``her'''' probably means Nadia and not Sue and that ``the seats'''' means the seats of Nadia''s new car is not a simple task. .br This thesis is an extensive review of the reference and anaphor problem, and the approaches to it that NLU systems have taken, from early systems such as STUDENT through to current discourse-oriented ones such as PAL. .br The problem is first examined in detail, and examples are given of many different types of anaphor, some of which have been ignored by previous authors. The approaches taken in traditional systems are then described and abstracted and it is shown why they were inadequate, and why discourse theme and anaphoric focus need to be taken into account. The strengths and weaknesses of current anaphora theories and approaches are evaluated. The thesis closes with a list of some remaining research problems. .br The thesis has been written so as to be as comprehensible as possible to both AI workers who know no linguistics, and linguists who have not studied artificial intelligence.


#*On the efficiency of control procedures for computer communication networks
#@Holger Opderbeck
#t1975
#cACM SIGOPS Operating Systems Review
#index547431
#%244054
#!The last decade has seen an explosive growth in the area of computer communications and, in particular, computer networking. Similar to the early stages of the development of time sharing systems, the first studies in this new area concentrated on demonstrating the feasibility and building a theoretical foundation [CHU 69, DAVI 68, SCAN 68, HEAR 70, FRAN 70, KLEI 70, CARR 70]. While many theoretical questions remain unresolved [CHOU 74, KLEI 74a, OPDE 74a], the feasibility of these systems has clearly been established. The interest has recently shifted toward efficient and secure implementations of computer communication systems. In this paper we will comment on the efficiency of control procedures and report on the experience which we have gained with the operation of the ARPANET.


#*The AUGMENT precompiler as a tool for the development of special purpose arithmetic packages
#@F. D. Crary,J. M. Yohe
#t1979
#cACM SIGNUM Newsletter
#index548520
#%318741
#%329807
#%330195
#%334744
#!We discuss the use of a FORTRAN precompiler in the development of packages for nonstandard arithmetics. In particular, the use of the FORTRAN precompiler, AUGMENT, renders the source code more lucid, reduces the number of lines of code in a nonstandard arithmetic package, facilitates modification, and ameliorates the problems of transporting such a package to another host system.


#*A rider to "A Question of Semantics"
#@Rod Steel
#t1978
#cACM SIGARCH Computer Architecture News
#index350074
#%191539
#%196688
#%550480
#!Peter Denning, in the April '78 issue of CAN, voiced several very incisive observations concerning the generally slow rate at which commercial computer systems have incorporated the architectural knowledge currently available.


#*Provable programs and processors
#@Donald I. Good
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index68231
#%205752
#%318506
#!"A proof of correctness guarantees that a program will run correctly every time it is executed." That statement is not necessarily true. Suppose, for sake of concreteness, that a valid proof of a Fortran program has been constructed. When this program was proved, it most likely was proved in isolation from the other software components which ultimately will be involved in actually making the program run. So, even though we have proved the Fortran program, one of these other components, or the system hardware, may malfunction causing the actual machine language program that is executed to produce an error. These comments are not an argument against proving programs at the Fortran level, but rather an indication of the eventual need for a completely proved computing system.


#*Some statistics from the software testing service
#@Edward F. Miller
#t1979
#cACM SIGSOFT Software Engineering Notes
#index433445


#*Process management and communication
#@
#t1969
#cProceedings of the second symposium on Operating systems principles
#index312257


#*A new mathematical programming time-sharing system using a precompiler and numerical derivatives
#@James L. Noyes
#t1976
#cProceedings of the 1976 annual conference
#index551701
#%196589
#!One approach for allowing a problem-oriented user to easily state and solve a given problem on a time-sharing system is by using a precompiler. The precompiler recognizes statements in a simple problem-oriented language, generating corresponding computer instructions and subprograms. These are used to define the problem and select the solution algorithms from a software library. To illustrate this approach, a simple Fortran precompiler has been implemented for the Univac which accepts mathematical programming commands (e.g. MINIMIZE:, SUBJECT TO:, etc.) and allows certain standard algorithms to be invoked. In order for this mathematical programming system to be genuinely easy to use, the required gradients and Hessians are approximated by accurate Richardson extrapolated difference schemes.


#*Trace driven modeling: Review and overview
#@S. W. Sherman,J. C. Browne
#t1973
#cProceedings of the 1st symposium on Simulation of computer systems
#index546515
#%188357
#%203578
#%303004
#%305254
#%316426
#%332602
#%332853
#%545806
#!Trace-driven modeling is a technique whereby a recorded trace of system activities is directly used to define the environment and workload for a model of a computer system. A review of the simulations of computer systems which have used trace-driven modeling as the simulation tool is presented. The advantages and disadvantages of trace-driven modeling are examined and comparison to conventional distribution driven simulation techniques is made.


#*Storage Modification Machines
#@Arnold Schönhage
#t1979
#cProceedings of the 4th GI-Conference on Theoretical Computer Science
#index274128


#*Computer aided instruction in system dynamics
#@Don Martin
#t1972
#cProceedings of the second SIGCSE technical symposium on Education in computer science
#index552604
#!In any large engineering school, there are many courses in various disciplines which can be roughly categorized as studies of system dynamics. The computer has long held great promise both as a means for improving the content of such courses and as an aid for improving the methods of teaching. While some of this promise has been realized in isolated cases, very little has been accomplished in universities where large numbers of students are involved. It is certainly true that significant improvement in course content can be achieved by using the computer to solve more meaningful and realistic dynamic problems. For example, the effects of changing the parameters in the problem formulation can be studied. However, with centralized analog and digital computing facilities this can be accomplished only in a very limited way. Problems can be programmed by the instructor and used as a demonstration for the class or the student can program the computer himself. Some demonstrations are useful and desirable but it is impossible to get the student intimately involved, and in most cases they serve only as a supplement to textbook illustrations. Student programming is an excellent approach for advanced undergraduate or graduate courses such as control system design, but it has proven less than satisfactory for first and second year science and engineering courses. Even when the students have had a basic programming course, valuable classroom time must be spent on the techniques for programming, numerical methods, and discussions of debugging. The students tend to become involved in the mechanics of programming at the sacrifice of a serious study of the dynamic system. With inexperienced students, even when turnaround time on the digital computer is good, the elapsed time between problem assignment and a satisfactory solution is much too long. The analig computer, while admittedly an outstanding device for the study of dynamic systems, is usually not available in sufficient quantity for a large class and suffers from the same student programming restriction as the digital. We felt that terminals based on an analog or hybrid computer would materially improve student/computer interaction, especially aiding in the comprehension of those dynamic systems described by ordinary differential equations. This paper is a report of the implementation of such a system at N. C. State University. The system was funded by the National Science Foundation with the hardware developed by Electronic Associates Inc. and the software developed by the university.


#*Programming Techniques: ASP&mdash;a ring implemented associative structure package
#@C. A. Lang,J. C. Gray
#t1968
#cCommunications of the ACM
#index316785
#%327662
#%545852
#!ASP is a general purpose Associative Data Structure Package in which an arbitrary number of data items and an arbitrary number of the relationships between these data items may be represented. A special picture language is described which has proved very useful for drawing ASP structures on paper. ASP structures are built and manipulated by means of a series of macro calls, which are outlined in the Appendix. Emphasis is on the philosophy of the system rather than a particular implementation, though sufficient information is included to enable the reader to produce his own implementation of ASP.


#*Probabilistic Tree Automata
#@Clarence A. Ellis
#t1970
#cProceedings of the second annual ACM symposium on Theory of computing
#index549363
#%579380
#%549991
#!The purpose of this paper is meant to be three-fold. First it will introduce the reader to the concepts of Probabilistic Languages and Probabilistic Grammars. Second, it indicates that previous definitions of probabilistic finite automaton have always been restricted to 1 of 8 classes of automaton and shows that other classes are useful. Third, the probabilistic concept is extended from finite automata to higher level automata (such as probabilistic PDAs and probabilistic Turing automata). A specific application of this theory is given in the development of Probabilistic Tree Automata. Theorems concerning these automata and operations on them are presented. It is indicated that this type of automaton is relevant because it characterizes Probabilistic Context Free Languages. The results are taken from the author's PhD Thesis.4


#*Computational issues in linear least-squares estimation and control.
#@John Anthony Newkirk
#t1979
#c
#index203090


#*Fundamental GPSS tutorial
#@
#t1973
#cProceedings of the 6th conference on Winter simulation
#index552428
#!Approach to modeling in GPSS. Fundamental GPSS blocks, including GENERATE, TERMINATE, SIEZE and RELEASE, ADVANCE, and QUEUE and DEPART. A GPSS &ldquo;case study&rdquo; model for a one-line, one- server queuing system. Internal logic of the GPSS processor, including the current and future events chains, and a numeric example explaining how the processor simulates with the one-line, one-server model.


#*Interference between communicating parallel processes
#@Philip Gilbert,W. J. Chandler
#t1972
#cCommunications of the ACM
#index332939
#%316233
#%319561
#%335624
#!Various kinds of interference between communicating parallel processes have been examined by Dijkstra, Knuth, and others. Solutions have been given for the mutual exclusion problem and associated subproblems, in the form of parallel programs, and informal proofs of correctness have been given for these solutions. In this paper a system of parallel processes is regarded as a machine which proceeds from one state S (i.e. a collection of pertinent data values and process configurations) to a next state S&prime; in accordance with a transition rule S &rArr; S&prime;. A set of such rules yields sequences of states, which dictate the system's behavior. The mutual exclusion problem and the associated subproblems are formulated as questions of inclusion between sets of states, or of the existence of certain sequences. A mechanical proof procedure is shown, which will either verify (prove the correctness of) or discredit (prove the incorrectness of) an attempted solution, with respect to any of the interference properties. It is shown how to calculate transition rules from the &ldquo;partial rules&rdquo; by which the individual processes operate. The formation of partial rules and the calculation of transition rules are both applicable to hardware processes as well as to software processes, and symmetry between processes is not required.


#*Inventory and distribution models
#@David R. Anderson,Brian D. Sellers,Lynn E. Bussey,M. Palmer Terrell,Donald A. Heimburger,Kailash M. Bafna,Roland Young
#t1973
#cProceedings of the 6th conference on Winter simulation
#index546720
#!Inventory control is one of the &ldquo;classical&rdquo; problems areas for quantitative analysis. Inventory and distribution systems have been subjected to analysis using simulation since the advent of medium size computers. In this session the emphasis is on production inventories and their interaction with production efficiency and warehouse operations.


#*Description and recognition of scenes and object shapes from gray level inputs.
#@Hou-Yuan Franklin Feng
#t1974
#c
#index205694


#*Note on dynamic own arrays
#@Peter Naur
#t1961
#cIssue 12 (April 1961)
#index102222


#*On the nonexistence of a phrase structure grammar for ALGOL 60
#@Robert W. Floyd
#t1962
#cCommunications of the ACM
#index324391
#!ALGOL 60 is defined partly by formal mechanisms of phrase structure grammar, partly by informally stated restrictions. It is shown that no formal mechanisms of the type used are sufficient to define ALGOL 60.


#*The allocation of real-time computing within a multiple-user organization
#@Jeffrey H. Moore
#t1978
#cProceedings of the 10th conference on Winter simulation - Volume 2
#index552587
#!The allocation of computer time among competing uses within an organization has received considerable attention in the literature. Most approaches focus upon the use of decentralized mechanisms for effecting resource allocation of computer time within the non-market setting of an organization. Under the simplifying assumption that the only resource to be allocated is computer time, this paper investigates a decentralized mechanism, based upon bidding, for the optimal real-time allocation of computer time within a multiple-user organization. A simulation model is then developed to generate alternative decision rules for the cases in which no known analytical rules exist. A general principle for simulation methodology, called &ldquo;reducto ad credibilis,&rdquo; is proposed for restricting the class of simulations.


#*Introduction to SPLM
#@R. Hokom,A. Grebert,F. Gerbstadt,R. Bock
#t1973
#cComputer
#index342761
#!This is an introduction to, and an overview of, the Space Programming Language Machine (SPLM), which is an architecture for a class of machines designed for efficient execution of on-board, aerospace computation functions. It directly executes software written in the SPLM Language (SPLML), which has been specially constructed as a complete, concise notation for the application area. The goal of the SPLM development effort is to design machines that are smaller, faster and easier to program than currently available aerospace computers. The specific features and characteristics of the SPLM may have general applicability, although this was not a design criterion.


#*Evening 1: Night in a berkeley laboratory
#@Austin Haggatt,Mark Greenberg,Jeffrey Moore,Martin Shubik,Myron Uretsky
#t1973
#cProceedings of the 6th conference on Winter simulation
#index555059
#!A novel micro-programmed APL computer for laboratory control is being developed in the Laboratory under sponsorship of the National Science Foundation. Visitors will have an opportunity to see a demonstration of the system and hear a presentation of its design features. In addition there will be two presentations on joint teaching and research use of business games.


#*Exception handling: issues and a proposed notation
#@John B. Goodenough
#t1975
#cCommunications of the ACM
#index335238
#%314822
#%316233
#%321876
#%323067
#%327662
#%328151
#%562103
#%553250
#!This paper defines exception conditions, discusses the requirements exception handling language features must satisfy, and proposes some new language features for dealing with exceptions in an orderly and reliable way. The proposed language features serve to highlight exception handling issues by showing how deficiencies in current approaches can be remedied.


#*Multinational corporate computer-based information systems and the parent-subsidiary interface.
#@Steven Leslie Mandell
#t1975
#c
#index192479


#*Models for specification and anaysis of parallel computing systems
#@R. M. Mattheyses,S. E. Conry
#t1979
#cACM SIGSIM Simulation Digest
#index550121
#%240173
#%323067
#%324771
#%324964
#%332514
#%333809
#%335365
#%619912
#!The problem of designing a properly functioning parallel hardware or software system is considerably more difficult than that of designing a similar sequential system. In this paper we formulate criteria which a design methodology for parallel systems should satisfy and explore the use of various models as the basis for such a design tool.


#*Problems, productions, and piaget: a developmental approach to artificial intelligence
#@Joseph William Dempsey
#t1979
#c
#index191853


#*Subscript optimisation and checking
#@C. A. R. Hoare
#t1968
#cIssue 29 (November 1968)
#index103964


#*Certification of algorithm 123: real error function, ERF (x)
#@Henry C. Thacher, Jr.
#t1963
#cCommunications of the ACM
#index329543


#*Distributed Processing
#@A. van Dam
#t1978
#cComputer
#index350355
#!This issue of Computer is based on two workshops in distributed processing held at Brown University August 17-19, 1976, and August 3-5, 1977. Sponsored by the Army Research Office, the National Science Foundation, and the Office of Naval Research, the workshops attempted to define what distributed processing means and to develop a taxonomy of distributed processing applications and techniques. Achievements to date and outstanding research problems were examined in an attempt to find either commonality of problems and solutions or substantial differences.


#*Control structures in Illiac IV Fortran
#@Robert E. Millstein
#t1973
#cCommunications of the ACM
#index324461
#!As part of an effort to design and implement a Fortran compiler on the ILLIAC IV, an extended Fortran, called IVTRAN, has been developed. This language provides a means of expressing data and control structures suitable for exploiting ILLIAC IV parallelism. This paper reviews the hardware characteristics of the ILLIAC and singles out unconventiona features which could be expected to influence langluage (and compiler) design. The implications of these features for data layout and algorithm structure are discussed, and the conclusion is drawn that data allocation rather than code structuring is the crucial ILLIAC optimization problem. A satisfactory method of data allocation is then presented. Language structures to utilize this storage method and express parallel algorithms are described.


#*A many-state Markov model for the estimation and prediction of computer software performance parameters
#@Ashok K. Trivedi,Martin L. Shooman
#t1975
#cProceedings of the international conference on Reliable software
#index552062
#%198428
#!A many-state Markov model has been developed for the purpose of providing various performance criteria for computer software. The software system under consideration is assumed to be fairly large, of the order of 105 words of code, so that statistical deductions become meaningful, and is assumed to initially contain an unknown number of unknown bugs. The model provides estimates and predictions of the most probable number of errors that will have been corrected at a given time t in the operation of this software package based on preliminary modeling of the error occurrence rate &lgr; as well as the error correction policy &mgr;. The model also provides predictions for the availability A(t) and for the reliability R(t) of the system. The differential equations corresponding to the Markov model are solved for the case when &lgr; and &mgr; are constant using an exact (closed-form) solution. The numerical solution is also obtained for this case for verification and demonstrative purposes. The more interesting and important case, from an applications point of view, is that when &lgr; and &mgr; are not constant, but rather functions of the state of debugging achieved. This case is solved numerically only, since the exact solution is cumbersome. It is also demonstrated that the numerical solution is superior to the so-called exact solution. Finally, some extensions and modifications of the basic Markov model are briefly discussed.


#*Two Level Grammars: CF-Grammars with Equation Schemes
#@Piotr Dembinski,Jan Maluszynski
#t1979
#cProceedings of the 6th Colloquium, on Automata, Languages and Programming
#index365507


#*Direct methods of computer analysis
#@Norman Davids
#t1966
#cCommunications of the ACM
#index316077
#%331937


#*Automated Process Control Systems: Concepts and Hardware
#@Ronald P. Hunter
#t1978
#c
#index621184
#!:In this revised and updated second edition, Ronald P. Hunter includes new chapters on theory of measurements, the process control operator interface, and robotics. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Certification of algorithm 292 [S22]: regular coulomb wave functions and of remark on algorithm 292 [S22]: regular coulomb wave functions
#@K. S. Kölbig
#t1969
#cCommunications of the ACM
#index325114


#*Proceedings of the 5th annual conference on Computer graphics and interactive techniques
#@
#t1978
#cInternational Conference on Computer Graphics and Interactive Techniques
#index553433


#*Rechnerverbund: Motivation, M&ouml;glichkeiten und Gefahren
#@Wolfgang Händler
#t1976
#cRechnernetze und Datenfernverarbeitung, Fachtagung der GI und NTG
#index366508


#*Certification of algorithm 52: a set of test matrices
#@H. E. Gilbert
#t1961
#cCommunications of the ACM
#index319981


#*Automatic recognition of synthetic speech using an electronic model of the middle and inner ear.
#@Donald Bruce Warmuth
#t1978
#c
#index191496


#*Theoretical and computational considerations for finite time interval system identification without initial state estimation.
#@Yuen-Kwok Chin
#t1977
#c
#index185824


#*Octal diagrams of binary conception and their applicability to computer design logic
#@Shu-T'ien Li
#t1959
#cCommunications of the ACM
#index324567


#*TEDDY2: a program package for 2D parabolic composite region problems (abstract)
#@S. J. Polak,N. V. Philips
#t1975
#cACM SIGNUM Newsletter
#index97319
#!Applied physicists usually do not want to solve their problem with a computer, they want to have it solved by a computer.


#*A phenomenalistic theory of the development of science.
#@Warren Thomas Jones
#t1973
#c
#index197139


#*A model of interference in a shared resource multiprocessor
#@John E. Jensen,Jean-Loup Baer
#t1976
#cProceedings of the 3rd annual symposium on Computer architecture
#index553648
#%192067
#%195384
#%201874
#!This paper presents a generalized model of tightly-coupled multiprocessor systems which is then simplified to form a stochastic model for the study of interference. Analysis is performed on the resource contention which is characteristic of such systems in order to find a measure of system performance. After reviewing the problem of memory interference, the analysis is extended to contention in other individual resources, then combined to form a model for the interacting effects of contention in systems where processors contend for several shared resources.


#*Automated documentation
#@Martin A. Goetz
#t1976
#cACM SIGDOC Asterisk Journal of Computer Documentation
#index578827
#!The problem of developing and maintaining adequate documentation for computerized user applications is certainly not being addressed properly at most installations. Documentation is needed at the module, program, and system levels, at the user levels, and at the operations level.


#*Proceedings of the 1973 ACM SIGME symposium
#@
#t1973
#cJoint International Conference on Measurement and Modeling of Computer Systems
#index552781


#*A high security log-in procedure
#@George B. Purdy
#t1974
#cCommunications of the ACM
#index321094
#%622734
#!The protection of time sharing systems from unauthorized users is often achieved by the use of passwords. By using one-way ciphers to code the passwords, the risks involved with storing the passwords in the computer can be avoided. We discuss the selection of a suitable one-way cipher and suggest that for this purpose polynomials over a prime modulus are superior to one-way ciphers derived from Shannon codes.


#*Computer Society Officers and Members of the Board of Governors for 1971
#@
#t1971
#cComputer
#index349506


#*Fast algorithms for multivariable systems.
#@Martin Morf
#t1974
#c
#index203646


#*Algorithms for higher level functions in machine hardware.
#@Paul William Baker
#t1976
#c
#index190504


#*Direct search for optimal parameters within simulation models
#@Hans-Paul Schwefel
#t1979
#cProceedings of the 12th annual symposium on Simulation
#index545503
#%553448
#!The tool of systems simulation can be improved by superposing optimization techniques onto the computer model of the object or system investigated. Direct search methods for parameter optimization are applicable in a much wider field than any other technique. Outstanding among such partly heuristic methods is one that is based on principles of organic evolution. The results of a comprehensive test program in which all important algorithms have been compared reveal the superiority of this evolution strategy. Reference is made to examples of actual application.


#*Graphics in APL
#@Alfred M. Bork
#t1972
#cProceedings of the fourth international conference on APL
#index545868
#!This document describes an experimental graphic facility within APL. The terminals are assumed to be inexpensive timeshared graphic terminals equipped with an APL character set. We first describe functions in a graphic workspace, and then APL primitives for graphing.


#*Data integrity considerations in computer based accounting systems
#@Dan S. Dhaliwal,Benn R. Konsynski
#t1977
#cProceedings of the 1977 annual conference
#index550916
#%314331
#%326368
#!Over the past few years there has been a steady increase in the applications of computers to accounting functions. While computerized accounting systems enable one to store a large volume of data and process these data very rapidly, such systems also contribute to the complexity of data integrity problems. The purpose of this paper is to review several important considerations in developing and maintaining the integrity of data in computerized accounting systems. In order to establish a reasonable degree of confidence in data generated by an accounting system, the hardware, software, communications and human operating procedures must operate in concert. Integrity of data can be compromised in any one of the several phases of the &ldquo;life cycle&rdquo; of accounting data. The basic stages in this life cycle might be characterized as follows: 1. Measurement and classification 2. Transcription, validation and storage 3. Processing, updating and recovery


#*Some thoughts on the use of simulation in the health services sector
#@Arnold Reisman
#t1979
#cACM SIGSIM Simulation Digest
#index581167
#%548447
#!Simulation has been used in a number of modes in conducting studies for the health care industry. This paper briefly presents these usage modes and references each to more extensive write-ups of studies performed by teams which included the author of this article.


#*Small systems performance in business (Panel Session)
#@Percy Wood,Jonathan Schmidt,Stuart E. Savory,Dale Johnson
#t1978
#cProceedings of the first SIGMINI symposium on Small systems
#index554368


#*Database machines
#@Stanley Y. W. Su,P. Bruce Berra,Paul Fisher,Hsu Chang,Stuart Schuster,George Copeland
#t1978
#cProceedings of the 1978 ACM SIGMOD international conference on management of data
#index613252
#!There is much to be said on the limitations of the conventional Von Neumann processors and the available hardware organizations for database applications. Through research and development, several recent efforts have been in the investigation and development of new architectures and special prupose machines for supporting database applications. This panel aims to familiarize the attendants with 1) the motivations for works on data machines, 2) the objectives and characteristics of several categories of database machines, 3) the accomplishments made in this area of research and development, 4) the problems and current issues confronting the area, and 5) the impact of the current and future technologies on database management.


#*Modeling and Analysis using SAINT: A combined discrete/continuous network simulation language
#@David B. Wortman,Steven D. Duket,Deborah J. Seifert
#t1977
#cProceedings of the 9th conference on Winter simulation - Volume 2
#index551745
#!SAINT, Systems Analysis of Integrated Networks of Tasks, is a network modeling and simulation technique developed to assist in the design and analysis of complex man-machine systems.* SAINT provides the concepts necessary to model systems that consist of tasks (discrete elements), state variables (continuous elements), and interactions between them. It facilitates the assessment of the contribution that system components make to overall system performance.


#*The computer solution of english probability problems
#@Jack Peter Gelb
#t1971
#c
#index203303


#*Modellierung von Kanten bei unregelm&auml;&szlig;iger Rasterung
#@Ernst E. Triendl
#t1978
#cBildverarbeitung und Mustererkennung, DAGM Symposium
#index568644


#*Investigation of the mechanisms for interprocess communication
#@Jan Polek,Imtiaz Ahmad
#t1973
#cProceedings of the ACM annual conference
#index553346
#!From a study of the computer systems operating in a multiprogramming environment, a model for the interrupt activity is derived. The basic components of the interrupt activity are identified and a formulation is developed to express process switching in terms of these components. The systems studied include, in particular, the IBM 360/370, Burroughs 5000/6000/6, PDP 10/11/8, Nova 1200, etc. Some important aspects of interrupt structure, such as, response time, overhead and saturation are examined and compared. The results indicate that while logical functions1, such as, interrupt acknowledge, saving, servicing and post processing are easily identifiable, their hardware implementation exhibit variations which have significant influence on process switching flexibility2. The use of interrupt mechanisms in scheduling of processes in multiprogramming systems is illustrated with examples. Problems of suitable functional modules for processor multiplexing are discussed. The results of the aforementioned study are used to suggest a suitable representation of the mechanisms for interprocess communication.


#*Computational understanding: analysis of sentences and context.
#@Christopher Kevin Riesbeck
#t1974
#c
#index187115


#*A path analysis approach to the diagnosis of combinational circuits
#@Sarma R. Vishnubhotla,Ying Huang Chuang
#t1971
#cProceedings of the 8th Design Automation Workshop
#index550287
#!A unified procedure to find test patterns for detection and location of stuck-at-type single faults in the combinational circuits is described. A reduction algorithm to obtain a minimal set of detection patterns and a location algorithm to obtain complete location information obtainable by external observation; are presented. The circuit may consider AND, OR, NOT, NOR, NAND, EXCLUSIVE OR and LOGICAL EQUIVALENCE gates. A basis for the article are the single and multi-dimensional path sensitization (1,2) and the graph theoretical approach for system diagnosis (3). The main parts of this work is the construction of sensitization functions and the path analysis table, and the development of the reduction and location algorithms. The procedure is illustrated in detail by two examples.


#*MURJE: a multiple user remote job entry system
#@James M. Hobbs,Jon Todd Rickman
#t1979
#cProceedings of the 7th annual ACM SIGUCCS conference on User services
#index449448
#!MURJE is a DEC 2780 RJE package modified at Northwest Missouri State University allowing anyone who has a timesharing account on the University's PDP 11/70 timesharing computer to submit and receive batch jobs processed on a AMDAHL 470/V7 processor running under JES2 (OS,VS2). Jobs can be sent and received at any of the 58 terminals within 10 academic labs on campus. Even portable dial up terminals can use the system.The AMDAHL in Columbia, Missouri, is the host computer, while the PDP 11/70 interactive network in Maryville, Missouri, is considered the remote station. The advantages the remote users receive in such an environment includes both the large capacity and multitude of batch languages provided by the host. This is especially important where the remote has a limited but real demand for these services. The amount of use of the services would not however, financially justify their local support (see figure 1).Using a text editor, files containing the job control language, program, and possibly the data are created and stored on the remote's disk. These files are then queued by the user to the host. Remote host communication is via a 4800 baud private telephone line. Basically the AMDAHL is operational 24 hours a day, 6 1/2 days a week and MURJE makes it possible for anyone at these times to send a job to the host computer and receive the output in their private account.By having the software direct the RJE input and output from multiple user accounts, it frees up operators from running, printing, and handling output for RJE jobs. At the same time it frees the sender from extended waits for an operator to submit jobs and distribute output listings at some type of user dispatch window. The user does not go to the computing center to pick up the listing of his or her program, and is not limited to a single copy of the output.Another savings is the amount of paper that is required for output, since the output is stored on disk, available only to the sender, the sender has the capability of displaying the output on any video terminal as in figure 2, and checking its correctness before listing it on a hardcopy terminal or printer as in figure 3.


#*An alternative method for the computation of earnings per share.
#@Stephen Alton Jolly
#t1978
#c
#index197366


#*Dynamic routing in computer communication networks.
#@Adam Livne
#t1977
#c
#index199818


#*Design considerations for a Boolean search system with automatic relevance feedback processing
#@Jon T. Rickman
#t1972
#cProceedings of the ACM annual conference - Volume 1
#index234457
#%186311
#%573537
#!Two major problems are considered in the design of a Boolean search system with automatic relevance feedback processing. The first problem is how terms should be connected with Boolean logic when constructing a modified query. A number of fixed formats are presented and evaluated. The second problem is how to select terms for entry into the modified query. The stability of the system is found to be quite sensitive to its method of selecting terms. Only very restrictive term selection methods are found to be workable in several on-line experiments.


#*New Applications & Recent Research
#@D. Michalopoulos
#t1979
#cComputer
#index335656
#!More compact than previous memories due to the elimination of bulky drive coils, Bell Labs' improved bubble memory will be used to store digitally recorded messages. It will also see service in high- capacity telephone switching systems and in a variety of microprocessor-based terminal equipment. Consumer products such as pocket calculators and programmable microwave ovens may also benefit from the new development.


#*Using an APL macroprocessor to implement generalized software systems
#@Mark R. Dempsey
#t1979
#cACM SIGAPL APL Quote Quad
#index547884
#%315342
#!Several techniques for implementing generalized software packages in APL are considered. One technique in particular, data-driven code generation, is expanded upon. When this technique is employed, application software is written in template form. These templates are then compiled into APL objects when an individual application is configured. Some areas which are investigated are the use of software templates, an APL macrolanguage, and an APL macroprocessor. Specific examples relevant to data base management systems are presented.


#*Systematic recursion removal
#@M. A. Auslander,H. R. Strong
#t1978
#cCommunications of the ACM
#index317746
#%322153
#%323067
#!The recursion removal algorithm presented by Strong and Walker is amplified and applied to a relatively complex PL/I program. The aim is to demonstrate systematic recursion-removal techniques on something more complex than Knuth's &ldquo;sturdy toddler&rdquo; and to obtain measurements of the cost of procedure linkage in PL/I and the savings achievable via procedure integration in the presence of recursion. First, the paper describes the recursion-removal process and the example on which it will be illustrated. Recursion removal is then applied to the two major parts of this example and the final result of the process is displayed. Our performance comparison results are presented, and our conclusions are briefly discussed


#*Computer-Assisted Structure Elucidation
#@Dennis H. Smith
#t1977
#c
#index620678


#*A systems approach to career development: report of two surveys
#@Paul D. Oyer,Dorothy L. Ray
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index65251
#%54894
#%57734
#%554640
#%319577
#%550201
#%552684
#%548613
#%71257
#%67033
#%318784
#%458820
#!The so-called profession of computer data processing has barely reached adolescence. Like the electrical engineering profession of 25 years ago we have no standards for describing our job tasks (what we do), nor for defining job skills needed (how we do it), nor for defining educational needs (what we need to know), nor for estimating time and cost for a complete job (how long it takes and level of skills/knowledge needed).


#*Algorithms: bisection routine
#@S. Gorn
#t1960
#cCommunications of the ACM
#index323759


#*Interactive Image Analysis for Astronomers
#@D. C. Wells
#t1977
#cComputer
#index342498
#!During the last five years, ground-based astronomers have seeh some remarkable changes in the image data available to us for scientific analysis. Our image intensifiers have been greatly improved, and new photographic emulsions (Kodak IIIa-J and IIIa-F) with higher detective quantum efficiency and greater storage capacity have been introduced. Precise microdensitometers with digital output and adequate speed have become commercially available, so that we are now able to convert essentially all of the information from a photographic emnulsion into digital form. Integrating digital television cameras and silicon diode arrays with excellent sensitivity and good cosmetic quality are now replacing photographic plates in many ground-based astronomical observations. Meanwhile, radio astronomers have devised their own scheme-aperture synthesis-for recording radio-wavelength digital pictures of the sky. But improvements in digital image-handling technology are needed if we are to fully exploit the scientific research possibilities created by these new detector systems. One step in this direction is the Interactive Picture Processing System (IPPS) developed at the Kitt Peak National Observatory. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A note on the multiplication of 4x4 matrices
#@R. K. Shyamasundar
#t1978
#cACM SIGACT News
#index435988


#*Features of a proposed synchronous data network
#@F. R.E. Dell
#t1971
#cProceedings of the ACM second symposium on Problems in the optimizations of data communications systems
#index546654
#!Marketing surveys on data communication have indicated the possible need for a new data service. Technical studies have resulted in a number of detailed proposals for providing a service which, although functionally distinct, is physically integrated with other telecommunications services. The proposed network utilises synchronous digital transmission with a processor controlled T.D.M. switching structure. A range of speeds is available. Users data bytes are structured in 'envelopes' to provide an in-band control signalling facility. The use of a processor for switch control gives greater flexibility, allows the implementation of sophisticated diagnostics, and, with high speed inter switch signalling, reduces overall call set up times. The proposed network is hybrid in that it can operate in a conventional circuit switched mode, or operate in a 'packet' switched mode. Extensive multiplexing is used to increase transmission utilisation and reduce local area transmission costs.


#*Special 25th Anniversary Issue of the IEEE Transactions on Computers
#@
#t1976
#cComputer
#index341932


#*Time flow mechanisms for use in digital logic simulation
#@Stephen A. Szygenda,Cliff W. Hemming,John M. Hemphill
#t1971
#cProceedings of the 5th conference on Winter simulation
#index550250
#!Implementation of a system for the simulation of the time domain operation of a deterministic digital logic net involves consideration of problems different from those encountered simulation of the time domain operation of a stochastic system. Examination of two different simulation time flow mechanisms illustrates how each technique may be applied to the simulation of logic nets. The design goals for a general purpose logic simulator are examined and the implementation techniques used in TEGAS2 are illustrated.


#*Discriminating Content Addressable Memories
#@Carl H. Smith,Larry D. Wittie
#t1974
#cProceedings of the Sagamore Computer Conference on Parallel Processing
#index262061


#*ALGOL - Conference in Paris, 12-14 November 1959
#@Peter Naur
#t1959
#cIssue 8 (December 1959)
#index99133


#*Random deviates from the DIPOLE distribution
#@
#t1973
#cACM SIGSIM Simulation Digest
#index575143
#!The function subprogram DIPOLE, written by Robert E. Knop of the Physics Department, The Florida State University at Tallahassee FL 32306, returns a random deviate - &infin; < z < &infin; sampled from the two parameters (R2 < 1, &alpha; arbitrary) family of the density function: f(z) = 1/(&pi; (1 + z2)) + R2 * ((1 - z2) * cos(2&alpha;) + 2* z* sin (2&alpha;)/(&pi; * (1 + z2)2). The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Modulkonzept und separate Compilation in der Programmiersprache MODULA-2
#@Leo Geissmann
#t1979
#cMicrocomputing, Tagung III/1979 des German Chapter of the ACM
#index271612


#*Simulation of a minicomputer in a communications system
#@Frederick V. Crowley
#t1974
#cProceedings of the 7th conference on Winter simulation - Volume 1
#index547076
#%607651
#!An analysis of the performance of a minicomputer, which is used in a computer communications environment, is presented. The purpose of the paper is to show how some of the minicomputer's capabilities may be defined, and to establish a basis for a more detailed analysis. The principal aspect being considered is message throughput. Two models, oriented about the software, were developed: one using conventional mathematical queuing techniques and the other using a discrete simulation language (GPSS). The GPSS model was used to provide an approximate verification of the assumptions and of the results obtained mathematically.


#*The nag library "machine"
#@Brian Ford,Janet Bentley
#t1977
#cACM SIGNUM Newsletter
#index97361
#%268210
#!Since its inception the Numerical Algorithms Group (NAG) Project has pursued four aims:(i) To create a balanced, general purpose numerical algorithms library to meet the mathematical and statistical requirements of computer users.(ii) To support the Library with documentation giving advice on problem identification and algorithm selection, and on the use of each routine.(iii) To provide a test program library for certification of the Library.(iv) To implement the Library as widely as user demand required.


#*Correction to November Issue
#@
#t1977
#cComputer
#index346882
#!The spatial warp techniques illustrated in color photographs b-c- d-f on p. 63 of the November 1976 issue of Computer were incorrectly credited. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Sound learning: an application of a computer to automated teaching
#@John A. Swets
#t1961
#cCommunications of the ACM
#index320963


#*Toward a discipline of real-time programming
#@Niklaus Wirth
#t1977
#cCommunications of the ACM
#index328968
#%332514
#%330303
#!Programming is divided into three major categories with increasing complexity of reasoning in program validation: sequential programming, multiprogramming, and real-time programming. By adhering to a strict programming discipline and by using a suitable high-level language molded after this discipline, the complexity of reasoning about concurrency and execution time constraints may be drastically reduced. This may be the only practical way to make real-time systems analytically verifiable and ultimately reliable. A possible discipline is outlined and expressed in terms of the language Modula.


#*Languages for Simulation
#@George E. Heidorn,Nicholas R. Hurst,A. Alan B. Pritsker,Lee Rogin,Jerry Katzke,Jim Nickerson,Julian Reitman,R. F. Zant,Paul F. Wyman,Arnold Ockene,Robert H. Downs
#t1973
#cProceedings of the 6th conference on Winter simulation
#index545448
#!Simulation languages are past adolescence and nearing maturity. This is seen in the two papers in this session that describe improved and extended versions of the widely-used simulation languages GPSS and GASP, and by the papers that bring linguistics and mathematics to bear in providing more useful and usable simulation tools.


#*An evaluation of data-processing training in georgia public and private schools and the derivation of behavioral objectives for entry-level computer programmer and operator curricula based upon responses of data-processing managers.
#@Marguerite Castles Toyne
#t1974
#c
#index194283


#*Graphic update of automated logic diagrams
#@Richard J. Uhlik
#t1968
#cProceedings of the 5th annual Design Automation Workshop
#index549544
#%317795
#!The Automated Logic Diagram, or ALD, is a well defined document prepared by engineers to specify the design of a machine. 1 The document is coded for computer input by highly trained transcription personnel. Changes or corrections are batched for a master file update computer run. Because of the number of queues involved, a day or more is normally required to complete this process. A project was undertaken to investigate the utility of a graphic display device as a direct interface between the designer and the computerized data base. The purpose was to drastically reduce the turnaround time of updating ALD's. In this paper, the format and contents of the ALD are first defined. This will aid the reader in understanding the document which this project was designed to display and update at the graphic console.


#*Two computer games for APL students
#@Portia C. Elliott
#t1978
#cACM SIGAPL APL Quote Quad
#index241839


#*Simulation of a corporate cash budget: Application and validation
#@Thomas M. Cook,Lawrence J. Gitman,Charles Defelice
#t1974
#cProceedings of the 7th conference on Winter simulation - Volume 1
#index545627
#!The importance of cash budgeting has been thoroughly discussed in the financial literature, but the application of this technique to actual problems has not been fully developed. The failure to consider the random nature of certain critical financial variables such as sales and purchases is the concern of this paper. Frequently, it is suggested that the financial manager make point estimates of relevant variables such as gross sales and based upon these estimates calculate the resulting net cash flows. The authors of this paper question the validity of point estimates for use in short-term financial decision making. This paper describes the results of an actual simulation of a firm's cash budget. The mathematical model utilized was developed previously by the authors. The modification and application of the model to a specific firm is described along with a step by step description of the actual cash budget simulation. The results of this application are presented along with a discussion of the model validation and a comparison of simulated versus actual end-of-month cash flows. The importance of this research lies in the resulting ability to provide the financial decision maker with a probability distribution of cash flows. Utilizing the probability distribution, the financial manager can select a short-term financial strategy consistent with his attitude toward risk.


#*On the Efficiency of Clique Detection in Graphs
#@A. H. Dixon
#t1973
#c
#index193961


#*Algorithms: Remark on algorithm 248: netflow
#@J. H. Henderson,R. M. Knapp,M. E. Volberding
#t1968
#cCommunications of the ACM
#index315462


#*Variable-Mode Counting with Straight Binary Counters
#@J. S. Byrd
#t1971
#cIEEE Transactions on Computers
#index340142
#!A design technique using complementary gating and simulated data was developed to permit a straight binary counter to be used as a variable-mode counter. Any family of binary logic modules can be used.


#*Development of information systems to support university planning
#@Vance Allen Etnyre
#t1972
#c
#index193030


#*The challenge of human resources staffing and utilization in industrial computing - part 1
#@Marvin Kornbluh,William McCartin,Richard G. Schneider
#t1975
#cProceedings of the fifth SIGCSE technical symposium on Computer science education
#index546592
#!Marvin Kornbluh Industry today is looking for creative systems analysts and programmers who can develop physical systems on the basis of sound business judgement rather than merely increasing the level of sophistication. They need &ldquo;entrepeneurs&rdquo; - those who know how to work effectively with hardware and software suppliers, know how to harness and direct the creative systems people, know how to be communications catalysts in giving advice and counsel to systems users, and know how to establish and maintain sensible budgets and project control systems. How these types of EDP personnel can be developed by the application of sound management principles to the establishment of &ldquo;custom-built&rdquo; educational and training programs that emphasize both the operations of the organization as well as the technical aspects of data processing will be discussed. William McCartin The nature of computer technology in a manufacturing environment and the resulting demand for extensive computer education and professional knowledge will be outlined. A company's response to this demand as it was influenced by technical and budgetary considerations is described. The current and future educational requirements necessary to successful implementation of computerized industrial applications, manufacturing process control, and factory automation is considered. Richard G. Schneider Computer-related careers in banking will be discussed. Personnel are needed who can specialize in such areas as computer operations efficiency, hardware performance measurement, systems software support and development, the use of management science techniques, data base development and systems support, and application systems development in programming. They must understand the technical aspects of their fields and communicate effectively to their technical and corporate management, with coordination of all the efforts involved in a large scale, 24 hour, 7 day week operation.


#*Modeling the write behavior of computer programs.
#@Frank Shi-Kong Yu
#t1976
#c
#index204048


#*MICSIM - a microprogrammed expression parsing simulator: part I - language and algorithm
#@S. Habib
#t1972
#cACM SIGMICRO Newsletter
#index342065


#*A memory model and simulation of memory processes for driving a car.
#@Teiji Furugori
#t1974
#c
#index203946


#*A model for a generalized data access method
#@Randall L. Frank,Koichi Yamaguchi
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index55685
#%550481
#%196997
#%190541
#%549845
#%204886
#!The proliferation of the methods used in modern operating systems to access data is apparent. In the operating system OS/360 alone there exist multiple ways of accessing sequential data (BSAM, QSAM, BPAM), indexed sequential data (BISAM, QISAM) and directly addressable data (BDAM). If one adds to this the variations of the above used by various systems that run under the control of OS/360, such as IBM's data base management system IMS/360, there exists almost a countless number of ways to access and store data within a computer system.


#*Zur Detektion von Relativbewegungen in bewegten nat&uuml;rlichen Szenen
#@Axel Korn,G. Wedlich
#t1979
#cAngewandte Szenenanalyse, DAGM Symposium
#index561017


#*A data flow language for operating systems programming
#@Paul R. Kosinski
#t1973
#cProceeding of ACM SIGPLAN - SIGOPS interface meeting on Programming languages - operating systems
#index546318
#%321318
#%329737
#!This paper describes a graphical programming language based on the concept of pure data flow sequencing of computations. Programs in this language are constructed through function definition and composition, and are based on the primitive notions of iteration, recursion, conditional expression, data replication, aggregation and selection, and the usual arithmetic and logical operations. Various useful programming devices such as the DO loop and, surprisingly, the memory cell are defined in terms of these primitives. Programs in this language are determinate in operation unless indeterminism is explicitly introduced. The utility of this language for designing and implementing operating systems is discussed.


#*WYLBUR: an interactive text editing and remote job entry system
#@Roger Fajman,John Borgelt
#t1973
#cCommunications of the ACM
#index318875
#%330178
#%330350
#%332824
#!WYLBUR is a comprehensive system for manipulating all kinds of text, such as computer programs, letters, and manuscripts, using typewriter terminals connected to a computer. It has facilities for remote job entry and retrieval as well as facilities for text alignment and justification. A powerful method for addressing text by content is provided. This paper describes the external appearance of WYLBUR as well as its internal structure. A short description of the major features of ORVYL, a general purpose time-sharing system which operates in conjunction with WYLBUR, is also included.


#*LSI components modelling in a three-valued functional simulation
#@G. Alia,P. Ciompi,E. Martinelli,F. Bernardini
#t1978
#cProceedings of the 15th Design Automation Conference
#index554979
#%553242
#%555098
#!This paper deals with the problem of describing the behaviour of LSI components for a three-valued functional simulation. The proposed functional description uses a set of predefined functional modules, named primitives, for handling data signals, and test blocks for handling control signals. Some primitives with relative algorithms are described and a procedure for test blocks management with three-valued control signals is proposed.


#*Teaching structured programming in FORTRAN with IFTRAN
#@William R. Bezanson
#t1975
#cACM SIGCSE Bulletin
#index550075
#%335365
#%458820
#!The outline of an introductory FORTRAN programming course based on structured programming is presented. The language IFTRAN was used as a FORTRAN preprocessor, allowing regular FORTRAN statements plus more powerful conditional and looping statements. Program development was taught in the course by means of top-down stepwise refinement. Students were well motivated and developed a professional attitude towards programming.


#*A methodology for the inferential derivation of retrieval semantics utilizing a relational view of a meta-base.
#@Thomas Richard Cousins
#t1978
#c
#index188883


#*Perfect hashing functions: a single probe retrieving method for static sets
#@Renzo Sprugnoli
#t1977
#cCommunications of the ACM
#index313888
#%79620
#%332247
#%322079
#%318002
#!A refinement of hashing which allows retrieval of an item in a static table with a single probe is considered. Given a set I of identifiers, two methods are presented for building, in a mechanical way, perfect hashing functions, i.e. functions transforming the elements of I into unique addresses. The first method, the &ldquo;quotient reduction&rdquo; method, is shown to be complete in the sense that for every set I the smallest table in which the elements of I can be stored and from which they can be retrieved by using a perfect hashing function constructed by this method can be found. However, for nonuniformly distributed sets, this method can give rather sparse tables. The second method, the &ldquo;remainder reduction&rdquo; method, is not complete in the above sense, but it seems to give minimal (or almost minimal) tables for every kind of set. The two techniques are applicable directly to small sets. Some methods to extend these results to larger sets are also presented. A rough comparison with ordinary hashing is given which shows that this method can be used conveniently in several practical applications.


#*Complex refractive index of ice fog at a radio wavelength of 3 mm.
#@John Windsor Perry
#t1973
#c
#index195421


#*Syntax directed on-line recognition of cursive writing
#@Yung Taek Kim
#t1968
#c
#index205318


#*DIXIT Algorizmi - His Background, his Personality, his Work, and his Influence
#@Heinz Zemanek
#t1979
#cProceedings on Algorithms in Modern Mathematics and Computer Science
#index271124


#*ISP/1: A conversational statistical package
#@Michael D. Murray
#t1974
#cProceedings of the sixth international conference on APL
#index553884
#!A library of conversational programs written in APL and designed to perform a great many common statistical procedures is described. Areas covered include simple parametric statistics, analysis of variance and covariance, multivariate analysis of variance, multiple discriminate analysis, correlation and regression analysis, factor analysis and assorted nonparametricstatistics.


#*The augmented predictive analyzer for context-free languages&mdash;its relative efficiency
#@Susumu Kuno
#t1966
#cCommunications of the ACM
#index333082
#%319281
#%328639
#%328874
#%331818
#%335119
#!It has been proven by Greibach that for a given context-free grammar G, a standard-form grammar Gs, can be constructed, which generates the same language as is generated by G and whose rules are all of the form Z&rarr; cY1 &middot;&middot;&middot; Ym (m &ge; 0) where Z and Yi are intermediate symbols and c a terminal symbol. Since the predictive analyzer at Harvard uses a standard-form grammar, it can accept the language of any context-free Grammar G, given an equivalent standard-form grammar Gs. The structural descriptions SD(Gs, &khgr;) assigned to a given sentence &khgr; by the predictive analyzer, however, are usually different from the structural descriptions SD(G, &khgr;) assigned to the same sentence by the original context-free grammar G from which Gs is derived. In Section 1, an algorithm, originally due to Abbott is described, which converts a given context-free grammar into an augmented standard-form grammar each of whose rules is in standard form, supplemented by additional information describing its derivation from the original context-free grammar. A technique for performing the SD(Gs, &khgr;) to SD(G, &khgr;) transformation effectively is also described. In Section 2, the augmented predictive analyzer as a parsing algorithm for arbitrary context-free languages is compared with two other parsing algorithms: a selective top-to-bottom algorithm similar to Irons' &ldquo;error correcting parse algorithm&rdquo; and


#*An Algorithm for Determining the Topological Dimensionality of Point Clusters
#@D. H. Schwartzmann
#t1975
#cIEEE Transactions on Computers
#index351764
#!The main thrust of this paper is to present a new algorithm for the analysis of structure in multivariate data point clusters from the standpoint of intrinsic (topological) dimensionality.


#*The impact of the computer upon the job tasks of individuals employed in the financial accounting system of selected businesses.
#@John Richard Schillak
#t1975
#c
#index195367


#*On-Set Realization of Fail-Safe Sequential Machines
#@M. Diaz
#t1974
#cIEEE Transactions on Computers
#index352999
#!Fail-safe sequential machines can be constructed in such a way that if a failure happens in the sequential part, the ulterior functioning must carry on outside the code chosen to represent the set of states. This paper presents a study of the failures in the input combinational circuit and of the feasibility conditions of sequential machines with states coded by a k-out-of-n code. The electronic circuit is realized in a classical way (on-set realization) and must obey two hypotheses, 1) no failure on clock line C, and 2) single fault (stuck at 0 or stuck at 1) on other connections than C.


#*Some complexity questions related to distributive computing(Preliminary Report)
#@Andrew Chi-Chih Yao
#t1979
#cProceedings of the eleventh annual ACM symposium on Theory of computing
#index549993
#!Let M &equil; {0, 1, 2, ..., m&mdash;1} , N &equil; {0, 1, 2,..., n&mdash;1} , and f:M &times; N &rarr; {0, 1} a Boolean-valued function. We will be interested in the following problem and its related questions. Let i &egr; M, j &egr; N be integers known only to two persons P1 and P2, respectively. For P1 and P2 to determine cooperatively the value f(i, j), they send information to each other alternately, one bit at a time, according to some algorithm. The quantity of interest, which measures the information exchange necessary for computing f, is the minimum number of bits exchanged in any algorithm. For example, if f(i, j) &equil; (i + j) mod 2. then 1 bit of information (conveying whether i is odd) sent from P1 to P2 will enable P2 to determine f(i, j), and this is clearly the best possible. The above problem is a variation of a model of Abelson [1] concerning information transfer in distributive computions.


#*Simulation of a two-man interaction system
#@D. S. Kochhar,B. L. Wills
#t1971
#cProceedings of the 5th conference on Winter simulation
#index549476
#!This paper describes a GPSS/360 simulation of a two-man machine model where the performance of both operators as they together perform a task comprising of a series of individual and/or interacting subtasks is simulated. The program considers in ter and in tra operator variance, and such factors as operator proficiency, stress tolerance and partner confidence. Output for various systems consists of areas of operator overload and underload, subtask and task failure or success and a comparison of the standard and actual execution times.


#*B74-13 Operating Systems Infotech State of the Art Report # 14.
#@P. Freeman
#t1974
#cIEEE Transactions on Computers
#index354022
#!This is another in a series of state-of-the-art reports from Infotech. It consists of edited discussions and presentations plus invited papers. Because a volume of this price will most likely not be sent out on approval, I think it important to review briefly the contents in detail before commenting on their value. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*The use of an interactive information storage and retrieval system in medical research
#@Henry C. Lucas, Jr.
#t1978
#cCommunications of the ACM
#index317461
#!This paper presents the results of a study of the use of an interactive computerized storage and retrieval system. A monitor built into the computer system provided usage data for the study. Additional data on user reactions were gathered from a questionnaire. The results show the important role played by frequently chosen laboratory reference leaders in influencing the use of this system. The implications of the study for the design of similar systems are discussed.


#*Lapac--a computer package for solving the laplace transform.
#@Michael William Kappel
#t1977
#c
#index204015


#*Modelling of concurrent control structures and parallel processing.
#@Jeffry Wen-Hu Yeh
#t1975
#c
#index206310


#*A use of macros in translation of symbolic assembly language of one computer to another
#@George T. Dellert, Jr.
#t1965
#cCommunications of the ACM
#index335134


#*On-line textile designing
#@Janice R. Lourie,John J. Lorenzo,Abel Bomberault
#t1966
#cCommunications of the ACM
#index334244


#*'76 NCC Landmarks in Data Processing
#@
#t1976
#cComputer
#index340876


#*Invited papers: Decision tables in systems design
#@B. Grad
#t1962
#cProceedings of the 1962 ACM national conference on Digest of technical papers
#index549569
#!EFFICIENT IMPLEMENTATION and operation have received more attention in business system planning than system study and design. Since programming and equipment installation are such important and difficult steps, there has been a tendency to deemphasize other critical steps: (a)&mdash;Problem definition. (b)&mdash;Problem analysis. (c)&mdash;Solution specification. (d)&mdash;Documentation. Even some aspects of implementation and operation have been neglected: (a)&mdash;Debugging. (b)&mdash;Modification. (c)&mdash;Maintenance. Thorough systems design requires careful evaluation of alternatives, with consideration of all features needed for efficient continuing work and growth. While it is difficult to sell the extra cost of professional design, it may be inexpensive in the long run. Decision tables are a valuable aid in systems design; they provide a different view of problems and their solution than other generally used methods: flow diagrams, narrative, and Boolean algebra. By presenting alternate courses of action under various combinations of conditions, a decision table enables the analyst to think through a problem and its solution more effectively; he can check more readily for completeness and accuracy.


#*Scenario reality planning: review of The future of consensus-formation technology utilization in a normative governmental planning support system environment by R. H. Martin: and Social and political protocol aspects of large scale media &mdash; conferencing planning systems and consensus-formation technology utilization by R. H. Martin.
#@
#t1976
#cACM SIGCAS Computers and Society
#index312931


#*A comprehensive approach to a connectivity audit, or a fruitful comparison of apples and oranges
#@R. M. Allgair,D. S. Evans
#t1977
#cProceedings of the 14th Design Automation Conference
#index547798
#!A connectivity comparison program that has proven effective in a production environment is described. The pattern recognition framework utilized automatically recognizes component renaming and pin swapping, and performs robustly in the face of connectivity errors.


#*Multi-queue scheduling of two tasks
#@Jeffrey R. Spirn
#t1976
#cProceedings of the 1976 ACM SIGMETRICS conference on Computer performance modeling measurement and evaluation
#index550484
#!A class of schedules in the two customer central server queueing model, consisting of a &ldquo;CPU&rdquo; server and m &ldquo;I/O&rdquo; servers, is considered. Optimal (maximal CPU utilization) CPU and I/O schedules are obtained. The best CPU schedule depends on the I/O schedule in effect; and is either Longest or Shortest-Expected-Remaining-Processing-Time-First. However, for certain I/O schedules the CPU schedule is immaterial. The best I/O schedule is always to process the (expected) longer CPU customer first.


#*Proposal for a program support facility
#@Jon Sachs
#t1975
#cACM SIGDOC Asterisk Journal of Computer Documentation
#index16489
#!This paper presents a preliminary definition of a program support facility (PSF). A PSF supports a programming effort with reporting operations and documentation. It interacts with other software running on the host operating system, and thus can perform many of its functions automatically.The properties of a PSF are described here in the context of IBM's OS/360 or 370, but the principles are applicable to any hardware and operating system sophisticated enough to support them. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*An Associative Processor Architecture for Air Traffic Control
#@H. N. Boyd
#t1974
#cProceedings of the Sagamore Computer Conference on Parallel Processing
#index267926


#*Computer science as an interdisciplinary study
#@William W. Agresti
#t1976
#cACM SIGCSE Bulletin
#index555253
#%320517
#%549124
#!The organization of computer science education as an interdisciplinary program is described. First, various possible relationships among disciplines are traced, and the features of interdisciplinarity are explained. Next, a specific interdisciplinary program in computer science is introduced, including experiences with the administration and operation of the program. An appraisal of the interdisciplinary approach to computer science education follows. The advantages are significant: a lower cost program, a more adaptive program, and one that is better able to treat the interfaces of computer science with other areas. Such a favorable report suggests that the interdisciplinary approach merits consideration, especially by colleges which want to offer a computer science degree but have limited funds.


#*A mathematical model for the determination of system burn-in times in complex electronic equipment
#@Victor Selman
#t1969
#c
#index196131


#*A Tutorial on Satellite Graphics Systems
#@J. D. Foley
#t1976
#cComputer
#index348984
#!Satellite graphics terminals, which include a micro or minicomputer to perform interactive processing, present a number of advantages-not the least of which are accessibility and responsiveness. This paper describes two basic types of satellites and outlines techniques for best exploiting their capabilities.


#*Guarded commands, nondeterminacy and formal derivation of programs
#@Edsger W. Dijkstra
#t1975
#cCommunications of the ACM
#index325067
#%320995
#%328020
#!So-called &ldquo;guarded commands&rdquo; are introduced as a building block for alternative and repetitive constructs that allow nondeterministic program components for which at least the activity evoked, but possibly even the final state, is not necessarily uniquely determined by the initial state. For the formal derivation of programs expressed in terms of these constructs, a calculus will be be shown.


#*Letters to the editor: corrections to Sattley paper in January communications
#@Kirk Sattley
#t1961
#cCommunications of the ACM
#index331691


#*Proceedings of the ninth annual ACM symposium on Theory of computing
#@
#t1977
#cAnnual ACM Symposium on Theory of Computing
#index551621


#*Consistency and correctness of duplicate database systems
#@Clarence A. Ellis
#t1977
#cACM SIGOPS Operating Systems Review
#index551062
#%159845
#%197660
#%203632
#%314331
#%317300
#%317485
#%332939
#%335107
#%550522
#%552714
#!Solutions to the duplicate database update problem are considered, and a formal validation technique using the theory of L systems is developed and applied to the problem. The paper shows some particular solutions but is primarily concerned with general properties of the problem, convenient representational techniques, and formal proof procedures which are general enough to apply to this and to a number of other problems in parallel processing and synchronization.


#*Specification and verification of the UCLA Unix security kernel (Extended Abstract)
#@Bruce J. Walker,Richard A. Kemmerer,Gerald J. Popek
#t1979
#cProceedings of the seventh ACM symposium on Operating systems principles
#index553118
#!Data Secure Unix, a kernel structured operating system, was constructed as part of an ongoing effort at UCLA to develop procedures by which operating systems can be produced and shown secure. Program verification methods were extensively applied as a constructive means of demonstrating security enforcement. Here we report the specification and verification experience in producing a secure operating system. The work represents, to our knowledge, the first significant attempt to verify a large-scale, production level software system including all aspects from initial specification to verification of implemented code.


#*News and notices
#@R. E. Merwin
#t1973
#cACM SIGMICRO Newsletter
#index9887
#!The News and Notices in this issue include reprints from recent journals. The following is a list of the items included in this section.


#*Software Abstraction Principles: Tutorial Examples of: An Operating System Command Language Specification, and a PL/I-like On-Condition Language Definition
#@Dines Bjørner
#t1978
#cThe Vienna Development Method: The Meta-Language
#index273937


#*Algorithm 410: Partial sorting
#@J. M. Chambers
#t1971
#cCommunications of the ACM
#index329686
#%322734
#%324760


#*Computer-based analytic grading for german grammar instruction
#@David Rayner Levine
#t1973
#c
#index190364


#*Schedules and memory requirements of computation graphs and multiprocessor systems
#@Yi-Chuen Eric Chen
#t1969
#c
#index192674


#*Integrated automation program (I.A.P.) for an electronic switching system
#@F. Albertini,A. Ascagni,P. Jabes,A. Stefanini
#t1975
#cProceedings of the 12th Design Automation Conference
#index547796
#!Now-a-days any large electronic system design invariably involves the support of automated facilities. The R and D laboratories of Societ&agrave; Italiana Telecomunicazioni Siemens spa are currently developing such an automated facility oriented for manufacturing a telecommunication switching system called PROTEO, which is also being designed and developed here. Particular design aids for printed circuits; automated wiring, testing, production and diagnosis of printed circuit boards, testing and diagnosis of subsystems and generation of relevant documentation, have been implemented already. The next objective is to develop an integrated automation program (I.A.P.) with the help of a DATA-BASE and to review it for future procedural techniques.


#*Cost effectiveness of alternative sewage collection treatment and disposal systems at recreational areas
#@Mesbah U. Ahmed,Kenneth B. Young,Arun G. Walvekar
#t1978
#cProceedings of the 10th conference on Winter simulation - Volume 2
#index553903
#!This paper illustrates the applicability and usefulness of systems approach in evaluating the sewage collection, treatment and disposal alternatives at a selected recreational area. The paper identifies the interactions among sewage collection, treatment and disposal alternatives. The analysis process considers increases in effluent loading rates with additional developments of the project over time and is designed to select the least cost combination of collection, treatment and disposal facilities. The model, as developed in this study, is general; that is, it can be applied to other interactive sewage projects where land application may be beneficial.


#*An interactive computer-aided modeling system for the discretization of bridge structures for finite-element analysis.
#@Gholam Ali Semsarzadeh
#t1973
#c
#index188153


#*A special purpose multiprogramming system for a computer-controlled telemetry data reduction system
#@Harold R. Gillette
#t1966
#cCommunications of the ACM
#index328081


#*A system simulation study of dynamic social change
#@Lynn P. Madden
#t1971
#cProceedings of the 5th conference on Winter simulation
#index544924
#!This paper will apply the concepts of general systems theory and systems modeling simulation to an initial study of social group interaction. The social groups or organizations to be considered are those relating to the &ldquo;civil rights movement&rdquo; within American society. It is necessary, at an initial stage, to deal with higher level, macro structure, relations and interactions. This paper will show that it is possible, at a macro level, to examine the dynamic nature of the interactions between social groups and categories such as the civil rights movement, legislative bodies, and the general non-civil rights society. The method that is used to accomplish this examination of &ldquo;key&rdquo; social system parameters and interactions is that of systems modeling and simulation.


#*Ein Multi- Mini- Prozessor- Konzept mit Hardware- Multitasking
#@E.-L. Bohnen
#t1974
#cFachtagung Struktur und Betrieb von Rechensystemen
#index570367


#*IEEE Computer Society Publications
#@
#t1973
#cComputer
#index343077


#*On the efficient implementation of production systems.
#@Charles Lanny Forgy
#t1979
#c
#index195862


#*The computerized statesman: Further explorations into the escalation of conflict
#@Douglas F Johnson,William L Mihal
#t1971
#cProceedings of the 1971 26th annual conference
#index553921
#!An experiment is described which treats the computer as an interacting member of a dyad in studying the social psychology of conflict. An internation simulation is used to test the effects of threat type (Deterrent vs. Compellent), situation (Hostile vs. Friendly set) and opponent (Man vs. Computer) on compliance. The results indicate that those playing against the computer are more likely to initiate an early pre-emptive attack. Of those that do not attack, though, those playing against the computer are more likely to comply to a threat than those playing another person. Further, compellent threats are less likely to be complied with and are more likely to result in an attack from the person being threatened. Possible reasons for these findings are discussed. Finally, it was found that individual self-perceptions and perceptions of the other vary as a function of the condition.


#*Introduction to the SIMSCRIPT II programming language
#@Philip J. Kiviat
#t1968
#cProceedings of the second conference on Applications of simulations
#index555208
#%323755
#!SIMSCRIPT II is a new computer programming language designed and implemented at The RAND Corporation1. It has been modeled after SIMSCRIPT2, the simulation programming language introduced by RAND in 1963, but goes far beyond the design goals of that language. The design goals of SIMSCRIPT II were stated in3; briefly, they were to produce a readable, user-oriented language strongly oriented to the efficient debugging and running of large simulation models. In addition, the implementation was to be as computer independent as possible. As it is difficult in a short abstract to describe a complex language adequately, the following strategy has been adopted. Section 1 describes the basic properties of the SIMSCRIPT II language in concise, but hopefully communicative, terms. Section 2 illustrates the language through excerpts taken from a job shop simulation model. Section 3 discusses the present status of the language, its implementation and its use.


#*Automatic Correction of Syntax Errors in Programming Languages
#@Jean Levy
#t1971
#c
#index114741
#!A very substantial fraction of the time and efforts required to develop a program is devoted to the removal of errors. In order to simplify this task, a model to automatize the correction of syntax errors is developed. It is the first model which is both formal and fairly realistic to appear in the literature. The notion of error is defined and studied formally. Then, using this definition, a systematic error-correction process is modelled. This process makes local corrections over clusters of errors, using the context around the errors to determine the corrections and to insure that the different local corrections performed on the string do not interfere with one another. The error-correction process can be naturally embedded in many left-to-right syntax checking processes. It uses the recognizer both to detect errors and to find possible corrections. The process has two modes: a ``standard mode'''' used for syntax checking and an ``error-correction mode'''' used for determining the context of a cluster of errors and for finding all possible corrections of these errors. In the ``standard mode'''', the syntax is checked at the same speed as if no error-correction mechanism is implemented. Thus, for programs which contain no errors, no price is paid for the presence of this mechanism. The ``error-correction mode'''' consist of two phases: the backward move which locates the left context of the cluster, and the forward move which construct possible corrections and locates the right context of the cluster. This process seems the most natural way to perform left-to-right syntax checking and error correction. Some techniques for efficiently finding the range of the backward move are developed. The formal model is not practical when using the conventional context-free description of programming languages. In order to make it more practical, the notion of bracketed context-free language is introduced and proposed as a model for the syntax fo programming languages. Then, heuristic restrictions on the type of errors corrected are discussed. They may lead to a simpler process. In particular, assuming that brackets are corrected only when no other correction is possible, and that errors in deep levels of nesting (with respect to the point where the errors are detected) are neglected, it is shown how the process can be used to correct syntax errors in programming languages.


#*Effective service for remote computing users
#@A. Faye Borthick
#t1976
#cProceedings of the 14th annual Southeast regional conference
#index620852
#!In recent years, a growing number of computing users have experienced the effects of the replacement of their local computing facilities with remote computing facilities. Unfortunately, remote computing may imply remoteness not only in the sense of distance but also in the senses of accessibility, control, compatibility, and responsiveness. The providers of computing service at the central site may be oblivious to these issues, but if remote users view any of these aspects of the service as unsatisfactory, effective service is thereby undermined.This paper addresses problems which arise as the result of the installation of remote computing service for users who had heretofore had access to local service. It is written from the point of view of management at the central site providing remote computing service in the hope that recognition of the problems of providing such service will be a step in the direction of solving them.


#*The Computer Sciences Program at Purdue University
#@Sam D. Conte
#t1964
#cProceedings of the 1964 19th ACM national conference
#index547343
#!The Computer Sciences Program at Purdue University was initiated in the Fall of 1962. It is predicated on the conviction that there is a rapidly expanding body of knowledge centered about the computer which is capable of development into a science of computing, that there is a clear and urgent need for programs in the Computer Sciences, and that the development of such programs will hasten progress towwards a Theory of Computation. The Computer Sciences Program at Purdue is administered by a Department of Computer Sciences, one of 3 departments in the Division of Mathematical Sciences. The location of this program in the Division of Mathematical Sciences is a reflection of our belief that Computer Sciences as a discipline is more closely related in methodology and philosophy to mathematics than to any other discipline. This belief is strengthened by the clear evidence that the leaders in research and development in computing today were largely trained as mathematicians. The formation of a separate department of Computer Sciences to administer this program is a recognition of the fact that substantial difficulties arise when such programs are organized within the framework of an existing department. These difficulties center around the problems of attraction and promotion of faculty members, the relative expense of such programs, the interdisciplinary nature of Computer Sciences, and the administrative problems of servicing large numbers of students with various types of backgrounds.


#*Modeling the ice-age climate
#@W. Lawrence Gates
#t1976
#cACM SIGSIM Simulation Digest
#index576183
#!The last great (Wisconsin) ice age has long held the interest of climatologists, geologists, and geographers as the best documented of the several ice ages of the last million years. Although local glaciation maximums varied by several thousand years, the time 18,000 B.P. (years before present) is globally representative of this event. The changes of flora and fauna that accompanied this ice age are recorded in an extensive paleoclimatic literature, and are supplemented by widespread evidence of changes in the physical character of the earth's surface, such as changes in sea level, sea-ice extent, and local orography. From these and other evidence, estimates of the local nature of the ice-age climate itself have been derived at selected sites in terms of such variables as the local wind, temperature, or rainfall. Although they are insufficient to portray the overall global climatic regime, these estimates indicate that the ice-age climate was substantially different from today's in many regions of the world.


#*Current Status of Ambulatory Health Care Computer Applications
#@G. A. Giebink
#t1975
#cComputer
#index340782
#!Much of the present consumer concern with American health care starts with the discrepancy most people experience between the office visit to a doctor and the focus of most medical research and its results. Medical progress has affected public health and the acutely ill or disabled, but has had comparatively minor impact on the average doctor-patient encounter outside the hospital, university medical center, or other specialized setting. In 1970, 72% of the population consulted a physician at least once, but only 10.3% reported one or more hospital episodes; American Hospital Association statistics showed community hospitals averaging 4.6 outpatient visit every one inpatient admission.1


#*A prototype system for interactive data analysis
#@Gerald Levitt,David H. Stewart,Beatrice Yormark
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index73295
#!The analysis of small and simple data collections is commonly accomplished through the application of "canned" statistical analysis programs. For larger more complex data collections, however, such programs often do not satisfy a researcher's needs. In these cases, the additional use of specially developed computer programs may be necessary. These programs frequently require modification and reformatting of data to meet their input requirements. These additional complexities are compounded when a researcher attempts to investigate alternative hypotheses or pursue hunches requiring further transformations or restructuring of the original data collection. Often, this process involves the services of a professional programmer making repeated program modifications and computer runs.


#*An integrated health care information processing and retrieval system
#@Kevin C. O'Kane,Richard J. Hildebrandt
#t1974
#cProceedings of the May 6-10, 1974, national computer conference and exposition
#index74008
#%202001
#!In this paper we present the design and some initial experiences with a computerized medical records system (called the CSAR System) currently in use in several departments of the Milton S. Hershey Medical Center of The Pennsylvania State University. The purpose of this work has been to develop a high-speed efficient information system for the storage, retrieval and dissemination of the total patient medical record.


#*Flow graph reducibility
#@Matthew S. Hecht,Jeffrey D. Ullman
#t1972
#cProceedings of the fourth annual ACM symposium on Theory of computing
#index545321
#%321318
#%325267
#%546754
#%549572
#!The structure of programs can often be described by a technique called &ldquo;interval analysis&rdquo; on their flow graphs. Here, we characterize the set of flow graphs that can be analyzed in this way in terms of two very simple transformation on graphs. We then give a necessary and sufficient condition for analyzability and apply it to &ldquo;goto-less programs,&rdquo; showing that they all meet the criterion.


#*The structure of groups of ree type with computer calculations.
#@Mark Raymond Hopkins
#t1978
#c
#index194802


#*Remark on &ldquo;Some Performance Tests of &lsquo;Quicksort&rsquo; and Descendants&rdquo;
#@M. Mackay,J. E. Radue
#t1977
#cACM Transactions on Mathematical Software (TOMS)
#index323596


#*Analysis of computational systems: Discrete Markov analysis of computer programs
#@C. V. Ramamoorthy
#t1965
#cProceedings of the 1965 20th national conference
#index545172
#!A PROGRAM with a number of subroutines can be represented by a flow diagram; Figure 1. The nodes represent the subroutines and the directed branches indicate the allowed transitions between them. Given a program consisting of n subroutines R1, R2 .....Rn, two matrices are also assumed to be known, viz., an n &times; 1 matrix of execution times of each subroutine and a n &times; n matrix P, such that its ij-th element Pij is the branching probability that the program will branch to subroutine j from subroutine i. We shall assume Pij's are statistically independent so that the model of the computer program is that of a discrete Markov process. The expected time to complete a program is then a summation of all possible statistically weighted paths that begin at an initial or starting subroutine and end at the terminal subroutine.


#*PUFFT&mdash;The Purdue University fast FORTRAN translator
#@Saul Rosen,Robert A. Spurgeon,Joel K. Donnelly
#t1965
#cCommunications of the ACM
#index320760
#%326755
#%334014


#*Towards an efficient, machine-independent language for microprogramming
#@David A. Patterson,Karl Lew,Richard Tuck
#t1979
#cProceedings of the 12th annual workshop on Microprogramming
#index547834
#%324042
#%332709
#!A machine independent low level language YALLL is presented. This language produces microcode for two very different machines: Hewlett Packard HP 300 and Digital Equipment Corporation VAX 11/780. The efficiency of this language is tested by comparing two examples on both machines to microassembly coded versions. To our best knowledge, this is the first time programs have been compiled and executed on two different microarchitectures. These examples also let us compare the efficiency of the microarchitectures and macroarchitectures of these machines and re-examine the benefits of microprogramming versus macroprogramming. We conclude this paper with comments upon transportability of high level microprogramming languages.


#*The nested rectangular array as a model of data
#@Trenchard More
#t1979
#cACM SIGAPL APL Quote Quad
#index545960
#%183108
#%249437
#%252748
#%313666
#%317475
#%318294
#%320435
#%326368
#%545726
#%551208
#%553421
#%546665
#!Data, like electricity and gravity, are part of the world in which we live. Some occur naturally, as in the genetic code, while most occur as a consequence of language and social organization. The search for a theory of data, which begins with the choice of a model, is as important and interesting as the development of theories in physics, economics, and psychology. Most models of data are collections, such as the unnested array of APL, the one-axis nested list of LISP, and the set, which is nested but lacks the properties of order, repetitions, type, and multiple axes inherent in rectangular arrangement. Nested rectangular arrays have all these properties. The existence of simple, universally valid equations in both set theory and linear algebra suggests that equally simple equations may hold for all arrays. The principles of nested collections developed in set theory apply with few changes to the nesting of arrays. A one-sorted theory of arrays, in which type is preserved for empty arrays, provides an algebra of operations interpreted not only for data but also types of data.


#*Lambda-terms as total or partial functions on normal forms
#@Corrado Böhm,Mariangiola Dezani-Ciancaglini
#t1975
#cProceedings of the Symposium on Lambda-Calculus and Computer Science Theory
#index263701


#*Group discussion on crystal diodes
#@Ralph J. Slutz
#t1953
#cPapers and discussions presented at the Dec. 8-10, 1953, eastern joint AIEE-IRE computer conference: information processing systems---reliability and requirements
#index388542


#*Memory allocation in paging systems
#@Art Lew
#t1973
#cProceedings of the ACM annual conference
#index545826
#%316426
#%331724
#!We discuss in this paper three major problems related to the allocation of memory resources in paging systems. These are the problems of deciding how best to distribute program code and data into pages (pagination), of deciding which pages residing in main memory should next be removed (replacement), and of deciding how many pages of each of several competing programs should be permitted in main memory (allotment). We do not provide definitive solutions to these problems, as indeed no one has as yet. Instead, we suggest novel approaches to the problems, based primarily on their interrelationships, and describe specific techniques to illustrate our ideas. Our main contention is that a joint consideration of these problems is feasible and more realistic and would lead ultimately to practical and more efficient solutions.


#*Evaluating curricula for the teaching of programming
#@Ronald G. Ragsdale
#t1978
#cACM SIGCUE Outlook
#index353832
#%301435
#%315832
#%327169
#%334039
#%593112
#%622654
#%548199
#%458820
#!Despite the great and continuing interest in methods of effective teaching of computer science concepts, especially programming, there is little hard data to back up the opinions that are so vigorously expressed. Moreover, most of those studies that have attempted to investigate programming instruction have been sufficiently flawed so as to render them of little use. The first section of this paper deals with many of the flaws commonly found in studies of instruction in programming. These include non-random assignment of subjects, assuming identical instruction to different groups, experimenter bias, use of "available resources", short experimental treatments, home grown tests, and questionable analysis techniques. The second section contains a description of the principles of good experimental design, using the concepts of internal and external validity. An experiment usually requires a compromise between the internal validity, which relates to control of experimental conditions, and the external validity, which has to do with the generalizability of the results. The final section contains conclusions concerning initial steps that might be taken to rectify the problem caused by a lack of valid data. These steps include better and more objective quantification of the attributes of good programs and more integrative techniques for analyzing the results of multiple studies.


#*Semiconductor Rams - a Status Report
#@G. E. Moore
#t1971
#cComputer
#index350950
#!Semiconductor data storage offers many advantages. These include: The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A position paper on computing and communications
#@Jack B. Dennis
#t1968
#cCommunications of the ACM
#index316014
#%544606
#%545236
#%322134


#*Design and implementation of a non-binary code for byte-organized memory with binary and quaternary logics
#@Tich T. Dao
#t1978
#cProceedings of the eighth international symposium on Multiple-valued logic
#index552735
#!Byte-organized memory requires an error control scheme which can handle errors involving one or several entire bytes. A special parallel non-binary single error correction and double error detection SEC-DED block code is constructed by an iterative technique. This code is optimum in the sense that it lends itself to a simple and high speed hardware implementation either in binary or in quaternary logic. A double extension field GF(22m) of the subfield GF(2m) is then introduced. As a design example a (80,64) SED-DED code in GF(24) is constructed and implemented.


#*Database Management Systems Development in the USSR
#@A. G. Dale
#t1979
#cACM Computing Surveys (CSUR)
#index328234
#%321947


#*Guest Editorial: An Overview of Parallel Processors and Processing
#@Tse-Yun Feng
#t1977
#cACM Computing Surveys (CSUR)
#index331860


#*Programming by Refinement, as Exemplified by the SETL Representation Sublanguage
#@Robert B. K. Dewar,Arthur Grand,Ssu-Cheng Liu,Jacob T. Schwartz,Edmond Schonberg
#t1979
#cACM Transactions on Programming Languages and Systems (TOPLAS)
#index326226
#%200129
#%235673
#%331887
#!&ldquo;Pure&rdquo; SETL is a language of very high level allowing algorithms to be programmed rapidly and succintly. SETL's representation sublanguage adds a system of declarations which allow the user of the language to control the data structures that will be used to implement an algorithm which has already been written in pure SETL, so as to improve its efficiency. Ideally no rewriting of the algorithm should be necessary. The facilities provided by the representation sublanguage and the run-time data structures that it can generate are described; based on this a heuristic which uses some of the methods of global program analysis and which should be capable of selecting an acceptably efficient representation automatically is given.


#*Text file inversion: An evaluation
#@R. M. Bird,J. B. Newsbaum,J. L. Trefftzs
#t1978
#cProceedings of the fourth workshop on Computer architecture for non-numeric processing
#index553870
#!This paper compares inversion of text files with inversion of more structured records. The unique characteristics of textual data which restrict the utility of inversion are identified and discussed. Inversion is shown to be useful only for small, static data bases, and when full text search is not required.


#*Facilitating information access: interaction between system components (the data library and the traditional library)
#@Judith Rowe
#t1974
#cACM SIGSOC Bulletin
#index576101
#!During the last twenty years, social scientists involved with the establishment and administration of data archives have been making overtures to traditional libraries. But until recently, there has been almost no response. In 1957, York Lucci and Stein Rokkan proposed a "library center of survey research data." [1] In 1965, Ithiel de Sola-Pool argued cogently that "the storing of basic data... [is] a library function." [2] In 1967, Ralph Bisco addressed the question, "Why should university libraries undertake data services...?" [3] That same year, a report prepared for the National Academy of Sciences examined some of the factors which seemed to vitiate against a merger of data archives and traditional libraries. [4] In 1969, at the last conference of the Council of Social Science Data Archives, David Elesh, then director of Wisconsin's Social Science Data and Program Library Service, and Erwin Welsch, Wisconsin's Social Studies Librarian, addressed an audience composed of data archivists and librarians on "The Library of the Future." [5] In 1970, Jack Dennis, present director of the Data and Program Library Service, addressed a conference of librarians where he spoke of the need for "closer integration of the local archive into existing local university information services--particularly those provided by the traditional university library." [6] By 1971, when David Nasitir summarized the history of the data archive movement's attempts to establish a rapprochement with the traditional library [7], there was little positive activity to report. However, in commenting on a paper delivered by Constance Citro in 1968, which was concerned with the desire on the part of the Bureau of the Census to allow libraries to manage the summary tapes of the 1970 census [8], his words proved prophetic. Nasitir said, "This is the one area in which the data archive movement is converging with academic libraries....If the census tapes form the thin end of the wedge, a large number of sample survey data tapes now held in archives may follow." [9] The wedge is now in the door and the remainder of this discussion will look briefly at the evidence of its presence.


#*Scope Structures and Defined Functions in Lucid
#@E. A. Ashcroft,W. W. Wadge
#t1977
#c
#index188661


#*Languages for specifying protection requirements in data base systems--a semantic model.
#@H. Rex Hartson
#t1975
#c
#index185896


#*The reallocation of hash-coded tables
#@Carter Bays
#t1973
#cCommunications of the ACM
#index329703
#%317208
#%324107
#%331163
#!When the space allocation for a hash-coded table is altered, the table entries must be rescattered over the new space. A technique for accomplishing this rescattering is presented. The technique is independent of both the length of the table and the hashing function used, and can be utilized in conjunction with a linear reallocation of the table being rescattered. Moreover, it can be used to eliminate previously flagged deletions from any hash-coded table, or to change from one hashing method to another. The efficiency of the technique is discussed and theoretical statistics are given.


#*Automatic Software Test Drivers
#@D. J. Panzl
#t1978
#cComputer
#index346558
#!Typical testing activities may involve many hundreds of tests. An automatic software test driver assists the tester by managing all of the test data, and automatically running the tests. Savings during regression testing can be significant.


#*A positive approach to personnel relations
#@L. Allan Wright
#t1972
#cProceedings of the tenth annual SIGCPR conference
#index550972
#!A personal position paper is not research - with a bow to my colleagues on the program who are researchers - but is rather a contribution based on experience (good and bad), study, and hopefully thoughtful contemplation. Personnel relations is a general term used here as synonymous with Personnel, Employee Relations, Manpower, Human Resources, and the host of other expressions in the field. If anything is excluded, it probably is the term Industrial or Labor Relations which seems to be used in the industry more frequently when all or part of the work force is unionized.


#*Method for partial rewriting of magnetic tape
#@James A. Miller
#t1964
#cCommunications of the ACM
#index318018
#!In simulating the operation of a large storage computer on the IBM 7094, a technique was developed whereby sections of the computer memory which were stored on magnetic tape (IBM 729 Mod II tape drive) could be rewritten without affecting other sections stored on the same tape. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*National opinions from university computing center documentors on procedures, ideals, and interpersonal relationships
#@Ann White
#t1977
#cProceedings of the 5th annual ACM SIGUCCS conference on User services
#index551849
#!In this compendium 44 individuals who review or produce computer-related documentation at their university computing installations, have contributed their opinions on what it is like to be a &ldquo;documentor&rdquo; as well as their philosophy of what a &ldquo;documentor&rdquo; should be as a professional. The individuals responded to a questionnaire that explored the advantages and disadvantages of being a documentor, their techniques for communicating with the people they must inevitably communicate with&mdash;programmers, their experiences in developing documentation that meets certain standards of quality, and their attempts to educate others with regard to solving documentation production problems. The respondents seem to agree that the documentation function is necessary and that perseverance, tact, analysis, attention to detail, self-assurance, cooperation, and oral and written communication are important. However, differences of opinion arise in several areas. (1) Whose skills are better suited for producing quality documentation&mdash;those of the programmer or those of the professional communicator? (2) What are the necessary documentation standards that should guide documentors? (3) How flexible should these standards be? (4) What can documentors do to gain greater respect and support from programmers and managers&mdash;which in turn could lead to higher salaries and a more rewarding profession? This compendium provides insight into how documentors solve some of their problems. It reveals what they themselves consider qualifies them to be documentors. And, most important, it discloses much about the psychology of the documentor.


#*A topologically based non-minimum distance routing algorithm
#@Michel T. Doreau,Luther C. Abel
#t1978
#cProceedings of the 15th Design Automation Conference
#index547933
#%332105
#%549495
#%550493
#%551954
#%549856
#%554436
#!In this paper, a unique topologically based non-minimum distance routing algorithm is presented. It offers both maximal completion rates and minimal via usage. The algorithm is based on a topological transformation of a significant subset of the PC routing problem: A broad channel encompassing a full row of DIPs and all routes within it. This transformation eliminates the need to consider detailed path shapes during routing. The routing problem is transformed into a permutation of nets. It is coupled with a backtrack search to produce a powerful routing algorithm. The search is conducted in a planar environment.


#*Feedback coupled resource allocation policies in the multiprogramming-multiprocessor computer system
#@Richard S. Brice,J. C. Browne
#t1978
#cCommunications of the ACM
#index331351
#%185596
#%198896
#%203578
#%315247
#%324484
#%549573
#%550756
#%332853
#%546515
#%550484
#!Model studies of some integrated, feedback-driven scheduling systems for multiprogrammed-multiprocessor computer systems are presented. The basic control variables used are the data-flow rates for the processes executing on the CPU. The model systems feature simulated continuous-flow and preempt-resume scheduling of input-output activity. Attention is given to the amount of memory resource required for effective processing of the I/O activity (buffer space assignment). The model studies used both distribution-driven and trace-driven techniques. Even relatively simple dynamic schedulers are shown to improve system performance (as measured by user CPU time) over that given by optimal or near-optimal static schedulers imbedded in identical system structures and workload environments. The improvement is greatest under a heavy I/O demand workload.


#*Visible surface plotting program
#@Thomas Wright
#t1974
#cCommunications of the ACM
#index329278


#*Two-way a-transducers and afl (abstract family of languages).
#@Donald Ivan Kiel
#t1973
#c
#index203826


#*Transformation and canonization algorithms for graph representable structures with applications to a heuristic program for the synthesis of organic molecules.
#@Krishna Kumar Agarwal
#t1976
#c
#index199318


#*Parametric analysis for computer performance evaluation of large data processing facilities.
#@William Julius Wenker
#t1978
#c
#index199476


#*How to Profit from Your Personal Computer
#@T. G. Lewis
#t1978
#c
#index622303


#*Autodoc: Computer-based assistance for document production
#@Michael D. Callahan,Gloria Lauer Grace
#t1967
#cProceedings of the 1967 22nd national conference
#index550009
#!Autodoc is a man-machine system designed to provide automated documentation capability to assist professional and secretarial personnel in carrying out their routine work assignments. The initial application is the production of user documentation. However, design intent is not limited to this single application. The completed system permits broad application by a variety of users. This system provides automated capability for document production, maintenance, and bookkeeping.


#*Tabsol decision table preprocessor
#@Robert F. Sterbenz
#t1971
#cACM SIGPLAN Notices
#index305091
#!This paper describes the Tabsol Decision Table Preprocessor, a program product of the B.F. Goodrich Company. The Tabsol (Tabular systems oriented language) Preprocessor, itself written in ANSI Cobol, is designed to translate horizontalrule, extended-entry decision tables into equivalent Cobol statements. Design objectives, language format and implementation results of the Tabsol Preprocessor are summarized in this paper. This preprocessor has been in full production use by the Information Systems Department of B.F. Goodrich Chemical Company since January 1971.


#*Remark on algorithm 62: a set of associate Legendre polynomials of the second kind
#@John R. Herndon
#t1961
#cCommunications of the ACM
#index317707


#*On Achieving Distributed Termination
#@Nissim Francez
#t1979
#cProceedings of the International Sympoisum on Semantics of Concurrent Computation
#index264923


#*Certification of Algorithm 3: Solution of polynomial equations by Bairstow Hitchcock method
#@James S. Vandergraft
#t1961
#cCommunications of the ACM
#index327814


#*The Electronic Briefcase: The Office of the Future
#@Robert Arnold Russel
#t1978
#c
#index621521


#*Constructive Specifications of Abstract Data Types by Replacements
#@Hans-Dieter Ehrich,V. G. Lohberger
#t1978
#cProceedings of the International Workshop on Graph-Grammars and Their Application to Computer Science and Biology
#index270611


#*Probability Distrbution of the Duration of Hidden Faulty States in Case of Incomplete On-Line Tests
#@Winfrid G. Schneeweiss
#t1977
#cGI - 7. Jahrestagung, N&uuml;rnberg
#index269993


#*Advanced programming and the aims of standardization
#@Saul Gorn
#t1966
#cCommunications of the ACM
#index334929
#!Some of the most advanced programming techniques have emerged either because of the complete lack of coordinated standards, or because there was too rigid standardization and too soon, whether it was planned that way or not. The standardization that was lacking, or too rigid, was in programming techniques, programming languages, programming terminology, equipment techniques, available equipment, and specification and documentation methods for equipment, programs, languages, and problems to be solved. For example, common programming languages developed because of the lack of standardized equipment or languages for their use.


#*Data Types for Very High Level Programming Languages
#@Narain Gehani
#t1975
#c
#index116086
#!Very high level programming languages (higher than PL/I, Algol 60, etc.) attempt to free the programmer from providing details and let him concentrate on the algorithm for the problem at hand. The importance of very high level programming languages is further emphasized by decreasing machine costs, increased programming costs and the desire to have programs that are well structured, easy to understand and prove correct. Very high level languages provide powerful control structures and data structures that allow the problem to be specified in a natural manner. In this dissertation, we propose several ways of raising the level of a language. The different types of for iteration statements are consolidated into one general for statement. This, along with a new type, the domain of an array, provides us with an easy way of processing arrays; nested iteration statements are no longer necessary. The syntactic list and array generators and the concept of overloading make programming more flexible. The current notion that a data type is a set of values together with basic operations on that set leads us to conclude that formal parameter types need not be explicitly stated. Given a formal parameter X with operations $z_{1}, z_{2},\ldots, z_{n}$ being performed on it within the procedure, one should be able to supply, as an actual parameter in a call, a variable of any type that has the operations $z_{1}, z_{2},\ldots, z_{n}$ defined on it. For example, this concept allows us to write one procedure that finds the maximum value of the elements of an array of any dimension and any element or index type. Grids are arrays that can have any shape. Grid elements need not be contiguous i.e. grids can have holes in them. For example, grids can be trapezoidal, parabolic, rectangular with a hole or pyramid-like. Programs written using grids are more general than those written using arrays and/or functions to simulate non-array shapes. To alter an existing program to work for another grid shape one need only modify the grid declaration suitably, leaving the rest of the program intact. Programs are smaller, semantically clearer and have a more natural problem representation. Grids may be used to represent sparse matrices. Data security is achieved by allowing parts of grids pass as parameters to be readd only or completely masked out. Grids have been implemented as an extension to Fortran. Using Pascal as the base language, we show by series of examples from numerical analysis, data processing, engineering etc., how the above concepts raise the level of a programming language and how they blend together naturally and systematically. Efficient ways of implementing them are also discussed.


#*The PL/EXUS language and virtual machine
#@Gary A. Sitton,Thomas A. Kendrick,A. Gil Carrick
#t1973
#cProceedings of a symposium on High-level-language computer architecture
#index305234
#%328020
#!This paper describes a high level general purpose language which evolved from another high level systems programming language. As well, the compiler, pseudocode, and virtual machine are discussed in some detail. The new language is a powerful PL/1 dialect, as is its parent language, XPL1. PL/EXUS (<u>P</u>rogramming <u>L</u>anguage/<u>E</u>xtended <u>X</u>PL <u>U</u>sers' <u>S</u>uperset), was created to satisfy a particular set of needs. A highly machine independent, mobile, compact, and powerful programming system was needed for implementation of programs to manipulate medical record data on modestly configured minicomputers. The primary extensions to XPL were semantic and dictated the structure of a host virtual machine. Because of the number of different data types and implicit mixed mode conversion rules, the virtual machine has a tagged data architecture. This results in a small instruction set of under 64 operators and thus enables powerful, implicit, run time instruction interpretation. The PL/EXUS virtual machine has a basic eight bit word size. Its virtual memory capabilities require only a fraction of the program and data to be in real memory at a time. The ability to specify storage space for most data types results in parsimonious space allocation in spite of the presence of tag words (one eight-bit byte per identifier or constant). Some instructions were specifically created to allow the compiler to "peep-hole" (i.e., locally) optimize generated pseudocode programs. The compiler itself is written in XPL, which permits self-compilation and makes possible its execution on the virtual machine or a simulated (interpretive) version of it.


#*Recovery scenario for a DB/DC system
#@Lawrence A. Bjork
#t1973
#cProceedings of the ACM annual conference
#index552437
#%547167
#!Previously developed sphere-of-control (SOC) concepts are used to develop a scenario for post-process recovery. An information structure provides the recovery boundary around the effects of the usage of a resource. Rules for building this structure are addressed, and the capability for searching backward in time is identified to determine the source of error and possible recovery strategies.


#*Ordinary differential-operators with complex coefficients.
#@Sung-Jae Lee
#t1972
#c
#index198030


#*The for statement in ALGOL
#@B. A. Galler
#t1966
#cIssue 22 (February 1966)
#index108723


#*Discretization theory for gamma-polynomials and two nonlinear settings for the remez algorithm
#@Mark Myrom Holte
#t1972
#c
#index206109


#*An interactive system for page layout design
#@Peter B. Denes,Ira K. Gershkoff
#t1974
#cProceedings of the 1974 annual conference - Volume 1
#index552763
#%327644
#!A prototype interactive page layout system is described in which textual and pictorial information can be manipulated under computer control on a scanned color display. The system demonstrates the unique advantages of a scanned display for the showing of both text and illustrations, of details of different fonts, and of color. Text can be edited, positioned, and changed in size, font, and case; pictures can be positioned, shrunk, enlarged, and cropped. The color of both text and pictures can also be changed in order to guide the designer's eye to essential parts of the page. The system is suitable for designing both the individual advertisements and complete pages of directories or newspapers.


#*Procedure for testing microprograms
#@W. G. Bouricius
#t1974
#cConference record of the 7th annual workshop on Microprogramming
#index547894
#%316592
#%545252
#%549965
#!To produce reliable, i.e. defect-free microprograms a two phase procedure is recommended. The first phase consists of expressing the desired algorithms in a precise formal way employing a suitable specification language so that the 'correctness' of the specifications can be examined. The second phase consists of transcribing these specifications into machine code microprograms and proving the 'equivalence' between the formal specifications and the machine microcodes. Various desiderata of such a specification language are described and the reasons supporting each are given. Several uses for an implemented version are advocated and all depend on the 'correctness' of the implementation. Unique means for thoroughly checking the programmed implementation are given and the possibility of mathematically proving it correct is discussed.


#*The influence of the computer on medium-size manufacturing organizations.
#@George Lawrence Hess
#t1974
#c
#index199678


#*Computer applications in the humanities: a SNOBOL4 procedure for conflating the variants produced by textual collation
#@Susan L. Follett,Miriam J. Shillingsburg
#t1976
#cProceedings of the 14th annual Southeast regional conference
#index616039
#!Highly trained humanists who edit literary texts now spend vast amounts of time in what is universally acknowledged to be the necessary but tedious comparison of texts and the sorting and merging of the variants between the editions. The computer has the capability to relieve much of this drudgery and do the job more rapidly and accurately than can humans. A research project in computerized textual comparison is currently underway at Mississippi State University. This paper discusses one phase of this project, a procedure for the computerized production of a report giving the conflated (merged) results of collating (comparing character-by-character) any number of texts. This procedure, which is implemented in the SNOBOL4 programming language, is described and discussed in terms of the overall goals and efforts of the total research project.


#*SYSL: system description language
#@Nobuyoshi Terashima
#t1974
#cACM SIGPLAN Notices
#index307454
#%321731
#%320395
#!SYSL-System Description Language, which is a higer level language like FORTRAN, COBOL and so on, has been developed as a system implementation language for use by DIPS-1 operating system, a large scale OS for time-sharing services, banking control services and so on.Run-time efficiency and space efficiency of SYSL object codes are 1.11 time and 1.17 times, respectively, of those obtained from assembly language.SYSL has been used to write about 90 per cent of language processors and other processing programs of DIPS-1 OSSYSL has reduced the huge amount of time required for coding, debugging, maintaining and documenting.


#*A File System Extension to Micro-PL/CS
#@James E. Archer, Jr.
#t1979
#c
#index118853
#!Micro-PL/CS is a version of PL/CS developed for interactive use with a dedicated microprocessor. A file system extension is proposed to give PL/CS a simple, but extremely powerful file system capability. The system allows for the creation and manipulation of files for sequential, random, or keyed access (or any combination) in an unrestricted manner. Essential to the capability is a set of built-in functions and pseudo-variables which allow file manipulation without syntactic complication.


#*Optimising automatic tracking of multilayer boards
#@H. G. Adshead
#t1975
#cACM SIGDA Newsletter
#index101783
#%547559
#%549495
#%550493
#%551954
#%332105
#!The paper commences with a brief but critical appreciation of some known automatic tracking techniques for multilayer printed circuit boards, viz. Maze-Running, Line-Search and Channel-Allocation. The purpose here is to bring out their inherent similarity and to propound their specific superiority under different combinations of controlling criteria dictated by technological constraints. Consideration is given to the prohibitive core and time requirement for a real life environment involving an approximately 500 x 500 track matrix associated with the request for orthogonally connecting about 2500 pin-pairs, on each board. The paper then proceeds to discuss in detail the evolution of an effective algorithm and list-structure capable of successfully handling this problem. Finally several side issues of major significance are introduced. The efficient pre-sorting of the order in which wires are submitted to the main algorithm has been found to make a significant contribution to the efficiency of the entire system. Profile analysis is developed as a technique for comparing the relative merits of various topological placements of the logic network. The importance of the basic board layout and its relation to the algorithm employed is stressed.


#*Solution of Eigenvalue problems with approximately known Eigenvectors
#@Klaus Appel
#t1962
#cCommunications of the ACM
#index323650
#!It is often desired to solve eigenvalue problems of the type (A - &lgr;1)C = 0 or (A - &lgr;B)C = 0 repeatedly for similar values of the matrix elements Aij, where A and B are Hermitean or real symmetric matrices. Among the various methods to find all eigenvalues and eigenvectors, Jacobi's method of two-dimensional rotations [1] has been very popular for its numerical stability, although it is comparatively time-consuming. The purpose of this note is to show how existing subroutines can be used to reduce substantially the computing time, if approximate eigenvectors are known from the previous solution of a similar problem.


#*On attribute grammars and the semantic specification of programming languages.
#@Mehdi Jazayeri
#t1975
#c
#index199584


#*Frame selection systems and languages for medical applications.
#@Pierre Joseph Lebeux
#t1974
#c
#index196251


#*An algebraic approach to test data generation
#@A. Brown
#t1972
#cProceedings of the ACM annual conference - Volume 1
#index246822
#!In this paper the Test Data Generation problem is considered from the point of view of symbolic logic i.e., Boolean algebra. Essentially, the problem is the determination of various transfer functions describing the behavior of the network under test. This can be done by solving a corresponding system of Boolean equations using straight forward and easily understood algebriac techniques.This algebraic approach is enhanced significantly by the use of the novel concepts of logic flowgraphs and variational derivatives. Logic flowgraphs are a particular application of flowgraphs extending to logic networks the signal flow theory and other graphical concepts which have been successfully applied elsewhere. The logic flowgraph results in a visualization and a mechanization of the algebraic approach not evident from other approaches. Indeed it provides a schedule (an ordering relative to precedence) for the above mentioned substitional process.The variational derivative concept, characterizing transitions in a network, is ultimately related to fault detection and is, in effect, an algebraic generalization of the star-product and d-cube concepts of Roth. In fact, the concept provides a concise algebraic means of describing the responses (R (Lt ; Lt-1 )) and (R' (Lt ; Lt-1 ;X)) mentioned above by Mr. Krosner.We will demonstrate the usefulness of these concepts by the analysis of the illustrative examples in figures (1), (2), and (3). Experience has shown that they provide a very general framework from which the broad spectrum of more practical and specialized techniques can be more readily understood.A more extensive and detailed account of the concepts and techniques briefly mentioned here can be found in Reference 1. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Manufacturing applications
#@M. J. Maggard,W. G. Lesso,G. L. Hogg,D. T. phillips,Carter L. Franklin, II,J. Douglas DeMaire,M. M. Patel,J. M. Panchal,M. T. Coughlin,Willaim L. Berry
#t1973
#cProceedings of the 6th conference on Winter simulation
#index547548
#!The objective of this session is to bring together a wide range of new concepts in manufacturing simulation to stimulate discussion and interest. The concepts involve the strategic and tactical decisions that are made during the course of a successful application in the manufacturing environment. Strategic aspects revolve around the selling of results to management. Tactical considerations include the scope of modeling detail and in the simulation model. The over-all goal of the papers and discussion is to provide a systematic foundation for analysts to draw from during the development of practical applications. Tactical considerations are concerned with the step-by-step abstraction of the simulation model from the real-world environment, and include setting the level of detail with the model as well as choosing an appropriate language.


#*1979-1980 IEEE Computer Society Scholorships for Members of Student Branch Chapters of the Computer Society
#@
#t1978
#cComputer
#index344767


#*Applications of the inner product computer
#@Earl E. Swartzlander, Jr.
#t1973
#cProceedings of the ACM annual conference
#index544857
#%188691
#!Recently much interest has been expressed in the idea that future improvements in computer speed will be due primarily to architectural innovations as opposed to improvement in the characteristics of components (i.e., logic circuits, delays, memories, cycle times, etc.). In view of this it is not surprising that the current generation of &ldquo;super computers&rdquo; (i.e., the ILLIAC IV, the STAR 100, and the ASC) all exemplify the use of new architectures to achieve great increases in computing speeds. In this paper yet another new architecture is proposed - the inner product computer4. Like the ILLIAC IV it is a &ldquo;special purpose&rdquo; processor which is intended to be used in conjunction with a general purpose (i.e., host) computer.


#*A note on matrix multiplication in a paging environment
#@Patrick C. Fischer Robert L. Probert
#t1976
#cProceedings of the 1976 annual conference
#index554739
#%326422
#%330858
#!In order to minimize the number of page fetches required when multiplying matrices occupying many pages of virtual storage, we consider adapting Strassen-like recursive methods to a paging environment. An algorithm with a theoretically better rate of growth results. Also presented is an algorithm for efficiently converting matrices from row storage form to sub-matrix storage form, thus making more accessible the benefits of algorithms based on sub-matrix storage form which were presented in [5].


#*Real time animation of dynamic processes
#@G. C. Morris
#t1974
#cProceedings of the 1st annual conference on Computer graphics and interactive techniques
#index235681
#!Animation and simulation processes are facilitated by the use of high level graphic languages. The results of these processes are not generally available in real time, developing of microfilm delaying the screening of the process until some time after the computer run.A technique is described which overcomes this problem whilst still allowing the use of a high level graphical language.The addition of a single feature to a "static" graphical language has transformed it into a "dynamic" graphical language allowing real time illustration of time varying processes.The technique is not restricted to the language described but may well be employed by other high level graphical languages.


#*Partitioning of weighted hypergraphs.
#@Henry Harcis Driver
#t1977
#c
#index189353


#*A functional view of data independence
#@Michael Stonebraker
#t1974
#cProceedings of the 1974 ACM SIGFIDET (now SIGMOD) workshop on Data description, access and control
#index554073
#%79620
#%316195
#%326368
#%335280
#%547267
#%554998
#!Many researchers have used the term &ldquo;data independence&rdquo; without indicating a precise meaning. One common definition is&mdash;the isolation of a program from considerations of the data which it processes [1,2].Another is&mdash;the ability of an applications program to execute correctly regardless of the actual storage of its data[3,4].Although these suggest the general concept, a precise framework is clearly needed. The current paper provides such a framework and explores its ramifications.


#*Systems design education: a gaming approach
#@Norman R. Lyons
#t1978
#cCommunications of the ACM
#index318373
#%329254
#%319577
#%576007
#!One of the problems facing managers of computer installations is the problem of configuring the computer system to meet the demands made by the mix of jobs that the computer center must service, This paper presents a management game that allows the player to configure a computer system to meet a hypothetical job mix. The job mix is under the control of a game administrator and can be varied to simulate a variety of real-world situations (I/0 bound jobs, compute bound jobs, etc.). The player of the game receives a set of detailed reports on the cost of his choices and a simulated run of the center operating under his choices.


#*An application of automata theory to the multiple level top down design of digital computer operating systems
#@Hartwell Blair Burner, Jr.
#t1973
#c
#index187068


#*Letters to the editor: self-reproducing automata
#@Michael Arbib
#t1961
#cCommunications of the ACM
#index321344


#*A method for generating uts (uni-code totally sequential) assignments with an iterative state transition algorithm.
#@Dattatraya Govind Raj-Karne
#t1972
#c
#index191369


#*IEEE Computer Membership Certificate
#@
#t1976
#cComputer
#index351469


#*Fortran 77
#@Walt Brainerd
#t1978
#cCommunications of the ACM
#index323839
#%317895
#%318564
#!There is a new standard Fortran. The official title is &ldquo;American National Standard Programming Language Fortran, X3.9-1978,&rdquo; but it is more commonly referred to as &ldquo;Fortran 77,&rdquo; since its development was completed in 1977. It replaces the Fortran standard designated X3.9-1966. This paper describes many of the features of Fortran 77 and also provides some information about how and why the standard was developed.


#*A Suggestion for a High-Speed Parallel Binary Divider
#@R. Stefanelli
#t1972
#cIEEE Transactions on Computers
#index336365
#!A family of four procedures to compute the inverse 1/X of a given binary number X normalized between 0.5 and 1 is described. The quotient is obtained in redundant binary form, i.e., in a base 2 code in which digits can assume any positive or negative integer value. All methods here described can be implemented by combinatorial networks; the dividers realized in this way are very fast because all carry propagations take place at the same time.


#*Concurrent fault simulation and functional level modeling
#@M. Abramovici,M. A. Breuer,K. Kumar
#t1977
#cProceedings of the 14th Design Automation Conference
#index553242
#%323455
#%545225
#%549102
#%552519
#%555098
#!In this paper we discuss some of the major issues dealing with the design of a functional level concurrent fault simulator for digital net works. In the area of functional level modeling we discuss the following items: motivation; algorithms for primitives; state events; u-events; timing considerations including inertial delays; and finally the relationship between faults and functional models. For concurrent faults simulation we first discuss the various advantages of this technique, including its compatiability with function level modeling. We then present the major attributes of an abstract data structure required for this system, and then the concurrent simulation mechanism is described. Finally we discuss the problem of switching between functional and gate level models for a module.


#*Design of Diagnosable Sequential Machines Utilizing Extra Outputs
#@H. Fujiwara
#t1974
#cIEEE Transactions on Computers
#index336496
#!This paper is concerned with the problem of designing easily testable sequential machines, output-observable machines, for which there exist very short checking experiments. A sequential machine for which any initial state can be uniquely determined only by the output response is said to be output-observable. An algorithm is developed to modify a given machine to an output-observable one by adding a minimum number of extra outputs. This method is based on the fact that the output-observable realization of a given machine M exists if and only if M is semi-FSR realizable (a special type of feedback shift register realization).


#*Binary Multiplication with Overlapped Addition Cycles
#@P. M. Fenwick
#t1969
#cIEEE Transactions on Computers
#index351947
#!With a suitable adder organization it is possible to overlap the adder operation during a binary multiplication and significantly decrease the overall multiplication time. The method is explained and a prototype multiplier described. The new technique provides a very economical method of obtaining a reasonably fast multiplier.


#*Review of "Computers in Knowledge-Based Fields, by Charles H. Myers", M. I. T. Press, Cambridge, Massachusetts, 1970
#@Ronald E. Anderson
#t1971
#cACM SIGSOC Bulletin
#index574132


#*Minimum Steiner trees, roots of a polynomial, and other magic
#@J. Soukup
#t1977
#cIssue 22 (December 1977)
#index13070
#%3323
#!The paper is a collection of observations and ideas on a surprising similarity between Steiner points on one hand, and roots of a complex polynomial on the other. These ideas can also be used to derive a simple practical method to generate good suboptimal Steiner trees. However, the main purpose of the paper is to point out a vast area of problems still open to further research.


#*Mixed integer programming algorithms for site selection and other fixed charge problems having capacity constraints
#@Paul Gray
#t1968
#c
#index202160


#*The REL animated film language
#@F. Thompson,R. Bigelow N. Greenfeld J. Odden,D. Reece P. Szolovits
#t1974
#cProceedings of the 1st annual conference on Computer graphics and interactive techniques
#index237214
#!Motion picture films generated by computers have now been produced by a number of groups across the country. We wish to report here on the design and implementation of the REL Animated Film Language (AFL), designed primarily for use by artists interested in the aesthetics of abstract motion graphics. The language is simple enough to be used by the artist directly, rather than by a professional programmer acting for the artist. It provides convenient means of expressing spatial and temporal changes in the shape and location of the objects with which the artist constructs his compositions. The artist uses the language to express the inter-object relationships which embody the aesthetic content of the work.


#*An approach to microprogram optimization considering resource occupancy and instruction formats
#@Mario Tokoro,Eiji Tamura,Kazuhiko Takase,Kiichiro Tamaru
#t1977
#cACM SIGMICRO Newsletter
#index552030
#%554092
#!This paper describes a microprogram optimization technique considering resource occupancy and microinstruction format. This technique is applicable to machines whose microoperation occupies several machine cycles on a submachine cycle basis, and whose microinstruction format varies from horizontal to partially encoded, to vertical. &ldquo;Microtemplate&rdquo; is proposed to represent fetch timing and period of resource usage for a microoperation on a machine cycle and submachine cycle basis. An algorithm is shown, which detects concurrency of sequentially written microoperations through manipulation of microtemplates. An algorithm of microinstruction format selection is also discussed which decides one instruction format when several candidates exist. Effectiveness of this technique is evaluated. Efficient object codes are generated when applied to a practical sophisticated microprogrammable computer.


#*T-operators and the roots of complex polynomials.
#@John James Kane
#t1975
#c
#index190861


#*Global flow analysis and register allocation for simple code structures
#@Kenneth Wade Kennedy, Jr.
#t1971
#c
#index199832


#*Real World Applications of Network Related Problems and Breakthroughs in Solving Them Efficiently
#@Fred Glover,Darwin Klingman
#t1975
#cACM Transactions on Mathematical Software (TOMS)
#index335379


#*A Fortran II load-time saver
#@A. Frank Ackermann
#t1964
#cCommunications of the ACM
#index319446
#!The FORTRAN II CHAIN feature on the 7090 can be used to save card-to-tape time, loading time, and to provide a convenient method for storing and transporting producting programs. The method is simply to load the desired program as a CHAIN and save the tape on which it is stored. A trivial program can then be used to recall the major program.


#*Medical Information Systems: A Resource for Hospitals
#@Melville H. Hodge
#t1977
#c
#index622532


#*Two Hadamard numbers for matrices
#@Garrett Birkhoff
#t1975
#cCommunications of the ACM
#index322489
#%457304
#!A discussion is given of two functions of the entries of a square matrix, both related to Hadamard's determinant theorem, which have some merits as alternatives to norm-bound &ldquo;condition numbers.&rdquo; One (for linear systems) is known; the other (for eigensystems) seems to be new.


#*On Parallel-Acting Index Registers
#@D. Mandelbaum
#t1971
#cIEEE Transactions on Computers
#index336106
#!It is shown how index registers can be made so as to act parallel to the computer instruction flow, thus not requiring a programmed instruction to decrement (or increment) and jump. This method would save one instruction per loop but would require more hardware.


#*Improving the administration of computer-assisted game simulations within an executive development program.
#@William George O'Leksy
#t1973
#c
#index190446


#*Review of "Automated theorem proving: a logical basis" by D. W. Loveland. North-Holland Publishing Co. 1977.
#@
#t1979
#cACM SIGACT News
#index436266


#*The design of the Cambridge algebra system
#@S. R. Bourne,J. R. Horton
#t1971
#cProceedings of the second ACM symposium on Symbolic and algebraic manipulation
#index548788
#%328541
#!This paper discusses the design of the CAMbridge ALgebra system and describes some of the techniques that are used in its implementation. These techniques enable that system to provide reasonably general algebraic manipulation in an efficient way. The concepts of modularity and selection are introduced and their influence on the overall structure of the system is described. Examples of selection and editing facilities are given since these are considered to be a necessary part of any algebra system. The paper also discusses data structures that are appropriate for algebraic systems and examples are given for two of the CAMAL modules.


#*Functional and pattern sensitive fault testing algorithms for semiconductor random access memories.
#@Dong Sung Suk
#t1978
#c
#index201526


#*A methodology of application program analysis and conversion based on database semantics
#@Stanley Y. W. Su,B. J. Liu
#t1977
#cProceedings of the 1977 ACM SIGMOD international conference on Management of data
#index617810
#%316007
#%326368
#%328220
#%369138
#%548941
#%619461
#!This research studies the effects of 1) association changes in database semantics, 2) file composition and decomposition, and 3) the conversion of one DBMS to another to the application programs. A methodology of application program analysis and conversion based on database semantics is proposed. The semantics of both the source and target databases are described in terms of entity types and their associations. The semantics of application programs is represented by an "application structure" of language sequences which correspond to a number of access path graphs representing the general access patterns associated with entity types and their associations. Program conversion is achieved by meaning-preserving transformations of the access path graphs to account for the various types of database changes.


#*Certification of Algorithm 51: Adjust inverse of a matrix when an element is perturbed
#@Richard George
#t1962
#cCommunications of the ACM
#index315502


#*A nonlinear multiprocessor scheduling problem.
#@Camille Cook Price
#t1979
#c
#index195683


#*From the President
#@
#t1977
#cComputer
#index341894


#*The complexity of combinatorial optimization problems.
#@Christos Harilaos Papadimitriou
#t1976
#c
#index201087


#*Computer organization and algorithms for very-high speed computations.
#@Samuel Ellis Orcutt, Jr.
#t1975
#c
#index200214


#*The data structure set model
#@Charles W. Bachman
#t1975
#cProceedings of the 1974 ACM SIGFIDET (now SIGMOD) workshop on Data description, access and control: Data models: Data-structure-set versus relational
#index548739
#!I think we have a discussion today; not a debate. Its real purpose is to increase our understanding of the basic concepts underlying data base structures and their models; to note the similarities and differences between them, and to determine their compatibility or the lack thereof. We are talking about concepts, not about implementations. The reason for all data base structuring is retrieval: retrieval for output, retrieval for decision-making, retrieval for updating. To pinpoint the object of retrieval we must intelligently select the &ldquo;right&rdquo; data&mdash;the correct single record, the correct group of records, and, in some sense, the correct sequence of records (in those situations where the sequence in which these records are seen is important). For accurate selection, dependent on the particular interests, needs, and requirements of a given person, we want a mechanism for readily defining records to be selected. We want a mechanism that will permit the data base to evolve as the enterprise and information systems change. We want a mechanism which will protect already existing investment in programs and report specifications, while the data base evolves. We want a mechanism which permits the reoptimization of the structure of stored data as things change.


#*Sur un Cas Particulier de la Conjecture de Cerny
#@Jean-Eric Pin
#t1978
#cProceedings of the Fifth Colloquium on Automata, Languages and Programming
#index561712


#*Process structuring, synchronization, and recovery using atomic actions
#@D. B. Lomet
#t1977
#cACM SIGPLAN Notices
#index546154
#%322720
#%330864
#%332514
#%553264
#!This paper explores the notion of an atomic action as a method of process structuring. This notion, first introduced explicitly by Eswaren et al [6] in the context of data base systems, reduces the problem of coping with many processes to that of coping with a single process within the atomic action. A form of process synchronization, the await statement, is adapted to work naturally with atomic actions. System recovery is also considered and we show how atomic actions can be used to isolate recovery action to a single process. Explicit control of recovery is provided by a reset procedure that permits information from rejected control paths to be passed to subsequent alternative paths.


#*Computer programming for facilities treating developmentally disabled children
#@Ronald H. Nelson
#t1977
#cACM SIGCAS Computers and Society
#index349408
#!In the mental health institution, the staff are generally divided into two areas: the administrators and the clinicals. "The administrative-programmatic objective is the make a general class of services available to a specific individual or group of individuals" (Hurder & Hurder, ND). Therefore, each group is interested in different kinds of data for different purposes.


#*Motivating freshmen engineering students
#@R. T. DeLorm,T. C. Smith
#t1975
#cACM SIGCSE Bulletin
#index546897
#!In an effort to lower the rate of attrition of Engineering students, during the early years of their education, the University of Nebraska - Lincoln has instituted a series of two freshman engineering courses which are designed to motivate and retain these students. A description of each of these courses and the motivating factors of each are discussed. Creative plots and conceptual engineering design projects are used as a means of holding interest and teaching the basic engineering skills. Surveys taken over a number of years have shown an increase in the retention of engineering students since these courses were instituted. These surveys are discussed.


#*Cost evaluation of storage schemes
#@Jair M. Babad,V. Balachandran,Edward A. Stohr
#t1974
#cProceedings of the 1974 annual conference - Volume 1
#index549350
#%314151
#!In this paper we present a methodology for the cost evaluation of file system performance. The cost structure we consider takes into account the various operations that are required during the processing of data in the system. The cost evaluation approach is then applied to several systems. A new storage scheme&mdash;a partially ordered file&mdash;is proposed, and experimental data which demonstrate its performance are presented. Finally, the cost evaluation approach is applied to this proposed storagse scheme.


#*Future prospects in data processing
#@
#t1975
#cProceedings of the May 19-22, 1975, national computer conference and exposition
#index61680


#*A user-controlled synchronization method
#@John M. Chambers
#t1973
#cACM SIGOPS Operating Systems Review
#index114255
#%310300
#%321943
#%315691
#%314331
#%315276
#%322720
#%335624
#%314206
#%335280
#%319561
#%301394
#%323203
#!In any system that allows the sharing of facilities between independently-running processes, it is occasionally necessary to 'synchronize' references to shared facilities. A method is presented here that enables any set of processes to achieve such synchronization without any aid from the executive system or special hardware. Only normal load and store operations on two arrays of shared data are required. No overhead is required for unsynchronized operations. And dead-locks are avoided, since it is never necessary to 'block' a process.This method can be viewed as a generalization of Dijkstra's example [D3], though the connection may not be obvious at first glance.


#*Correct and optimal implementations of recursion in a simple programming language
#@Jean Vuillemin
#t1973
#cProceedings of the fifth annual ACM symposium on Theory of computing
#index552986
#%192411
#%200702
#!The object of this paper is to study the mechanism of recursion in a simple, LISP-like programming language, where the only mean of iteration is through recursion. The theory of computation developped in Scott [4] provides the framework of our study. We show how the implementations of recursion which deserve to be called &ldquo;correct&rdquo; can be characterized semantically, and demonstrate a general criterion for the correctness of an implementation. We then describe an implementation of recursion which is both correct and optimal in a general class of sequential languages, and therefore constitutes an attractive alternative to both &ldquo;call-by-name&rdquo; and &ldquo;call-by-value&rdquo;.


#*Concurrency in Operating Systems
#@J. W. Atwood
#t1976
#cComputer
#index347990
#!As general-purpose computing systems become larger and more complex, it has become uneconomical to restrict their use to a single user or program. This has introduced the necessity of finding ways to safely share them.


#*A PERT-CPM tutorial
#@H. S. Swanson,R. E. D. Woolsey
#t1974
#cIssue 16 (April 1974)
#index9108
#!PERT and CPM, acronyms for "program evaluation and review technique" and "critical path method", respectively, are network techniques used to aid in the planning, scheduling, monitoring, and control of activities which are related to each other. For example, CPM is frequently used in the construction industry to help organize and schedule those activities which together constitute a given construction project. PERT was first used to help coordinate the activities in the development of the Polaris missle system. PERT and CPM differ from each other in that activity times are handled differently by these two closely related techniques. In using CPM, one assumes the activity times are known with certainty (deterministic activity times); PERT allows for uncertainty and statistical variation in activity times (stochastic activity times). Never the less, PERT and CPM are closely related (CPM may be a special case of PERT), and a variety of projects are subject to analysis by either technique:(1)(1) construction projects(2) planning and launching a new product(3) a turn around in an oil refinery (or other maintenance projects)(4) installing and debugging a computer system(5) scheduling ship construction and repairs(6) manufacture and assembly of large job-lot operations(7) missile countdown procedures(8) end-of-the month closing of accounting records(9) research and development projects


#*A performance information system for data processors
#@Francis L. Harmon,George W. Mayeske,Albert S. Glickman
#t1965
#cProceedings of the third annual computer personnel research conference
#index545555
#!During the past three years the Personnel Research Staff of the U. S. Department of Agriculture has been doing research aimed at improving our performance information systems. I am going to tell you about the work we have done with one group&mdash;the 400-odd ADP people employed in the Department.


#*Session 14c: program library care and feeding
#@
#t1976
#cProceedings of the 4th annual ACM SIGUCCS conference on User services
#index230516


#*Compiling techniques
#@Thomas E. Cheatham
#t1966
#cCommunications of the ACM
#index314812


#*LL(k) Languages are Closed Under Union with Finite Languages
#@Ileana Streinu
#t1977
#cProceedings of the Fourth Colloquium on Automata, Languages and Programming
#index361309


#*A Proposed Standard for Binary Floating-Point Arithmetic
#@D. Stevenson
#t1981
#cComputer
#index343014
#!Offered here for public comment, this proposed standard facilitates transportation of numerically oriented programs and encourages development of high-quality numerical software.


#*Preserving the integrity of the medium: a method of measuring visual and auditory comprehension of electronic media
#@Mary Alice White,Barbara Sandberg,Eda Behar,Jean Mockler,Elizabeth Perez,Janine Pollack,Kenneth Rosenblad
#t1984
#cInternational Journal of Man-Machine Studies
#index168953


#*An Efficient Deadlock Removal Scheme for Non-Two-Phase Locking Protocols
#@Zvi M. Kedem,C. Mohan,Abraham Silberschatz
#t1982
#cProceedings of the 8th International Conference on Very Large Data Bases
#index367512
#%233760
#%314331
#%317485


#*Subject Index
#@
#t1981
#cIEEE Computer Graphics and Applications
#index351025


#*Programming with data frames for everyday data items
#@David W. Embley
#t1980
#cProceedings of the May 19-22, 1980, national computer conference
#index65223
#%548210
#!Processing everyday data items such as dollar amounts, time, dates, and account numbers constitutes a significant portion of real-world computer applications. Programmers involved with everyday data items confront the drudgery of writing routines to recognize, validate, transform, store, retrieve, manipulate, and display these items and also the challenge to develop user-friendly data-entry systems and insure data integrity. They usually meet these challenges using various and sundry ad hoc techniques.


#*An array simulator generator
#@Daniel John Kopetzky
#t1980
#c
#index191967


#*The Ada Compiler Validation Capability
#@John B. Goodenough
#t1980
#cProceedings of the ACM-SIGPLAN symposium on The ADA programming language
#index544699
#!The Ada Compiler Validation Capability consists of tests, tools, procedures, and documentation designed to enforce (and encourage) development of compilers that conform to the Ada language Standard. In this paper, we discuss our approach to solving the principal problems faced in developing and using such a capability.


#*Realisierung schneller numerischer Steuerungen unter Verwendung von Bitsclice-Prozessoren
#@A. Schuler,M. Smoliner
#t1983
#cMicrocomputing, Tagung III/1983 des German Chapter of the ACM
#index278475


#*Specification of compilers as abstract data type representations
#@Marie-Claude Gaudel
#t1980
#cSemantics-Directed Compiler Generation, Proceedings of a Workshop
#index562641


#*Recognizing intended meaning and speakers' plans
#@Candace L. Sidner,David J. Israel
#t1981
#cProceedings of the 7th international joint conference on Artificial intelligence - Volume 1
#index490662
#%618658
#!Human conversational participants depend upon the ability of their partners to recognize their intentions, so that those partners may respond appropriately. In such interactional the speaker can encode his intentions that the hearer act in a variety of sentence types. Instead of telling the hearer what to do. the speaker may Just state his goals, and expect a response that meets these goals. This paper presents a new model for recognizing the speaker's Intended meaning in determining a response. We show that this recognition makes use of the speaker's plan, his beliefs about the domain and about the hearer's relevant capacities.


#*Sorrento workshop papers
#@
#t1984
#cACM SIGSIM Simulation Digest
#index576025


#*The computational metaphor and quantum physics
#@Michael J. Manthey,Bernard M.E. Moret
#t1983
#cCommunications of the ACM
#index335420
#%317316
#%319217
#%320646
#%326751
#%622654
#%553110
#!Concurrent computational systems, viewed as sets of cooperating processes, are shown to have close analogies in the world of quantum physics. In particular, analogies exist between processes and particles, between a process' state and a particle's mass, between a process'state changes and a particle's velocity, and between interprocess communications and particle interactions. This view allows the application in the computational world of special relativity theory, the uncertainty principle, the law of conservation of momentum, and many of particle physics' fundamental results. This paper describes the basic analogy and some fundamental results. It is the authors' belief that new insights into a computational processes will be gained as the analogy is developed and vice versa. It is conceivable that established results of the computational sciences may contribute to a new understanding of some of the problems of physics. Other process-oriented sciences, such as biology, economics, and psychology, could also benefit from such development.


#*A stream function method for computing steady rotational transonic flows with application to solar wind-type problems
#@David Alan Kopriva
#t1982
#c
#index204133


#*Ganzheitliche Beurteilung von Benutzerschnittstellen und Gestaltungsanforderungen an die Software-Produktion
#@Lothar P. Schardt,Friedrich-L. Holl
#t1983
#cGI - 13. Jahrestagung
#index260661


#*The software sieve
#@M H Darling
#t1984
#cProceedings of the 2nd IFIP international conference on Computer security: a global challenge
#index171658


#*Worst-Case Complexity Bounds on Algorithms for Computing the Canonical Structure of Infinite Abelian Groups and Solving Systems of Linear Diophantine Equations
#@C. S. Iliopoulos
#t1983
#c
#index203652


#*Geometry versus topology in map grammars
#@Azaria Paz
#t1982
#cProceedings of the 2nd International Workshop on Graph-Grammars and Their Application to Computer Science
#index277085


#*Parallel algorithms for algebraic problems
#@Joachim von zur Gathen
#t1984
#cSIAM Journal on Computing
#index178206


#*Lecture notes in computer science; Vol. 170
#@Philip H. Enslow
#t1984
#cComputer Networks and ISDN Systems
#index160311


#*Some effects of considerate and inconsiderate systems
#@Ronald E. Anderson
#t1981
#cACM SIGSOC Bulletin
#index575290
#%319498
#%579668
#!Concern for the human factors in computer systems continues to grow as computerization becomes more and more pervasive. In the early period of computing such concern was expressed in terms of "user orientation" and "user requirements." As interactive systems evolved it became more common to hear terms like "responsive systems," and "end-user requirements." In the early Seventies, when the computer profession experienced a wave of social responsibility, discussions emerged on "humanizing" systems [1]. More recent discussions on these issues describe ideal systems as people-oriented, convivial, or friendly [2]. Despite this attention to human factors there is relatively little systematic knowledge about what system features actually take human needs and desires into account, and, in this sense, are considerate.


#*A study of degeneracy in the simplex algorithm for linear programming and network flow problems (optimization, mathematical)
#@Mohammad Hassan Partovi
#t1984
#c
#index191646


#*Database theory
#@
#t1984
#cProceedings of the 1984 ACM SIGMOD international conference on Management of data
#index444019


#*Is distributed locking harder?
#@Paris C. Kanellakis,Christos H. Papadimitriou
#t1982
#cProceedings of the 1st ACM SIGACT-SIGMOD symposium on Principles of database systems
#index232648
#%320363
#%317485
#%246836
#!We examine the problem of determining whether a set of locked transactions, accessing a distributed database, is guaranteed to produce only serializable schedules. For a pair of transactions we prove that this concurrency control problem (which is polynomially solvable for centralized databases) is in general coNP-complete. We employ a new graph-theoretic technique and provide an efficient test for the special case of databases distributed between two sites only.


#*Zur Didaktik der Datenstrukturen
#@Walter Dosch
#t1984
#cInformatik als Herausforderung an Schule und Ausbildung, GI-Fachtagung
#index257668


#*Design of the WELL System
#@Rudolf Munz
#t1980
#cProceedings of the 1st International Conference on the Entity-Relationship Approach to Systems Analysis and Design
#index277316


#*Crisis in computer science education at the precollege level
#@Larry W. Cornwell
#t1982
#cProceedings of the thirteenth SIGCSE technical symposium on Computer science education
#index545393
#%333124
#!This paper attempts to focus attention on the problem of providing meaningful and effective educational programs for precollege teachers. Computer science departments caught in their own staffing problems have not given much attention to precollege teacher training in computer science. Elementary and secondary schools are experiencing very little turnover in staff. Even when these schools have an open position, individuals entering the teaching field have little or no training in computer science. Yet the need for precollege teachers with a computer science background exists and is growing larger each year. This paper addresses this crisis in computer science education at the precollege level and proposes an approach which can be implemented easily and effectively.


#*A simple semaphore-queue management for multiprocessing systems
#@Neta Amit,Micha Hofri
#t1980
#cACM SIGOPS Operating Systems Review
#index116223


#*Accurate computation of divided differences
#@Allan Charles Mccurdy
#t1980
#c
#index203956


#*The representation and synthesis of design specifications for distributed software systems
#@Sol Mark Shatz
#t1983
#c
#index186841


#*The SLATEC mathematical subroutine library
#@W. H. Vandevender,K. H. Haskell
#t1982
#cACM SIGNUM Newsletter
#index99322
#%107873
#%264180
#%326262
#%314303
#%102806
#%321457
#%319620
#%320844
#%323437
#%329807
#%335126
#%320741
#!The SLATEC Common Mathematical Subroutine Library is an experiment in resource sharing by the computing departments of several Department of Energy Laboratories. The objective is to cooperatively assemble and install at each site a mathematical subroutine library characterized by portability, good numerical technology, good documentation, robustness, and quality assurance. The result is a portable Fortran mathematical subroutine library of over 130,000 lines of code.Much of the following report is based on [1], a chapter to be included in a forthcoming book about mathematical software.


#*An O(n2 log n) parallel max-flow algorithm
#@Yossi Shiloach,Uzi Vishkin
#t1982
#cJournal of Algorithms
#index470070


#*An empirical methodology for writing user-friendly natural language computer applications
#@J. F. Kelley
#t1983
#cProceedings of the SIGCHI conference on Human factors in computing systems
#index549238
#!A six-step, iterative, empirical, human factors design methodology was used to develop CAL,a natural language computer application to help computer-naive business professionals manage their personal calendars. Language is processed by a simple, non-parsing algorithm having limited storage requirements and a quick response time. CAL allows unconstrained English inputs from users with no training (except for a 5 minute introduction to the keyboard and display) and no manual (except for a two-page overview of the system). In a controlled test of performance, CAL correctly responded to between 86% and 97% of the inputs it received, according to various criteria. This research demonstrates that the methodological tools of the engineering psychologist can help build user-friendly software that accommodates the unruly language of computer-naive, first-time users by eliciting the cooperation of such users as partners in an iterative, empirical development process. The principal purpose of the research reported here was to design and test a systematic, empirical methodology for developing natural language computer applications. This paper describes that methodology and its successful use in the development of a natural language computer application: CAL,Calendar Access Language. The limited context or domain in which the application operates is the management of a personal calendar, or appointment book, data base by computer-naive business professionals.


#*An application of the digital speech interpolation technique to the variable rate subband coding system
#@Kuei Yung Kou
#t1983
#c
#index205250


#*1985 IEEE Microprocessor Forum
#@
#t1984
#cIEEE Micro
#index347925


#*Proceedings of the 15th annual workshop on Microprogramming
#@
#t1982
#cInternational Symposium on Microarchitecture
#index551806


#*An Alphard Specification of a Correct and Efficient Transformation on Data Structures
#@J. L. Bentley
#t1980
#cIEEE Transactions on Software Engineering
#index337253
#!In this paper we study the problem of designing and specifying standard program components applicable to a wide variety of tasks; we choose for this study the specific problem domain of data structures for general searching problems. Within this domain Bentley and Saxe [1] have developed transformations for converting solutions of simple searching problems to solutions of more complex problems. We discuss one of those transformations, specify precisely the transformation and its conditions of applicability, and prove its correctness; we accomplish this by casting it in terms of abstract data types-specifically by using the Alphard form mechanism. The costs of the structures derived by this transformation are only slightly greater than the costs of the original structures, and the correctness of the transformation definition together with the correctness of the original structure assure the correctness of the derived structure. The transformation we describe has already been used to develop a number of new algorithms, and it represents a new level of generality in software engineering tools.


#*Interval Methods for Processing Geometric Objects
#@S. Mudur,P. Koparkar
#t1984
#cIEEE Computer Graphics and Applications
#index347339
#!In this approach, the parametric form is applied without the usual computational nightmare. The key is to view the parametric range as an interval, relying on subdivision algorithms.


#*Stop losing sleep over incomplete data type specifications
#@Jean Jacques Thiel
#t1984
#cProceedings of the 11th ACM SIGACT-SIGPLAN symposium on Principles of programming languages
#index548549
#%547807
#!We give an algorithm to test the completeness of definitions holding on the rewrite systems that they generate. At the opposite of existing techniques that are very restrictive (left-hand sides of definitions must be linear) or rather inefficient our solution is both powerful and efficient. Also, the algorithm that we give detects ambigous or/and incomplete definitions and can tell you why they are ambigous or/and incomplete. It applies too to definitions in presence of equations.


#*Recursive programs as definitions in first order logic
#@Robert Cartwright
#t1984
#cSIAM Journal on Computing
#index176362


#*Documentational analysis: Or Good Common Sense
#@Diana Patterson
#t1982
#cProceedings of the 1st annual international conference on Systems documentation
#index545783
#!Those who never documented their systems are suffering the consequences. In response your friendly marketplace has come up with some solutions to be purchased at the same price as a piece of software. It may or may not be partly software. It is a specific guide for generating documentation in as mechanical and predictable a method possible. If it is mechanical, it can be controlled, and that is what the product is: control. Control of system analysis and design. The necessary by-product is documentation. The kind of analysis that documentation requires, falls under that mysterious grace called &ldquo;Good Common Sense.&rdquo;


#*Validation (Panel)
#@Stewart V. Hoover
#t1984
#cProceedings of the 16th conference on Winter simulation
#index546813


#*An integrated design for testability and automatic test pattern generation system: An overview
#@Erwin Trischler
#t1984
#cProceedings of the 21st Design Automation Conference
#index549968
#%547348
#%547442
#%548455
#%549420
#%553311
#!A general overview on an Integrated Design for Testability and Automatic Test Pattern Generation System (IDAS) is given. The major components of IDAS include: heuristic controllability/observability (C/O) analysis, prediction of testing costs, tools for evaluation, display and improvement of testability, and C/O guided automatic test pattern generator. The IDAS system includes also the logic and concurrent fault simulator CADAT. A brief description of major components with a scenario how to use IDAS is given. Future research activities are discussed.


#*&ldquo;Software Piracy and protection&rdquo;
#@Peter S. Vogel
#t1982
#cProceedings of the ACM '82 conference
#index548794
#!Protection of the intellect was difficult before the advent of computer technology, and controlling and protecting software is even more complicated. This panel is made up of attorneys whose practices are concentrated in computers and related technologies, and will discuss the relation of the legal system to software protection from misappropriation - &ldquo;PIRACY&rdquo;.


#*Performance evaluation of a multiple processor system with shared busses
#@Pauline Markenscoff
#t1981
#c
#index193543


#*An exercise in constructing multi-phase communication protocols
#@C. H. Chow,M. G. Gouda,S. S. Lam
#t1984
#cProceedings of the ACM SIGCOMM symposium on Communications architectures and protocols: tutorials symposium
#index554015
#%188285
#%188880
#%202428
#%204451
#%204744
#%321201
#%327825
#%433405
#%622779
#!Many real-life protocols can be observed to go through different phases performing a distinct function in each phase. We present a multi-phase model for such protocols. A phase is formally defined to be a network of communicating finite state machines with certain desirable correctness properties; these include proper termination, and freedom from deadlocks and unspecified receptions. A multi-function protocol is constructed by first constructing separate phases to perform its different functions. We discuss how to connect these phases together to implement the multi-function protocol such that the resulting network of communicating finite state machines is also a phase (i.e. it possesses the desirable properties defined for phases). A high-level session control protocol modeled after one in IBM's Systems Network Architecture is discussed, and constructed as a multi-phase protocol.


#*Don't look back, something's gaining on us: more mixware software engineering metaphor
#@Dennis E. Hamilton
#t1980
#cACM SIGSOFT Software Engineering Notes
#index436802


#*A simulation model for assessment of large-scale power system reliability
#@John H. Blackstone, Jr.,Gary L. Hogg,Alton D. Patton
#t1980
#cProceedings of the 12th conference on Winter simulation
#index544451
#!This paper describes research on the applicability of Monte Carlo simulation to the study of large scale power system reliability. Reliability in this context refers to the ability of the system to meet demand for electricity over time. A generalized program capable of modeling any pool of generators was developed using a modified version of the GASP-IV simulation language. The logic of this program is described and the results of two applications of the program are presented.


#*Computer simulation of solar electric generating plants in a utility grid
#@S. Young,O. Merrill,R. Knowles,Y. Gupta
#t1980
#cProceedings of the May 19-22, 1980, national computer conference
#index63403
#!Solar electric power systems have the potential to supply power for industrial, commercial, institutional, and utility applications and to reduce consumption of non-renewable fossil fuels. However, widespread utilization of solar electric technologies in the United States will require that the solar systems be operated in parallel with, or as supplements to, the existing utility grid. For such systems, assumptions regarding future electric energy costs and rate structures have a major impact on solar system design and economics. Thus, in order to fully assess the economic worth of solar electric systems, it is necessary to evaluate their impacts on utility generation characteristics and to determine solar electric system design and cost relations within the context of the overall utility/solar system interaction.


#*Statistical Databases: Characteristics, Problems, and some Solutions
#@Arie Shoshani
#t1982
#cProceedings of the 8th International Conference on Very Large Data Bases
#index380747
#%233318
#%239553
#%355651
#%374906
#%383689
#%620539


#*Safety and power
#@Stavros M. Macrakis
#t1982
#cACM SIGSOFT Software Engineering Notes
#index436888
#!Although the "question of safety vs. power in programming languages" is most interesting, Glass's letter [SEN 6:5 (Oct 81)] addresses only a peripheral issue, namely some (seemingly arbitrary) areas in which certain programming languages have required unsafe solutions.In order to focus discussion, let me propose a definition of safety: a practice is "safe" if it relies only on the language's semantics. Clearly, unsafe practices are in general not portable between compilers or machines. There appear to be two primary motivations for unsafe practices: efficiency and extra-linguistic operations. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Code optimization of pipeline constraints
#@Thomas Karl Richard Gross
#t1983
#c
#index200099


#*Subscribe to IEEE Computer Graphics and Applications
#@
#t1981
#cIEEE Computer Graphics and Applications
#index349240


#*Computer chess at ACM 79: the tournament and the man vs. man and machine match
#@Ben Mittman,Monroe Newborn
#t1980
#cCommunications of the ACM
#index316358
#%329074


#*Maintaining order in a linked list
#@Paul F. Dietz
#t1982
#cProceedings of the fourteenth annual ACM symposium on Theory of computing
#index555274
#%317676
#%325466
#%550539
#!We present a new representation for linked lists. This representation allows one to efficiently insert objects into the list and to quickly determine the order of list elements. The basic data structure, called an indexed 2-3 tree, allows one to do n inserts in O(nlogn) steps and to determine order in constant time. We speed up the algorithm by dividing the data structure up into log*n layers. The improved algorithm does n insertions and comparisons in O(nlog*n) steps. The paper concludes with two applications: determining ancestor relationships in a growing tree and maintaining a tree structured environment (context tree).


#*A systems approach to the introductory course in information systems
#@David R. Adams,William Leigh
#t1982
#cProceedings of the thirteenth SIGCSE technical symposium on Computer science education
#index545903
#%320383
#!Introductory courses in information systems are typically taught as computer &ldquo;literacy&rdquo; courses; in computer science they are oriented to &ldquo;algorithm development&rdquo;. The course described in this paper is concerned with providing the student with facility in the top-down development of hierarchically related systems of programs to be used in a business context. It is considered critical to orient students to this conceptual approach early on in their professional education. The course has been offered for four terms and has been well received by students and valuable for continued educational development in later courses in the curriculum.


#*An investigation of idam file organizations
#@James Cornelius French
#t1982
#c
#index193387


#*State dependency issues in evaluating distributed database availability
#@Fabio A. Schreiber
#t1984
#cComputer Networks and ISDN Systems
#index162706


#*Proceedings of the ACM '81 conference
#@Toni Shelter,Steven Abraham,Emily Friedman
#t1981
#cACM Annual Conference/Annual Meeting
#index551457


#*IBM Speedcoding System (from IBM Manual)
#@
#t1983
#cIEEE Annals of the History of Computing
#index397534
#!SPEEDCODE (also called SpeedCo I and Speedcoding) was a three-address system that provided for floating point calculations. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Sub-protocol-evaluators for attribute grammars
#@Rodney Farrow
#t1984
#cACM SIGPLAN Notices
#index614492
#%192251
#%332308
#%370744
#%544585
#!This paper presents a new strategy for evaluating attribute grammars, sub-protocol attribute evaluation, and gives an algorithm for constructing sub-protocol-evaluators. Sub-protocol-evaluators can be built for any non-circular attribute grammar; this paper describes how to construct them for absolutely noncircular grammars [4]. Sub-protocol-evaluators are most easily understood as a simple optimization of another evaluator we call the protocol-evaluator. The protocol-evaluator has elements in common with the tree-walk evaluator of Kennedy-Warren [4] and with Nielson's direct evaluator [6]; it can be viewed as a refinement of each of these. Furthermore, the uniform AGs, proposed by Warren [9], and the ordered AGs, proposed by Kastens [3], are both subclasses of grammars for which especially efficient protocol-evaluators can be built.


#*Folk (abstract only)
#@Jan Oldervoll
#t1981
#cProceedings of the joint conference on Easier and more productive use of computer systems. (Part - I): Information processing in the social sciences and humanities - Volume 1981
#index552122
#!Ethnography is a methodology which emphasises a "soft" interpretative approach to social reality. It is often portrayed as being at the opposite pole to quantitative approaches as exemplified in the classic Merton-Lazarsfeld paradigm (Structural-Functionalism wedded to the survey method).Ethnography is a method in which the researcher actively engages in and records the life of a social group. This record of experience is essentially qualitative. It is primarily constructed in the form of textual description: an ongoing account of a person's observations, thoughts and feelings while in the "field". This text is usually given the generic title of field-notes.The Ethnographic researcher is therefore normally confronted with a vast amount of textual data. To get some understanding of, and control over this data, the Ethnographer must in some way split up this record of raw experience. He must in some way "chunk" up his data into easily manageable units or categories. It is this classificatory activity which forms the basis of Ethnographic analysis.In greater detail, Ethnographic data analysis may be generally portrayed as consisting of three analytically distinct, but empirically indistinct activities: represents a1. The reading of field-notes, accompanied by the recording of themes and hypotheses;2. The coding of important topics observed within the field-notes under different category headings;3. The disassembling of field-notes by coded category; the purpose being the creative filing and retrieving of one's data.The prime concern of this presentation will be to discuss means by which such analysis may be accomplished.It is the author's belief that the schema shown below possible evolutionary trend in Ethnographic data analysis: items lower down the schema give the Ethnographer greater power and flexibility in the way he handles text. Reference will be made to presently ongoing research at Cardiff as evidence of this claim.1. The Traditional Filing Cabinet.a. Simple chronological filing of text.b. Multiple filing: the actual disassembling of text into files.2. The Filing cabinet and Separate Indices.a. Chronological filing: card indices.b. Chronological filing: specialised indices.c. Chronological filing: computer indices.3. The Full Computer Approach.a. Indices and fieldnotes stored on UNIX.b. A System of Personalised Interactive Computing for Ethnographers. SPICE: a term purely invented to emphasise the "spice" of Ethnographic research.Finally, this presentation will also discuss the implications that this research has for textual management in general. The projected computer arrangement will, I believe, prove of advantage not only to the Ethnographer, but to any researcher who employs continuous text as his/her primary resource.


#*Graphic model building system
#@Yoshikazu Yamamoto,Mats Lenngren
#t1983
#cProceedings of the 16th annual symposium on Simulation
#index553558
#%144895
#%548099
#!An interactive Graphic Model Building System (GMBS) for discrete event simulation is presented. The GMBS is designed so as to be used even for unexperienced users who have no previous knowledge about neither modeling nor simulation languages. We introduce a new concept in which a model is divided into two specifications, that is, structural relations between system components and description of the logical behavior of each component.


#*Novanet communications network for a control system
#@J. R. Hill,J. R. Severyn,P. J. VanArsdall
#t1983
#cProceedings of the eighth symposium on Data communications
#index554663
#!Novanet is a control system oriented fiber optic local area network that was designed to meet the unique and often conflicting requirements of the Nova laser control system which will begin operation in 1984. The computers and data acquisition devices that form the distributed control system for a large laser fusion research facility need reliable, high speed communications. Both control/status messages and experimental data must be handled. A subset of NOVANET is currently operating on the two beam Novette laser system.


#*Error-Correcting Codes and Self-Checking Circuits
#@D. K. Pradhan
#t1980
#cComputer
#index340823
#!Error-control coding techniques, implemented by means of self-checking circuits, will improve system reliability.


#*The triggering and control of inference processes (ficsr)
#@James Steven Botic
#t1983
#c
#index187264


#*Multi-stage switching networks as local network packet switches
#@Edward Stanley Szurkowski
#t1982
#c
#index185607


#*A fast sequential method for polygonal approximation of digitized curves
#@Karin Wall,Per-Erik Danielsson
#t1984
#cComputer Vision, Graphics, and Image Processing
#index161058


#*What's up in Europe?: the CEDAR project
#@Nick Rushby
#t1980
#cACM SIGCUE Outlook
#index308270


#*New Products
#@D. A. Michalopoulos
#t1981
#cComputer
#index336062
#!Designed for users of IBM Series/I Comers, the Program Executive System (PXS) available from Alan Hochschild, Inc., is a supplement to the EDX operating system that provides extensive user facilities for program development and distributed processing operations, integrating these facilities into one product with its own high-level language.


#*A study to determine the uses of computers by college and university media services
#@Wilbert L. Sadler, Jr.
#t1981
#c
#index194153


#*Computability and complexity issues of translator generation
#@Doyt Lee Perry
#t1982
#c
#index201848


#*Fundamentals of operating systems (3rd ed.)
#@A M. Lister
#t1984
#c
#index176261


#*Data Communications Dictionary
#@Charles J. Sippl
#t1980
#c
#index447142


#*10,000 Microcomputers for French Secondary Schools
#@J. Hebenstreit
#t1980
#cComputer
#index351020
#!Few projects compare in scope to France's first CAI experiment. An even more ambitious plan, now in its initial stages, will be implemented by 1985.


#*The importance of being square
#@Clyde P. Kruskal,Marc Snir
#t1984
#cACM SIGARCH Computer Architecture News
#index552769
#%195236
#%546355
#%553235
#!We present a theory that defines performance of packet-switching interconnection networks (delay and capacity) and their cost in terms of their geometry. This is used to prove that square banyan networks have optimal performance/cost ratio. These results, together with some known results on the complexity of routing in multistage networks, show that multistage shuffle-exchange networks are the unique networks with both optimal performance and simple routing. Finally, square delta networks are shown to have optimal area complexity.


#*Subject Index
#@
#t1983
#cIEEE Micro
#index386213


#*Control structures in expert systems
#@Jean-Pierre Laurent
#t1984
#cTechnology and Science of Informatics
#index144934


#*Optimal tree layout (Preliminary Version)
#@Michael J. Fischer,Michael S. Paterson
#t1980
#cProceedings of the twelfth annual ACM symposium on Theory of computing
#index546488
#!We consider the problem of finding a minimal cost layout of a tree in Euclidian d-space. A tree is an acyclic undirected edge-weighted graph, and a layout is an assignment of a point in d-dimensional Euclidian space to each of the nodes of the tree. The &ldquo;length&rdquo; of an edge in the layout is the &ldquo;distance&rdquo; between its endpoints as measured by some norm. The cost of an edge is its length times its weight, and the cost of the whole layout is the sum of the costs of all the edges. We assume the positions of certain nodes are fixed in advance, and we wish to place the remaining nodes so as to minimize the cost of the layout.


#*Geometric Optimization and Computational Complexity
#@Chanderjit Bajaj
#t1984
#c
#index113594
#!Our purpose here is to study problems involving geometric optimization, namely, questions of the type: Is there at least a minimum or at most a maximum number of certain geometric figures, that are within certain distances of other figures (objects). We are also concerned with the optimization of the size of these geometric figures. These problems arise as geometric reductions from various classes of location-allocation optimization problems and are inherently not pure combinatorial. Our primary aim, then, is to discover techniques of dealing with such geometric optimization problems, while adapting to these problems the older combinatorial design and analysis methods. The task of classifying problems accurately in the polynomial hierarchy is one of increasing importance. To solve an optimization problem deterministically it seems that one must solve both an $NP$ and a $Co-NP$ problem. The significance of the classes $NP$ and $Co-NP$ are that none of the problems they include is known to have a polynomial time solution. We show that if $NP \neq Co-NP$ then there are interesting natural geometric optimization problems (location-allocation problems under minsum) in $\Delta^{P}_{2}$ that are in neither $NP$ nor $Co-NP$. Hence, all these problems are shown to belong properly to $\Delta^{P}_{2}$, the second level of the polynomial hierarchy. We also show that if $NP \neq Co-NP$ then there are again some interesting geometric optimization problems (location-allocation problems under minmaz) properly in $\Delta^{P}_{2}$ and furthermore they are complete for a class $D^{P}$ (which is contained in $\Delta^{P}_{2}$ and contains $NP \bigcup Co-NP$). Also considered are the above geometric location-allocation optimization problems for the case when the allocation is predetermined. Both efficient algorithms and worst-case lower bounds are derived. Necessary conditions for the existence of mazima and minima in optimization problems are generally tied to the question of solvability of an equation or a system of equations. In calculus these equations are algebraic. By generating the minimal polynomial whose root over the field of rational numbers is the solution of the geometric optimization problem on the real (Euclidean) plane, we are able to prove the non-solvability of certain geometric optimization problems by radicals. The algebraic degree of the optimizing solution, which is the degree of the irreducible minimal polynomial for the problem, correlates with the inherent difficulty of constructing the solution and provides an algebraic complexity measure for these geometric optimization problems.


#*Computing and the Handicapped: A Promising Alliance
#@M. J. Giannini
#t1981
#cComputer
#index342005
#!The advantages of computer technology are now reaching the handicapped. The author here surveys some NIHR-sponsored research. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Recent verification work at MITRE
#@J. K. Millen
#t1981
#cACM SIGSOFT Software Engineering Notes
#index434429


#*Experiments with the SLIM Circuit Compactor
#@Ralph C. McGarity,Daniel P. Siewiorek
#t1983
#cProceedings of the 20th Design Automation Conference
#index545866
#%544809
#%546641
#%547720
#%551522
#%553579
#!Experiments performed with the SLIM symbolic circuit compactor are described. The experiments were designed to compare SLIM created modules to manually created modules, to attempt to find performance predictors for SLIM, and to determine how well SLIM would compact modules created by a &ldquo;synthesis-by-refinement&rdquo; program. The results indicate that SLIM compacts modules which will be created by this program as area efficiently as it compacts modules created by other methods. Also, a performance predictor which estimates the area required by SLIM generated modules was developed. Finally, it was found that SLIM's designs are larger than manual designs by 60% to 90%.


#*An Advanced Communication Protocol for the Proposed IEEE 896 Futurebus
#@Paul Borrill,John Theus
#t1984
#cIEEE Micro
#index338609
#!With its asynchronous protocol, the proposed IEEE 896 Futurebus achieves an extended design life, unequaled performance, and unprecedented flexibility. Its design eliminates many of the problems traditionally associated with multimicroprocessor system buses.


#*ICAD/PCB: Integrated computer aided design system for printed circuit boards
#@Hiroshi Shiraishi,Mitsuo Ishii,Shoichi Kurita,Masaaki Nagamine
#t1982
#cProceedings of the 19th Design Automation Conference
#index544468
#%550521
#%549301
#%549052
#%551716
#%544950
#%550256
#%549123
#%553101
#%554903
#!The advanced computer aided design system, ICAD/PCB, was recently put into operation at Fujitsu. The system provides designers with powerful tools to significantly lower the cost and the time required to design and manufacture printed circuit boards (PCBs). Interactive and automatic facilities to support the entire PCB design process are integrated in the ICAD/PCB system.


#*Algorithm 555: Chow-Yorke Algorithm for Fixed Points or Zeros of C2 Maps [C5]
#@Layne T. Watson,Dan Fenner
#t1980
#cACM Transactions on Mathematical Software (TOMS)
#index321601
#%283978
#%326665


#*Parallel computation on large arrays
#@Piyush Mehrotra
#t1982
#c
#index197158


#*Information systems and organizational change
#@Peter G. W. Keen
#t1981
#cCommunications of the ACM
#index326404
#%330572


#*Computer-Integrated Manufacturing of Surfaces Using Octree Encoding
#@K. Yamaguchi,T. Kunii,David Rogers,Steven Satterfield,Francisco Rodriguez
#t1984
#cIEEE Computer Graphics and Applications
#index351048
#!This preliminary report presents an algorithm for automatically generating from an octree description the data that a computerized numerical control milling machine requires to manufacture a part.


#*The problem of producing teachers with computing expertise within the school system
#@Annie G. Brooking
#t1983
#cProceedings of the fourteenth SIGCSE technical symposium on Computer science education
#index544790
#!(This paper has been accepted for publication in the Proceedings, but the photo-ready form was not delivered in time. Copies of the paper should be available upon request at the presentation.)


#*Performance evaluation of reorganized and updated index files based on moments
#@Yuan Liu
#t1983
#c
#index189749


#*A computer package for ranking, selection, and multiple comparisons with the best
#@Shanti S. Gupta,Jason C. Hsu
#t1984
#cProceedings of the 16th conference on Winter simulation
#index555294
#!RS-HCB is the simultaneous computer implementation of Ranking and Selection (RS) and Multiple Comparisons with the Best (MCB) procedures. This is made possible by recent developments in statistics which showed that Ranking and Selection (both Subset Selection Indifference Zone) can be executed simultaneously with Multiple Comparisons with the Best without increasing the error rate of any component inference, for equal as well as unequal sample sizes. These developments are described, and the use of RS-MCB is illustrated with sample computer sessions.


#*Manipulating simulated objects with real-world gestures using a force and position sensitive screen
#@Margaret R. Minsky
#t1984
#cACM SIGGRAPH Computer Graphics
#index545274
#%547509
#%554618
#!A flexible interface to computing environments can be provided by gestural input. We describe a prototype system that recognizes some types of single-finger gestures and uses these gestures to manipulate displayed objects. An experimental gesture input device yields information about single finger gestures in terms of position, pressure, and shear forces on a screen. The gestures are classified by a &ldquo;gesture parser&rdquo; and used to control actions in a fingerpainting program, an interactive computing system designed for young children, and an interactive digital logic simulation.


#*Title, Conference Committee, Table of Contents
#@
#t1983
#cDatabases for Business and Office Applications, Database Week
#index267069


#*Commercial network security&mdash;does anyone care?
#@Edmund L. Burke
#t1983
#cProceedings of the eighth symposium on Data communications
#index553960
#!Since World War II, the US government has had a comprehensive way to deal with communication security. Under pressure from commercial interests, the government moved in the 70's to make some communication security technology available in the form of the Data Encryption Standard. DES has been available for some time, yet there is little interest in the marketplace. The lack of interest could stem from unawareness or unconcern with security or from the feeling that data security is not the weak point in the system. This session will investigate the techniques and vulnerabilities of commercial network security. Panel members will present their experiences with developmental and product activities aimed at providing security in a business environment. The panel will try to stimulate discussion on why there has been no market and what technical characteristics that market should have.


#*Requirements for improving the use of computers to support the development of policy decisions (abstract only)
#@John Henize
#t1981
#cProceedings of the joint conference on Easier and more productive use of computer systems. (Part - I): Information processing in the social sciences and humanities - Volume 1981
#index552598
#!Computer based information systems have been developed and used successfully for production and engineering and for lower level management tasks but they have yet to be widely applied to aiding management decision making at the higher policy making levels. Despite many attempts, the failures have been many and the successes few. This has resulted in large part from the fact that the technicians who have been engaged to design such systems have not correctly understood the nature of the problem environment with which they are dealing. Because they themselves have had no experience at the policy making levels, they have had a poor conception of the problems to be solved, and thus have made mistakes which they would not have made, had they been designing an information system for lower level tasks. In designing an inventory or process control system, for instance, the technicians have carefully studied the nature of the problems to be dealt with, and have decided which information is important and which not. They have not, in these cases, delivered reams of superfluous information to every point in the system. But when designing an information system to aid higher level decision making, they have tended to do the exact opposite. They have attempted to put every conceivable piece of information that could possibly be of the most remote interest at the fingertips of each and every policy maker -- each of whom is already suffering from a severe information overload. The decision maker could never possibly begin to digest all of this information, even if he found it useful, which, in general, he does not. This paper proposes methods for dealing with this crucial inhibiting problem.


#*Tree transformation techniques and experiences
#@S. E. Keller,J. A. Perkins,T. F. Payton,S. P. Mardinly
#t1984
#cProceedings of the 1984 SIGPLAN symposium on Compiler construction
#index611629
#%190050
#%305543
#%324137
#%547296
#%554763
#!A formal description technique for describing transformations from one well-defined language to another is introduced. A TT-grammar contains context-free grammars for describing the syntax of both languages. The transformation between the languages is described by a relationship of productions from the grammars. The TT-grammar is supported by an automated tool. SSAGS -- a translator writing system based on attribute grammars -- has been extended to support certain classes of TT-grammars. SSAGS analyzes TT-grammars and automatically generates Ada source programs implementing the transformation specified by the TT-grammar. Experience with two different restricted forms of TT-grammars is described with respect to their practical application. The experience demonstrates the readability, ease of development, and additional verification available through the use of TT-grammars.


#*Education II - college & university - ED II
#@
#t1980
#cProceedings of the 18th annual Southeast regional conference
#index610920


#*Creating volume models from edge-vertex graphs
#@Patrick M. Hanrahan
#t1982
#cACM SIGGRAPH Computer Graphics
#index545313
#%547104
#!The design of complex geometric models has been and will continue to be one of the limiting factors in computer graphics. A careful enumeration of the properties of topologically correct models, so that they may be automatically enforced, can greatly speed this process. An example of the problems inherent in these methods is the &ldquo;wire frame&rdquo; problem, the automatic generation of a volume model from an edge-vertex graph. The solution to this problem has many useful applications in geometric modelling and scene recognition. This paper shows that the &ldquo;wire frame&rdquo; problem is equivalent to finding the embedding of a graph on a closed orientable surface. Such an embedding satisfies all the topological properties of physical volumes. Unfortunately graphical embeddings are not necessarily unique. But when we restrict the embedding surface so that it is equivalent to a sphere, and require that the input graph be three-connected, the resulting object is unique. Given these restrictions there exists a linear time algorithm to automatically convert the &ldquo;wire frame&rdquo; to the winged edge representation, a very powerful data structure. Applications of this algorithm are discussed and several examples shown.


#*A reconfigurable VLSI architecture for a database processor
#@Kemal Oflazer
#t1983
#cProceedings of the May 16-19, 1983, national computer conference
#index63057
#%64186
#%550314
#%348598
#%326368
#%350058
#%195687
#%185862
#!This work brings together the processing potential offered by regularly structured VLSI processing units and the architecture of a database processor---the Relational Associative Processor (RAP). The main motivations are to integrate a RAP cell processor on a few VLSI chips and improve performance by employing procedures exploiting these VLSI chips and the system level reconfigurability of processing resources. The resulting VLSI database processor consists of parallel processing cells that can be reconfigured into a large processor to execute the hard operations of projection and semijoin efficiently. It is shown that such a configuration can provide 2 to 3 orders of magnitude of performance improvement over previous implementations of the RAP system in the execution of such operations.


#*Protocols for Data Security
#@R. DeMillo
#t1983
#cComputer
#index340316


#*Computational Comparison of Eight Methods for the Maximum Network Flow Problem
#@To-Yat Cheung
#t1980
#cACM Transactions on Mathematical Software (TOMS)
#index322737
#%335569
#%328482


#*Alternatives for on-line help systems
#@T. P. Kehler,M. Barnes
#t1980
#cProceedings of the 8th annual ACM SIGUCCS conference on User services
#index552266
#%322167
#!This paper reviews some existing possibilities for help systems and proposes a series of steps for improving the interactive interface to users. We consider a hypothetical environment of a predominantly time- sharing facility providing services to multiple campuses over a large geographical area with s small staff for training and user services.


#*Programming environments for pre-college instruction (Special Session)
#@William E. Baird,Charles E. Rughes,J. Michael Moshell
#t1983
#cACM SIGCSE Bulletin
#index546622
#!This session features two presentations and demonstrations of computer software/hardware systems for teaching problem solving techniques and programming concepts. Several computers will be available for hands-on demonstration at the conclusion of the session.


#*The 801 minicomputer
#@George Radin
#t1982
#cProceedings of the first international symposium on Architectural support for programming languages and operating systems
#index548014
#%551837
#!This paper provides an overview of an experimental system developed at the IBM T. J. Watson Research Center. It consists of a running hardware prototype, a control program and an optimizing compiler. The basic concepts underlying the system are discussed as are the performance characteristics of the prototype. In particular, three principles are examined: system orientation towards the pervasive use of high level language programming and a sophisticated compiler, a primitive instruction set which can be completely hard-wired, storage hierarchy and I/O organization to enable the CPU to execute an instruction at almost every cycle.


#*Practical take-grant systems: do they exist?
#@Matthew Allen Bishop
#t1984
#c
#index188205


#*Computer Graphics in Japan Part 2
#@
#t1984
#cIEEE Computer Graphics and Applications
#index336734


#*Subjektorientierte Zugriffsautorisierung
#@W. Ballin
#t1980
#cGI - 10. Jahrestagung
#index275921


#*Determining the last process to fail
#@Dale Skeen
#t1983
#cProceedings of the 2nd ACM SIGACT-SIGMOD symposium on Principles of database systems
#index236629
#%247066
#%319217


#*Structured Programming Can Be Applied to Microprocessors-Even by Novices
#@Allan Mosak
#t1982
#cIEEE Micro
#index408878


#*A Software Testbed for the Development of 3D Raster Graphics Systems
#@T. Whitted,D. M. Weimer
#t1982
#cACM Transactions on Graphics (TOG)
#index328922
#%153803
#%188642
#%193872
#%205516
#%234204
#%313829
#%326818
#%547048
#%614218
#%329425
#%545884
#%554973
#%550028
#%544734
#%547386
#%553148


#*Admissible State Semantics for Representational Systems
#@J. Doyle
#t1983
#cComputer
#index353809


#*The application of optical character recognition techniques to bandwidth compression of facsimile data
#@Patrice J. Capitant,Robert H. Wallis
#t1980
#cProceedings of the May 19-22, 1980, national computer conference
#index69021
#!The goal of facsimile bandwidth compression is the efficient transmission of documents achieved by the removal of redundancy in the encoding technique. For the case of printed or typewritten documents, the most powerful encoding technique is the Combined Symbol Matching (CSM) algorithm, which is based on the detection of recurrent patterns (such as alphanumeric characters) in the document being encoded &lang;4, 5, 6, 10&rang;. As the transmitter scans the document, it locates and extracts isolated patterns, transmits them to the receiver, and stores them in a library. Using the received patterns, the receiver also accumulates an exact copy of the transmitter's library. As each new pattern is isolated, it is compared with the library patterns which have been previously encountered. If the pattern is unfamiliar, it is added to the library. However if a "match" is detected, this indicates a recurrence of a pattern, and there is no need to retransmit it, since it is available in the receiver's copy of the library. Therefore, the library entry number (library ID) is transmitted instead, enabling the receiver to reconstruct the pattern from the "prototype" in its library. Since the library ID can be transmitted with far fewer bits than the binary pattern that it points to, a significant bandwidth compression may be attained. For printed documents, the CSM algorithm is typically twice as efficient as the best run-length coding algorithms.


#*Use of artificial intelligence and simple mathematics to analyze a physiological model
#@John C. Kunz
#t1984
#c
#index202673


#*Mastering Master Mind logically
#@Peter Koppstein
#t1984
#cIssue 88 (April 1984)
#index101390
#%163740
#%109103
#!Some readers of the recent note by Ehud Shapiro on "Playing Master Mind Logically" (SIGART 85, July 1983) may reasonably have concluded that Prolog was a suitable language for a "generate and test" strategy, as the author stated, but that perhaps there was something intrinsic to Prolog that made anything much more subtle unwieldy. The present note at any rate shows how a more "logical" strategy incorporating that previously described may readily be implemented without compromising the elegance and simplicity of Ehud Shapiro's original problem. A related approach, using templates as generators, is also described.


#*Microprogram documentation with design in mind
#@C. R. Stevens
#t1983
#cACM SIGMICRO Newsletter
#index9785
#!This paper discusses the dilemmas of microcode documentation. It discusses the traditional relationship between "designing" microcode and "documenting" microcode. It establishes a different relationship between designing and documenting, one where the primary emphasis is shifted to documentation. The activities of documenting become the "process" by which a quality design can be achieved. A strategic documentation framework combined with a high-level design language to form and test the proper solution is suggested as a means of achieving quality designs. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Concepts of the document interchange protocol for the telematic services - CCITT draft recommendation s.a
#@W Horak
#t1984
#cComputer Networks and ISDN Systems
#index159436


#*NCC '81 Professional Development Seminars
#@
#t1981
#cComputer
#index348458


#*Design principles for software manufacturing tools
#@Paul Bassett
#t1984
#cProceedings of the 1984 annual conference of the ACM on The fifth generation challenge
#index555342
#%313666
#%313746
#%320245
#%327864
#%552107
#!A good solution to the reusable code problem turns out to provide a solid technical basis from which to understand and deal with the production, quality, and maintenance issues currently besieging the software industry. To this end, a software manufacturing methodology has been developed called Computer Aided Programming tm. CAP is based on a functional programming concept called a frame, motivated in turn by the reusable code problem. The introduction explains the necessary background ideas about frames. Section two analyzes the subtle but important distinction between problem solving and programming. CAP design principles are then developed which show how to build software tools that support problem solving through open&mdash;ended, structured, program manufacturing techniques. The principles are organized around the flow of program specifications from 'under' to 'optimally', to 'over' specified, machine executable instructions. The components of an existing CAP system are described in section three, and section four discusses the usage of CAP as a manufacturing technique. Statistics from a case study are presented which indicate that: (a) production quality commercial software can be manufactured at rates exceeding 2000 lines of debugged COBOL per man-day (including systems design time), and (b) less than 10% of this code needs to be hand written /-maintained.


#*Response time distributions for a multi-class queue with feedback
#@Simon S. Lam,A. Udaya Shankar
#t1980
#cProceedings of the 1980 international symposium on Computer performance modelling, measurement and evaluation
#index554231
#!A single server queue with feedback and multiple customer classes is analyzed. Arrival processes are independent Poisson processes. Each round of service is exponentially distributed. After receiving a round of service, a customer may depart or rejoin the end of the queue for more service. The number of rounds of service required by a customer is a random variable with a general distribution. Our main contribution is characterization of response time distributions for the customer classes. Our results generalize in some respects previous analyses of processor-sharing models. They also represent initial efforts to understand response time behavior along paths with loops in local balanced queueing networks.


#*Self-adjusting binary trees
#@Daniel Dominic Sleator,Robert Endre Tarjan
#t1983
#cProceedings of the fifteenth annual ACM symposium on Theory of computing
#index551923
#%79620
#%157847
#%163009
#%250122
#%321138
#%457887
#!We use the idea of self-adjusting trees to create new, simple data structures for priority queues (which we call heaps) and search trees. Unlike other efficient implementations of these data structures, self-adjusting trees have no balance condition. Instead, whenever the tree is accessed, certain adjustments take place. (In the case of heaps, the adjustment is a sequence of exchanges of children, in the case of search trees the adjustment is a sequence of rotations.) Self-adjusting trees are efficient in an amortized sense: any particular operation may be slow but any sequence of operations must be fast. Self-adjusting trees have two advantages over the corresponding balanced trees in both applications. First, they are simpler to implement because there are fewer cases in the algorithms. Second, they are more storage-efficient because no balance information needs to be stored. Furthermore, a self-adjusting search tree has the remarkable property that its running time (for any sufficiently long sequence of search operations) is within a constant factor of the running time for the same set of searches on any fixed binary tree. It follows that a self-adjusting tree is (up to a constant factor) as fast as the optimal fixed tree for a particular probability distribution of search requests, even though the distribution is unknown.


#*A computer architecture with hardware operating system features for communications processing
#@Gene Charles Barton
#t1981
#c
#index194026


#*Protection
#@Donald W. Davies
#t1981
#cDistributed Systems - Architecture and Implementation, An Advanced Course
#index267476


#*A conceptual design for simulation in a real time control tool
#@Carolyn D. Tobin,Neal N. NcCollom
#t1984
#cProceedings of the 16th conference on Winter simulation
#index545072
#%182067
#!This paper discusses the use of simulation as an evaluation technique within an automated or semiautomated real time control system. Within this control system, simulation will be used to play out possible scenarios emphasizing various objectives of system control. The simulater will be, as much as possible, a deterministic model utilizing factory data bases to more accurately forecast results. The structure of the simulation model, including typical inputs from appropriate data bases, will be detailed. As a result of including a simulation model in the control system, an evaluator would examine the simulation outputs. This evaluator can be automated, human or a combination of the two. Through the control system, this evaluation would then be employed to direct the physical system. An ideal application of this approach is in the manufacturing environment. The advent of automated and computerized equipment makes the implementation of an automated control and evaluation system a feasible and practical enhancement to a manufacturing system. This paper will discuss the authors' thoughts on how such a control system could be implemented and what form it would take. Special emphasis will be given to the structure of the control system. The structure of the system will include description of the actions and interactions of appropriate factory data bases, the simulation model, evaluation criteria and the physical scheduling or control of the system. The overall control structure will be detailed as an integrated system. Different roles or utilizations of human interfaces will also be investigated. The final discussion will include an analysis of an implementation environment and a suggested implementation strategy.


#*Quotient Networks
#@J. P. Fishburn
#t1982
#cIEEE Transactions on Computers
#index336476
#!A large-network algorithm solves a problem of size N on a network of N processors. We present a method for transforming certain large networks into quotient networks that emulate those large networks with fewer processors. Large-network algorithms are easily modified to execute on the quotient network. The emulations result in no loss in execution efficiency. Quotient networks allow algorithms to be designed assuming any number of processors and executed efficiently at a great savings in hardware cost.


#*Future Ada environments
#@Sabina H. Saib
#t1983
#cProceedings of the May 16-19, 1983, national computer conference
#index65862
#%350688
#%546305
#!The current Ada environments are oriented toward traditional code production tools such as editors, compilers, loaders, and program library managers. Future Ada environments will add to the initial capabilities to provide support from the initiation of requirements to the enhancement of existing operational software. In addition to software development facilities, future Ada environments will support management activities. The future will also see applications of current tools and techniques across the entire life cycle.


#*ACM doctoral dissertation award: ACM international scholastic programming contest awards
#@Gwen Bell
#t1984
#cACM SIGCSE Bulletin
#index550235
#!Dr. Bell is director of The Computer Museum in Marlboro, Mass., a memeber of the Charles Babbage Institute Program Committee and an editorial board member for the Annals of the History of Computing. As director of The Computer Museum since 1980, she has interpreted computer history via exhibitions, programs and public speeches.


#*Parallel algorithms for the convex hull problem in two dimensions
#@Dhruva Nath,S. N. Maheshwari,P. C. P. Bhatt
#t1981
#cProceedings of the Conference on Analysing Problem Classes and Programming for Parallel Computing
#index270681


#*Searching with probabilities
#@Andrew James Palay
#t1983
#c
#index185909


#*Consistency Management in Distributed Data Bases: a Selective Analysis
#@Mohan L. Ahuja
#t1983
#c
#index199146


#*Implementation of Differential Geometric Objects and Functions with an Application to Extended Maxwell Equations
#@Peter K. H. Gragert,P. H. M. Kersten
#t1982
#cProceedings of the European Computer Algebra Conference on Computer Algebra
#index566875


#*General topics in computer science II - GCS II
#@
#t1980
#cProceedings of the 18th annual Southeast regional conference
#index618119


#*1984 looming closer: Secret Service computers pose dangers
#@Don Edwards
#t1983
#cACM SIGCAS Computers and Society
#index311329


#*Special issue on reliability and maintainability
#@Thomas L. Magnanti
#t1984
#cOperations Research
#index180442


#*CAD/CAM Systems: justification, implementation, productivity measurement
#@Edward J. Preston,George W. Crawford,Mark E. Coticchia
#t1984
#c
#index180808


#*Performance Analysis of Shamir's Attack on the Basic Merkle-Hellman Knapsack Cryptosystem
#@J. C. Lagarias
#t1984
#cProceedings of the 11th Colloquium on Automata, Languages and Programming
#index363329


#*VT: a virtual terminal window package for UNIX
#@Robert Gammill,Prithvi Ram
#t1984
#cACM SIGSMALL Newsletter
#index24647
#%178360
#%153803
#!A window package called VT has been developed for UNIX version 6 and the Heath H19 terminal. The package is written in C and is implemented entirely at the user level. Only a nonstandard system call named port is required. VT enables the user to act as if he is commanding several terminals while using a single CRT terminal. The user can make rectangular windows, each with a shell (UNIX command interpreter), and concurrently run commands in each window. All input and output for each shell is confined to its own window, so each window serves as a virtual terminal. Implementation under Version 7 and later releases of UNIX is planned.


#*A general user interface for creating and displaying tree-structures, hierarchies, decision trees, and nested menus
#@Judith S. Reitman-Olson,William B. Whitten, II,Thomas M. Gruenenfelder
#t1984
#cProc. of the NYU symposium on user interfaces on Human factors and interactive computer systems
#index146862


#*ACM Algorithms Policy
#@Fred T. Krogh
#t1982
#cACM Transactions on Programming Languages and Systems (TOPLAS)
#index324387
#%320741


#*Are we becoming addicted to computers?
#@Arthur Fink
#t1983
#cProceedings of the 1983 annual conference on Computers : Extending the human resource
#index553543
#!What do we mean by &ldquo;addicted&rdquo;? The Oxford English Dictionary defines it as: &ldquo;(1) Delivered over devoted, destined, bound. (2) Attached by one's own act; given up, devoted, ... naturally attached bondage, which displaces free will.&rdquo; It is a condition in which really objective self-examination does not and probably cannot guide our behavior. It is generally regarded as a pitiful state, over which one has little control.


#*State of the art issues in distributed databases (Panel session): Site autonomy issues in the R@@@@ distributed database system
#@P. Selinger
#t1981
#cProceedings of the ACM '81 conference
#index545054
#!It is desirable to have a Distributed Database Management System (DDBMS) whose behavior and control is as identical as possible to that used in single site database management systems. We call this notion site autonomy. Preserving the autonomy of sites which join a DDBMS network is essential to the peace of mind of its managers and users, and more technically, is essential in an environment where sites and communication lines fail. To achieve resilience to failures of sites and communication lines (these are indistinguishable from one site's viewpoint), there can be no reliance on centralized functions or services. This means no global dictionary, no global information collector for deadlock detection, and no broadcast of local events such as file creation or addition of a new site. Aside from these prohibitions, this goal of site autonomy also implies that sites should perform their own compilation, their own binding of print names to internal names, their own decomposition of compound objects (such as relational views), and their own authorization checking. This talk discusses the concept of site autonomy in further detail and discusses several specific issues on which the site autonomy philosophy has an impact.


#*A dual approach to nonconvex nonlinear programming problems
#@Reynold Jen-Ren Chen
#t1981
#c
#index189641


#*General Correctness: A Unification of Partial and Total Correctness
#@Dean Jacobs,David Gries
#t1984
#c
#index112572
#!General correctness, which subsumes partial and total correctness, is defined for both weakest preconditions and strongest postconditions. Healthiness properties for general-correctness predicate transformers are more uniform and complete than those for partial-and-total-correctness systems. In fact, the healthiness properties for partial and total correctness are simple restrictions of those for general correctness. General correctness allows simple formulations of the connections between weakest and strongest postconditions and between the notions of weakest precondition under the ``demonic'''' and ``angelic'''' interpretations of nondeterminism. A problem that plagues $sp sp(P, C)$ is undefined if execution of $C$ begun in some state of $P$ may not terminate disappears with the generalization. This paper is a study of some simple theory underlying predicate transformer semantics, and as yet has little bearing on current programming practices. The theory uses a relational model of programs.


#*Proceedings of the ACM-SIGPLAN symposium on The ADA programming language
#@
#t1980
#cAnnual International Conference on Ada
#index553172


#*Independence Results about Context-Free Languages and Lower Bounds
#@Juris Hartmanis
#t1984
#c
#index125097
#!We show that for any axiomatizable, sound formal system F there exist instances of natural problems about context-free languages, lower bounds of computations and P versus NP that are not provable in F for any recursive representqation of these problems. Most previous independence results in computer science have been proven for specific representations of the problems, by exploiting the ``opaqueness'''' of Turing machine names. Our results rely on the complexity of the logical structure of the problem and yield independence results which do not depend on the representations of problems. We show, for example, that there exists a non-regular context-free language $L_{o}$ such that for no cf-grammar $G, L(G) = L_{o}$, it is provable in F that ``L(G) is not regular''''. We also show, among other results P and NP, that there exists a recursive oracle A such that $NP^{A} \neq P^{A}$, and that this fact is not provable in F for any recursive representation of A. The difference of what is and is not provable in F is well illustrated by questions about polynomial time isomorphisms (p-isomorphisms) of NP complete sets. We show that for every NP complete set, L, there is a representation of L by a non-deterministic polynomial time machine for which we can prove that L is NP complete. Furthermore if L is p-isomorphic to SAT then this is also provable in F for some representation of L. On the other hand, if there exist NP complete sets not p-isomorphic to SAT then there exists an NP complete set L for which, independent of its representation, there is no proof in F that L is or is not p-isomorphic to SAT.


#*Computing at Carnegie-Mellon University
#@Keith Slack,Jim Morris,Douglas Van Houweling,Nina Wishbow
#t1984
#cProceedings of the ACM 12th annual computer science conference on SIGCSE symposium
#index555109
#!Carnegie-Mellon University (CMU) and International Business Machines (IBM) have recently decided to collaborate on an innovative project: to implement a distributed computing system at CMU. A distributed computing system integrates personal computers, midsized machines known as file servers, and mainframes through a network. This system will provide CMU's students, faculty and staff with state-of-the-art equipment and software, and will be designed to facilitate communication on campus. The authors describe the reasons that motivated the CMU-IBM project, the technology of this distributed system, and the impact they expect this system to have.


#*SETL-a very high level language oriented to software systems prototyping
#@Jack Schwartz
#t1981
#cACM SIGAPL APL Quote Quad
#index552195
#!SETL, like APL, is a language which facilitates manipulation of large relatively abstract data objects, namely sets, vectors, and maps, whose elements may in turn be sets, vectors, or maps. This language has been used to develop executable prototypes of several large software packages, including a full compiler for the new DoD Ada language. This talk will describe the man semantic features of SETL, and assess its use as a software prototying tool.


#*Improved compaction by minimized length of wires
#@W. L. Schiele
#t1983
#cProceedings of the 20th Design Automation Conference
#index545204
#%544809
#%547373
#%546640
#!The compaction of IC or hybrid layouts by means of the &ldquo;longest path&rdquo; method yields a slack in the placement of part of the elements, which, in its turn, can be used to reduce the overall wire-length. The result is an improved electrical performance and a smaller layout. The optimization problem was transformed to a graphtheoretical problem in a way similar to the compaction problem itself. Our procedure starts by adding pieces of information out of the connectivity of the layout to the constraint graph. The succeeding heuristic algorithms generate a new tree of longest paths, taking the linear inequalities and the result of the longest path calculation into consideration. A few examples demonstrate the significant reduction of wire-length and sometimes even an additional reduction of layout area achieved with low computational effort.


#*on And/Or Schemes
#@David Harel
#t1980
#cProceedings of the 9th Symposium on Mathematical Foundations of Computer Science
#index370151


#*The microcomputer as a tool in numerical analysis
#@Kris Stewart
#t1980
#cACM SIGNUM Newsletter
#index104049
#!The affordability of microcomputers makes them a practical tool for scientific computations and development of algorithms as well as a dramatic teaching aid. A package of mathematical software called SCRUNCH (1) is available to run in BASIC on moderate sized microcomputers (at least 8K and preferably 16K program space) to aid in the above tasks. SCRUNCH consists of translations of FORTRAN routines taken from three excellent sources:


#*Coping with complexity
#@J. F. Traub
#t1984
#cProc. of a symposium on Computer culture: the scientific, intellectual, and social impact of the computer
#index155276


#*An Interactive Data Dictionary System to Support Logical Database Design
#@P. Gupta,Umeshwar Dayal,Alfred G. Dale
#t1980
#c
#index193428


#*Computing surfaces of constant mean curvature with singularities
#@D E Hewgill
#t1984
#cComputing
#index154057


#*Designs arising from symplectic geometry
#@Lucien Bénéteau,Jacqueline Lacaze
#t1984
#cProceedings of the 2nd International Conference on Applied Algebra, Algorithms and Error-Correcting Codes
#index379952


#*On the simplification and equivalence problems for simple programs
#@Brian Scott Leininger
#t1981
#c
#index195714


#*Mikrorechner im Unterricht am Beispiel der Physik
#@Kurt Wagner
#t1982
#cGI - 12. Jahrestagung
#index274143


#*Building Usable Menu-Based Natural Language Interfaces To Databases
#@Craig W. Thompson,Kenneth M. Ross,Harry R. Tennant,Richard M. Saenz
#t1983
#cProceedings of the 9th International Conference on Very Large Data Bases
#index378771
#%190480


#*Static and dynamic topological re-configurability in multi-microcomputer systems
#@Y. Hoffner
#t1983
#cProceedings of the 1983 ACM SIGSMALL symposium on Personal and small computers
#index555039
#%321115
#%477074
#!This paper proposes a method of constructing multi-microcomputer systems which allows both static and dynamic topological re-configurability. The method uses a time-multiplexed shared bus which avoids bus contention altogether. Two systems are presented. In the dynamic, any number of micro-computers can be connected to the bus; the shared memory can be configured by software at run-time to allow the communication between any CEs, enabling interconnection topologies to develop dynamically. In the static, only two micro-computers are allowed to share a common memory, thus limiting topology modifications to physical changes of the connections between microcomputers.


#*An efficient channel router
#@Takeshi Yoshimura
#t1984
#cProceedings of the 21st Design Automation Conference
#index547282
#%549495
#%550925
#%551009
#%550013
#!In the LSI chip layout design, channel routing is one of the key problems. The problem is to route a specified net list between two rows of terminals across a two layer channel. This paper presents a new routing algorithm, which is an improved version of the classical &ldquo;left edge algorithm&rdquo;. The new algorithm uses a row by row approach, calculating an optimum net assignment to each row. The algorithm was implemented for examples in previously published papers. Experimental results show that the new algorithm produces optimum solutions in most cases.


#*Computer aided design (CAD) using logic programming
#@Paul W. Horstmann,Edward P. Stabler
#t1984
#cProceedings of the 21st Design Automation Conference
#index553282
#%544869
#!This paper gives an overview of expert systems and logic programming as applied to Computer-Aided Design (CAD) systems. Our objective is to show the relevance of these two approaches developed from research in artificial intelligence for the solution of problems in VLSI design. We will provide some examples of the use of logic programming for familiar CAD tasks. The expert systems discussed function as experts in a very narrowly defined area of expertise, and can be called designer's assistants. We will also compare the use of logic programming (PROLOG) to current algorithmic solutions to VLSI design problems and discuss some future research in this area.


#*An Algorithm for Filling Regions on Graphics Display Devices
#@J. M. Lane,R. and M. Rarick
#t1983
#cACM Transactions on Graphics (TOG)
#index333061
#%194960
#%331365
#%549390
#%552220


#*Dynamic matrix control: an optimal multivariable control algorithm with constraints
#@Charles Ray Cutler
#t1983
#c
#index204322


#*On the computational complexity of ordinary differential equations
#@Ker-I Ko
#t1984
#cInformation and Control
#index152476


#*The intelligent voice-interactive interface
#@Christopher Schmandt,Eric A. Hulteen
#t1982
#cProceedings of the 1982 conference on Human factors in computing systems
#index547509
#!&ldquo;Put That There&rdquo; is a voice and gesture interactive system implemented at the Architecture Machine Group at MIT. It allows a user to build and modify a graphical database on a large format video display. The goal of the research is a simple, conversational interface to sophisticated computer interaction. Natural language and gestures are used, while speech output allows the system to query the user on ambiguous input. This project starts from the assumption that speech recognition hardware will never be 100% accurate, and explores other techniques to increase the usefulness (i.e., the &ldquo;effective accuracy&rdquo;) of such a system. These include: redundant input channels, syntactic and semantic analysis, and context-sensitive interpretation. In addition, we argue that recognition errors will be more tolerable if they are evident sooner through feedback and easily corrected by voice.


#*A user's approach to requirements analysis of a large software system
#@Meir Burstin,Moshe Ben-Bassat
#t1984
#cProceedings of the 1984 annual conference of the ACM on The fifth generation challenge
#index545546
#%622456
#!Arriving at all the requirements of a large software system is a very difficult task, whose success or failure significantly affects the system design and implementation. A user oriented approach is suggested in this paper, that expands the definition of a user and allows hierarchal decomposition of users. Requirements are formed at the elementary level of the users and then composed to upper levels and checked. The checks are done against the real needs of the user community rather then among the requirements themselves. A possible use of automated tools in this process is suggested.


#*The digital data exchange--a space-division switching system
#@Emil Hopner,Michael Allen Patten
#t1984
#cIBM Journal of Research and Development
#index178293


#*Computer Communications through Telecommunications Satellite Systems - The NADIR Project
#@Jean-Louis Grangé
#t1982
#cProceedings of the Working Conference of the joint GI/NTG working group "Computer Network" on Data Networks with Satellites
#index384365


#*Methodology for the Specification of Software Systems: From Formal Requirements to Algebraic Design Specifications
#@Hartmut Ehrig,Werner Fey
#t1981
#cGI - 11. Jahrestagung in Verbindung mit Third Conference of the European Co-operation in Informatics (ECI)
#index277270


#*Software support for the Yorktown Simulation Engine
#@E. Kronstadt,G. Pfister
#t1982
#cProceedings of the 19th Design Automation Conference
#index548596
#%545586
#%549519
#!The Yorktown Simulation Engine (YSE) is a special-purpose, highly-parallel programmable machine for the gate-level simulation of logic. The YSE has been designed and is being constructed at the IBM T. J. Watson Research Center. It can simulate up to one million gates at a speed of over two billion gate simulations per second; it is estimated that the IBM 3081 processor could have been simulated on the YSE at a rate of 1000 instructions per second. This is far beyond the capabilities of existing register-level software simulators. This paper describes the software support for the YSE.


#*A Method for Computing All Solutions to Systems of Polynomials Equations
#@Alexander P. Morgan
#t1983
#cACM Transactions on Mathematical Software (TOMS)
#index317883
#%326665
#%325477
#%321601


#*A fast parallel algorithm for thinning digital patterns
#@T. Y. Zhang,C. Y. Suen
#t1984
#cCommunications of the ACM
#index315192
#%332918


#*A new method for coin flipping by telephone
#@S. C. Kak
#t1984
#cCryptologia
#index451266


#*Intelligent Assistance for Complex Systems
#@Tom Kehler,Avron Barr,Tim Finin,Peter Friedland,Mike Genesereth,Jim Miller,Mark Miller,Elliot Soloway,Harry Tennant
#t1982
#cProceedings of the ACM '82 conference
#index550748
#!Complex systems are becoming more pervasive, yet in order for these systems to be used effectively, machine-based assistance is needed. With the advent of powerful personal systems it is anticipated that experts in various disciplines will become increasingly dependent on computational environments provided they are given a means of exploiting system capabilities. Traditional help systems have made use of canned text which is presented in response to typing a &ldquo;?&rdquo; or &ldquo;help&rdquo;. Many integral help systems embed canned hints at appropriate places in the program. Help is commonly provided via a scheme for accessing text files. Help files may be indexed by names such as MAIL, EDIT, LOGIN. Indexing of files is sometimes extended by permitting the user to type a sequence of words such as HELP MAIL READ to provide assistance on subcategories of a topic. Canned text can also be accessed hierarchically through use of a menu system. Most traditional help systems use one of the techniques described to provide assistance.


#*Animation of output applied to manufacturing capacity analysis
#@D. J. Medeiros,John T. Larkin
#t1983
#cProceedings of the 15th conference on Winter simulation - Volume 1
#index546406
#!A general purpose technique for animating simulation output is described. The technique can be implemented using inexpensive hardware and is applicable to many types of simulation models. An example which uses the procedure for capacity analysis in a job shop is presented.


#*A vision of probability and statistics using APL
#@
#t1981
#cProceedings of the international conference on APL
#index552698
#%314048
#!Topics in probability and statistics are becoming more and more common in the high school curriculum of today. APL provides a concise language to express these concepts. If it is used in conjunction with a computer, the tedious development of important notions can be simplified. In choosing a sequence of ideas to explore, I am guided by the rather natural way data are collected, organized and analyzed. Computer simulations of experiments are possible to vary the collection process. I encourage students to use their imagination to visualize and create arrays of information and to become comfortable with a language capable of expressing and transforming those data into usable statistics. APL is used to develop theoretical expectations and to provide sampling data for comparisons. Finally, conclusions are drawn. As a bonus, the universality of the mathematical models make them easy to generalize and apply to many diverse situations. We have worked for many years in Scotch Plains-Fanwood High School to blend APL into our teaching of traditional mathematics and science courses. This paper points toward its use in developing concepts in probability and statistics.


#*A logic simulation machine
#@M. Abramovici,Y. H. Levendel,P. R. Menon
#t1982
#cProceedings of the 19th Design Automation Conference
#index547569
#%323455
#%545310
#%546461
#%547544
#%552857
#%554649
#!Special-purpose CAD hardware is increasingly being considered as a means to meet the challenge posed to conventional (software-based) CAD tools by the growing complexity of VLSI circuits. In this paper we describe the architecture of a logic simulation machine employing distributed and parallel processing. Our architecture can accommodate different levels of modeling ranging from simple gates to complex functions, and support timing analysis. We estimate that simulation implemented by the proposed special-purpose hardware will be between 10 and 60 times faster than currently used software algorithms running on general-purpose computers. With the available technology, a throughput of 1,000,000 gate evaluations/second can be achieved.


#*Resolution of Conflicts in Data Ownership and Sharing in a Corporate Environment
#@Kenmore S. Brathwaite
#t1983
#cDatabases for Business and Office Applications, Database Week
#index272255


#*CADAC: A Controlled-Precision Decimal Arithmetic Unit
#@M. S. Cohen
#t1983
#cIEEE Transactions on Computers
#index339146
#!This paper describes the design of an arithmetic unit called CADAC (clean arithmetic with decimal base and controlled precision). Programming language specifications for carrying out "ideal" floating-point arithmetic are described first. These specifications include detailed requirements for dynamic precision control and exception handling, along with both complex and interval arithmetic at the level of a programming language such as Fortran or PL/I.


#*Proceedings of the joint conference on Easier and more productive use of computer systems. (Part - I): Information processing in the social sciences and humanities - Volume 1981
#@Gregory Marks
#t1981
#cConference on Human Factors in Computing Systems
#index549748


#*Intel Local Network Architecture
#@Robert Ryan,George Marshall,Robert Beach,Steven Kerman
#t1981
#cIEEE Micro
#index406112
#!Networks using Intel's Local Network Architecture promise significant benefits in resource sharing, communications multiplexing, and distributed computing.


#*Correction
#@
#t1983
#cIEEE Computer Graphics and Applications
#index394746
#!In the January/February issue of IEEE CG&A, an incorrect entry was in-advertently included in Carl Machover's ¿An Updated Guide to Sources of Information about Computer Graphics.¿ The correct address for Computer-Aided Design, a publication of Butterworth Scientific Ltd.¿ Journals Division, is PO Box 63, Westbury House, Bury St., Guildford, Surrey GU2 5BH, England. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Converting a swap-based system to do paging in an architecture lacking page-referenced bits
#@Özalp Babaoglu,William Joy
#t1981
#cACM SIGOPS Operating Systems Review
#index554680
#%206066
#%323243
#%330178
#%548848
#%552507
#%553645
#!This paper discusses the modifications made to the UNIX operating system for the VAX-11/780 to convert it from a swap-based segmented system to a paging-based virtual memory system. Of particular interest is that the host machine architecture does not include page-referenced bits. We discuss considerations in the design of page-replacement and load-control policies for such an architecture, and outline current work in modeling the policies employed by the system. We describe our experience with the chosen algorithms based on benchmark-driven studies and production system use.


#*System/370 extended architecture: A program view of the channel subsystem
#@Robert J. Dugan
#t1983
#cProceedings of the 10th annual international symposium on Computer architecture
#index549199
#%331907
#!The 370-XA channel-subsystem architecture represents an evolutionary and significant extension of the System/370 channel architecture. This paper examines the programming-machine interface of the 370-XA channel subsystem and how it was designed to meet the requirements called for by the evolution of IBM's large-scale systems. In particular, emphasis has been placed upon meeting the needs of multiprocessing, maintaining availability, and supporting large I/O configurations while at the same time preserving compatibility for running System/370 channel programs.


#*Extended precision computation of the incomplete beta function
#@Leigh Allen Ihnen
#t1983
#c
#index187661


#*Computer Graphics and an Interactive Stereotactic System for CT-Aided Neurosurgery
#@Michael Rhodes,William Glenn,Yu-ming Azzawi,Robert Howland,Don Hibbard
#t1983
#cIEEE Computer Graphics and Applications
#index396201
#!Using digital CT image data transformed to a patient-frame coordinate system, neurosurgeons can simulate, plan, and execute their procedures with submillimeter precision¿all in the CT suite.


#*Superconcentrators, generalizers and generalized connectors with limited depth
#@Danny Dolev,Cynthia Dwork,Nicholas Pippenger,Avi Wigderson
#t1983
#cProceedings of the fifteenth annual ACM symposium on Theory of computing
#index546441
#%369524
#%545677
#%550726
#!We show that the minimum possible size of an n-superconcentrator with depth 2k&ge;4 is &thgr;(n&lgr;(k, n)), where &lgr;(k, .) is the inverse of a certain function at the k-th level of the primitive recursive hierarchy. It follows that the minimum possible depth of an n-superconcentrator with linear size is &thgr;(&bgr;(n)), where &bgr; is the inverse of a function growing more rapidly than any primitive recursive function. Similar results hold for generalizers. We give a simple explicit construction for a (d1...dk)-generalizer with depth k and size (d1+...+dk)d1...dk. This is applied to give a simple explicit construction for a generalized n-connector with depth 2k&minus;3 and size (2d1+3d2+...+3dk&minus;1+2dk) d1...dk. These are the best explicit constructions currently available. We also show that, for each fixed k&ge;2, the minimum possible size of a generalized n-connector with depth k is &Ohgr;(n1+1/k) and 0((n log n)1+1/k).


#*Multiprocessing: An Annotated Bibliography
#@M. Satyanarayanan
#t1980
#cComputer
#index352923
#!The years since the advent of multiprocessing have witnessed the proliferation of journal articles, conferences, and symposia on multiprocessing systems and closely related topics. The body of literature so generated is both vast and scattered-a situation that can be quite disheartening to one unfamiliar with this area of computer science.


#*Proceedings of the 22nd Annual Symposium on Foundations of Computer Science
#@
#t1981
#cSFCS
#index42844


#*System functions
#@
#t1983
#cACM SIGAPL APL Quote Quad
#index244726
#!System functions are primitive functions whose names are distinguished-identifiers rather than primitives. System functions are not permitted in the locals-list of a defined-function header-line.The system functions related to shared-variables and defined-functions are specified in those chapters. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Structured trace diagnosis for LSSD board testing&mdash;an alternative to full fault simulated diagnosis
#@F. Hsu,P. Solecky,R. Beaudoin
#t1981
#cProceedings of the 18th Design Automation Conference
#index547464
#%545457
#%546447
#!This paper reviews the structured design concept and conventional diagnostic methods. It presents an alternate approach, called structured-trace method, for diagnosing failures on high level packages, which are structurally designed, such as LSSD structure. Implications of structured designs on failure diagnosis are discussed. Results from an evaluation study of the method are presented.


#*Session 9
#@
#t1984
#cProceedings of the 3rd ACM SIGACT-SIGMOD symposium on Principles of database systems
#index247714


#*The Y programming language
#@David R. Hanson
#t1981
#cACM SIGPLAN Notices
#index304545
#%178360
#%249575
#%318451
#%324042
#%625619


#*Klassifizierung von Siedlungen in digitalisierten Luftbildern, die als Quad-Tree-Strukturen codiert sind
#@Peter Haberäcker,R. Thiemann
#t1984
#cProceedings of the DAGM/&Ouml;AGM Symposium
#index557556


#*Aspects and the overlap function
#@Marilyn M. Levine,Leonard P. Levine
#t1984
#cInformation Processing and Management: an International Journal
#index143508


#*Synchronization: a formal approach
#@Janice Emily Cuny
#t1981
#c
#index192331


#*Reflections on grades
#@J. Philip Benkard,John N. Seebe
#t1983
#cACM SIGAPL APL Quote Quad
#index546047
#%318406
#!The APL function REVERSE and a certain defined function generate a group of order four on permutation vectors. The group is extended with the GRADE-UP function to produce GRADE-DOWN and the order eight group known as D4, the fourth dihedral group. The symmetries of a square are generated by REVERSE and TRANSPOSE on square matrices. The resulting isomorphism maps GRADE-DOWN and its inverse to the ninety degree rotations. APL's powerful formalism easily reveals the isomorphisms between the domains of algebra and geometry.


#*An expert model based on user/process profiles for computer systems evaluation
#@Paul Edward Zeldin
#t1984
#c
#index200444


#*The implication and finite implication problems for typed template dependencies
#@Moshe Y. Vardi
#t1982
#cProceedings of the 1st ACM SIGACT-SIGMOD symposium on Principles of database systems
#index233810
#%231400
#%369598
#%544764
#%326368
#%544457
#%546803
#!The class of typed template dependencies is a class of data dependencies that includes embedded multivalued and join dependencies. We show that the implication and the finite implication problems for this class are unsolvable. An immediate corollary is that this class has no formal system for finite implication. We also show how to construct a finite set of typed template dependencies whose implication and finite implication problems are unsolvable.The class of simple template dependencies is a proper subclass of the above class, and it generalizes slightly embedded join dependencies. It is shown that the implication and the finite implication problems for this class are also unsolvable. An immediate corollary is that this class has no formal system for either implication or finite implication.


#*Automation of design for uncommitted logic array
#@Frank R. Ramsay
#t1980
#cProceedings of the 17th Design Automation Conference
#index554767
#!This paper explains the design automation strategy developed at the Ferranti Electronics C.A.D. Centre for the Uncommitted Logic Array (U.L.A.). This strategy was to develop a modular automated design system for the single layer metallisation U.L.A.'s which automatically referred a central design document - the logic diagram. The system handles the function of auto layout and checking. It also links into the logic analysis and test schedule verification system.


#*Costing management information&mdash;a more formal approach
#@M. P. Carter
#t1984
#cJournal of Information Science
#index183932


#*Are the university computer sciences satisfying industry (Panel Discussion)
#@Barry B. Flachsbart,Leslie D. Gilliam,Bernie C. Patton,Daniel C. Clair
#t1980
#cProceedings of the eleventh SIGCSE technical symposium on Computer science education
#index546182


#*Crossing the machine interface
#@A. G. Olbert
#t1982
#cACM SIGMICRO Newsletter
#index547969
#!The concepts and theory behind a specific type of hardware accelerator, oar &ldquo;assist&rdquo;, are presented. Such accelerators are specific extensions to an existing, generalized data processor architecture. Both the software system and the hardware implementation are changed by the extensions. For the accelerators discussed here, the hardware implementation is accomplished solely in microcode. The generalized architecture can be compatible across a line of data processors. The accelerators are defacto extensions to the basic architecture and are normally only defined on a subset of the processor line. These architectural extensions consist of functions migrated from &ldquo;above&rdquo; the generalized architecture (i.e. software functions) into the processor architecture and processor implementation. The accelerators provide a method of improving system performance that is complementary to improving performance through modification of the generalized processor architecture itself or the underlying circuitry implementation.


#*Dynamic characterization prediction system for space oriented architecture in meta structures by interactive computer graphics visualization modeling techniques
#@Donald Warren Collins
#t1980
#c
#index192498


#*A knowledge-based system for individual income and transfer tax planning
#@Robert Herman Michaelsen
#t1982
#c
#index194028


#*Fact-based data analysis and design
#@W Kent
#t1984
#cJournal of Systems and Software
#index155645


#*The Unix Progamming Environment
#@B. W. Kernighan
#t1981
#cComputer
#index344571
#!Since complex Unix tools are built from simple, single-function components, programmers see their work as the creation and use of tools. This view encourages growth, not reinvention.


#*A man-machine interface for interpreting electron density maps
#@Thomas Victor Williams
#t1982
#c
#index199533


#*Automatic tuning algorithms and statistical circuit design
#@Dale Edward Hocevar
#t1982
#c
#index187753


#*Algorithms for the set covering problem
#@Angela Margaret Hey
#t1981
#c
#index186811


#*A polynomial-time algorithm for determining the isomorphism of graphs of fixed genus
#@I. S. Filotti,Jack N. Mayer
#t1980
#cProceedings of the twelfth annual ACM symposium on Theory of computing
#index553414
#%547104
#%550836
#!The isomorphism problem for graphs has been in recent years the object of a much research (see e.g. [Col 78] or [Re-Cor 77]). Its complexity is still unknown. It is not known whether the problem is NP-complete, although it is NP, of course. It is not known whether there exists a polynomial-time algorithm for it. Recently, Babai [Ba 79] has discussed probabilistic algorithms. For additional information see also [Mi 77]. The problem has also some practical applications. Of the known algorithms let us only quote the work of Weinberg [We 66] and of Hopcroft and Tarjan [Ho-Ta 72]. Weinberg's algorithm rums in quadratic time (in &agr;o, the number of vertices of the graphs). Hopcroft and Tarjan's runs in time 0(&agr;o log&agr;o) and uses their powerful technique of depth-first search. Both these algorithms apply only to planar (Weinberg's only to 3-connected planar) graphs. They rely on a well-known rigidity theorem of Withney [Withney 32].


#*Isomorphism Completeness for Some Algebraic Structures
#@Ludek Kucera,Vera Trnková
#t1981
#cProceedings of the 1981 International FCT-Conference on Fundamentals of Computation Theory
#index560374


#*A VLSI FSM design system
#@M. J. Meyer,P. Agrawal,R. G. Pfister
#t1984
#cProceedings of the 21st Design Automation Conference
#index544544
#%178360
#%487502
#%554242
#%546183
#%551460
#%553305
#%551353
#%553290
#!This paper describes a fully automated finite-state machine (FSM) synthesis system. The FSM is realized as a PLA. This synthesizer accepts a high-level description of the FSM and generates a mask level layout. Several simulation models are produced at different levels of abstraction; these models can be integrated with other modules on the chip to aid in the debugging of the overall VLSI chip design. Valuable information on speed, area, and testability of the PLA can be obtained through a collection of audit programs. This system has been used to design complex controllers for many VLSI chips at AT T Bell Laboratories. Although a PLA implementation is assumed, the system can be extended to synthesize a random logic implementation of the FSM.


#*Computer-based instruction: methods and development
#@Stephen M. Alessi,Stanley R. Trollip
#t1984
#c
#index161833


#*Some Mathematical Tools for a Modeler's Workbench
#@Elaine Cohen
#t1983
#cIEEE Computer Graphics and Applications
#index352382


#*Approaches to Mechanization of the Conversation Scheme Based on Monitors
#@K. H. Kim
#t1982
#cIEEE Transactions on Software Engineering
#index348680
#!A basic problem in designing error detection and backward recovery capabilities into concurrent programs is to coordinate the detection and recovery activities of cooperating processes. As an aid to such design Randell proposed a language construct called conversation in an abstract form. Practical mechanization of the conversation scheme, i.e., selection of a well-structured syntax and associated semantics, is the issue dealt with in this paper. Four different mechanizations based on the monitor approach to interprocess communication are presented. They are presented as feasible extensions of Concurrent Pascal in order to enable visualization of their full implementation details in at least one type of concurrent programming environment. They are presented in the increasing order of the amount of efforts that they require for extending Concurrent Pascal. They offer different degrees of assistance to the programmer in proper structuring of recoverable process interactions.


#*Using electronic mail as a teaching tool
#@Lawrence A. Welsch
#t1982
#cCommunications of the ACM
#index313788


#*Locking Policies in Distributed Databases
#@Ouri Wolfson
#t1984
#cProceedings of the First International Conference on Data Engineering
#index366922


#*Signal processing in dual-energy computerized tomography (beam-filter)
#@Ali Mohamad Doost-Hoseini
#t1984
#c
#index185754


#*A status survey of instructional computer use in selected elementary and secondary schools in texas
#@Richard Layne Smith
#t1984
#c
#index200845


#*Rehabilitation and the Handicapped Programmer
#@R. J. Leneway
#t1981
#cComputer
#index336799
#!The lives of many handicapped persons have been vastly improved by computer technology, both in adaptive devices and job opportunity but millions wait to be served.


#*Improving personal efficiency: Time management in today's changing university computing environment
#@Darleen Pigford
#t1982
#cProceedings of the 10th annual ACM SIGUCCS conference on User services
#index552724
#!With escalating technological advances and increased computing demands, the director of a university based computing facility finds greater professional responsibilities to perform with somewhat diminishing resources. To partially resolve this imbalance of task and resources, the leaders of computing organizations must seek to utilize their own time as efficaciously as possible. Planning to achieve maximum efficiency in a given time frame is a complex and individualized process. Even though people react differently to time constraints, each can seek to improve individual productivity within a constant time parameter. Practical ways to manage time to improve performance in a changing university computing environment is the theme of this paper.


#*The wigner distribution and its application to speech analysis and recognition
#@David Bruce Chester
#t1982
#c
#index197931


#*A coherent scheme to support location-independent references in internetwork environment
#@Ray Cheng,J. W. S. Liu
#t1982
#cProceedings of the June 7-10, 1982, national computer conference
#index66670
#%317300
#!We describe in this paper a coherent scheme to support location-independent references of remote entities in an internetwork environment where entities may dynamically connect to computer systems in different networks. More specifically, we propose that name servers be provided within networks and in hosts to support user creation and use of symbolic internetwork names of entities. Message-forwarding mechanisms to support communication between entities that may migrate from network to network are designed.


#*Performance of SNA's LU-LU session protocols
#@James P. Gray
#t1982
#cProceedings of the Computer Network Performance Symposium
#index546470
#!SNA is both an architecture and a set of products built in conformance with the architecture (1,2,3). The architecture is layered and precisely defined; it is both evolutionary and cost effective for implementing products. Perhaps the largest component of cost effectiveness is performance: transaction throughput and response times. For SNA, this involves data link control protocols (for SDLC and S/370 channel DLC's), routing algorithms, protocols used on the sessions that connect logical units (LU-LU session protocols), and interactions among them. SNA's DLC and routing protocols have been discussed elsewhere (4,5,6); this talk examines protocols on sessions between logical units (LU-LU session protocols) and illustrates the results of design choices by comparing the performance of various configurations.


#*The transformational approach to the development and verification of programs in a very high level language
#@Edith Gail Deak
#t1980
#c
#index204029


#*Parallel conic recognition by bus automata
#@Leila Anne Breene
#t1982
#c
#index196764


#*The remodularization of a compiler by abstract data types
#@Klaus Bothe
#t1983
#cProc. IFIP working conference on Programming Languages and System Design
#index159699


#*Contracts made by electronic mail: legal issues, technology and services
#@Julian Newman,Sharon Harvey
#t1984
#cProc. of the IFIP WG 6.5 working conference on Computer-based message services
#index177127


#*Generation Scavenging: A non-disruptive high performance storage reclamation algorithm
#@David Ungar
#t1984
#cACM SIGPLAN Notices
#index548382
#%151297
#%316426
#%318294
#%325256
#%329255
#%332054
#%334426
#%544696
#%547237
#%547268
#%550651
#%550264
#%626568
#!Many interactive computing environments provide automatic storage reclamation and virtual memory to ease the burden of managing storage. Unfortunately, many storage reclamation algorithms impede interaction with distracting pauses. Generation Scavenging is a reclamation algorithm that has no noticeable pauses, eliminates page faults for transient objects, compacts objects without resorting to indirection, and reclaims circular structures, in one third the time of traditional approaches. We have incorporated Generation Scavenging in Berkeley Smalltalk(BS), our Smalltalk-80 implementation, and instrumented it to obtain performance data. We are also designing a microprocessor with hardware support for Generation Scavenging.


#*Computergest&uuml;tzte Informationssysteme in der Materialwirtschaft
#@Joachim Griese
#t1980
#cGI - 10. Jahrestagung
#index260702


#*Paper faire
#@
#t1980
#cProceedings of the May 19-22, 1980, national computer conference
#index71892


#*Solid model in geometric modelling system: HICAD
#@Shinji Tokumasu,Yoshio Kunitomo,Yoshimi Ohta,Shigeru Yamamoto,Norihiro Nakajima
#t1983
#cProceedings of the 20th Design Automation Conference
#index548846
#!The geometric modelling system plays an important role in CAD for the mechanical engineering. This paper presents the general purposed conversational geometric modelling, HICAD which has been developed to confirm the integrated CAD. The HICAD is a generalized geometric model which includes three of the typical geometric modellings, i.e., the wire frame, surface, and solid models. Herein, the implementation method of solid model is especially discussed with the summary of whole system.


#*ELAN: An Elementary Language that promotes godd programming
#@Lowell A. Carmony
#t1982
#cProceedings of the thirteenth SIGCSE technical symposium on Computer science education
#index554055
#!The purpose of this paper is twofold: To consider the characteristics that a programming language for beginners ought to have, and to offer a new language from Germany that shows great promise for providing beginners with many of these characteristics. This language is called ELAN (Elementary LANguage) and was designed in 1974 by C. H. A. Koster and his associates at the Technical University of Berlin. An ELAN compiler was developed soon thereafter from two theses written by J. Liedtke and U. Bartling at the University of Bielefeld. It is hoped that this paper will bring to ELAN some of the recognition that it deserves but has not yet received in this country.


#*Computer crime career of the future?
#@Jay Becker
#t1982
#cACM SIGCAS Computers and Society
#index306562


#*Lexicon design using perfect hash functions
#@Nick Cercone,Max Krause,John Boates
#t1981
#cProceedings of the joint conference on Easier and more productive use of computer systems. (Part - II): Human interface and the user interface - Volume 1981
#index546132
#%317208
#%326956
#!The research reported in this paper derives from the recent algorithm of Cichelli (1980) for computing machine-independent, minimal perfect hash functions of the form:hash value: hash key length + associated value of the key's first letter + associated value of the key's last letterA minimal perfect hash function is one which provides single probe retrieval from a minimally-sized table of hash identifiers [ keys]. Cichelli's hash function is machine-independent because the character code used by a particular machine never enters into the hash calculation.Cichelli's algorithm uses a simple backtracking process to find an assignment of non-negative integers to letters which results in a perfect minimal hash function. Cichelli employs a twofold ordering strategy which rearranges the static set of keys in such a way that hash value collisions will occur and be resolved as early as possible during the backtracking process. This double ordering provides a necessary reduction in the size of the potentially large search space, thus considerably speeding the computation of associated values.In spite of Cichelli's ordering strategies, his method is found to require excessive computation to find hash functions for sets of keys with more than about 40 members. Cichelli's method is also limited since two keys with the same first and last letters and the same length are not permitted.Alternative algorithms and their implementations will be discussed in the next section; these algorithms overcome some of the difficulties encountered when using Cichelli's original algorithm. Some experimental results are presented, followed by a discussion of the application of perfect hash functions to the problem of natural language lexicon design.


#*A numerical study of an orthotropic solid under dynamic loads (finite difference, elastic-plastic deformation)
#@Kelvin Lee
#t1984
#c
#index188067


#*A general lexicographic partial enumeration algorithm for the solution of integer nonlinear programming problems
#@Mohammad Saiid Sabbagh
#t1983
#c
#index204051


#*Integrated software validation in the view of inspections/reviews
#@Horst Remus
#t1984
#cProc. of a symposium on Software validation: inspection-testing-verification-alternatives
#index184736


#*An Application of the Theory of Graphs and Hypergraphs to the Decomposition of Relational Database Schemes
#@Jan Paredaens,Dirk Van Gucht
#t1983
#cProceedings of the 8th Colloquium on Trees in Algebra and Programming
#index563396


#*User Software Engineering and the design of interactive systems
#@Anthony I. Wasserman
#t1981
#cProceedings of the 5th international conference on Software engineering
#index548140
#%324042
#%326368
#%327006
#!The successful construction of interactive systems requires the utilization of principles of user-centered design, combined with techniques for software engineering, in order to produce systems that are reliable, easy to use, and well adapted to user needs. This paper presents some of these principles and shows how they are achieved in the User Software Engineering (USE) project, which is intended to provide the applications developer with a development environment that supports the systematic specification and implementation of interactive systems.


#*How to Get Rid of Pseudoterminals
#@W. Ainhirn
#t1980
#cProceedings of the 7th Colloquium on Automata, Languages and Programming
#index375427


#*The decomposition of relations based on relational dependencies
#@Antonio Claudio Monteiro Da Silva
#t1980
#c
#index195833


#*Directions and Issues in Architecture and Language
#@M. J. Flynn
#t1980
#cComputer
#index335780
#!Traditional architectures are based on technological premises that are no longer valid. The new " ground rules" make possible new relationships between architecture and language.


#*The Japanese approach: a better way to manage programmers?
#@Paul S. Licker
#t1983
#cCommunications of the ACM
#index327448
#%179654
#%317344
#%323764
#%553799
#%618813
#%332407
#%551656
#%546748
#%327864
#%458820
#!With a turnover rate among computer programmers of 25%-50% per year, it's time somebody came up with a better way to manage computer professionals. One approach that holds promise is to create a Japanese-style Theory Z atmosphere in the firm, stressing lifetime employment, non-specialized career paths, collective decision-making, and other holistic matters.


#*Program optimization based on a non-procedural specification
#@Kang-Sen Lu
#t1981
#c
#index186891


#*Extended Boolean Information Retrieval
#@Gerard Salton,Edward A. Fox,Harry Wu
#t1982
#c
#index114659
#!In conventional information retrieval Boolean combinations of index terms are used to formulate the users'' information requests. While any document is in principle retrievable by a Boolean query, the amount of output obtainable by Boolean processing is difficult to control, and the retrieved items are not ranked in any presumed order of importance to the user population. In the vector processing model of retrieval, the retrieved items are easily ranked in decreasing order of the query-record similarity, but the queries themselves are unstructured and expressed as simple sets of weighted index terms. A new, extended Boolean information retrieval system is introduced which is intermediate between the Boolean system of query processing and the vector processing model. The query structure inherent in the Boolean system is preserved, while at the same time weighted terms may be incorporated into both queries and stored documents; the retrieved output can also be ranked in strict similarity order with the user queries. A conventional retrieval system can be modified to make use of the extended system. Laboratory tests indicate that the extended system produces better retrieval output than either the Boolean or the vector processing systems.


#*A hierarchical model for manipulator control systems
#@Ayman Ibrahim El-Dessouki
#t1981
#c
#index196661


#*Applying the RSA Digital Signature to Electronic Mail
#@D. W. Davies
#t1983
#cComputer
#index337640


#*Distributed processing in brokerage operations: a case study (computers, securities, backoffice)
#@James Joseph Murtha
#t1984
#c
#index195261


#*AFIPS secondary education curriculum in information technology
#@
#t1984
#cProceedings of the 1984 annual conference of the ACM on The fifth generation challenge
#index545562
#!This session includes a report on work in progress by a committee developing an interdisciplinary computers and information-based course/curriculum intended for all students at the secondary level. Content, objectives, and a topical outline will be discussed. Audience reaction and input are requested. In the fall of 1983, the AFIPS (American Federation of Information Processing Societies) Education Committee funded a project to develop a technologically oriented, interdisciplinary course /curriculum for all students at the secondary level. A Steering Committee met in September 1983 and recommended that a working committee be formed to produce recommendations on course/curriculum.


#*Architecture and paradigms for ai symbolic processing using content addressable memories (knowledge representation, list)
#@Jaihie Kim
#t1984
#c
#index197451


#*Design automation and VLSI in the 80's (Position Statement)
#@R. M. Jacobs
#t1980
#cProceedings of the 17th Design Automation Conference
#index550158
#!The density of silicon integrated circuits has been increasing by a factor of two per year and this increase can be expected to continue in the forseeable future. This increasing scale of integration requires the use of comprehensive aids in order to prevent the design intervals from becoming excessively long and to limit the expenditure of design resources per circuit. With the increasing density and the trend to larger chips, silicon utilization will not be as critical a consideration as it has been in the past. It is therefore likely that faster turnaround and lower design cost can be achieved at the expense of some silicon area. Turnaround time and design cost considerations will likely cause the design style to become more modular and the use of predesigned blocks will become more common.


#*Connected transformational grammars for languages and compilers
#@Thomas Julian Pennello
#t1982
#c
#index199794


#*Experience in writing VCG systems
#@J. Moore
#t1981
#cACM SIGSOFT Software Engineering Notes
#index438168


#*Technology: a threat to democracy
#@R. D. Parslow
#t1982
#cACM SIGCAS Computers and Society
#index303163
#%552493
#!"Short-term unemployment trends are likely . . . But far more critical are the long-term dangers of drastic population bipolarization. This would appear to generate a small minority of technologically oriented elitists against a vast majority of unskilled, nearly unemployable workers. This event, predicted by some and doubted by others, would probably represent the end of the road for contemporary Western civilization as now understood" (1)


#*The Second Software Engineering Standards Applications Workshop Call for Papers
#@
#t1982
#cIEEE Transactions on Software Engineering
#index347992


#*Book reviews
#@
#t1982
#cIssue 82 (October 1982)
#index99050


#*Automating mask layout and specification panel session
#@Robert B. Cutler
#t1983
#cProceedings of the 20th Design Automation Conference
#index551351
#!It is becoming increasingly important that the photomasks needed for a VLSI circuit be produced correctly the first time. To obtain good masks, both the design of the chips and their arraying onto masks must be correct. Much attention has been given to chip design&mdash;simulators and design-rule checkers are abundant. In this panel discussion, however, we will be addressing the other aspect&mdash;the layout and specification of the masks themselves. Since a growing number of VLSI designers are turning from traditional optical mask-making to electron-beam (E-beam) mask-making, the emphasis of this discussion will be towards E-beam technology, although many of the concepts apply to all mask making.


#*The development of alternating-direction finite element methods for enhanced oil recovery simulation
#@Peter M. Roberts
#t1984
#c
#index186163


#*A high accuracy computer recognizer of speech for medical data input
#@Richard Alan Parfitt
#t1980
#c
#index205684


#*Erratum
#@
#t1983
#cComputer
#index342612


#*Motorola's MC68HC11: Definition and Design of a VLSI Microprocessor
#@James Sibigtroth
#t1984
#cIEEE Micro
#index336702
#!The MC68HC11 demonstrates Motorola's conviction that 8-bit devices still address a significant market; its design proves that 8-bit technology still offers ample technical challenge and opportunity for creativity.


#*Selective Update
#@
#t1982
#cIEEE Computer Graphics and Applications
#index338938


#*VLSI Processor Architecture
#@J. L. Hennessy
#t1984
#cIEEE Transactions on Computers
#index344081
#!A processor architecture attempts to compromise between the needs of programs hosted on the architecture and the performance attainable in implementing the architecture. The needs of programs are most accurately reflected by the dynamic use of the instruction set as the target for a high level language compiler. In VLSI, the issue of implementation of an instruction set architecture is significant in determining the features of the architecture. Recent processor architectures have focused on two major trends: large microcoded instruction sets and simplified, or reduced, instruction sets. The attractiveness of these two approaches is affected by the choice of a single-chip implementation. The two different styles require different tradeoffs to attain an implementation in silicon with a reasonable area. The two styles consume the chip area for different purposes, thus achieving performance by different strategies. In a VLSI implementation of an architecture, many problems can arise from the base technology and its limitations. Although circuit design techniques can help alleviate many of these problems, the architects must be aware of these limitations and understand their implications at the instruction set level.


#*Symposium on Architectural Support for Programming Languages and Operating Systems
#@
#t1982
#cComputer
#index340209


#*Call for Papers
#@
#t1980
#cComputer
#index336332


#*On the application of rule-based techniques to the design of advice giving systems
#@Peter Jackson,Paul Lefrere
#t1984
#cInternational Journal of Man-Machine Studies
#index180800


#*Applications of operations research and management information system concepts to management of large software projects
#@John Hearn Lee
#t1983
#c
#index196440


#*The Dependence of Sojourn Times in Closed Queueing Networks
#@Frank P. Kelly
#t1983
#cProceedings of the International Workshop on Computer Performance and Reliability
#index355781


#*Algorithm 554: BRENTM, A Fortran Subroutine for the Numerical Solution of Nonlinear Equations [C5]
#@Jorge J. Moré,Michael Y. Cosnard
#t1980
#cACM Transactions on Mathematical Software (TOMS)
#index325545
#%325477


#*Computing with text-graphic forms
#@Fred H. Lakin
#t1980
#cProceedings of the 1980 ACM conference on LISP and functional programming
#index547288
#%318294
#%548297
#%551360
#!Computing with text-graphic forms occurs when text-graphic patterns are used to direct the processing of other text-graphic patterns. The PAM graphics system was designed for just this kind of computation; PAM stands for PAttern Manipulating&mdash;PAM is a generalization of LISP (McCarthy [0]) from computing with (textual) symbolic expressions to computing with text-graphic forms. Like LISP, PAM acheives processing power by providing atomic objects, means of structuring them into complex objects and taking them apart, and equality tests for objects. Text-graphic engines can then be defined, allowing text editors, text-graphic editors, circuit design aids and visual language processors to all be developed in the same LISP-like environment. Examples discussed in the paper are: handPAM is an agile environment for the manual manipulation of text-graphic objects (described briefly). writtenPAM provides programmatic manipulation of visual objects. Pattern processing is demonstrated by functions which translate a LISP sexpr to the visual name-shape synonyms of the OUTLINE notation system, and then spatially lay it out. writtenPAM also permits definition of pattern evaluating, enabling actual computation with text-graphic forms. An evaluate function for text-graphic objects is given which can execute OUTLINE expressions. An experimental version of the PAM system has been implemented in MACLISP at the Stanford Artificial Intelligence Lab.


#*Tutorials for Ada
#@Richard T. Close
#t1980
#cProceedings of the 8th annual ACM SIGUCCS conference on User services
#index551737
#%319828
#%474871
#!Ada is a modern high order programming language that has been developed by the U.S. Department of Defense for use in embedded computer applications. Such applications are typically large, volatile and long-lived. Facilities for such features as real-time and parallel processing, fail-soft execution, exception handling and the control of a wide variety of peripheral devices have been included in the language design. These features broaden the possible applications of Ada to such areas as process control, systems programming, scientific calculation, and commercial data processing. It is anticipated that Ada will be quickly adopted by DoD contractors and that it may also become the most popular computer language in general use because of its unique features and capabilities.


#*Proceedings of the ACM 12th annual computer science conference on SIGCSE symposium
#@
#t1984
#cACM Annual Computer Science Conference
#index552870


#*The 8 by 8 display
#@R. F. Sproull,I. Sutherland,A. Thomson,S. Gupta,C. Minter
#t1983
#cACM Transactions on Graphics (TOG)
#index323401
#%153803
#%319069
#%552623
#%328621


#*Concurrent error detection in VLSI interconnection networks
#@W. Kent Fuchs,Jacob A. Abraham,Kuang-Hua Huang
#t1983
#cACM SIGARCH Computer Architecture News
#index553402
#!Comprehensive VLSI fault models are proposed for three broad classes of interconnection networks between multiple processors and multiple memory modules. System-level algorithms are given for concurrent detection of errors produced by these faults during the normal use of the networks. The proposed algorithms are shown to be applicable to the three classes of interconnection networks with minimal changes in their classical design. The algorithms are appropriate for the broad classes of permanent and transient faults predominant in dense VLSI and wafer-scale integration with a minimal amount of network redundancy required for implementation.


#*Validation, Verification, and Testing for the Individual Programmer
#@M. A. Branstad
#t1980
#cComputer
#index346260
#!Good programming demands sound testing, verification, and validation techniques throughout the life cycle-even if the development environment has limited support and resources.


#*Examples of hard tautologies in the propositional calculus
#@Balakrishnan Krishnamurthy,Robert N. Moll
#t1981
#cProceedings of the thirteenth annual ACM symposium on Theory of computing
#index544724
#%186863
#%435293
#%544896
#%552550
#%551850
#!We present examples of hard tautologies in propositional calculus by encoding instances of the assertions made by Ramsey's theorem. We provide evidence that these tautologies are indeed hard by 1. showing that there are no short proofs for these tautologies in certain restricted classes of proof systems; 2. relating a proof of these tautologies to the problem of determining the diagonal Ramsey numbers for graphs.


#*Get in Step with ACM'80
#@
#t1980
#cComputer
#index353810


#*Performance prediction during database system development
#@Stanley Wulf
#t1983
#c
#index194554


#*Digital system simulation: Current status and future trends or darwin's theory of simulation
#@Melvin A. Breuer,Alice C. Parker
#t1981
#cProceedings of the 18th Design Automation Conference
#index545705
#%545533
#%545695
#%553010
#%548291
#!This paper presents a philosophical view of the changing field of design verification. The evolution of simulation and fault simulation are briefly summarized. Current research issues in design verification are discussed. The paper concludes with a discussion of the future direction simulation will take, along with other techniques destined to compete with simulation for the design verification task.


#*The effect of number of Hamiltonian paths on the complexity of a vertex-coloring problem
#@Udi Manber,Martin Tompa
#t1984
#cSIAM Journal on Computing
#index168032


#*A microsequencer architecture with firmware support for modular microprogramming
#@Christos A. Papachristou,Satnam Sing Gambhir
#t1982
#cProceedings of the 15th annual workshop on Microprogramming
#index553939
#%544725
#%553445
#%607120
#!The aim of this paper is to propose a microsequencer architecture and supporting firmware that are suitable for implementing modular microprogramming. The structure consists of a PLA sequencer store, a microcode store (memory) and an address processor. The latter, operating under sequencing commands issued by the PLA, generates the effective address for both stores. The supporting firmware primitives or transactions, stored in PLA, are suitable for structured microprogramming constructs, e.g., while-do, if-then-else, etc. This capability is extended to complex sequencing structures which are then implemented by context-free transaction blocks. Such sequencing is required to achieve migration of complicated. software functions, such as operating systems, in firmware. It is expected that the proposed method is compatible with LSI/VLSI array technology.


#*Soft machines: A philosophy of user-computer interface design
#@Lloyd H. Nakatani,John A. Rohrlich
#t1983
#cProceedings of the SIGCHI conference on Human factors in computing systems
#index548117
#!Machines and computer systems differ in many characteristics that have important consequences for the user. Machines are special-purpose, have forms suggestive of their functions, are operated with controls in obvious one-to-one correspondence with their actions, and the consequences of the actions on visible objects are immediately and readily apparent. By contrast, computer systems are general-purpose, have inscrutable form, are operated symbolically via a keyboard with no obvious correspondence between keys and actions, and typically operate on invisible objects with consequences that are not immediately or readily apparent. The characteristics possessed by machines, but typically absent in computer systems, aid learning, use and transfer among machines. But &ldquo;hard,&rdquo; physical machines have limitations: they are inflexible, and their complexity can overwhelm us. We have built in our laboratory &ldquo;soft machine&rdquo; interfaces for computer systems to capitalize on the good characteristics of machines and overcome their limitations. A soft machine is implemented using the synergistic combination of real-time computer graphics to display &ldquo;soft controls,&rdquo; and a touch screen to make soft controls operable like conventional hard controls.


#*Entwurfsverifikation mit Computer Design Language - Version Munich
#@Friedhelm Mündemann,Winfried Hahn,Kristian Fischer
#t1984
#cGI - 14. Jahrestagung
#index273237


#*Languages and Inverse Semigroups
#@Stuart W. Margolis,Jean-Eric Pin
#t1984
#cProceedings of the 11th Colloquium on Automata, Languages and Programming
#index375532


#*Notes from Left Field: Corporate Slide Presentations
#@Joan Wright
#t1983
#cIEEE Computer Graphics and Applications
#index339157
#!An informal look into the way one company uses a slide-making system shows that machines are nice, but nothing is more important than planning. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A Class of Program Schemes Based on Tree Rewriting Systems
#@Bruno Courcelle,F. Lavandier
#t1983
#cProceedings of the 8th Colloquium on Trees in Algebra and Programming
#index557554


#*HITS: a symbolic testing and debugging system for multilingual microcomputer software
#@Takeshi Chusho,Atsushi Tanaka,Eri Okamoto,Akinori Honda,Toru Kurosaki
#t1983
#cProceedings of the May 16-19, 1983, national computer conference
#index67264
#%554960
#%346558
#%353076
#%336132
#%314402
#%343019
#!The use of a large-scale computer is the key to the development of increasingly numerous and large-scale microcomputer software programs. HITS (Highly Interactive Testing-and-debugging System) constructs an integrated programming environment for 68000 microcomputer systems on a large-scale computer in cooperation with language translators. This system supports efficient and effective software validation from module testing through system testing. Functions of HITS are provided in the test-procedure description language, in which test data, expected results and the testing environment are described and separated from the target program. The main features are (1) symbolic support of both a high-level language and an assembly language, (2) module testing facilities such as driver and stub definitions, (3) a testing coverage monitor for branch testing, (4) debugging commands added temporarily to a test procedure from a terminal, and (5) a macro definition for language extension. HITS has already been used at many sites. In our early experience of applying it to the software development of various communication systems, software productivity and reliability were considerably improved.


#*The Open Channel
#@V. Myasnikov
#t1982
#cComputer
#index344177


#*Design automation status in Japan
#@Akihiko Yamada
#t1981
#cProceedings of the 18th Design Automation Conference
#index551475
#%544616
#%544829
#%545549
#%546810
#%546980
#%547763
#%551716
#%554439
#%554944
#%553224
#%553024
#!This paper surveys the Japanese design automation (DA) status and activities. First, the DA statistics for major Japanese organizations are presented. These statistics show the status of logic, physical and test DA for digital systems and LSIs. Second, notable DA activities of Japanese manufacturers, laboratories and universities are introduced.


#*Computerized closed form solutions to nonserial dynamic programming problems
#@Don Nelson Pope
#t1980
#c
#index190675


#*Perspectives on programming environments
#@John R. Mashey
#t1983
#cProceedings of the 1983 computer science conference
#index547893
#%324042
#%325278
#%547296
#%548051
#!Many people have realized that programming needs more support than a compiler, linker, debugger, and a few other tools. More comprehensive systems have been proposed, built, and (sometimes) used. Although the perfect programming environment is yet to be found, people have widely divergent views of the ideal. This paper neither surveys the field nor describes any single environment, but instead offers some attributes by which programming environments can be classified. It frequently uses the Unix system to illustrate these attributes, and comments on the implications of the Unix system's success for other programming environments.


#*Some Observations on Compositional Semantics
#@Theo M. V. Janssen,Peter van Emde Boas
#t1981
#cLogic of Programs, Workshop
#index557045


#*The First International Conference on Computers and Applications: Reflections
#@E. A. , Jr. Parrish
#t1984
#cComputer
#index389013


#*Using Stochastic Modeling for Texture Generation
#@Shinichiro Haruyama,Brian Barsky
#t1984
#cIEEE Computer Graphics and Applications
#index386554
#!A new computer graphics technique generates complicated random textures, like those found on natural objects. Requiring little data, it allows easy control of textural properties.


#*Dezentrale Software-Erstellung durch Netzwerkprogrammierung
#@Hermann von Issendorff
#t1983
#cGI - 13. Jahrestagung
#index262473


#*Digital complex demodulation of nonlinear fluctuation data
#@Labib Khadra
#t1981
#c
#index191508


#*Program slicing
#@Mark Weiser
#t1981
#cProceedings of the 5th international conference on Software engineering
#index550486
#%191858
#%193629
#%235915
#%255120
#%307288
#%317235
#%321171
#%322574
#%324621
#%326066
#%327803
#%329737
#%548588
#%622654
#!Program slicing is a method used by experienced computer programmers for abstracting from programs. Starting from a subset of a program's behavior, slicing reduces that program to a minimal form which still produces that behavior. The reduced program, called a &ldquo;slice&rdquo;, is an independent program guaranteed to faithfully represent the original program within the domain of the specified subset of behavior. Finding a slice is in general unsolvable. A dataflow algorithm is presented for approximating slices when the behavior subset is specified as the values of a set of variables at a statement. Experimental evidence is presented that these slices are used by programmers during debugging. Experience with two automatic slicing tools is summarized. New measures of program complexity are suggested based on the organization of a program's slices.


#*Algorithm 565: PDETWO/PSETM/GEARB: Solution of Systems of Two-Dimensional Nonlinear Partial Differential Equations [D3]
#@David K. Melgaard,Richard F. Sincovec
#t1981
#cACM Transactions on Mathematical Software (TOMS)
#index330487
#%319676
#%328991
#%330143


#*Experiments on the Knee Criterion in a Multiprogrammed Computer System
#@T. Nishigaki
#t1983
#cIEEE Transactions on Software Engineering
#index340527
#!Although the effectiveness of the knee criterion [7] as a virtual memory management strategy is widely accepted, it has been impossible to take advantage of it in a practical system, because little information is available about the program behavior of executing jobs.


#*Overhead Storage Considerations and a Multilinear Method for Data File Compression
#@T. Y. Young
#t1980
#cIEEE Transactions on Software Engineering
#index339469
#!The paper is concerned with the reduction of overhead storage, i.e., the stored compression/decompression (C/D) table, in field-level data file compression. A large C/D table can occupy a lage fraction of maim memory space during compression and decompression, and may cause excessve page swapping in virtual memory systems. A two-stage approach is studied, including the reuired additional C/D table decompression time. It appears that the approach has limitations and is not completely satisfactory.


#*Erfahrungen mit 20 Installationen des Systems FIBBS (Finanzbuchhaltung mit Betriebswirtschaft und Bildschirmen)
#@Peter Schehka
#t1980
#cOnline-Systeme im Finanz- und Rechnungswesen, Anwendergespr&auml;ch, Berlin, 29.-30. April 1980, Gesellschaft f&uuml;r Informatik e.V. und Verband der Hochschullehrer f&uuml;r Betriebswirtschaft e.v. (WK Betriebsinformatik)
#index267907


#*Verbesserung der automatischen Spracherkennung durch die erwartungsorientierte Analyse
#@Joachim Mudler
#t1984
#cProceedings of the DAGM/&Ouml;AGM Symposium
#index555450


#*On Pushdown Tree Automata
#@Irène Guessarian
#t1981
#cProceedings of the 6th Colloquium on Trees in Algebra and Programming
#index571759


#*Operational Response Time Formulas and Their Sensitivity to Error
#@Jeffrey A. Brumfield
#t1983
#c
#index199136


#*Fast programs for initial segments and polynomial time computation in weak models of arithmetic (Preliminary Abstract)
#@Deborah Joseph,Paul Young
#t1981
#cProceedings of the thirteenth annual ACM symposium on Theory of computing
#index550893
#%547835
#%548318
#%551345
#%552378
#!In this paper we study two alternative approaches for investigating whether NP complete sets have fast algorithms. One is to ask whether there are long initial segments on which such sets are easily decidable by relatively short programs. The other approach is to ask whether there are weak fragments of arithmetic for which it is consistent to believe that P &equil; NP. We show, perhaps surprisingly, that the two questions are equivalent: It is consistent to believe that P &equil; NP in certain models of weak arithmetic theories iff it is true (in the standard model of computation) that there are infinitely many initial segments on which satisfiability is polynomially decidable by programs that are much shorter than the length of the initial segment.


#*Coding guidelines for pipelined processors
#@James W. Rymarczyk
#t1982
#cACM SIGARCH Computer Architecture News
#index554081
#%316784
#!This paper is a tutorial for assembly language programmers of pipelined processors. It describes the general characteristics of pipelined processors and presents a collection of coding guidelines for them. These guidelines are particularly significant to compiler developers who determine object code patterns.


#*ADA:: past, present, future
#@Jean Ichbiah
#t1984
#cCommunications of the ACM
#index323097
#%171332
#%321318
#%333244
#!Since the mid-1970s, the U.S. Department of Defense has been laying the groundwork for a major new computer language that may substantially displace FORTRAN and COBOL in the years ahead. With Ada just now starting to be used, Communications felt it would be timely to conduct an interview with Jean Ichbiah, the principal designer of this new language. Ichbiah discusses the evolution of Ada, evaluates its success so far, and speculates on its future.


#*Design of incremental tools for interactive programming environments with application to compiler generators
#@Fahimeh Jalili
#t1982
#c
#index186401


#*Modeling a production system in a recessionary environment
#@Edward C.Y. Lai,Donald E. Schacht
#t1981
#cProceedings of the 14th annual symposium on Simulation
#index555317
#%553744
#!The design of an automatic overhead storage and conveyor system is discussed in this paper. The problem centers on the introduction of a modern material handling system into an existing manufacturing facility. Simulation was originally premised on a production schedule of 25,000 computer systems per day. The value of simulation was demonstrated when recessionary trends reduced initial production projections by 40%.


#*Seed corn session
#@Artie Briggs,Roger Elliott,Orrin Taulbee,Ray Miller,Fred Maryanski
#t1982
#cProceedings of the ACM '82 conference
#index544671
#!There is a consensus in academia and industry that the shortage of computer science faculty is at crisis proportions. The solutions to this crisis involve actions both independent and concurrent. Some of the actions suggested for the academic arena include the offering of salaries competitive with industry wages, marketing the perceived advantages of university appointments as opposed to industrial positions, recruit from industry, provide stronger career counseling to avoid a surplus in esoteric specialties, reaffirm teaching as the primary responsibility, actively develop industrial contracts and acknowledge the validity of industrial research and selection of directions for computer sciences. Industry could help alleviate the problem by rebuilding computer science laboratories with state-of-the-art hardware, provide summer jobs and encourage graduate students to complete degree work before seeking employment. Both groups need to work together to improve channels of communication, to share personnel, seek better job matches and open research centers on both sides.


#*A prestructuring model for system arrangement problems
#@Keiichi Sato,Charles L. Owen
#t1980
#cProceedings of the 17th Design Automation Conference
#index549278
#%545583
#%546232
#%549090
#%555271
#%551054
#%550015
#!A computer supported procedure is presented for using requirement information to prestructure component relationships for a general class of arrangement problems. The procedure generalizes and extends the range of admissable requirement information and reduces the risk of local optimality in arrangement. Three categories of requirements and implicit requirements. These three are integrated and used to organize the components to be arranged into a &ldquo;normative structure&rdquo; in the form of a semi-lattice hierarchy. The normative structure is an approximation of the spatial or temporal arrangement to be generated in real space.


#*The VLSI Design Automation Assistant: Prototype system
#@T. J. Kowalski,D. E. Thomas
#t1983
#cProceedings of the 20th Design Automation Conference
#index545263
#%206294
#%553017
#%547112
#!This paper describes an approach to VLSI design synthesis that uses knowledge-based expert systems to proceed from an algorithmic description of a VLSI system to a list of technology-independent registers, operators, data paths, and control signals. This paper describes how the prototype Design Automation Assistant uses large amounts of expert knowledge to design an architecture with little searching. It also presents the current design of a small microprocessor along with a discussion of improvements currently being added.


#*Cross-Program Simulator for any Microprocessors
#@A. Miyagawa,T. Itajima,T. Takagi,S. Nakano
#t1984
#cProceedings of the First International Conference on Data Engineering
#index371589


#*NLARGEing a z80 Microprocessor
#@John Fitch,Jed Marti
#t1982
#cProceedings of the European Computer Algebra Conference on Computer Algebra
#index259578


#*Selective Update
#@
#t1983
#cIEEE Computer Graphics and Applications
#index336653


#*Educational programs in information systems: a report of the ACM curriculum committee on information systems
#@Jay F. Nunamaker, Jr.
#t1981
#cCommunications of the ACM
#index318794
#%318784
#%323936
#%319577
#!This report describes the status of educational programs in Information Systems at the B.S., M.S., and Ph.D. levels. A survey was conducted during the period June 1977-June 1979 of schools of Business Administration, Departments of Computer Science, Engineering Colleges, and academic units offering programs in Information Systems. A one-page description of each program was then generated according to a standard format. This standardized description was used as a guide to summarize information about each program. The report outlines career opportunities in Information Systems and lists brief descriptions of positions available to graduates of Information Systems programs. The need for an Information Systems program and problem areas with respect to teaching information systems are discussed. The results of the survey include a listing of the most common names for the Information Systems program and an evaluation of the number of programs that met the guidelines established by the Curriculum Committee on Computer Education for Management in 1972 and 1973. A list of institutions by degree level that met the proposed guidelines is presented.


#*The Impact of Network System Architecture on CAD/CAM Productivity
#@David Weisberg
#t1984
#cIEEE Computer Graphics and Applications
#index387262
#!High-level,predictable CAD/CAM performance can be realized with intelligent engineering workstations that are connected in a distributed/networked arrangement. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Determining computer support requirements: Implications for design
#@Sidney E. Harris,Harvey J. Brightman
#t1984
#cACM SIGOA Newsletter
#index552522
#!In this research paper, we discuss a design methodology for determining computer support system needs. We were aware that research work is communications-oriented and highly cognitive in nature, it was necessary to define a profile of the tasks that characterize the key elements of research work. The researcher then selects those tasks that constitute bottlenecks in completing the various research activities. In addition, the modes of support which are essential in completing the tasks are evaluated along several dimensions &mdash; quality, timeliness, dependability, reliability, and cost. This procedure allowed us to define the primary tasks that are consistent barriers in the completion of research work and the modes and nature of support which are inadequately provided as support service capabilities. The design methodology approach was implemented and evaluated using the research faculty at Georgia State University.


#*Why LOGO?
#@Brian Harvey
#t1984
#cNew horizons in educational computing
#index156465


#*A dynamic logic of multiprocessing with incomplete information
#@John H. Reif,Gary L. Peterson
#t1980
#cProceedings of the 7th ACM SIGPLAN-SIGACT symposium on Principles of programming languages
#index249680
#%241688
#%334756
#%330862
#%547330
#%544458
#%555061
#!A crucial property of distributed multiprocessing systems is the lack of complete information by any given process about the states of other processes. The contribution of this paper is a fundamental modal logic, MPL, for multiprocessing with incomplete information. (Section 1.5 gives an informal introduction to MPL; the formal definitions are in Section 2.)By way of this logic, we develop a solid (practical and theoretical) correspondence between distributed multiprocessing and multiplayer games of incomplete information.Fischer and Ladner, [1979] have shown a logspace reduction from the outcome problem for two person games of perfect information to satisfiability of formulas in their propositional dynamic logic (PDL). We provide in Section 3 a log-space reduction from the outcome problem for multiplayer games of incomplete information to satisfiability of formulas in our logic MPL. Although in general satisfiability in out logic is undecidable, the satisfiability problem of formulae with hierarchical visibility structure is shown decidable (using the methods for solving hierarchical games developed in Reif [1979] and Peterson and Reif [1979], and also the model theoretic techniques of Fischer and Ladner [1979] and Pratt [1979b]).At a more practical level, we argue that the game-like semantics of our logic provides a robust paradigm in which to view distributed multiprocessing problems. We apply our logic to describe total correctness properties of multi-process programs with shared variables as well as communicating processes with "handshake"-type message passing.


#*KI-Verfahren zur Unterst&uuml;tzung der &auml;rztlichen Urteilsbildung
#@Wolfgang Wahlster
#t1981
#cGI - 11. Jahrestagung in Verbindung mit Third Conference of the European Co-operation in Informatics (ECI)
#index270994


#*Software quality &equil; test accuracy &times; test coverage
#@M. Ohba
#t1982
#cProceedings of the 6th international conference on Software engineering
#index546117
#!The software quality index, SPQL (Software Product Quality Level), is proposed. The index indicates the software quality based on program test results and consists of two subindices: the test accuracy index and the test coverage index. The test accuracy index can be measured by applying the capture-recapture method. Pseudo defects called control defects are seeded prior to the test and their capture ratio is measured as the ratio of the number of detected defects to the estimated number of detectable defects (estimated by applying the software reliability growth model). Two experimental results are presented and the SPQL is compared with both the ordinary capture-recapture method and the software reliability growth prediction based method. The result indicates that the SPQL is practical.


#*Designing with Programmable Array Logic, 2nd edition
#@Technical Staff of Monolithic Memories Inc.
#t1983
#c
#index237560


#*Future Directions for VLSI and Software Engineering
#@Connie U. Smith,John A. Dallen
#t1984
#cVLSI Engineering: Beyond Software Engineering
#index381232


#*Structured procedure for comparison and selection of computer system designs
#@Antonio Vallone
#t1980
#cProceedings of the May 19-22, 1980, national computer conference
#index71144
#%323219
#%332317
#%325617
#!Decisions about selecting a configuration for a computer system require an unbiased comparison among alternative designs of the system. Several heterogeneous factors need to be considered and their combined effect must be evaluated. The procedure provides a structure to the selection process activities: developing a selection plan, evaluating each design, and ranking the alternatives. It is based on a cost-effectiveness methodology which characterizes each design by the life-cycle cost through a "system cost index" and by the design effectiveness in reaching the system objectives through a "system utility index." The procedure is applicable to the selection of a system, to tradeoff analysis during the system design, and may constitute the framework for the analysis of the risk associated to a design implementation.


#*A study of algorithms for multicriteria decision making
#@Zahid Yahya Khairullah
#t1982
#c
#index199663


#*On refuting the creation theory of computer architecture
#@Kenneth E. Mackenzie
#t1981
#cProceedings of the 8th annual symposium on Computer Architecture
#index545316
#!There is an enormous body of software implemented on the common CPU architectures of today, such as Intel 8080, DEC PDP-11, and IBM System/370. For computer vendors in a profit-seeking environment, future products must not only support this existing software, but also exploit hardware and software technologies that are being, and will be, developed. The computer architect must balance the changes made to support new software with the requirement for cost-effective execution of old software. This problem is independent of the execution speed of the processor and the size of the system of which it is a part. The process of striking a balance between advancement and compatibility will be presented. Strengths and weaknesses of various types of solutions will be described using examples from commercial vendors. Reasons why certain well-known concepts in computer architecture have not been included in the products of commercial vendors will be discussed. The impact of management-level personnel on changes in computer architecture will also be explored. Future computer architectures must be engineered to meet the needs and concepts of those who use and control computers. Therefore, the process of its development within the industry must necessarily occur in orderly and constrained steps, rather than random leaps.


#*Meta-assemblers
#@E. Skordalakis
#t1983
#cIEEE Micro
#index395828
#!Meta-assemblers automate the construction of assemblers. The availability of microcomputers spurred the development of meta-assemblers, and many now exist. They are described and classified here. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*New Products
#@R. Eckhouse
#t1984
#cIEEE Software
#index337694


#*Mp/c: a multiprocessor / multicomputer architecture
#@Ran Ginosar
#t1982
#c
#index188717


#*Control flow, data flow and program complexity
#@Enrique Ivan Oviedo
#t1984
#c
#index200635


#*Evaluation and reliability estimation of distributed architectures for on-board computers
#@Alderico Rodrigues De Paula, Jr.
#t1982
#c
#index191291


#*Computing Point Enclosures
#@V. K. Vaishnavi
#t1982
#cIEEE Transactions on Computers
#index343217
#!Given a set of n rectangles in the plane, the point enclosure query is the question to determine for any point p which rectangles of the set it is contained in. It is the "dual" of the well-known range query in computational geometry. It is shown that the point enclosure query in the plane can be answered in 0(log n + k) time, where k is the number of rectangles reported. The solution makes use of a new data structure, called the S-tree. The data structure can be generalized to obtain an efficient algorithm for the point enclosure problem in d-dimensional space d = 2.


#*Artists interfacing with technology: Basic concepts of digital creation
#@Larry Cuba,Darcy Gerbarg,Andrew Lippman,Dan Sandin
#t1983
#cACM SIGGRAPH Computer Graphics
#index545201
#%182964


#*A programming environment for small business
#@James Leigh,William Leigh
#t1981
#cACM SIGSMALL Newsletter
#index552087
#!In order to provide cost effective applications programming for small businesses, it is necessary to have the proper programming tools, including a structured high level language, file access methods, terminal interface routines, and a data dictionary. The approach to provide a stable and portable programming environment incorporating a consistent set of programming tools is discussed in this paper.


#*An efficient signature scheme based on quadratic equations
#@H. Ong,C. P. Schnorr,A. Shamir
#t1984
#cProceedings of the sixteenth annual ACM symposium on Theory of computing
#index551063
#%327827
#!Electronic messages, documents and checks must be authenticated by digital signatures which are not forgeable even by their recipients. The RSA system can generate and verify such signatures, but each message requires hundreds of high precision modular multiplications which can be implemented efficiently only on special purpose hardware. In this paper we propose a new signature scheme which can be easily implemented in software on microprocessors: signature generation requires one modular multiplication and one modular division, signature verification requires three modular multiplications, and the key size is comparable to that of the RSA system. The new scheme is based on the quadratic equation m &equil; s21 + ks22 (mod n), where m is the message, s1 and s2 are the signature, and k and n are the publicly known key. While we cannot prove that the security of the scheme is equivalent to factoring, all the known methods for solving this quadratic equation for arbitrary k require the extraction of square roots modulo n or the solution of similar problems which are at least as hard as factoring. A novel property of the new scheme is that legitimate users can choose k in such a way that they can sign messages even without knowing the factorization of n, and thus everyone can use the same modulus if no one knows its factorization.


#*An approach to software architecture design specification
#@Chen-Chau Yang
#t1980
#c
#index198510


#*The estimation of large-scale complex system reliability
#@William Arledge Metler
#t1980
#c
#index204416


#*A Sound and Complete Hoare Axiomatization of the Ada-Rendevous
#@Rob Gerth
#t1982
#cProceedings of the 9th Colloquium on Automata, Languages and Programming
#index366471


#*Documentation of a Fortran compiler study of a case
#@Ignacio Canals Navarrete
#t1984
#cProceedings of the 3rd annual international conference on Systems documentation
#index551415


#*On the complexity and axiomatizability of consistent database states
#@Marc H. Graham,Moshe Y. Vardi
#t1984
#cProceedings of the 3rd ACM SIGACT-SIGMOD symposium on Principles of database systems
#index252317
#%231453
#%232301
#%237378
#%242483
#%326368
#%547402
#%553848
#!A database is consistent with respect to a set &sigma; of dependencies if it has a weak instance. A weak instance is a universal relation that satisfies &Sigma;, and whose projections on the relation schemes are supersets of the relations in the database. In this paper we investigate the complexity of testing consistency and the logics that can axiomatize consistency, relative to a fixed set &Sigma; of dependencies. If &Sigma; is allowed to include embedded dependencies, then consistency can be non-recursive. If &Sigma; consists only of total dependencies, then consistency can be tested in polynomial time. The degree of the polynomial can, however, be arbitrarily high. Consistency can be axiomatized but not finitely axiomatized by equality generating dependencies. If embedded dependencies are allowed then consistency cannot be finitely axiomatized by any effective logic. If, on the other hand, only total dependencies are allowed then consistency can be finitely axiomatized by fixpoint logic.


#*Guest Editors' Introduction: Approaches to Knowledge Representation
#@G. McCalla
#t1983
#cComputer
#index348213


#*Comparison of arithmetic functions with respect to boolean circuit depth
#@Helmut Alt
#t1984
#cProceedings of the sixteenth annual ACM symposium on Theory of computing
#index547486
#%81323
#%370894


#*Algebraic Computation of the Solution of Some NonLinear Differential Equations
#@F. Lamnabhi-Lagarrigue,M. Lamnabhi
#t1982
#cProceedings of the European Computer Algebra Conference on Computer Algebra
#index268554


#*A methodology for the analysis of programmer productivity and effort estimation within the framework of software conversion
#@John Diego Fernandez
#t1984
#c
#index185715


#*Fundamental limitations of design algorithms for digital fir filters
#@Lawrence Lee Woodward, Jr.
#t1983
#c
#index191201


#*Software Function, Source Lines of Code, and Development Effort Prediction: A Software Science Validation
#@A. J. Albrecht
#t1983
#cIEEE Transactions on Software Engineering
#index354088
#!One of the most important problems faced by software developers and users is the prediction of the size of a programming system and its development effort. As an alternative to "size," one might deal with a measure of the "function" that the software is to perform. Albrecht [1] has developed a methodology to estimate the amount of the "function" the software is to perform, in terms of the data it is to use (absorb) and to generate (produce). The "function" is quantified as "function points," essentially, a weighted sum of the numbers of "inputs," "outputs,"master files," and "inquiries" provided to, or generated by, the software. This paper demonstrates the equivalence between Albrecht's external input/output data flow representative of a program (the "function points" metric) and Halstead's [2] "software science" or "software linguistics" model of a program as well as the "soft content" variation of Halstead's model suggested by Gaffney [7].


#*Achieving excellence in communications: A key to developing complete, accurate and shared information requirements
#@Robert P. Bostrom,Barry D. Thomas
#t1983
#cThe Proceedings of the Twentieth Annual Computer Personnel on Research Conference
#index549746
#%242052
#!After 25 years of experience building Computer-Based Information Systems, we still seem to have plenty of problems. A major cause of these problems is incomplete and/or inaccurate specifications (i.e., functional specifications or logical design) of requirements. Inadequate specifications reflect ineffective communication transactions between system users and developers. The ability of system developers and users to develop a shared (i.e., clearly understood by both parties), complete and accurate model of the current and desired (i.e., requirements) systems is the key to a successful implementation. Although recently a number of techniques have emerged to facilitate requirements definition (e.g. structured design methodologies), the key remains effective communication between system developers and users. In this paper we are introducing a generalized communication model called PRECISION which quickly and accurately establishes &ldquo;shared&rdquo; models or maps. We also discuss preliminary research findings which describe the success of the PRECISION Model in eliciting information requirements. Our findings indicate that the use of this model would greatly increase the ability of both systems developers and users to create shared, complete and accurate requirement specifications.


#*Methodische Unterst&uuml;tzung an der Systementwicklung
#@August Tepper
#t1983
#cGI - 13. Jahrestagung
#index266360


#*Algorithms for solving some undiscounted stochastic games
#@Jerzy Andrzej Filar
#t1980
#c
#index197804


#*A formalism for the syntactic description and recognition of two dimensional patterns
#@Sarukkai R. Narayanan
#t1981
#c
#index192236


#*A bit map architecture and algorithms for design automation
#@William Thomas Blank
#t1982
#c
#index185833


#*Inferring cognitive focus from students' programs
#@Jean B. Rogers
#t1984
#cACM SIGCSE Bulletin
#index551304
#%202076
#%546160
#!Programs written by students in an introductory Computer Science course were analyzed and patterns abstracted from them. These patterns include style of modularization, choice of constructs, choice of vocabulary, and style of communication through user-interaction and documentation. Individual characteristics of the students, such as their focus on detail or on aggregate conceptual units, their manner of organizing knowledge, and their perception of the purpose of computer programs was compared with the patterns in the students' programs, with tentative relationships being identified.


#*Query optimization II
#@
#t1982
#cProceedings of the 1982 ACM SIGMOD international conference on Management of data
#index231260


#*Combining graphics and a layout language in a single interactive system
#@Stephen Trimberger
#t1981
#cProceedings of the 18th Design Automation Conference
#index547239
#!Layout languages provide users with the capability to algorithmically define cells. But the specification language is so non-intuitive that it is impossible to debug a design in that language, one must plot it. Interactive graphics systems, on the other hand, allow the user to debug in the form in which he sees the design; but severely restrict the language he may use to express the graphics. For example, he cannot express loops or conditionals. What is really needed is a single interactive system that combines layout language and graphic modifications to the data. This paper describes just such a system.


#*The fifth generation project &mdash; a trip report
#@Ehud Y. Shapiro
#t1983
#cCommunications of the ACM
#index324072
#!As part of Japan's effort to become a leader in the computer industry, the Institute for New Generation Computer Technology has launched a revolutionary ten-year plan for the development of large computer systems which will be applicable to knowledge information processing systems. These Fifth Generation computers will be built around the concepts of logic programming. In order to refute the accusation that Japan exploits knowledge from abroad without contributing any of its own, this project will stimulate original research and will make its results available to the international research community.


#*On the use of extendible hashing without hashing
#@Ulrich Bechtold,Klaus Kuspert
#t1984
#cInformation Processing Letters
#index143035


#*FTCS-10
#@
#t1980
#cComputer
#index352623


#*Errors arising from the digital implementation of integration and lead/lag networks
#@Warren A. Murray
#t1984
#cProceedings of the 17th annual symposium on Simulation
#index548643
#!In the simulation of aircraft and other physical systems, the solution of differential equations is required and lead and/or lag networks have to be simulated. Many techniques have been devised for numerical integration when digital computers are used to solve ordinary differential equations. Obviously, since the digital computer uses discrete samples rather than continuous variables, such integration schemes are an approximation to the solution of a differential equation. The question naturally arises to how good the approximation offered by the use of a particular integration algorithm or lead network implementation is. This paper explores the sources and magnitudes of the errors which accrue from the use of different integration algorithms and compares such errors quantitatively.


#*A simulation model for managing state highway maintenance
#@J. F. Huang,S. M. Moussavi,D. R. Drew
#t1983
#cProceedings of the 15th conference on Winter simulation - Volume 1
#index546779
#!A simulation model is developed in this study for managing state highway maintenance. The purpose of this model is to develop causal links between revenue sources and expense demands of highway maintenance so as to suggest how to formulate cost allocation policies and programming strategies that are fair, economic and sustainable.


#*Introduction to computer crime
#@J Bloombecker
#t1984
#cProceedings of the 2nd IFIP international conference on Computer security: a global challenge
#index145643


#*A Family of Multi-version Locking Protocols with No Rollbacks
#@Avi Silberschatz,Gael N. Buckley
#t1983
#c
#index205452


#*Decomposition of 3-d arrays into simple objects
#@Tsaiyun Hong Phillips
#t1984
#c
#index191269


#*The genealogy of theoretical computer science: a preliminary report
#@David S. Johnson
#t1984
#cACM SIGACT News
#index433555


#*Corrigendum: Remark on &ldquo;Algorithm 539: Basic Linear Algebra Subroutines for FORTRAN Usage&rdquo;
#@David S. Dodson
#t1983
#cACM Transactions on Mathematical Software (TOMS)
#index321187


#*Tracing occurrences of patterns in symbolic computations
#@F. Gardin,J. A. Campbell
#t1981
#cProceedings of the fourth ACM symposium on Symbolic and algebraic computation
#index552989
#!A report is made on the present state of development of a project to construct a tracing aid for users of symbolic computing systems that are written in LISP (or, in principle, any similar high-level language). The traces in question are intended to provide information which is primarily in terms that are natural for a user, e.g. on patterns of actions performed on his data, or patterns occurring in the data themselves during the operation of his program. Patterns are described in a syntax which is inspired by SNOBOL.


#*On the use of simulation models to evaluate alternative schedules
#@S. A. Weiner,J. W. Grant,S. L. Pohly,L. Y. Tsui,S. B. O'Reilly
#t1983
#cProceedings of the 15th conference on Winter simulation - Volume 1
#index549557
#!The work presented here today is based on a simulation model of a portion of one of our stamping plants. The presentation begins by briefly describing a typical section of the stamping plant and the scheduling environment in which the plant operates. After describing the reality, the author will then proceed to describe the simulation model built and its verification and scheduling approaches. The presentation concludes with a summary of the results and some general remarks on the importance of scheduling in the factory of the future.


#*On the Multitasking Mechanisms of the Ada Language
#@Avi Silberschatz
#t1980
#c
#index196799


#*Structured design verification: Function and timing
#@C. J. Rimkus,M. R. Wayne,D. D. Cheng,F. J. Magistro
#t1983
#cProceedings of the 20th Design Automation Conference
#index553837
#%331137
#%545722
#%547942
#%548291
#%551454
#%552202
#%555124
#%554475
#%554439
#!Changes in the design verification environment brought about by VLSI design considerations are discussed. Multi-level modelling support is now required of efficient, interactive verification tools. The role of logic simulators in this environment is analyzed, especially in early error removal during the design cycle. A logic simulation system, which has been implemented as part of the IBM Design and Verification system, is described here. Particular attention is paid to the key areas of hierarchy in the design description, user interaction, and simulation speed.


#*Enhancement of system design and simulation via general system theories
#@J. Talavage
#t1981
#cProceedings of the 13th conference on Winter simulation - Volume 1
#index553343
#!My research into system design and simulation indicates at least two areas where General System Theories (GST) can provide insights and support for more detailed efforts. These areas are (I) system design as approached in a hierarchical fashion, and (II) system simulation by relatively naive users for systems that contain complex control or decision structures. As an example of a problem in area I, some designers of large software system have advocated a hierarchical structure to represent the interaction of the components of the software system. Structured Analysis (Ross 1977) is an example of such a methodology. An implicit assumption of such methods is that of closure of certain system properties under interconnection. That is, given functional or realizable components, the series, parallel, or feedback interconnection of such components is assumed to be again a functional or realizable component. An application of GST to this problem area has shown that, for both static (i.e., no concern for time-behavior) and dynamic perspectives, the assumed closure is certainly satisfied in the &ldquo;bottom up&rdquo; direction (i.e., connecting components together). However, in both cases, a well-established GST foundation for closure in a &ldquo;top-down&rdquo; direction (i.e., breaking a system into components) is not yet evident (Talavage). In fact, further developments in GST will be necessary before that issue can be settled.


#*Computerized Slide Making
#@
#t1983
#cIEEE Computer Graphics and Applications
#index337560


#*Development of an autonomous heterogeneous distributed database system: DHIM
#@Haeng Rae Cho,Yoo Sung Kim,Songchun Moon
#t1983
#cMicroprocessing and Microprogramming
#index224954


#*Software engineering applied to computer-aided design (CAD) software development
#@D. Nash,H. Willman
#t1981
#cProceedings of the 18th Design Automation Conference
#index554597
#%329737
#%335365
#%551234
#!This paper briefly discusses software engineering and its relationship to CAD. We look at: &bull; software engineering and the software life cycle &bull; the characteristics of CAD software &bull; a survey of software engineering use in CAD &bull; recommendations for the use of software tools in CAD &bull; recommendations for the development of new software engineering techniques to aid the CAD developer.


#*Integrating the testing, analysis and debugging of programs
#@Leon Osterweil
#t1984
#cProc. of a symposium on Software validation: inspection-testing-verification-alternatives
#index165510


#*ACM president's letter: metamorphosis
#@David H. Brandin
#t1982
#cCommunications of the ACM
#index333982


#*Automatic extension of an ATN knowledge base
#@Gail E. Kaiser
#t1981
#cCommunications of the ACM
#index329378
#%318506
#%534189
#!A computer program is described that acquires much of its knowledge from conversations among operators on Morse code radio networks. The system consists of a learning component and a language understander. The learning component extends a &lsquo;core&rsquo; augmented transition network (ATN) knowledge base by generalizing from sentences taken from scripts of actual conversations. The extensions enable the understanding component to process a large number of sentences that are syntactically and semantically similar to the examples.


#*Hellman Associates Presents Two Intensive State-of-the-Art Tutorial Seminars
#@
#t1980
#cComputer
#index353604


#*University Consortium for Industrial Numerical Analysis (UCINA)
#@S. McKee
#t1981
#cACM SIGNUM Newsletter
#index109534
#!The University Consortium for Industrial Numerical Analysis (UCINA) was formed on the 1st October 1979 with Dr. Sean McKee as the Project Coordinator. UCINA represents a collaborative effort by numerical analysts and interested applied mathematicians of the Universities of Bath, Brunel, Oxford, Reading and Imperial College, with strong support from the Division of Numerical Analysis and Computing Sciences at the National Physical Laboratory, to help with the solution of practical problems in industry and relevant research laboratories and to stimulate new and relevant research in numerical analysis in the Universities. Funding is from the Science and Engineering Research Council (SERC) for three years in the first instance. Dr. McKee has a part-time secretary, a direct line (Oxford 513035) to and from the outside world and travel and secretarial expenses.


#*A linear programming model for optimal computer network protocol design
#@John F. Heafner,Frances H. Nielsen
#t1980
#cProceedings of the May 19-22, 1980, national computer conference
#index57380
#!After providing background information on protocol modeling, we then describe a linear programming model useful in protocol design. This is followed by a description of its use and some comments on its implementation.


#*Open Channel
#@D. A. Feinberg
#t1982
#cComputer
#index353554


#*MPP: a supersystem for satellite image processing
#@Kenneth E. Batcher
#t1982
#cProceedings of the June 7-10, 1982, national computer conference
#index72825
#%549076
#!In 1971 NASA Goddard Space Flight Center initiated a program to develop high-speed image processing systems. These systems use thousands of processing elements (PE's) operating simultaneously to achieve their speed (massive parallelism). A typical satellite image contains millions of picture elements (pixels) that can generally be processed in parallel. In 1979 a contract was awarded to construct a massively parallel processor (MPP) to be delivered in 1982. The processor has 16,896 PE's arranged in a 128-row by 132-column rectangular array. The PE's are in the array unit (Figure 1). Other major blocks in the massively parallel processor are the array control unit, the staging memory, the program and data management unit, and the interface to a host computer.


#*The art of computer conversation: a new medium for communication
#@Brian R Gaines,Mildred L G Shaw
#t1984
#c
#index174117


#*Ans MUMPS in a multi-lingual operating system
#@Hollis V. Arban
#t1980
#cProceedings of the ACM 1980 annual conference
#index551075
#!I have often wondered why the people of the world do not have one common language. Yet my international traveling experiences have shown me that I must accept a multi-lingual world and adjuster to it. Likewise, the computer industry has its reasons, deeply imbedded in the process of evolution, for being multi-lingual. As we move into the decade of the 80's, computer users are not going to find selection of software and hardware any easier than in the 70's. The trade-offs between developing your own custom software and adapting to available products may be even more complex. One thing is certain as we enter the 80's: the decrease in cost of hardware, such as micro systems and user terminals, is rapidly bringing computer power to the home and office for more routine use. As equipment becomes more commonly used, user interface software must adjust to meet the needs of: (a) less sophisticated computer users, and (b) sophisticated users who continually seek more power and versatility at their finger tips. It is into this environment that MUMPS takes its place, as though timely created for a key role as an interface language between the user and his machine.


#*A New Approach to Text and Image Processing
#@Lars Blomberg,Kerstin Frenckner,Bjorn Kruse,Gunilla Lonnemark,Staffan Romberger,Yngve Sundblad
#t1984
#cIEEE Computer Graphics and Applications
#index349629
#!By envisioning an ¿electronic table,¿ it is possible to build a system model that employs the same conceptual tools and operations already used in traditional prepress graphics work.


#*Ambiguity and Decision Problems Concerning Number Systems
#@Karel Culik, II,Arto Salomaa
#t1983
#cProceedings of the 10th Colloquium on Automata, Languages and Programming
#index378331


#*A methodology for the distribution of databases (functional dependency, computer network, integer programming)
#@Mourad Oulid-Aissa
#t1984
#c
#index201431


#*Techniques for Reducing Pen Plotting Time
#@D. P. Anderson
#t1983
#cACM Transactions on Graphics (TOG)
#index314879
#%328601
#%329883
#%333034


#*Optimality of scheduling policy for processing a job stream
#@Hisao Kameda
#t1984
#cACM Transactions on Computer Systems (TOCS)
#index321818
#%313289
#%314574
#%332661
#%331474
#%545052
#%332853
#%324484


#*Predicting cost-of-change: from design structure metrics
#@Dennis George,David Gustafson,Sallie Henry,David Hutchens,Dennis Kafura,John Sayler
#t1982
#cACM SIGSOFT Software Engineering Notes
#index435823
#%205327
#%622654


#*Simulation methodology: Statistical aspects
#@G. Arthur Mihram
#t1983
#cProceedings of the 15th conference on Winter simulation - Volume 1
#index546128
#%335420
#!The present paper, of a tutorial nature, relates the literature of our simulation methodology since the publication of SIMULATION: STATISTICAL FOUNDATIONS AND METHODOLOGY [Academic Press, 1972 (1970)]. Explained will be the expansion of its Principium of Seeding not only to the Fundamental and the General Principia of Seeding but also to a Third Principium of Seeding. Of course, all three principia relate to the procedure(s) by which we simulationists can ensure that we meet the conditions (e.g., independence, experimental error, blocking) of extant statistical methodology, the conditions by which we may properly design and analyse experiments with a stochastic, computerised, and algorithmic (simulation) model. The paper (tutorial) will extend the current literature of statistical and simulation methodology by calling attention to a new class of pseudo-random number generators.


#*External customers enhance university services
#@Patrick J. Gossman
#t1981
#cProceedings of the 9th annual ACM SIGUCCS conference on User services
#index551127
#!The Computing Services Center (CSC) of Wayne State University began to actively seek business from local government, health care, other educational institutions, and research facilities in 1977. The addition of external customers acted as a catalyst, affecting CSC policies and procedures, hardware and software, marketing strategy, and most importantly, attitudes toward customers and ourselves. External customers forced us to examine our service organization from a new perspective, and as a result, helped us find new ways to improve the service we provide to our own University community.


#*Message addressing schemes
#@D. Tsichritzis
#t1984
#cACM Transactions on Information Systems (TOIS)
#index320852
#%316802
#%330779
#%323472
#%327708
#%323027


#*System design of the distributed loop database system (dldbs)
#@Chuen-Pu J. Chou
#t1981
#c
#index188164


#*Structured programming using BASIC
#@Robert N. Cook
#t1980
#cACM SIGCSE Bulletin
#index545729
#%153572
#!With the advent of inexpensive microcomputers, which are mainly programmed in BASIC, and the widespread availability of BASIC on both minicomputers and large scale computers, the advantages of structured programming mandate that the techniques be extended to BASIC. Alternation (IF-THEN-ELSE) as well as repetition (DO WHILE and DO UNTIL) are easily implemented in BASIC. The CASE structure and necessary style conventions to insure readable, easy to write, easy to debug programs are readily implemented in BASIC. Structured pseudocode is used to express algorithms which are then written in structured BASIC.


#*Program Specification Applied to a Text Formatter
#@M. S. Feather
#t1982
#cIEEE Transactions on Software Engineering
#index347594
#!Presentation of the fonnal specification of a small text formatter illustrates an approach to the construction of formal specifications. The key features of this approvach are described, and their beneficial influence on the construction and organization of specifications of tasks, especially those for which no concise descriptions are possible, are discussed. The intent is that in addition to serving as formal descriptions of tasks, such specifications will be of use in the processes of verification, development, and maintenance of their implementations.


#*Science applications II
#@
#t1980
#cProceedings of the 18th annual Southeast regional conference
#index612109


#*GPSS - finding the appropriate world-view
#@James O. Henriksen
#t1981
#cProceedings of the 13th conference on Winter simulation - Volume 2
#index548987
#%246511
#%546560
#!Every simulation language embodies a world-view which heavily influences approaches taken in building models in the language. In most applications for which a given language is used, the world-view of the language enforces a discipline of programming which results in models which are time- and space-efficient, reflecting the usefulness of the language and the appropriateness of language choice by the programmer. For some applications, however, the programming style encouraged by the world-view of a language can lead to programs which are time- and space-inefficient, even though the programs are natural, straightforward solutions to the problem at hand. In such cases, one may be forced to consider alternative languages or to alter one's approach in application of a given language. This paper briefly summarizes the world-view of the GPSS language and gives two examples of systems which, when modelled with conventional GPSS approaches, result in inefficient programs. For each system, two GPSS models are presented: a straightforward model which is inefficient, and a clever model which is efficient. In both cases, the clever models are easily programmed in GPSS and require only marginally more skill on the part of the programmer than do the straightforward models. Once an appropriate alternative to the obvious GPSS world-view is found, the rest is easy. A working knowledge of GPSS is required to read this paper.


#*Expert systems and fuzzy systems
#@Constantin Virgil Negoita
#t1984
#c
#index151818


#*Queueing delays on virtual circuits using a sliding window flow control scheme
#@G. Varghese,W. Chou,A. A. Nilsson
#t1983
#cProceedings of the 1983 ACM SIGMETRICS conference on Measurement and modeling of computer systems
#index548713
#%335516
#%549021
#!A tandem queue model is developed that models the end-to-end delay behavior in networks that employ sliding window flow control. Messages arriving to find the window filled are assumed to be queued outside the network to await their turn to enter. The model is analyzed using a hierarchical decomposition method; the key step entails incorporating the fact that the interdeparture process is not exponentially distributed. End-to-end delay in virtual circuits can then be obtained by modelling a virtual route as a tandem queue [1] using the method of &ldquo;adjusted rates.&rdquo;


#*Fast geometrical algorithms for vlsi design (x-y polygons)
#@Tina Man-Fong Nicholl
#t1983
#c
#index190495


#*Log Depth Circuits For Division And Related Problems
#@P. W. Beame
#t1984
#cProceedings of the 25th Annual Symposium onFoundations of Computer Science, 1984
#index37057
#!We present optimal depth Boolean circuits (depth O(log n)) for integer division, powering, and multiple products. We also show that these three problems are of equivalent uniform depth and space complexity. In addition, we describe an algorithm for testing divisibility that is optimal for both depth and space.


#*Computable Algebras, Word Problems and Canonical Term Algebras
#@Herbert Klaeren,Martin Schulz
#t1981
#cProceedings of the 5th GI-Conference on Theoretical Computer Science
#index265366


#*Aspects of the implementation of sequential graph rewriting systems
#@Philip Michael Dorin
#t1982
#c
#index190281


#*A mathematical typesetting system
#@Mike Folk
#t1980
#cACM SIGAPL APL Quote Quad
#index236620
#%316812


#*VLSI Testing
#@T W. Williams
#t1984
#cComputer
#index168964


#*Practical data-swapping: the first steps
#@Steven P. Reiss
#t1984
#cACM Transactions on Database Systems (TODS)
#index159038
#%119191
#!The problem of statistical database confidentiality in releasing microdata is addressed through the use of approximate data-swapping. Here, a portion of the microdata is replaced with a database that has been selected with approximately the same statistics. The result guarantees the confidentiality of the original data, while providing microdata with accurate statistics. Methods for achieving such transformations are considered and analyzed through simulation.


#*Semantic Considerations in the Actor Paradigm of Concurrent Computation
#@Gul Agha
#t1984
#cSeminar on Concurrency, Carnegie-Mellon University
#index268040


#*A dual processor VAX 11/780
#@George H. Goble,Michael H. Marsh
#t1982
#cProceedings of the 9th annual symposium on Computer Architecture
#index544772
#!This paper describes the design of a dual processor VAX 11/780 built at the Purdue University Electrical Engineering School. It covers the conversion of a standard single processor VAX 11/780 into a dual processor system. A detailed description of hardware modifications performed and a parts list are included. The dual processor VAX is currently running a modified version of the UNIX (Fourth Berkeley Distribution) operating system. Because of licensing restrictions, operating system modifications will only be covered in general. Finally some performance evaluation will be discussed along with the problems encountered.


#*Computers and the myth of neutrality
#@Abbe Mowshowitz
#t1984
#cProceedings of the ACM 12th annual computer science conference on SIGCSE symposium
#index548280
#%318088
#%547977
#!This paper is a critique of the widely held belief that computers are valueneutral instruments whose uses are determined primarily by individual choice. The critique is based on an analysis of the social relations of technology which reveals the operation of three kinds of constraints on human choice: 1) intrinsic features of techology; 2) accidental features such as organizational structure; and 3) techno-cultural paradigms. These constraints will be explained and illustrated with examples from the world of computing. My aim is to show that some uses of computers are more likely than others to be adopted under particular, concrete historical circumstances. For example, the mere fact that computers can be used to improve the quality of work-life or to increase citizen participation in government does not mean that they will be so used. The assumption of value-neutrality is at variance with this observation; it distorts analysis of the social impact of computers and serves partisan interests. To achieve fairness and equity in the design of public policies, we must disabuse ourselves of the mistaken notion of value-neutrality.


#*Distributed Query Optimization: An Engineering Approach
#@Ravi Krishnamurthy,Stephen P. Morgan
#t1984
#cProceedings of the First International Conference on Data Engineering
#index365700


#*Review of "Systems Engineering Models of Human-Machine Interaction by William B. Rouse", North Holland.
#@Kamesh Ramakrishna
#t1981
#cIssue 76 (April 1981)
#index100158
#!The author had three goals for the book: "to emphasize the current state of the art", "to provide a treatment of a highly mathematical topic while avoiding calculus, differential equations, Laplace and Fourier transforms, and so on", and, "to include basic tutorials on the modeling methodologies of interest and thus avoid requiring the reader to consult other basic sources." The book is based on the lecture notes of a graduate course in Industrial Engineering offerred at the University of Illinois to mostly engineering and psychology students. The author feels that the material in the book is "nicely complemented by having students pursue a series of small design projects in which they have to choose among the various available models, resolve measurement problems, and so on."


#*Office Information Systems
#@F. Maryanski
#t1981
#cComputer
#index345996
#!In recent years, computer scientists have recognized the office as a natural environment for the application of computing technology. At the same time, there has been a growing awareness of the need for automated tools to increase the productivity of white-collar workers. In an ideal office environment, machines would assume all the repetitive, mechanical tasks, thus freeing people to concentrate on problems that require creative thinking. The key to providing these office tools is the representation and utilization of information about the business of the office. This special issue of Computer focuses on recent office information systems research that is directed at improving the environment and productivity of office workers.


#*The Origins of Digital Computers: Selected Papers (Monographs in Computer Science)
#@B. Randell
#t1982
#c
#index11408


#*Algorithm 557: PAGP, A Partitioning Algorithm for (Linear) Goal Programming Problems [H]
#@J. L. Arthur,A. Ravindran
#t1980
#cACM Transactions on Mathematical Software (TOMS)
#index327389
#%324419


#*Microcomputers&mdash;acquisition and use
#@M. Lloyd Edwards
#t1983
#cProceedings of the 11th annual ACM SIGUCCS conference on User services
#index546558


#*Immediate files
#@Sape J. Mullender,Andrew S. Tanenbaum
#t1984
#cSoftware&mdash;Practice Experience
#index164054


#*Reversal-Bounded and Visit-Bounded Realtime Computations
#@Andreas Brandstädt,Klaus W. Wagner
#t1983
#cProceedings of the 1983 International FCT-Conference on Fundamentals of Computation Theory
#index570285


#*Reference-based protection
#@Jeffrey Charles Herrmann
#t1983
#c
#index189999


#*Deduction in nonhorn databases (incomplete databases, theorem proving, intelligent databases)
#@Adnan Hussein Yahya
#t1984
#c
#index206203


#*Priority dispatch and aircraft scheduling: A study of strategic airlift scheduling
#@Gerald R. Armstrong,Joseph W. Coleman,Vernon H. Hamilton,Jerry W. Poe
#t1983
#cProceedings of the 15th conference on Winter Simulation - Volume 2
#index550595
#!This paper demonstrates the development of a flexible methodology for examining strategic airlift resource allocation and cargo priority rules. The work was motivated by the need to develop and test heuristic rules to reduce the amount of cargo delivered late in a contingency operation. Priority rules derived from machine scheduling are adapted and used in conjunction with alternative aircraft allocation procedures to determine an improved method for scheduling C-5 aircraft. To test the different scheduling policies in a dynamic environment, a simulation model was developed, using SLAM. Multiattribute utility theory was also used to develop a scalar scoring function (SSF) which effectively combined the response variables into a single value for each policy to facilitate comparison among the various scheduling policies. A full factorial experiment was performed, using five levels of cargo priority rules and three levels of aircraft allocation rules. A one-way analysis of variance was used to compare the mean SSF values for each policy.


#*Emerald: A bus style designer
#@Chia-Jeng Tseng,Daniel P. Siewiorek
#t1984
#cProceedings of the 21st Design Automation Conference
#index550310
#%553388
#!This paper describes the development of a design generator. The design generator takes a behavioral description as its input and generates functional level structures as its output. Designs for two behavioral descriptions are compared with commercial designs. On the average, the total number of gates required for the allocated data paths is 15 percent more than the commercial designs. Mechanisms for exploring alternative designs are provided. The design space for one of the examples is extensively investigated. Limitations of automated design are also discussed.


#*A formula for computing the number of quadtree node fragments created by a shift
#@Clifford A. Shaffer
#t1984
#cPattern Recognition
#index161628


#*EXCL: A circuit extractor for IC designs
#@Steven P. McCormick
#t1984
#cProceedings of the 21st Design Automation Conference
#index544879
#%546991
#%553599
#%547857
#%545830
#!This paper describes EXCL, an automated circuit extraction program that transforms an IC layout into a circuit representation suitable for detailed circuit simulation. The program has built-in, general extraction algorithms capable of accurate computations of interconnection resistance, internodal capacitance, ground capacitance, and transistor sizes. However, where possible, the general algorithms are replaced with simple techniques, thereby improving execution speed. A basic component of the extractor is a procedure that decomposes regions into domains appropriate for specialized or simple algorithms. The paper describes the decomposition algorithm, the extraction algorithms and discusses how they connect with the rest of EXCL.


#*Analysis of a dynamic, decentralized economic model
#@Ennio Silvano Stacchetti
#t1983
#c
#index203143


#*Prototyping and simulation tools for user/computer dialogue design
#@Paul R. Hanau,David R. Lenorovitz
#t1980
#cProceedings of the 7th annual conference on Computer graphics and interactive techniques
#index544797
#%545793
#%545193
#%549882
#!The design and development of user interfaces to interactive computer systems is enhanced by permitting designers to easily express their design concepts in concrete, comprehensive, and comprehensible working models. A set of prototyping and simulation tools has been developed to be used as an integral part of the specification and design process. These include an interactive display building utility and a syntax-driven interactive dialogue controller. The display builder is used to develop initial conceptual snapshots of system display appearance at selected points in the user/system dialogue. The dialogue controller interprets a grammatical description of input tools and system logic, using predrawn and dynamically constructed displays to simulate the external appearance of the desired end system.


#*Anecdotes
#@
#t1983
#cIEEE Annals of the History of Computing
#index412523


#*Beyond war: implications for computer security and encryption
#@M E Hellman
#t1984
#cProceedings of the 2nd IFIP international conference on Computer security: a global challenge
#index183078


#*Evolutionary development
#@Tom Gilb
#t1981
#cACM SIGSOFT Software Engineering Notes
#index434470


#*An Algorithm for the Execution of Limited Entry Decision Tables in ALGOL 68
#@D. C. Ince
#t1980
#cIssue 45 (January 1980)
#index100824


#*A novel design for a natural language text processor
#@Steven Carl Bankes
#t1980
#c
#index203680


#*Program visualization: Graphics support for software development
#@David Kramlich,Gretchen P. Brown,Richard T. Carling,Christopher F. Herot
#t1983
#cProceedings of the 20th Design Automation Conference
#index548898
#%549200
#%552848
#!This paper reports on the design and implementation of a program visualization (PV) environment, intended to offer the user an integrated graphics programming support system. The PV environment will capitalize on recent progress in the graphical representation of information, to provide designers and programmers with both static and dynamic (animated) views of systems. PV is currently being implemented to support programming in C, although large portions of the system are independent of the software development language. In this paper we provide an overview of the PV environment, along with a detailed discussion of the technique used to instrument programs.


#*Treatment of Big Values in an Applicative Language HFP
#@Takuya Katayama
#t1983
#cProceedings of RIMS Symposium on Software Science and Engineering
#index379828


#*Computers and democracy: a critique of Parslow
#@H. L. Berghel,D. L. Sallach
#t1983
#cACM SIGCAS Computers and Society
#index307992
#%300953
#%303163
#%305676
#%325970


#*Telephone techniques for computer consulting
#@John E. Bucher
#t1981
#cProceedings of the 9th annual ACM SIGUCCS conference on User services
#index548839
#!Telephone consulting becomes very important when academic computing moves into a distributed environment. This is especially true in network consulting where end users are often hundreds of miles from the main site. In order to maintain a good consulting service in this type of situation, consultants need to develop and use effective telephone techniques. The goal is to provide efficient professional service with as few misunderstandings as possible. A wealth of knowledge can be locked behind poor telephone communication techniques. Besides presenting some general rules and guidelines of telephone techniques this paper presents methods for probing the caller for the right question, getting and holding attention, terminating a call graciously, handling complaints, &ldquo;attending behavior&rdquo; in telephone listening, and others. Since most user services personnel are already familiar with the problems of telephone consulting, this presentation is intended to sharpen skills and to provide a forum in which ideas can be discussed.


#*A semantics of multiple inheritance.
#@Luca Cardelli
#t1984
#cProc. of the international symposium on Semantics of data types
#index159912


#*Requirements and architecture of a cam-oriented cad system for design and manufacture of mechanical parts
#@Farhad Arbab
#t1982
#c
#index190744


#*A dynamic file organization model
#@R H. Davis,P Coumpas
#t1984
#cThe Computer Journal
#index171205


#*Experiments using interactive color raster graphics for CAD
#@Abe Shliferstein
#t1982
#cProceedings of the 19th Design Automation Conference
#index552779
#%153803
#%551378
#!Color raster graphics is being incorporated into CAD systems for printed circuit board (PCB) design. An interactive prototype CAD system developed as an experimental base is described, along with color graphics research using this prototype. Areas investigated included the generation and display of complex PCB's, the display of depth information using &ldquo;2 1/2 dimensional&rdquo; techniques, performance measurements on color raster systems, possibilities for new on-line design audit techniques, color graphics primitives, hardware and software architectures, and human factors considerations.


#*Lamport's algorithm reconsidered
#@H. Neil Singleton,Ronnie G. Ward
#t1982
#cProceedings of the ACM '82 conference
#index550159
#%314817
#%322589
#!A modification to Lamport's algorithm that eliminates busy waiting is presented. A processor that is waiting to enter its critical section is freed to do other useful work. The algorithm is modified further to recognize and honor priorities.


#*A Simple Class of Algorithmic Specifications for Abstract Software Modules
#@Herbert Klaeren
#t1980
#cProceedings of the 9th Symposium on Mathematical Foundations of Computer Science
#index368007


#*CCITT standardization for digital facsimile
#@T. L. McCullough
#t1980
#cProceedings of the May 19-22, 1980, national computer conference
#index66049
#!In November, 1979, the CCITT Study Group XIV met to complete, among other items, several years of work on the Recommendations defining Group 3 digital facsimile. This paper reviews the results of this work in terms of technical implication, terminal features, and facsimile services. In particular, CCITT Recommendations T.4 and T.30 are discussed. (These Recommendations will be finalized by the CCITT in Geneva, November, 1980.)


#*Intelligibility enhancement of voice-interfered speech signals
#@Brian Allen Hanson
#t1983
#c
#index194956


#*Alternate optimal solutions
#@C. A. Haverly
#t1980
#cIssue 28 (January 1980)
#index576541
#!The behavior of LP models is a topic in which I have had some interest in recent years. I speak of behavior of the model itself, as distinct from the behavior of the algorithm, the solution path or the accuracy of the model representation. I have submitted several papers on this topic before to the SIGMAP bulletin (1, 2, 3). In this paper I consider model behavior as reflected in alternate optimal solutions.


#*Pseudo-oracles for non-testable programs
#@Martin D. Davis,Elaine J. Weyuker
#t1981
#cProceedings of the ACM '81 conference
#index545476
#%148046
#%316266
#%331887
#!The most commonly used method of validating a program is by testing. The programmer typically runs the program on some test cases, and if and when they run correctly, the program is considered to be correct. We know that many difficult problems are associated with testing. One such problem is that it is a fundamental part of the testing process to require the ability to infer properties of a program by observing the program's behavior on selected inputs. The most common property that one hopes to infer through testing is correctness. But unless the program is run on the entire input domain, there are infinitely many programs which produce the correct output on the selected inputs, but produce incorrect output for some other element of the domain.


#*Interface design and multivariate analysis of UNIX command use
#@Stephen José Hanson,Robert E. Kraut,James M. Farber
#t1984
#cACM Transactions on Information Systems (TOIS)
#index321909
#%162207
#%547068
#%333626
#%548117
#%549613


#*Knowledge representation and natural language understanding
#@Daniel Coulon
#t1982
#cIssue 80 (April 1982)
#index100144
#!It is not necessary and it is even not advisable to translate the sentences into an internal representation [6]. It is preferable to keep them as they are, and to interpret them at variable depth. This concept consists of 3 aspects [4]: progressive description, multiplicity of inference strategies, and evaluation on demand of partial results.


#*A test generation and test set evaluation system for sequential logic networks
#@William Russell Read, Jr.
#t1980
#c
#index200077


#*Requirements/design debugging: session summary
#@Peter Bates
#t1983
#cACM SIGSOFT Software Engineering Notes
#index433904
#!This session was essentially a continuation of the earlier session on Knowledge-Based systems. The discussion proceeded along two dimensions. One is the paradigm used to, in some sense, debug high-level specifications. This is further broken into the 'current' and the 'operational specifications' paradigms. The other dimension is one of techniques for implementing these views. This dimension also has only two aspects, current techniques and knowledge-based techniques. The plan for the session was to introduce the technologies that may or may not exist to support these capabilities followed by a debate on these methods. There are four areas to be discussed in terms of technology---symbolic evaluation, fault analysis, behavior expectations and natural language explanations.


#*Information resource management theory training
#@John F. Schrage
#t1981
#cProceedings of the ACM '81 conference
#index547392
#!As with most topics in the information systems area, there is generally a problem with acceptance in educating people about new areas. One of the newest areas for information systems is that of IRM, Information Resource(s) Management. The term has been noted with the &ldquo;R&rdquo; being resource or resources thus resulting in a splitting of fine points to create, for some, two distinct areas. Discussion has resulted in government, business, and education as to what is IRM with the term being analyzed during the last two years in two major information systems curriculum studies.


#*Privacy: a survey
#@Paul Armer
#t1981
#cACM SIGCAS Computers and Society
#index309551
#!(This survey of the privacy issue is concerned only with the computer related aspects of privacy and does not touch upon non-computer related topics like wire-tapping, psychological testing, etc.)


#*Toward computational description of written Polish: Warsaw University, Poland
#@Janusz S. Bien,Stanislaw Szpakowicz
#t1982
#cIssue 79 (January 1982)
#index99812
#%181387
#!We present briefly the activity of the Warsaw University. computational linguistics team. The team is an informal group that consolidates around a seminar at the Institute of Informatics, coordinated by Prof. Zygmunt Saloni. The group adheres to a "bootstrapping methodology": we focus on developing surface linguistic descriptions which should allow the creation of efficient tools for low-level processing of natural language texts, in the hope that it will pay when more sophisticated problems are attacked.


#*Proceedings of the 1983 ACM SIGSMALL symposium on Personal and small computers
#@
#t1983
#cSymposium on Small Systems
#index551955


#*The infotex service
#@Tony Allsop
#t1984
#cAdvances in data communications management: Vol. 2
#index164593


#*Transforming cyclic schemas into trees
#@N. Goodman,O. Shmueli
#t1982
#cProceedings of the 1st ACM SIGACT-SIGMOD symposium on Principles of database systems
#index253329
#%553135
#%551958


#*Program verification using Ada
#@Andrew D. McGettrick
#t1982
#c
#index461872


#*A Tour Through Cedar
#@W. Teitelman
#t1984
#cIEEE Software
#index338724
#!This lively walk through a sophisticated programming environment is taken from a videotaped demonstration of the system. There is no need to adjust your set.


#*Review of "Discourse production: a computer model of some aspects of a speaker" by Anthony Davey. Edinburgh Univ. Press 1978.
#@
#t1980
#cComputational Linguistics
#index313510


#*Towards a family of languages for the design and implementation of machine architectures
#@Subrata Dasgupta,Marius Olafsson
#t1982
#cProceedings of the 9th annual symposium on Computer Architecture
#index547535
#%178360
#%321876
#%331755
#%619912
#%551146
#%551516
#%607120
#!In recent years, increases in complexity of hardware/firmware systems, and the concern for systems reliability have resulted in growing interest in methodologies and tools for the design, description and verification of computer systems. A vital component of any such design methodology is the language used for representing the design. In the case of particularly complex systems the design process may involve a succession of stages each of which represents the system at a particular level of abstraction. In such situations several languages may be required, each suited to a particular level of abstraction. We present here, one such family of languages, consisting at present of two members, S*A, an architectural description language, and S*, a high level microprogramming language schema. These closely related (&ldquo;kin&rdquo;) languages may be used collaboratively for the systematic, top-down development of an architecture, down to the microcode level. The resulting descriptions of the architecture provide, in addition, a complete unified document of the multilevel design process.


#*Generalized access-protocols for multi-access channels
#@Yaron Israel Gold
#t1982
#c
#index189646


#*Fault-tolerant algorithms for multiple processor systems
#@Kuang-Hua Huang
#t1983
#c
#index193977


#*On the norm of combining alias matrices of balanced fractional 2m factorial designs of resolution 2:6J+1 derived from simple arrays
#@Masahide Kuwada
#t1984
#cUtilitas Mathematica
#index180837


#*Number of Quantifiers is Better than Number of Tape Cells
#@Neil Immerman
#t1980
#c
#index111017
#!We introduce a new complexity measure, $QN[f(n)]$, which clocks the size of sentences from predicate calculus needed to express a given property. Techniques from logic are used to prove sharp lower bounds in the measure. These results demonstrate space requirements for computations and may provide techniques for separating Time and Space complexity classes because we show that: $NSPACE [f(n)] \subseteq QN[f(n)^{2}/log(n)] \subseteq DSPACE[f(n)^{2}].$ The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A wire routing scheme for double-layer cell arrays
#@Guy Dupenloup
#t1984
#cProceedings of the 21st Design Automation Conference
#index547724
#%546655
#%550013
#%550925
#%551009
#%554897
#%551907
#%552599
#%554258
#%549912
#!A channel model for routing double-layer cell arrays is presented. A switch-box is defined as an overlapping area of a horizontal channel and a vertical channel. Along the sides of switch-boxes, dynamic terminals are generated by the loose router and moved by the final router. A channel router, that is an extension of the &ldquo;Dogleg Channel Router&rdquo; introduced by D.N. Deutsch in 1976, is described.


#*Hardware protection against software piracy
#@Tim Maude,Derwent Maude
#t1984
#cCommunications of the ACM
#index317200
#%176082
#%322878
#!A system that prevents illicit duplication of proprietary software is suggested. It entails the customization of the programs for each computer by encryption. The use of a public key cryptogram for this purpose means that anyone can customize programs, but neither other programmers nor the people having complete access to the target computer can obtain copies that will run on other machines. A possible implementation of the system is considered in some detail. It is based on a hardware security unit that is attached to the computer and that decrypts and obeys some parts of the program.


#*IEEE Computer Society
#@
#t1983
#cIEEE Transactions on Computers
#index336489


#*Integrated program measurement and documentation tools
#@Anne Schroeder
#t1984
#cProceedings of the 7th international conference on Software engineering
#index546726
#%303868
#%310656
#%326409
#%329759
#%364587
#%436042
#%544563
#%551792
#%547610
#%551344
#%547602
#%622654
#!This paper describes an attempt to integrate the collection and the efficient utilisation of measurements in the development and the use of programs. The work presented consists in three parts: - the design of both static and dynamic measurement tools, - examples of data processing on measurements collected on a sample of Pascal programs, - the design of a quantitative documentation of a program, which is automatically built as measurements are collected. The first and third steps have been developed inside an existing programming environment, Mentor, and we shall discuss the advantages we found in integrating the tools in such an environment.


#*An Experiment in senior staff working alongside student consultants
#@John Thornton,Agnes Hoey
#t1984
#cProceedings of the 12th annual ACM SIGUCCS conference on User services
#index547394
#!This past Spring, Syracuse University Academic Computing Services (SUACS) had all staff members spend time working with our users at the AID Desk. The staff has progressed from a initial reluctance to an enthusiastic environment with enhanced communications, new ideas, and new learning experiences. The paper discusses the beginnings of our experiment, the reactions of the participants, and some of the resulting ideas.


#*How to connect stable memory to a computer
#@R. M. Needham,A. J. Herbert,J. G. Mitchell
#t1983
#cACM SIGOPS Operating Systems Review
#index121043
#%117096


#*Surveyor's Forum: Generating Solutions
#@Douglas J. Keenan
#t1981
#cACM Computing Surveys (CSUR)
#index320606
#%319884


#*Proceedings of the 1981 ACM SIGMETRICS conference on Measurement and modeling of computer systems
#@
#t1981
#cJoint International Conference on Measurement and Modeling of Computer Systems
#index554305


#*Knowledge engineering: the applied side of artificial intelligence
#@Edward A. Feigenbaum
#t1984
#cProc. of a symposium on Computer culture: the scientific, intellectual, and social impact of the computer
#index174031


#*Verification of attribute grammar
#@Takuya Katayama,Yutaka Hoshino
#t1981
#cProceedings of the 8th ACM SIGPLAN-SIGACT symposium on Principles of programming languages
#index254785
#%199584
#%324137
#%552630
#%544585
#%370744
#!Verification of attribute grammar is discussed. As is widely recognized, attribute grammar of Knuth [8] is a very convenient device to describe semantics of programming languages, especially in automating compiler construction. Many efforts have been made to obtain efficient evaluators for attribute grammar [1,3,4,5,7,10] so that efficient compilers may be produced from the semantic specifications written in the attribute grammar.There is another important problem about the semantic specifications. This is how to verify the correctness of the specification and is essential in ascertaining the correctness of produced compilers. In contrast with the evaluation problem, this has not been studied well and only a few partial results have been reported up to now [2,9].In this paper we propose a verification procedure for proving the correctness of attribute grammar, which is applicable to the wide class of attribute grammars called absolutely noncircular ones [7]. Our method can be extended to accept any noncircular attribute grammar since it is shown that any noncircular attribute grammar is transformed into an equivalent absolutely noncircular one [5].Our verification procedure utilizes dependency relations among attributes and verification is performed by induction based on this order relation, according to which attributes are evaluated. This procedure consists of (1) assigning assertions to relevant pairs of a nonterminal symbol and a parallelly evaluable subset of its attributes, (2) generating a set of verification conditions for each production rule with the aid of dependency graph of the rule and (3) proving the verification conditions. Of course, verification is performed production-rule-wise.Our method can accept attribute grammars which contain both synthesized and inherited attributes and handle them in a well-formed way. This contrasts to the previous works where only the synthesized case is considered [2] or there seems no general and formal descriptions about how to verify general attribute grammars [9].In this paper we first give necessary definitions and notations for attribute grammar and then propose a verification procedure to prove its correctness. After giving some examples of verification, we establish consistency and completeness of our procedure.


#*Quality level and fault coverage for multichip modules
#@K. E. Torku,C. E. Radke
#t1983
#cProceedings of the 20th Design Automation Conference
#index547554
#%544517
#!A relationship between the quality level of a multichip module package and test coverage is established. A fault model for each stage of assembly of the package is assumed and the contribution of each of these stages to the quality level is assessed to produce the required relationship to test coverage achieved through test generation programs.


#*Multiple-valued combinational logic design using theorem proving
#@Witold Stanislaw Wojciechowski
#t1980
#c
#index186579


#*Assessing a class of software tools
#@M. A. Hennell,D. Hedley,I. J. Riddell
#t1984
#cProceedings of the 7th international conference on Software engineering
#index551827
#!The roles and capabilities of LDRA software Testbeds and their appropriate environments have been described in a number of papers [1,2]. The way in which management uses the tools as elements of a controlled software development environment is described in [3]. The principal benefits of such use are that management has the assurance that software development standards are enforced, and has reliable information concerning project status. The explicit standards enforced by the use of these tools are described in detail in [2]. One class of these standards is that of test effectiveness, which is measured primarily through three test effectiveness metrics reinforced by a code auditing capability. This paper attempts to quantify the benefits of using such a software Testbed in providing assurance of the absence of program errors. The attempt is made from two viewpoints, the theoretical and the experimental. The theoretical aspect is important because the practical use of a tool may fail to demonstrate that the tool can be a powerful detector of a class of errors simply because no errors of that type were present in the software sample validated. Finally the paper attempts to summarise some of the experiences gained through the use of the tools over a twelve year period.


#*On the Composition and Decomposition of Assertions
#@Glynn Winskel
#t1984
#cSeminar on Concurrency, Carnegie-Mellon University
#index256193


#*Graceful preemption for multi-link link layer protocols
#@M. Wm. Beckner,T. J. J. Starr
#t1983
#cProceedings of the eighth symposium on Data communications
#index547527
#!This paper discusses a powerful priority mechanism that can be used on a physical communication medium supporting multiple, independent, logical data links. This scheme allows a high priority message to immediately interrupt a lower priority message which is in the process of being transmitted, and yet will not require the retransmission of the first part of the lower priority message; hence, the term graceful preemption. Graceful preemption may be extended to furnish multiple priority levels similar to existing processor interrupt structures which implement multiple levels. This protocol may serve a single processor which handles several different processes, or several independent stations that share a common bus. Hence, priority levels can be enforced without the need for a centralized bus &ldquo;master&rdquo; or &ldquo;arbitrator&rdquo; unit. As an example, the application of graceful preemption to the Integrated Services Digital Network (ISDN) link access procedure, LAPD, is discussed.


#*Contrasts in physical design between LSI and VLSI
#@William R. Heller
#t1981
#cProceedings of the 18th Design Automation Conference
#index547574
#%544869
#%547325
#%547565
#%553482
#%554378
#!In the last five years, there has been rapid growth in logic and memory chip circuit density. The number of different digital processors and the typical size of such processors has also grown. With all this growth, alternatives in VLSI design style as well as packaging have to be considered. These consist, on the one hand, of powerful automated placement and wiring routines, indispensable on large regular package images, and, on the other, of techniques facilitating rapid, interactive adaptation of functional logic design to the layout and interconnection of &ldquo;macros&rdquo; on large chips. Some results from study of each method are presented.


#*Software reliability&mdash;theory and practice
#@Pei Hsia
#t1984
#cComputers and Electrical Engineering
#index142784


#*Kinematic presentation of visual images to adults: differential affect of moving versus static presentation modes on visual retention (recognition memory)
#@Casimir Joseph Glodek
#t1984
#c
#index187947


#*Methoden der Mensch-Machine-Kommunikation durch Einsatz graphischer Ein/Ausgaben
#@Jürgen Grosche
#t1981
#cFachtagung Proze&szlig;rechner 1981, GI, VDI/VDE-GMR, KfK
#index277655


#*Special Message
#@D. H. Brandin
#t1983
#cComputer
#index350764


#*Planning for software tool implementation: experience with Schemacode
#@Pierre N. Robillard,Réjean Plamondon
#t1982
#cProceedings of the June 7-10, 1982, national computer conference
#index55025
#%343483
#%336641
#!The interactive tool called Schemacode assists users in the development, documentation, and structured coding of programs. Its unique property of word-graphic type of communication can be of great help during the main phase of program development: defining the control structure of the program at different levels of refinement. A Schematic Pseudocode which represents the control skeleton of the program constitutes the very-high-level language input. Construction of the schematic structure and its translation into an appropriate language are the two main functions of Schemacode. These transformations involve editing, formatting, cross referencing, and structure checking. The use of a formal language appears only at the end of the development, after the logic of the problem has been solved. A real advantage provided by Schemacode is that every program developed has a unique up-to-date documentation and listing. However, modest changes are made in the way programming is done. An integration plan is specifically designed to minimize disturbances in the work milieu where Schemacode is to be implemented and is thus effected in three phases: creation first of a virtual environment, then of linked environment, and finally of an integrated environment. The virtual environment promotes the introduction of the methodology, the linked environment favors an interactive process for learning about the tool, and the integrated environment leads the new users to autonomous control of Schemacode.


#*Solving Ordinary Differential Equations with Discontinuities
#@C. W. Gear,O. Osterby
#t1984
#cACM Transactions on Mathematical Software (TOMS)
#index320305
#%315261


#*Concurrent Transmissions in Broadcast Networks
#@Charles J. Colbourn,Andrzej Proskurowski
#t1984
#cProceedings of the 11th Colloquium on Automata, Languages and Programming
#index381567


#*Weak and Strong Fairness in CCS
#@Gerardo Costa,Colin Stirling
#t1984
#cProceedings of the Mathematical Foundations of Computer Science 1984
#index378913


#*Surveyor's Forum: An Update on SynthaVision
#@Herbert A. Steinberg
#t1981
#cACM Computing Surveys (CSUR)
#index333493


#*A tool that detects plagiarism in Pascal programs
#@Sam Grier
#t1981
#cProceedings of the twelfth SIGCSE technical symposium on Computer science education
#index551994
#%193000
#%622654
#!Plagiarism has become a problem in introductory Computer Science courses. Programmed assignments can be copied and transformed with little human effort. A pertinent recommendation has resulted from this realization; an on-line system to detect programs that are &ldquo;too similar&rdquo; and hence suspected of plagiarism should be developed [4]. This paper discusses such a system for Pascal programs.


#*A Systolic Architecture for the Singular Value Decomposition
#@Richard P. Brent,Franklin T. Luk
#t1982
#c
#index118889
#!We propose a systolic architecture for computing a singular value decomposition of an m x n matrix, where $m \geq n$. Our algorithm is stable and requires only $O(mn)$ time on a linear array of $O(n)$ processors. Extensions to algorithms for two-dimensional arrays are also discussed. Key Words and Phrases: Systolic arrays, singular value decomposition, Hestenes method, threshold Jacobi method, real-time computation.


#*The use of adaptive mechanisms for selection of search strategies in document retrieval systems
#@W. Bruce Croft,Roger H. Thompson
#t1984
#cProc. of the third joint BCS and ACM symposium on Research and development in information retrieval
#index162405


#*New variants of the quadrant interlocking factorisation (Q.I.F.) method
#@J. Shanehchi,D. J. Evans
#t1981
#cProceedings of the Conference on Analysing Problem Classes and Programming for Parallel Computing
#index265257


#*Toward a computational theory of pragmatics--discourse, presupposition, and implicature
#@Takao Gunji
#t1981
#c
#index189582


#*Number theoretic processors
#@Alan Huang
#t1981
#c
#index203607


#*Real time graphic simulation of visual effects of egomotion
#@Patrick Peruch,Viola Cavallo,Christian Deutsch,Jean Pailhous
#t1984
#cProc. of the 2nd European conference on Readings on cognitive ergonomics - mind and computers
#index161451


#*Computer-Aided Design of Plant Electrical Systems
#@F. T. Dawson
#t1982
#cIEEE Computer Graphics and Applications
#index336604
#!The electrical system is the crucial final stage of plant design. CAD relieves time pressure and yields significant savings of money.


#*On the use of the linear assignment algorithm in module placement
#@Sheldon B. Akers
#t1981
#cProceedings of the 18th Design Automation Conference
#index550895
#%325667
#%544567
#%548855
#!This paper examines the application of the computationally powerful linear assignment algorithm to the placement problem. A brief description of the algorithm is given, followed by a discussion of its use with various problem constraints, for improving existing placements, and in a constructive-initial placement procedure. Several examples are included.


#*A hierarchical bit-map format for the representation of IC mask data
#@James A. Wilmore
#t1980
#cProceedings of the 17th Design Automation Conference
#index548191
#%544616
#%545753
#%548089
#%549035
#%551855
#!An alternative representation to the usual outline description of geometric entities for IC mask artwork is described. Rather than identifying opaque areas of a mask by individual shape outlines as described by their corners' coordinates, both the opaque and transparent areas of the design are represented by 1' s and 0's respectively in a grid pattern or &ldquo;bit map&rdquo; of the entire mask plane. A bit-map representation is well suited to many computer design aids which deal with IC layout data. Artwork output programs which require a &ldquo;MERGE&rdquo; operation on all shapes of each mask benefit from this data format since it already contains the merged version of each mask's geometric entities. The bit-map format especially promises to increase the operational efficiency of Boolean comparisons of various mask levels as performed by artwork analysis programs for locating design rule errors and for identifying circuit elements directly from the masks. A hierarchical scheme for describing the bit patterns of a mask efficiently is presented which limits the memory requirements of this data format to a size proportional to the usual outline description. Consequently the bit-map representation can be used not only in those computer aids where it supports program functions very well, but also as the central data format for a CAD system.


#*Botanical Tree Image Generation
#@Masaki Aono,Tosiyasu Kunii
#t1984
#cIEEE Computer Graphics and Applications
#index345457
#!It may be true, as the poet said, that ¿...only God can make a tree,¿ but through geometric modeling a computer graphics system can produce a remarkable likeness.


#*Filing and printing services on a local-area network
#@P. Janson,L. Svobodova,E. Maehle
#t1983
#cProceedings of the eighth symposium on Data communications
#index548979
#%320315
#%330779
#%333770
#%544976
#%548446
#!This paper describes the design and implementation of filing and printing services in a distributed system based on a token-ring local-area network. The main emphasis is put on the communication aspects of the client/server scenario: roles of a client and a server in a communication protocol, and the integration of communication protocols with applications.


#*Satellite and Computer Communications
#@
#t1983
#cComputer
#index349817


#*Interconnection networks and compiler algorithms for multiprocessors
#@Kyungsook Yoon Lee
#t1983
#c
#index193529


#*Simplification of multiple-output boolean functions using an extension of the directed search algorithm
#@Sharon Ruth Perkins
#t1980
#c
#index195604


#*The Transient Behaviour of Networks with Infinite Server Nodes
#@J. P. C. Blanc
#t1984
#cProceedings of the Tenth International Symposium on Computer Performance Modelling, Measurement and Evaluation
#index274337


#*How to define a language using PROLOG
#@Chris D.S. Moss
#t1982
#cProceedings of the 1982 ACM symposium on LISP and functional programming
#index553369
#%148046
#%203250
#%313930
#%331016
#!There have been many papers, conferences and theses concerned with the task of defining programming languages. Yet, twenty years after McCarthy's (1962) seminal paper there is still no widely accepted method which will deal with all parts of a language clearly and concisely. Everyone who invents a language writes a BNF definition and the more theoretically minded will attempt a denotational semantics. For a complete definition of the syntax, attribute grammars are gaining increasing acceptance while more practically minded language designers will use one of the compiler definition languages such as Meta4 or CDL. At the same time as the PROLOG language was defined, a grammar system called Metamorphosis Grammar (M-grammar for short) was invented by Colmerauer (1978). This has been shown to be suitable (Moss 1981) for defining both the full syntax and semantics of programming languages. The present paper attempts to give an overview of this method in the form of a practical guide to writing a language definition. This includes the context sensitive syntax, and semantics using denotational, relational or axiomatic methods. This definition is not simply of theoretical interest. Since PROLOG is a practical programming language, though with a sound theoretical basis (Warren, Pereira, Pereira 1977), the definition can be used as a prototyping tool for a new language. With the addition of plan-formation techniques one might form a PROLOG based compiler generator and by adding other axioms form a program proving system.


#*Anti-aliased line drawing using brush extrusion
#@Turner Whitted
#t1983
#cACM SIGGRAPH Computer Graphics
#index550040
#%153803
#%188642
#%201733
#%316812
#%319751
#%545884
#%547591
#%549294
#%551963
#%552951
#!This algorithm draws lines on a gray-scale raster display by dragging a &ldquo;brush&rdquo; along the path of the line. The style of the line is determined by the properties of the brush. An anti-aliasing calculation is performed once for the brush itself and thereafter only a trivial additional operation is needed for each pixel through which the brush is dragged to yield an anti-aliased line. There are few constraints on the size, shape, and attributes of the brush. Lines can be curved as well as straight, It is possible to produce lines with a three dimensional appearance.


#*Finding Euler tours in parallel
#@Mikhail Atallah,Uzi Vishkin
#t1984
#cJournal of Computer and System Sciences
#index158342


#*The software development facility approach to improved software development
#@David Walter Johnson
#t1981
#c
#index200773


#*Jericho: A professional's personal computer system
#@Norton R. Greenfeld
#t1981
#cProceedings of the 8th annual symposium on Computer Architecture
#index549272
#%545129
#%546043
#%547237
#%547941
#%550068
#!Jericho is a reactive computing engine capable of supporting advanced high user-intensity applications systems. It has four primary architectural characteristics: 1. A user-dedicated computing environment 2. Direct execution of high-level programming languages 3. High bandwidth communication between user and system 4. High bandwidth communication between user-support machines and the other machines the task environment. Each of these architectural components will be described further, followed by a discussion of the Jericho hardware.


#*LISP programming
#@I Danicic
#t1983
#c
#index145270


#*CADAS: A tool for designing reliable embedded software and supporting testing 'in the large'
#@M. A. J. Burford,Fevzi Belli
#t1984
#cFehlertolerierende Rechensysteme, 2. GI/NTG/GMR-Fachtagung
#index260887


#*Guest Editorial
#@
#t1981
#cIEEE Transactions on Software Engineering
#index343434


#*System facilities for CAD databases
#@Charles M. Eastman
#t1980
#cProceedings of the 17th Design Automation Conference
#index545819
#%240173
#%307418
#%313930
#%326368
#!In this paper, an attempt is made to lay out the special needs of design databases, as compared to the facilities provided in conventional database systems now commercially available. The paper starts from a point of commonality and focusses on the limitations and shortcomings commonly found in current database systems. It is impossible and unwise to make universal statements about DBMS capabilities. Instead, the goal is to identify those special features that, by their capability, provide distinctions beyond the general notions of speed and ratio of logical size to physical size.


#*Concurrent Reading While Writing
#@Gary L. Peterson
#t1983
#cACM Transactions on Programming Languages and Systems (TOPLAS)
#index329642
#%318194
#%320699
#%554576
#%334601
#%330671
#%546039


#*An efficient computer model and simulation of synthetic neuronal rings using a two-dimensional color map display (cybernetics, neurophysiology)
#@William Jefferson Neal
#t1984
#c
#index205800


#*Solving large vehicle routing and scheduling problems in small core
#@Lawrence Bodin
#t1983
#cProceedings of the 1983 annual conference on Computers : Extending the human resource
#index552912
#!In this paper, an efficient implementation of the Clarke and Wright algorithm for solving the single depot vehicle routing and scheduling problem is presented. With this implementation, a 900 customer problem can be solved approximately in less than 9 seconds of CPU time and less than 128K bytes of storage on an IBM 3033 computer.


#*Dynamically maintaining configurations in the plane (Detailed Abstract)
#@Mark H. Overmars,Jan van Leeuwen
#t1980
#cProceedings of the twelfth annual ACM symposium on Theory of computing
#index551825
#%194960
#%317222
#%320823
#%324828
#%547743
#%625619
#!For a number of common configurations of points (lines) in the plane, we develop datastructures in which insertions and deletions of points (or lines, respectively) can be processed rapidly without sacrificing much of the efficiency of query answering of known static structures for these configurations. As a main result we establish a fully dynamic maintenance algorithm for convex hulls that can process insertions and deletions of single points in only O(log3n) steps or less per transaction, where n is the number of points currently in the set. The algorithm has several intriguing applications, including that one can &ldquo;peel&rdquo; a set of n points in only O(log3n) steps and that one can maintain two sets at a costs of only O(log3n) or less per insertion and deletion such that it never takes more than O(log2n) steps to determine whether the two sets are separable by a straight line. Also efficient algorithms are obtained for dynamically maintaining the common intersection of a set of half-spaces and for dynamically maintaining the maximal elements of a set of plane points. The results are all derived by means of one master technique, which is applied repeatedly and which seems to capture an appropriate notion of &ldquo;decomposability&rdquo; for configurations.


#*Requirements/design debugging
#@Peter Bates
#t1983
#cACM SIGPLAN Notices
#index434480


#*Preliminary Announcement and Call for Papers 1st International Conference on Distributed Computerized Picture Information Systems for Medical Applications
#@
#t1981
#cComputer
#index337591


#*Regionenbildende Operatoren und ihre Charakterisierung durch lokale Histogramme
#@Piero Zamperoni
#t1984
#cProceedings of the DAGM/&Ouml;AGM Symposium
#index572222


#*Optimized concurrent execution of an applicative language (dataflow)
#@Jiro Tanaka
#t1984
#c
#index202730


#*A Quantitative Comparison of Lockprotocols for Centralized Databases
#@Werner Kießling,G. Landherr
#t1983
#cProceedings of the 9th International Conference on Very Large Data Bases
#index361475
#%317485
#%333741
#%361914


#*Perturbation analysis of nonlinear oscillations using symbolic and numerical computations
#@Mohammad Bagher Dadfar
#t1982
#c
#index205243


#*An optimal algorithm for testing for safety and detecting deadlocks in locked transaction systems
#@Eljas Soisalon-Soininen,Derick Wood
#t1982
#cProceedings of the 1st ACM SIGACT-SIGMOD symposium on Principles of database systems
#index242708
#%317485
#!Various notions are introduced for the closure of a set of rectilinearly oriented rectangles on the plane. Optimal algorithms are presented for computing the closures. These algorithms imply optimal solutions to several problems related to database concurrency control.


#*Book review
#@
#t1981
#cIssue 76 (April 1981)
#index101015


#*Kl, a well-structured beginning computer language
#@Karen Jane Hamilton Van Houten
#t1980
#c
#index202596


#*A language-oriented interactive programming environment based on compilation technology
#@Peter Hermann Feiler
#t1982
#c
#index196279


#*VAX DEBUG: an interactive, symbolic, multilingual debugger
#@Bert Beander
#t1983
#cACM SIGSOFT Software Engineering Notes
#index438391
#!Digital Equipment Corporation's VAX-11 Debugger, usually called VAX DEBUG or simply DEBUG, is an interactive, symbolic, and multilingual debugger which runs on the VAX-11 series of computers under the VMS operating system. The following gives an overview of VAX DEBUG and examines how it solves some of the problems inherent in the design of any such debugger. Particular attention is paid to how its command language is designed, how it distinguishes between addresses and values in command input, how it solves the problem of accessing and organizing symbol table information, and how it exercises control over the user program.


#*Application downloading
#@Robert Balzer,Alvin Cooperband,Martin Feather,Philip London,David Wile
#t1981
#cProceedings of the 5th international conference on Software engineering
#index554481
#%186402
#%201894
#!The purpose of our research is to investigate the feasibility of this methodology for distributed application development by examining possible approaches to carrying out such developments. In particular, our emphasis lies in transformation technology, wherein user-invoked source-to-source transformations are applied to the partitioned system for the purpose of optimizing the transactions required to effect the distributed behavior. In this way, the application downloading system need only produce a correct partitioning of the original program, not an efficient one. The user, with system guidance, optimizes the partitioned program by applying transformations chosen from the system library. Thus, application downloading can be viewed as a narrow domain in which to apply the transformation technology we have developed elsewhere in a broader context(1).


#*Graph algorithms and NP-completeness
#@Kurt Mehlhorn
#t1984
#cEatcs Monographs On Theoretical Computer Science; Vol. 2
#index148288


#*Ein Sortierverfahren f&uuml;r Registermaschinen (Zusammenfassung)
#@Stefan Reisch
#t1980
#cGI - 10. Jahrestagung
#index276754


#*Teaching microprocessor architectures
#@Ratan K. Cuha
#t1983
#cACM SIGCSE Bulletin
#index546173
#%550714
#!For our undergraduate computer science architecture majors, we are making a major revision of our existing course sequence (three courses) on microprocessors. For effective utilization of microprocessors, a total system design and development methodology approach is used. In this paper, we discuss the development of the first course of the sequence. The first course emphasizes on various microprocessor architectures. Since our non-architecture major undergraduate students may take this first course as an elective, this course is designed as a self contained foundation course with proper mixes of hardware and software.


#*Capital-Intensive Software Technology Part 3: Knowledge Engineering
#@
#t1984
#cIEEE Software
#index342107
#!In the 1990's, software technology will increasingly emphasize knowledge reusability by both people and computers. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Replacement in Monotone Boolean Networks: An Algebraic Perspective
#@Meurig Beynon
#t1984
#cProceedings of the Fourth Conference on Foundations of Software Technology and Theoretical Computer Science
#index562696


#*Simulation of phonemic errors using artificial intelligence symbol processing techniques
#@James A. Reggia,Sanjeev B. Ahuja
#t1984
#cProceedings of the 17th annual symposium on Simulation
#index551459
#%157179
#!Using heuristically-guided state space search, a program has been developed to simulate phonemic errors occurring in the speech of both normal individuals and neurologically-impaired patients. Simulations are based on an interchangeable rule/operator set of elementary errors which represent a theory of phonemic processing faults. This work is significant because it introduces and evaluates a novel approach to error simulation, it provides a prototype simulation tool for neurolinguistic research, and it forms the initial phase of a larger research effort involving computer modelling of neurolinguistic processes.


#*Developing a long-range information architecture
#@James C. Wetherbe,Gordon B. Davis
#t1983
#cProceedings of the May 16-19, 1983, national computer conference
#index63080
#!A methodology is presented for eliciting enterprise information requirements and developing a long-range information architecture. The methodology is based on a combination of business system planning, critical success factors, and ends/means analysis. The methodology is independent of organizational structure, personnel, and hardware and software; and it has been successfully implemented in a variety of organizational settings.


#*Automatic input and interactive editing systems of logic circuit diagrams
#@Mitsuo Ishii,Yoshikazu Ito,Michiko Iwasaki,Masanari Yamamoto,Sadao Kodama
#t1981
#cProceedings of the 18th Design Automation Conference
#index549123
#%546198
#%547813
#%555150
#%550256
#!This paper discusses automatic input and interactive editing systems of logic circuit diagrams. Automatic input is based on pattern recognition, and interactive editing is executed through a graphic display. The system is implemented on a FACOM M-180 II and a PANAFACOM U-400. System overview, hardware configuration, pattern recognition algorithms, editing system, data-base, as well as current results are described.


#*Mxec: parallel processing with an advanced macro facility
#@William L. Ash
#t1981
#cCommunications of the ACM
#index329111
#!Mxec is a sophisticated computing environment (executive system) which extends and magnifies users' interactions with a computer. Principally, Mxec provides for parallel processing and also assumes many of the mundane, clerical tasks with which users of most systems find themselves burdened. Some of the characteristics of the Mxec system are given, and its motivation and implementation are discussed.


#*On the complexity of finding short vectors in integer lattices
#@Erich Kaltofen
#t1983
#cProceedings of the European Computer Algebra Conference on Computer Algebra
#index255548


#*Data Link Control Protocols
#@Simon S. Lam
#t1980
#c
#index194561


#*Reliability of complex systems
#@Ghasem Tarmast
#t1983
#c
#index198792


#*Algebraic Theory of Parameterized Specifications with Requirements
#@Hartmut Ehrig
#t1981
#cProceedings of the 6th Colloquium on Trees in Algebra and Programming
#index568368


#*Balanced job bound analysis of queueing networks
#@J. Zahorjan,K. C. Sevcik,D. L. Eager,B. I. Galler
#t1981
#cACM SIGMETRICS Performance Evaluation Review
#index545899
#!Applications of queueing network models to computer system performance prediction typically involve the computation of their equilibrium solution. When numerous alternative systems are to be examined and the numbers of devices and customers are large, however, the expense of computing the exact solutions may not be warranted by the accuracy required. In such situations, it is desirable to be able to obtain bounds on the system solution with very little computation. Asymptotic bound analysis (ABA) is one technique for obtaining such bounds. In this paper, we introduce another bounding technique, called balanced job bounds (BJB), which is based on the analysis of systems in which all devices are equally utilized. These bounds are tighter than ABA bounds in many cases, but they are based on more restrictive assumptions (namely, those that lead to separable queueing network models).


#*The CCITT Reference Model for Public Data Network Applications
#@Thomas B. Steel, Jr.
#t1981
#cProceedings on Kommunikation in Verteilten Systemen
#index355788


#*CAD/CAM: electrical engineering education
#@
#t1984
#cComputers in Industry
#index155487


#*On the Group Complexity of a Finite Language
#@Evelyne Barbin-Le Rest,Stuart W. Margolis
#t1983
#cProceedings of the 10th Colloquium on Automata, Languages and Programming
#index372471


#*Using Charts to Present International Trade Data
#@Irwin Jarett
#t1983
#cIEEE Computer Graphics and Applications
#index408966
#!A set of graphic icons based on international accounting principles can serve as a common language for comparison of commercial operations conducted in different currencies. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A microprogrammable dual processor based fast digital filter
#@Prakash Agarwal,Roland Priemer
#t1980
#cProceedings of the ACM 1980 annual conference
#index545192
#!A programmable digital signal processing system is proposed in this paper. The system utilizes a 16 bit microprocessor for user interaction and a bit slice microprocessor for executing the filtering algorithm.


#*A language for machine organization design (computer hardware description languages)
#@Gregory Frederick Maxey
#t1984
#c
#index190121


#*The effective utilization of a data dictionary for large state government application
#@June Rampy Ponder
#t1980
#cProceedings of the 18th annual Southeast regional conference
#index614851


#*Design and evaluation of a relational data base machine employing advanced data structures and algorithms
#@Y. Kiyoki,K. Tanaka,H. Aiso,N. Kamibayashi
#t1981
#cProceedings of the 8th annual symposium on Computer Architecture
#index549089
#%178659
#%325979
#%326368
#%551043
#!This paper presents the architecture design and evaluation of a relational machine employing advanced data structures and algorithms to manipulate set-level operations required in a relational model. We have developed data structures and algorithms that are suitable for VLSI-oriented parallel processing. The data structure called VTF (valid tuple flags) is a simple bit string that is used to distinguish valid tuples from invalid ones. VTF helps to reduce the cost to recognize the valid tuples, to minimize the memory requirement, and to avoid constructing a temporary relation as a result of executed relational operations. By extending concepts of VTF, we have established an advanced processing method based on efficient data structures and algorithms that could avoid reconstructing relations and numbers of iterative searches required in accomplishing relational operations. This paper describes basic concepts of VTF, an efficient processing method using VTF, design of a relational machine architecture introducing this method, and performance evaluations of the method and the architecture. Basic concepts and extended concepts of the method incorporated with VTF will provide strong foundations on architecture design of a relational machine.


#*Timed Petri nets and preliminary performance evaluation
#@W. M. Zuberek
#t1980
#cProceedings of the 7th annual symposium on Computer Architecture
#index549825
#%324964
#!It is shown that the behavior of a certain class of timed Petri nets can be represented by a finite labeled directed graph in which the labels describe times and probabilities of transitions between vertices of the graph. Further analysis of such a graph can be done by techniques known for Markov chains. The method is applied to evaluation of some performance indices for two simple processor architectures. The timed Petri nets modeling the processors are shown and the resulting performance indices are compared. Some other architectures are discussed shortly.


#*Microprocessor assembly language draft standard
#@Richard A. Marino
#t1981
#cACM SIGSMALL Newsletter
#index31515
#!Among the first languages used in programming computers were assembly languages, in which each instruction is translated directly into machine code. Since that time, the level and sophistication of computer languages has grown to such an extent that high-level computer languages are essentially machine-independent and some are nearly compatible with the spoken language. Even though high-level languages continue to become more and more sophisticated and are the subject of most computer language discussion, there still is and always be a need for assembly languages.


#*A 3-dimensional representation for fast rendering of complex scenes
#@Steven M. Rubin,Turner Whitted
#t1980
#cProceedings of the 7th annual conference on Computer graphics and interactive techniques
#index552170
#%188642
#%189595
#%197075
#%205516
#%313829
#%319069
#%319867
#%334528
#%550028
#!Hierarchical representations of 3-dimensional objects are both time and space efficient. They typically consist of trees whose branches represent bounding volumes and whose terminal nodes represent primitive object elements (usually polygons). This paper describes a method whereby the object space is represented entirely by a hierarchical data structure consisting of bounding volumes, with no other form of representation. This homogencity allows the visible surface rendering to be performed simply and efficiently. The bounding volumes selected for this algorithm are parallelepipeds oriented to minimize their size. With this representation, any surface can be rendered since in the limit the bounding volumes make up a point representation of the object. The advantage is that the visibility calculations consist only of a search through the data structure to determine the correspondence between terminal level bounding volumes and the current pixel. For ray tracing algorithms, this means that a simplified operation will produce the point of intersection of each ray with the bounding volumes. Memory requirements are minimized by expanding or fetching the lower levels of the hierarchy only when required. Because the viewing process has a single operation and primitive type, the software or hardware chosen to implement the search can be highly optimized for very fast execution.


#*Models for the color continuum and subsets thereof
#@E. P. Miles, Jr.
#t1980
#cProceedings of the 18th annual Southeast regional conference
#index617238


#*Get Reliable Learn DP Fault-Tolerance
#@
#t1980
#cComputer
#index340482


#*New Products
#@Victor Nelson
#t1983
#cIEEE Micro
#index387969


#*TurboDOSTM multiprocessor operating system
#@William A. Schultz
#t1983
#cProceedings of the 1983 annual conference on Computers : Extending the human resource
#index547209
#!The TurboDOS operating system is a product of Software 2000, Inc., and is trademarked and copyrighted by them. At MuSYS Corp., we have used TurboDOS in conjunction with various slave processor boards to construct a wide variety of S-100 based computer systems, ranging from two to over sixty users. TurboDOS is designed for multiprocessor networks of Z-80 based computers, although single user versions are available. Extensive use is made of the Z-80 instruction set to achieve a highly table oriented and reentrant architecture, which is very adaptable to the user's environment. In addition to MuSYS, many companies are selling TurboDOS for specific hardware configurations on an OEM basis. This is one of the primary distinctions with other multiprocessor operating systems, which are supported by only a single vendor.


#*From the Editors-in-Chief
#@
#t1984
#cIEEE Micro
#index336970


#*Optimal VLSI-circuits for the basic arithmetic functions
#@Kurt Mehlhorn
#t1984
#cProc. of the conference on Ninth colloquium on trees in algebra and programming
#index145655


#*Session summary: Distributed Debugging
#@Thomas Gross
#t1983
#cProceedings of the ACM SIGSOFT/SIGPLAN software engineering symposium on High-level debugging
#index553295
#!Both sessions on Tuesday morning (March 22, 1983) were devoted to the discussion of Distributed Debugging. Three papers were presented during the first part; then there was a lively panel discussion on Multiprocess and Distributed Debugging. Both session were chaired by John R. White (Xerox PARC).


#*Selecting the &ldquo;right&rdquo; programming language
#@Alan L. Tharp
#t1982
#cProceedings of the thirteenth SIGCSE technical symposium on Computer science education
#index547458
#%320383
#%551482
#%553647
#%552391
#!With the diversity of high-level programming languages available, selecting the &ldquo;right&rdquo; one for a computer science curriculum or course can be a befuddling process. For a multitude of reasons, such as the manner in which students approach problems to the utilization of scarce computing resources, the ramifications of a decision on the choice of a programming language are significant throughout a computer science curriculum. The purpose of this paper is to provide information relevant to the selection process. Particular attention is given to COBOL, FORTRAN, Pascal, PL-1, and Snobol; both qualitative and quantitative factors are considered. The quantitative results were obtained from processing a binary tree insertion and retrieval algorithm in each language. The machine resources used for this algorithm are given for both interpreter and compiler versions of translators for each language.


#*Prettyprinting in an interactive programming environment
#@Martin Mikelsons
#t1981
#cACM SIGPLAN Notices
#index547888
#%119584
#%243787
#!Prettyprint algorithms designed for printing programs on paper are not appropriate in an interactive environment where the interface to the user is a CRT screen. We describe a data representation and an algorithm that allow the efficient generation of program displays from a parsed internal representation of a program. The displays show the structure of the program by consistent and automatic indentation. They show the program in varying levels of detail by replacing unimportant parts with ellipsis marks. The relative importance of program parts is determined jointly by the structure of the program and by the current focus of attention of the programmer.


#*The computer users group: the evolution of an effective management tool
#@Quentin Ludgin
#t1980
#cACM SIGCPR Computer Personnel
#index342998
#!The Computer Users Group has been officially sanctioned by the Bureau of the Census as a forum for the interchange of information among the working-level programmers at the Bureau. At the biweekly meetings, programmers from over thirty different divisions meet in a relaxed atmosphere with responsible officials from the "provider" divisions in the EDP area. Since 1977, I have served as Chairman of this group. In this paper, I propose to examine the path by which it has reached its current status as an effective tool for both the programmers and the "providers."


#*Computing the Minimum Eigenvalue of a Symmetric Positive Definite Toeplitz Matrix
#@George Cybenko,Charles Van Loan
#t1984
#c
#index121562
#!A method for computing the smallest eigenvalue of a symmetric positive definite Toeplitz matrix is given. It relies solely upon the Levinson-Durbin algorithm. The procedure involves a combination of bisection and Newton''s method. Good starting values are also shown to be obtainable from the Levinson-Durbin algorithm.


#*Strategies and Techniques for Interactive Proof
#@Michio Honda,Reiji Nakajima
#t1983
#cThe IOTA Programming System, A Modular Programming Environment
#index381373


#*On One Tape Versus Two Stacks
#@Ming Li
#t1984
#c
#index111995
#!We develop a simple method which enables us to prove three new lower bounds (for both worst and average cases) for on-line computations, answering two open problems summarized in [DGPR]. We give a language that requires $\Omega (n^{2})$ time for any 1-tape deterministic on-line machine, but it can be accepted by a 2-stack 1-reversal bounded deterministic on-line machine in real time. This provides a tight lower bound, closing the gap between $\Omega ( n(logn)^{1/2})$ lower bound by [P2] and the trivial $O(n^{2})$ upper bound. We also prove that 1-tape nondeterministic real time is much stronger than its deterministic version. For 1-tape on-line machines, we give language L (L'''') which is in nondeterministic linear (real) time but requires $\Omega(n^{2})(\Omega (n^{1.5}))$ deterministic time. Finally we give a language which can be accepted by a 2-stack 1-reversal bounded deterministic machine in real time, but it requires $\Omega(n^{1+1/2})$ time for any one tape nondeterministic online machine. This sharply improves an $nlogn$ lower bound in [DGPR]. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*I/O complexity: The red-blue pebble game
#@Hong Jia-Wei,H. T. Kung
#t1981
#cProceedings of the thirteenth annual ACM symposium on Theory of computing
#index548104
#!In this paper, the red-blue pebble game is proposed to model the input-output complexity of algorithms. Using the pebble game formulation, a number of lower bound results for the I/O requirement are proven. For example, it is shown that to perform the n-point FFT or the ordinary n&times;n matrix multiplication algorithm with O(S) memory, at least &Ohgr;(n log n/log S) or &Ohgr;(n3/@@@@S), respectively, time is needed for the I/O. Similar results are obtained for algorithms for several other problems. All of the lower bounds presented are the best possible in the sense that they are achievable by certain decomposition schemes. Results of this paper may provide insight into the difficult task of balancing I/O and computation in special-purpose system designs. For example, for the n-point FFT, the lower bound on I/O time implies that an S-point device achieving a speed-up ratio of order log S over the conventional O(n log n) time implementation is all one can hope for.


#*International Conference on Data Engineering
#@
#t1984
#cComputer
#index345522


#*Parameterized Models for Facial Animation
#@F. I. Parke
#t1982
#cIEEE Computer Graphics and Applications
#index345380
#!Parameterized models can produce realistic, manipulable images of human faces with a surprisingly small number of parameters.


#*Formal program testing
#@Robert Cartwright
#t1981
#cProceedings of the 8th ACM SIGPLAN-SIGACT symposium on Principles of programming languages
#index251802
#%244366
#%326066
#%331447
#!This paper proposes a practical alternative to program verification -- called formal program testing -- with similar, but less ambitious goals. Like a program verifier, a formal testing system takes a program annotated with formal specifications as input, generates the corresponding verification conditions, and passes them through a simplifier. After the simplification step, however, a formal testing system simply evaluates the verification conditions on a representative set of test data instead of trying to prove them. Formal testing provides strong evidence that a program is correct, but does not guarantee it. The strength of the evidence depends on the adequacy of the test data.


#*Query processing
#@
#t1981
#cProceedings of the 1981 ACM SIGMOD international conference on Management of data
#index238125


#*MINUPROX - an advanced proximity correction technique for the IBM EL-2 electron beam tool
#@W. J. Guillaume,A. Kurylo
#t1984
#cProceedings of the 21st Design Automation Conference
#index553990
#!MINUPROX - (Minimum Neighborhood Proximity Correction) is a novel approach to proximity correction used with the IBM EL-2 E-Beam direct exposure tool. Based on earlier work by M. Parikh, it differs from his approach primarily by only correcting those shapes that form the edge definition of the image. Reflecting experimental observations that the dose assignment to the edges of the image is much more critical than the assignment made to the interior, MINUPROX separates the edges from the interior of the image


#*Specifying Concurrent Program Modules
#@Leslie Lamport
#t1983
#cACM Transactions on Programming Languages and Systems (TOPLAS)
#index335617
#%240818
#%256501
#%316045
#%334601


#*Grapevine: an exercise in distributed computing
#@Andrew D. Birrell,Roy Levin,Michael D. Schroeder,Roger M. Needham
#t1982
#cCommunications of the ACM
#index330779
#%317300
#%552884
#%334562
#%333770
#!Grapevine is a multicomputer system on the Xerox research internet. It provides facilities for the delivery of digital messages such as computer mail; for naming people, machines, and services; for authenticating people and machines; and for locating services on the internet. This paper has two goals: to describe the system itself and to serve as a case study of a real application of distributed computing. Part I describes the set of services provided by Grapevine and how its data and function are divided among computers on the internet. Part II presents in more detail selected aspects of Grapevine that illustrate novel facilities or implementation techniques, or that provide insight into the structure of a distributed system. Part III summarizes the current state of the system and the lesson learned from it so far.


#*Job and health implications of VDT use: initial results of the Wisconsin-NIOSH study
#@Steven L. Sauter,Mark S. Gottlieb,Karen C. Jones,Vernon N. Dodson,Kathryn M. Rohrer
#t1983
#cCommunications of the ACM
#index314552
#!Magnitudes and correlates of stress were investigated among 248 office workplace VDT users and 85 nonuser counterparts using field survey and objective physical measurement techniques. Other than a tenuous indication of increased eyestrain and reduced psychological disturbances among users, the two groups were largely undifferentiated on job-attitudinal, affective, and somatic manifestations of stress. However, aspects of working conditions were judged less favorably by VDT users. Stress mechanisms were much the same for both groups, involving psychosocial as well as physical environmental job attributes. For VDT users, the chair and workstation configuration were particularly important predictors of musculo-skeletal disturbances, as were corrective eyewear use and ambient lighting for visuo-ocular disturbances.


#*Comments, Questions, and Debate
#@
#t1983
#cIEEE Annals of the History of Computing
#index410879


#*Hardware implementation of communication protocols: A formal approach
#@Miguel García Hoffmann
#t1980
#cProceedings of the 7th annual symposium on Computer Architecture
#index546115
#%318723
#%320204
#%321526
#%325067
#%330862
#!This paper presents a formal method that permits the development of verified specifications and implementation of communication protocols. A non-executable high level language is introduced for specification purposes. This language permits the concise and unambiguous specification of those characteristics which are normally needed to be modeled in the design of protocols. A simple algorithm for verifying the protocol specifications is indicated. Then it is shown how the verified specifications can be transformed into another descriptive model, a processing machine which is more directly related to hardware implementation. The processing machine description resulting from this model simplifies the last stage of protocol design, that of the realization.


#*A Quantitative Evaluation of the Feasibility of, and Suitable Hardware Architectures for, an Adaptive, Parallel Finite-Element System
#@Pamela Zave,George E. Cole, Jr.
#t1983
#cACM Transactions on Mathematical Software (TOMS)
#index335628
#%314358
#%322072
#%324549
#%329407


#*Classification Categories and Historical Development of Circuit Switching Topologies
#@George Broomell,J. Robert Heath
#t1983
#cACM Computing Surveys (CSUR)
#index315770
#%549374
#%553235
#%441492
#%549617
#%549696
#%545517
#%553223
#%550288


#*Proceedings of the 1980 workshop on Data abstraction, databases and conceptual modeling
#@
#t1980
#cInternational Conference on Management of Data
#index549694


#*The optical memory media market in the U. S.
#@CORPORATE Frost Sullivan
#t1983
#c
#index145608


#*User friendly interface for messaging systems
#@Liane M. Rockenbach Tarouco
#t1984
#cProc. of the IFIP WG 6.5 working conference on Computer-based message services
#index145937


#*Evidence accumulation for spatial reasoning in aerial image understanding (expert system, computer vision)
#@Shang-Shouq Vincent Hwang
#t1984
#c
#index204840


#*An efficient context-free parsing algorithm
#@Jay Earley
#t1983
#cCommunications of the ACM
#index332759
#%187307
#%315280
#%328874
#!A parsing algorithm which seems to be the most efficient general context-free algorithm known is described. It is similar to both Knuth's LR(k) algorithm and the familiar top-down algorithm. It has a time bound proportional to n3 (where n is the length of the string being parsed) in general; it has an n2 bound for unambiguous grammars; and it runs in linear time on a large class of grammars, which seems to include most practical context-free programming language grammars. In an empirical comparison it appears to be superior to the top-down and bottom-up algorithms studied by Griffiths and Petrick.


#*A/I: a synthesis
#@William S. Curran
#t1982
#cProceedings of the 20th annual Southeast regional conference
#index609471
#%326719
#!There has never been a serious effort made to produce a program which would pass Turing's well known test for artificial intelligence. The present paper describes a program which, although not intended to meet the test, is a tentative step in that direction. It is a synthesis of earlier work on emotions, purpose, conversation, knowledge/belief acquisition. Provision for the incorporation of additional aspects of A/I has been made.


#*Compiling ADA
#@J C. Heliard
#t1984
#cMethods and tools for compiler construction
#index171187


#*Reasoning about success and failure in aerial image understanding
#@Peter Gilman Selfridge
#t1982
#c
#index203278


#*Dot: a distributed operating system model of a tree-structured multiprocessor
#@Scott Harrison Danforth
#t1983
#c
#index186555


#*Arctic: A functional language for real-time control
#@Roger B. Dannenberg
#t1984
#cProceedings of the 1984 ACM Symposium on LISP and functional programming
#index550687
#%313666
#%315709
#%319828
#%327702
#%332771
#%548238
#%553874
#!Arctic is a language for the specification and implementation of real-time control systems. Unlike more conventional languages for real-time control, which emphasize concurrency, Arctic is a stateless language in which the relationships between system inputs, outputs and intermediate terms are expressed as operations on time-varying functions. Arctic allows discrete events or conditions to invoke and modify responses asynchronously, but because programs have no state, synchronization problems are greatly simplified. Furthermore, Arctic programs are non-sequential, and the timing of system responses is notated explicitly. This eliminates the need for the programmer to be concerned with the execution sequence, which accounts for much of the difficulty in real-time programming.


#*Coordinated computing: tools and techniques for distributed software
#@Robert E. Filman,Daniel P. Friedman
#t1984
#c
#index157063


#*An improved projection operation for cylindrical algebraic decomposition (computer algebra, geometry, algorithms)
#@Scott McCallum
#t1984
#c
#index190151


#*Query optimization for CODASYL database systems
#@Umeshwar Dayal,Nathan Goodman
#t1982
#cProceedings of the 1982 ACM SIGMOD international conference on Management of data
#index240573
#%554998
#%252222
#%313668
#!One of the tasks of MULTIBASE, a system for integrated access to heterogeneous distributed databases, is to present a high-level query interface to navigational systems such as CODASYL. The interface compiles queries into efficient programs that implement the queries. The principal problem in constructing such an interface is access path optimization, i.e., the selection of an optimal sequence of access paths that must be traversed to process a given query. This paper identifies a class of queries for which efficient programs can be synthesized. It characterizes the strategies for processing a given query, and shows how to synthesize a program for implementing each strategy. It develops a model for estimating the cost of executing a program, and uses this model to find the optimal strategy for processing a given query.


#*Region representation: boundary codes from quadtrees
#@Charles R. Dyer,Azriel Rosenfeld,Hanan Samet
#t1980
#cCommunications of the ACM
#index328555
#%185853
#%314542
#%328020
#%334630
#%329028
#!There has been recent interest in the use of quadtrees to represent regions in an image. It thus becomes desirable to develop efficient methods of conversion between quadtrees and other types of region representations. This paper presents an algorithm for converting from quadtrees to a simple class of boundary codes. The algorithm is shown to have an execution time proportional to the perimeter of the region.


#*Real-time programming with fault-tolerance
#@Anthony Yu-Wu Wei
#t1981
#c
#index190895


#*Human relations, scientific management, and human factors research
#@Philip Kraft,David Strauss
#t1982
#cProceedings of the 1982 conference on Human factors in computing systems
#index552450
#!Human Factors research is concerned primarily with minimizing unpredictable behavior in computer-based systems. Much Human Factors research stresses simplification of computer-based work into discrete, standard, and measurable sub-tasks. The performance of these elemental work-fragments can then be compared against &ldquo;expert&rdquo; performance times. In addition to increased worker output, simplified and standardized jobs allow managers to control work more completely. Similarly, standardized jobs usually allow the use of less-skilled labor. This aspect of Human Factors research is an outgrowth of Scientific Management (&ldquo;time and motion&rdquo; studies) and, ironically, the management theories of Charles Babbage, the 19th-century inventor of the computer. Scientific Management and Human Factors research share a number of important assumptions. For the most part, these assumptions have not been subjected to careful scrutiny. In time, they may prove the source of significant problems for both systems designers and users.


#*On the Relationship of CCS and CSP
#@Stephen D. Brookes
#t1983
#cProceedings of the 10th Colloquium on Automata, Languages and Programming
#index559310


#*Selected topics in computer generation of pseudorandom numbers
#@Fred Chung-Man Ho
#t1981
#c
#index206190


#*Online-Systeme im Finanz- und Rechnungswesen der G. Bauknecht GmbH
#@Manfred Friedrich
#t1980
#cOnline-Systeme im Finanz- und Rechnungswesen, Anwendergespr&auml;ch, Berlin, 29.-30. April 1980, Gesellschaft f&uuml;r Informatik e.V. und Verband der Hochschullehrer f&uuml;r Betriebswirtschaft e.v. (WK Betriebsinformatik)
#index256147


#*Review of "Principles of Artificial Intelligence by Nils J. Nilsson", Tioga Publishing Co.
#@Elaine Kant
#t1980
#cIssue 72 (July 1980)
#index105268
#!Nils Nilsson's new book, (Principles of Artificial Intelligence) (Tioga Publishing Co., 1980) discusses some basic ideas underlying different applications of AI. The book, designed as a text for a senior or first-year graduate course, aims to fill a gap between theory and practice. It succeeds in building a good solid arch outward from the shore of theory, but only a few support beams anchor the bridge to the shore of practice.


#*A modern Curriculum for an ancient culture
#@Robert M. Aiken,Chien F. Chao,Yi Fen Zhu
#t1982
#cACM SIGCSE Bulletin
#index545762
#%552665
#!This paper reports on one such effort. The senior author was invited by the First Ministry of Machine Building to review a Computer Science program which had been established along the lines of the IEEE Model Curriculum [4]. The work of the two other authors and their colleagues forms the bulk of the reminder of the presentation. This discussion of a particular program presents one of the ways in which the PRC is &ldquo;catching up&rdquo;. A more complete review is provided in another document [5].


#*Development Support Systems
#@R. J. Lauber
#t1982
#cComputer
#index350607


#*The integrated local network
#@Pinhas Ziv
#t1982
#c
#index189033


#*Special Feature a New Approach to High-Speed Computer Graphics: The Line
#@M. Loceff
#t1980
#cComputer
#index339983
#!The design of a better line drawing algorithm led to some general strategies for boosting software efficiency. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Interactive image understanding
#@Andrew J. Hanson
#t1984
#cProceedings of the 1984 annual conference of the ACM on The fifth generation challenge
#index555049
#!Cooperation between a human expert and an image processing system can give much better results than either the human or computer working alone. The computer must display geometrical information that exploits the perceptual characteristics of the human user, while the human must convey to the computer system ideas that can result in practical computation. We discuss new image understanding systems with human interfaces that support a powerful dialog about image features and characteristics.


#*Optimizing for a multiprocessor: Balancing synchronization costs against parallelism in straight-line code
#@Peter G. Hibbard,Thomas L. Rodeheffer
#t1982
#cProceedings of the 5th Colloquium on International Symposium on Programming
#index572912


#*A powerful strategy for deriving efficient programs by transformation
#@Alberto Pettorossi
#t1984
#cProceedings of the 1984 ACM Symposium on LISP and functional programming
#index548272
#%149262
#%231454
#%250656
#%318520
#%335365
#%625619
#!We present a method for deriving efficient iterative programs by transformation from recursive equation specifications. It consists of two phases: i) the transformation of general recursive programs into linear recursive ones, and ii) the transformation of linear recursive programs into iterative ones. In the first phase we apply the &ldquo;tupling strategy&rdquo; studied in [BUD77, Pet77], and implicitly used by other authors in the area of program transformation. That strategy enables us to introduce linear recursive functions, instead of the general recursive ones occurring in program specifications. In the second phase we apply known methods for transforming linear recursion into iteration (avoiding the use of stacks) [WaS73], and equivalence results between recursive schemas and flowchart schemas. Through various examples we show how the breaking of the transformation process into the above mentioned phases allows the derivation of efficient iterative algorithms. Those examples include challenges by Prof. E. Dijkstra and other authors. Through our method we were also able to improve some recent results for eliminating redundant calls in recursive programs [Coh83].


#*The Interpretation of Meta Grammars Describing Syntax-Directed Interpreters Using an Attribute Grammar Interpreter
#@J. Kontos
#t1982
#cIEEE Transactions on Software Engineering
#index342307
#!A syntax-directed interpreter of attribute grammars is applied to interpret meta grammars describing translators. A specific example is used which concerns the formal description of the same syntax-directed interpreter of attribute grammars for illustration of our approach.


#*Structured software development
#@Harvey Michael Deitel
#t1980
#c
#index188256


#*Stand der Entwicklung von Bildschirmtext
#@Jürgen C. W. Schröder
#t1980
#cGI - 10. Jahrestagung
#index269094


#*Data processing and computer science theory
#@A. T. Berztiss
#t1983
#cProceedings of the fourteenth SIGCSE technical symposium on Computer science education
#index549286
#%313666
#!Theoretical results have had much greater impact on computing practice than we are normally aware of, and the practical significance of theoretical results can be expected to become more prominent in the future. We discuss the past and present significance for data processing specialists of some results in analysis of algorithms, languages, and program proofs, and argue for a greater emphasis on computer science theory in data processing curricula.


#*A more general algorithm for computing closed semiring costs between vertices of a directed graph
#@John G. Fletcher
#t1980
#cCommunications of the ACM
#index328257
#!This note describes a generalization of an algorithm given by Aho, Hopcroft, and Ullman [1], originally derived from the work of Kleene [2] and McNaughton and Yamada [3]. The algorithm is used to compute the total cost of all paths between each pair of vertices in a directed graph when the cost of each edge is known. The cost of a path is defined as the product of the costs of the edges forming it, and the total cost of a set of paths is the sum of their individual costs. If there are n vertices labeled 1 through n and E[i, j] is the cost of the edge from vertex i to vertex j (or is zero when there is no such edge), then the total cost T[i, j] of all paths from i to j is the solution of the equation T[i, j] = &dgr;[i, j] + &sum;nk-1 E[i, k]&middot;T[k, j], (1) where &dgr;[i, i] = 1 (the cost of the path of no edges from i to i) and &dgr;[i, j] = 0 if i &ne; j. To assure that T [i, j] is always well-defined, costs are required to be elements from an algebraic structure called a closed semiring.


#*Differentiation and generation of taylor coefficients in PASCAL-SC
#@L B. Rall
#t1983
#cProc. of the symposium on A new approach to scientific computation
#index148052


#*An Architectural Comparison of Contemporary 16-Bit Microprocessors
#@Hoo-min Toong,Amar Gupta
#t1981
#cIEEE Micro
#index412716
#!Today's microprocessors exhibit powerful computing capabilities. Their characteristic differences favor each machine for a distinct portion of the applications spectrum.


#*Beyond videotex: The library of congress pilot project in page image retrieval and transmission digital optical disk
#@W. Nugent,J. Harding
#t1983
#cProceedings of the eighth symposium on Data communications
#index549106
#!This paper arrived late and can be found published in full on pages 257-260 of this Proceedings.


#*The Forms Pattern Language
#@James A. Larson
#t1984
#cProceedings of the First International Conference on Data Engineering
#index568487


#*Pseudo-extensions of computable functions
#@John Case
#t1984
#cInformation and Control
#index160380


#*Efficient implementation of the smalltalk-80 system
#@L. Peter Deutsch,Allan M. Schiffman
#t1984
#cProceedings of the 11th ACM SIGACT-SIGPLAN symposium on Principles of programming languages
#index544696
#%151297
#%159559
#%180833
#%192831
#%322192
#%332054
#%544889
#!The Smalltalk-80* programming language includes dynamic storage allocation, full upward funargs, and universally polymorphic procedures; the Smalltalk-80 programming system features interactive execution with incremental compilation, and implementation portability. These features of modern programming systems are among the most difficult to implement efficiently, even individually. A new implementation of the Smalltalk-80 system, hosted on a small microprocessor-based computer, achieves high performance while retaining complete (object code) compatibility with existing implementations. This paper discusses the most significant optimization techniques developed over the course of the project, many of which are applicable to other languages. The key idea is to represent certain runtime state (both code and data) in more than one form, and to convert between forms when needed.


#*An interactive high-level debugger for control-flow optimized programs
#@Polle T. Zellweger
#t1983
#cACM SIGPLAN Notices
#index433217
#!The transformations performed by an optimizing compiler have traditionally impeded interactive debugging in source language terms. A prototype system called Navigator has been developed for debugging optimized programs written in Cedar, an Algol-like language. Navigator can be used to monitor program execution flow in the presence of two optimizations: inline procedure expansion and cross-jumping (merging identical tails of code paths that join). This paper describes the problems that these two optimizations create for debugging and Navigator's solutions to these problems. The selected approach collects extra information during the optimization phases of compilation. At runtime, Navigator uses the additional information to hide the effects of the optimizations from the programmer.


#*Computations in group cohomology for finite groups
#@Isabella Marie Beichl
#t1981
#c
#index202785


#*Parallel solution of certain toeplitz linear systems
#@Dario Bini
#t1984
#cSIAM Journal on Computing
#index160900


#*An Incremental Programming Environment
#@R. Medina-Mora
#t1981
#cIEEE Transactions on Software Engineering
#index350703
#!This paper describes an incremental programming environment (IPE) based on compilation technology, but providing facilities traditionally found only in interpretive systems. IPE provides a comfortable environment for a single programmer working on a single program.


#*Determining investment yields
#@Edward M. Kline
#t1980
#cACM SIGAPL APL Quote Quad
#index245806
#!One of the basic financial-analysis problems is to determine the yield rate on an investment. The yield can then be compared with yields on alternate investments to aid the investor in making a choice. The traditional approach to finding a yield is to use a trial-and-error method which requires setting up a loop for tests of successive trial solutions. This paper will present a different way of solving for yields, which does not require looping when implemented in APL. This method will also be shown to require less storage for data, less computing time, and less storage during calculations.


#*Demand assigned multiple access systems using collision type request channels: Priority messages
#@Gagan L. Choudhury,Stephen S. Rappaport
#t1981
#cProceedings of the seventh symposium on Data communications
#index545037
#!Demand Assigned Multiple Access (DAMA) schemes in which requests for communication channels are transmitted over collision type channels to a master controller and in which messages of different priorities are present is analyzed. Priority use of the request channels is achieved by having users select among those channels according to a priority dependent probability distribution. Two important schemes of this class are considered. Additionally, three schemes for priority assignment of message channels are treated; two are non-preemptive and one is preemptive. Trade offs among bandwidth utilization and delay are considered as well as optimization of system parameters.


#*Some comments on numerical reliability
#@Jules de G. Gribble
#t1982
#cACM SIGAPL APL Quote Quad
#index250203
#%242286
#!From a numerical point of view, certain commonly accepted algorithms may be unreliable. The Least-Squares Problem will be used to illustrate some of the differences between mathematics and numerics, or computational mathematics.


#*The COSIE communications subsystem: support for distributed office applications
#@Douglas B. Terry,Sten Andler
#t1984
#cACM Transactions on Information Systems (TOIS)
#index325610
#%118678
#%314305
#%316802
#%317881
#%318448
#%361665
#%548712
#%554984
#%555282


#*Inexpensive Large Capacity Storage will Revolutionize the Design of Database Management Systems
#@David L. Childs
#t1984
#cProceedings of the 10th International Conference on Very Large Data Bases
#index565470


#*Choosing application development tools and techniques
#@V. Kevin Whitney,Jane G. Morse
#t1981
#cProceedings of the May 4-7, 1981, national computer conference
#index62723
#!Many different tools and techniques for assisting application system development are available today, but there is no good method available for choosing the proper ones to use in a particular application. This paper presents a fivefold classification of application systems and the tools and techniques most suitable for each class. Characteristics of each class of applications are explained, and methods of using this analysis to select application development tools and techniques are discussed.


#*Distributed ray tracing
#@Robert L. Cook,Thomas Porter,Loren Carpenter
#t1984
#cACM SIGGRAPH Computer Graphics
#index554954
#%322314
#%334528
#%335006
#%546166
#%546262
#!Ray tracing is one of the most elegant techniques in computer graphics. Many phenomena that are difficult or impossible with other techniques are simple with ray tracing, including shadows, reflections, and refracted light. Ray directions, however, have been determined precisely, and this has limited the capabilities of ray tracing. By distributing the directions of the rays according to the analytic function they sample, ray tracing can incorporate fuzzy phenomena. This provides correct and easy solutions to some previously unsolved or partially solved problems, including motion blur, depth of field, penumbras, translucency, and fuzzy reflections. Motion blur and depth of field calculations can be integrated with the visible surface calculations, avoiding the problems found in previous methods.


#*A heuristic approximation for reducing problem size in network file allocation models
#@Terry R. Rakes,Lori S. Franz,Arun Sen
#t1984
#cComputers and Operations Research
#index150110


#*The one tree (breaking out of the workspace)
#@Stephen Taylor,Arthur Whitney
#t1984
#cACM SIGAPL APL Quote Quad
#index553064
#!The advent of enclosed arrays has provided an opportunity to bring into APL previously extra-lingual objects such as tokenstrings, packages and functions. By doing so a more formal and rigorous definition of APL is achieved. Within this definition many simplifications are possible, including the subsuming of workspaces, files, libraries and other 'entities' into arrays and functions. The work is being implemented on the Hewlett-Packard A900 minicomputer.


#*How shall we evaluate prototype natural language processors?
#@Bruce W. Ballard
#t1981
#cProceedings of the joint conference on Easier and more productive use of computer systems. (Part - II): Human interface and the user interface - Volume 1981
#index551575
#%315326
#%320167
#%329869
#%333244
#%547043
#%593112
#!Recent years have seen important advances in computational linguistics and artificial intelligence. Although many problems remain, the goal of providing limited English-processing facilities for non-technical computer users is within sight. By the end of the decade, numerous systems providing limited coverage of "natural language" will be available for business and home use. Several systems (e.g. TQA [16]) have already become operational. One system (ROBOT [7]) has been supporting natural language inputs in a dozen or so different commercial database applications for at least three years. Many other systems have been developed to the prototype stage and will soon be able to be transferred, with varying degrees of effort, from a research to a production environment. Each system tends to provide special features of its own, and the future prospects for database, office, instructional, and other environments are quite exciting.


#*An Adaptive Nonlinear Least-Squares Algorithm
#@John E. Dennis, Jr.,David M. Gay,Roy E. Walsh
#t1981
#cACM Transactions on Mathematical Software (TOMS)
#index315088


#*Scope
#@
#t1983
#cACM SIGAPL APL Quote Quad
#index245258


#*Functional testing vs. structural testing of RAMs
#@H. Sahami,B. Courtois
#t1984
#cFehlertolerierende Rechensysteme, 2. GI/NTG/GMR-Fachtagung
#index272809


#*An integrated approach for the specification and the design of the conceptual level in database systems
#@Sabah Saleh Al-Fedaghi
#t1981
#c
#index204227


#*A decomposition method for the analysis and design of finite state protocols
#@Tat Y. Choi,Raymond E. Miller
#t1983
#cProceedings of the eighth symposium on Data communications
#index545156
#%316041
#!Finite state automata have been applied with success to the modeling of Computer Network Protocols. The interaction of finite state machines can be very complex especially if the protocol involves a large number of states. To counteract the complexity of analysis and design, we propose an approach of decomposition. Through this approach, the protocol graph can be partitioned into subgraphs each having a unique entry node and zero or more exit nodes. The exit nodes of one subgraph can be connected only to the entry nodes of other subgraphs. From the standpoint of protocol analysis, the correctness of the entire protocol graph can be inferred from the correctness of individual protocol subgraphs. From the standpoint of protocol design, the individual protocol subgraphs can be designed to correspond to different phases of the protocol. If the individual protocol subgraphs are designed correctly and the connections between subgraphs conform to the structure discussed above, then we show that the entire protocol graph will operate correctly.


#*The acquisition, processing, and use of tactile sensor data in robot control
#@Kenneth Jackson Overton
#t1984
#c
#index190029


#*Fast Detection of Polyhedral Intersections
#@David P. Dobkin,David G. Kirkpatrick
#t1982
#cProceedings of the 9th Colloquium on Automata, Languages and Programming
#index371791


#*Teaching software engineering in the adult education environment
#@Steven M. Jacobs
#t1981
#cProceedings of the twelfth SIGCSE technical symposium on Computer science education
#index549042
#%437651
#%458820
#%473921
#%547590
#%577319
#!Teaching the evolving subject of software engineering has only recently been explored in the literature within the last five years. In a university-level, evening school environment, problems in the area of software engineering education arise due to 1) the quantity and approach of introducing software engineering concepts and 2) the background and motivation of the students. Working adults can be introduced to the components of the software life-cycle by a careful selection of reading assignments, lectures, discussion, and a team programming project. This paper addresses the problems associated with software engineering in adult education and presents a working solution.


#*An architecture for application of artificial intelligence to design
#@J. R. Dixon M. K. Simmons,P. R. Cohen
#t1984
#cProceedings of the 21st Design Automation Conference
#index552063
#%185812
#%550151
#%551079
#%552607
#%553227
#%618658
#!An architecture for application of artificial intelligence to engineering design is presented and discussed. The architecture places emphasis on evaluation and redesign, thus reflecting the iterative nature of the design process. Six independent knowledge sources are included having the following functions: initial design, evaluation, acceptability decisions, redesign, user-designer input, and flow of control. A &ldquo;blackboard&rdquo; is used to store and exchange information among the knowledge sources. The implementation of the architecture is illustrated with two examples from the mechanical design domain: v-belt drives and extruded aluminum shapes.


#*A model for estimating program size and its evaluation
#@Minoru Itakura,Akio Takayanagi
#t1982
#cProceedings of the 6th international conference on Software engineering
#index547357
#%545315
#!Estimation of the size and time required for software development is probably the most difficult aspect of any project. Up to now, most estimates have been done subjectively by experts. These estimates are often inaccurate. In the midst of development, faulty estimates may contribute to delays and/or excess expenses. In the last several years, several estimation have been proposed, most of which were models to estimate software development cost {manpower). These models used program size as a variable. However at the beginning of development, when estimations are made, program sizes are usually uncertain and costs (manpower) are equally uncertain. The authors developed a program-size estimation model for batch programs in a banking system, and used the model in an actual project. Using the adapted model, estimation errors amounted to only 7 percent. This is much better than the accuracy of estimtions made by experts in the field (usually about 10 percent accuracy), and indicates that objective estimation methods can be derived for program-size. In this paper, we introduce our estimation model and discuss the adaptation of that model for a specific project.


#*Chaotic and homoclinic behavior for numerical discretizations of the nonlinear Schro&uml;dinger equation
#@David W. McLaughlin,Constance M. Schober
#t1982
#cPhysica D
#index520990


#*Proceedings of the 13th annual symposium on Simulation
#@Garnet J. Borror
#t1980
#cAnnual Simulation Symposium
#index553190


#*Digital logic design: tutorials and laboratory exercises
#@John F. Passafiume,Michael Douglas
#t1984
#c
#index167002


#*A technique for testing command and control software
#@Marvin L. Watkins
#t1982
#cCommunications of the ACM
#index330428
#!A technique for testing embedded-microprocessor command and control programs is described. The continuity inherent in functions computed by programs which monitor natural phenomena is exploited by a simple difference equation-based algorithm to predict a program's next output from its preceding ones. The predicted output is compared with the actual output while indexing through the program's domain. Outputs which cannot be predicted are flagged as potential errors. Data are presented which show that this technique can be a sensitive measure of a program's correctness.


#*Introduction to Computer Music
#@Wayne Bateman
#t1983
#c
#index6549


#*Reversal-bounded computations
#@Tat-Hung Chan
#t1980
#c
#index188721


#*Code optimization of multivariate polynominal schemes: A pragmatic approach
#@J. A. van Hulzen
#t1983
#cProceedings of the European Computer Algebra Conference on Computer Algebra
#index271588


#*A Performance Comparison of Three Contemporary 16-bit Microprocessors
#@Martin Prycker
#t1983
#cIEEE Micro
#index392393
#!The performance of two addressing mechanisms on three different microprocessors is examined. One of the mechanisms-and one of the micros-provided superior performance. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Cache Performance in the VAX-11/780
#@Douglas W. Clark
#t1983
#cACM Transactions on Computer Systems (TOCS)
#index324639
#%478684
#%554914
#%328709
#%547602


#*An Overview of the Production-Quality Compiler-Compiler Project
#@B. W. Leverett
#t1980
#cComputer
#index350579
#!The PQCC experience reveals that contrary to common practice and belief retargetability and a high level of optimization are not incompatible.


#*User perceptual mechanisms in the search of computer command menus
#@Stuart K. Card
#t1982
#cProceedings of the 1982 conference on Human factors in computing systems
#index554052
#!Menu-based command systems, in which a user selects a command from a set of choices displayed to him, have acquired widespread use as a human-computer interface technique. The technique is especially attractive for use with new or untrained users since the user need not recall the command he wishes, but merely recognize it. But menu systems also find application in more sophisticated systems meant for expert users (for example, Teitelman, 1977) where they can be used to reduce the complexity of the options with which the user is presented.


#*VLSI circuit design using APL with fortran subroutines
#@Norman Brenner
#t1984
#cACM SIGAPL APL Quote Quad
#index549443
#!Our group at IBM Yorktown Research has written a number of tool programs for VLSI design, all in APL. Several crucial algorithms were speeded up by recoding them in Fortran and Assembler Language. For example, the algorithm for complementation of a Boolean expression (which can sometimes have thousands of terms in dozens of variables) is 5 times faster in Fortran than the best APL code I could write. The linking mechanism used from APL to outside languages is the experimental AP403 from IBM Heidelberg, though other similar auxiliary processors exist (e.g. the IUP AP999). Thus, each language, Fortran and APL, is used to its best advantage: Fortran for raw speed, and APL for interactiveness and ease of coding.


#*Tutorial Series 9 Operating Systems
#@D. A. Anderson
#t1981
#cComputer
#index351754
#!Research during the last decade has revealed techniques by which future operating systems can avoid the problems associated with previous and present systems.


#*Special Feature: Prometheus or Pandora: The Influence of Automation on Society
#@H. A. Simon
#t1981
#cComputer
#index352802
#!Even though computer technology may challenge one of man's last and most cherished illusions that he alone is capable of thought it can also show him how to live in harmony with nature.


#*Moment-based object recognition using a two-level classifier (pattern, image processing, feature extraction)
#@Robert Lee Cheatham
#t1984
#c
#index199526


#*The operational versus the conventional approach to software development
#@Pamela Zave
#t1984
#cCommunications of the ACM
#index335386
#%302650
#%313666
#%317979
#%323067
#%329737
#%334349
#%545434
#%435738
#%437235
#%549983
#%549138
#!The conventional approach to software development is being challenged by new ideas, many of which can be organized into an alternative decision structure called the &ldquo;operational&rdquo; approach. The operational approach is explained and compared to the conventional one.


#*Using a cognitive model of dialogue for reference retrieval
#@G. O. Ofori-Dwumfuo
#t1984
#cJournal of Information Science
#index161299


#*How do people really use text editors?
#@John Whiteside,Norman Archer,Dennis Wixon,Michael Good
#t1982
#cACM SIGOA Newsletter
#index549613
#%190012
#%192972
#%327802
#%329875
#!Keystroke statistics were collected on editing systems while people performed their normal work. Knowledge workers used an experimental editor, and secretaries used a word processor. Results show a consistent picture of free use patterns in both settings. Of the total number of keystrokes, text entry accounted for approximately 1/2, cursor movement for about 1/4, deletion for about 1/8, and all other functions for the remaining 1/8. Analysis of keystroke transitions and editing states is also presented. Implications for past research, editor design, keyboard layout, and benchmark tests are discussed.


#*The Art and Science of Programming
#@Kenneth Owen
#t1983
#cIssue 50 (December 1983)
#index103043


#*Time-constrained communication in multiple access networks (data communication, protocols)
#@James Francis Kurose
#t1984
#c
#index204554


#*Instrumentenrechner f&uuml;r interplanetare Missionen
#@Fritz Gliem
#t1984
#cArchitektur und Betrieb von Rechensystemen, 8. GI-NTG-Fachtagung
#index559043


#*The importance of written reports in programming education
#@Nils Andersen
#t1984
#cProc. of the IFIP TC3 working conf. on The role of programming in teaching informatics
#index147511


#*Modeling the urban development process and the related transportation impacts
#@Tenny N. Lam,Richard Corsi,Katherine Wages
#t1984
#cProceedings of the 16th conference on Winter simulation
#index551458
#!A conceptually realistic but highly idealized approach was taken to create a simulation model of the structural interactions between the many elements of urban land use and transportation decisions. The objective is to use the model to discover elements and links that are amenable to land use intensification policies. While land use decisions are based on system perspective, transportation decisions are individualized. While land use decisions are permanent, transportation decisions are susceptible to be influenced. Through planning and other governmental policies, it is hoped that &ldquo;infilling&rdquo; can be achieved and the transportation conditions ensued will be energy efficient and environmentally compatible.


#*Research on natural-language processing: SRI International
#@Barbara Grosz
#t1982
#cIssue 79 (January 1982)
#index99827
#%195359
#%193181
#%314195
#!Research on natural-language processing at SRI spans a broad spectrum of activity. Two of our major current efforts are a pair of research projects under the sponsorship of the Defense Advanced Research Projects Agency. The TEAM project is intended to provide natural-language access to large databases via systems that are easily adaptable to a wide range of new application domains. The KLAUS project is a longer-range effort to address basic research problems in natural-language semantics, commonsense reasoning, and the pragmatics of natural-language communication. These two projects share a common core-language-processing system called DIALOGIC.


#*A training program for the computer integrated factory
#@Dean J. Saluti
#t1984
#cProceedings of the ACM 12th annual computer science conference on SIGCSE symposium
#index555144
#%155878
#!This paper describes a training program to prepare individuals for careers in the management of computer integrated factories. Training is fourteen (14) months in length and has been funded through grants from the Cambridge Private Industry Council. The Digital Equipment Corporation donated a PDP 11/34 mini-computer and RSTS instructors for an interactive workshop. The Boston chapter of the American Production and Inventory Control Society provided curriculum quality control and instructors. Courses were taught by professors of MIS/Management Sciences from Boston area universities.


#*The use of design descriptions in automated diagnosis
#@Michael R. Genesereth
#t1984
#cArtificial Intelligence
#index181308


#*Die Gestaltung der Mensch-Computer-Interaktion Einf&uuml;hrung in ein interdiszipin&auml;res Forschungsgebiet
#@Ursula Danzer-Kahan,Uta Schwatlo,Gerhard Dirlich
#t1984
#cKognitive Aspekte der Mensch-Computer-Interaktion, Workshop
#index272574


#*Iterative algorithms for large sparse linear systems on parallel computers
#@Loyce Mae Adams
#t1983
#c
#index204179


#*Matroid algorithms, recursion and the subgraph homeomorphism problem
#@Paul August Kaschube
#t1984
#c
#index200151


#*Error recovery in concurrent processes
#@Krishna Kant
#t1981
#c
#index204225


#*Athenan: axisymmetric thermal nonlinear analysis - a computer program for cements and other chemically reactive cylindrical domains and associated computer graphics algorithms
#@Christos Gotsis
#t1984
#c
#index202985


#*Locally Least-Cost Error Recovery in Earley's Algorithm
#@S. O. Anderson,R. C. Backhouse
#t1981
#cACM Transactions on Programming Languages and Systems (TOPLAS)
#index314923
#%170184
#%198643
#%316491
#%320826
#%315137


#*The role of the user at standard oil company (Indiana) in the development of large-scale business systems
#@James E. Jackson
#t1982
#cProceedings of the June 7-10, 1982, national computer conference
#index66459
#!Over the past 15 years Standard Oil (Indiana) has been involved in the development and implementation of a number of major computer-based business systems. Concurrent with this, Standard management has organized the users of these systems into a structure that provides for their effective participation in the development process. This structure, which consists of user management, user representatives, and the end user, recognizes that each of these groups has specific roles to play during the system development project life cycle. This paper will examine these user groups and their respective roles. The emphasis will be on identifying the key areas of user involvement that are necessary for the successful development and implementation of large-scale business systems.


#*Capital-Intensive Software Technology Part 4: Accomplishments and Deficiencies of Ada
#@
#t1984
#cIEEE Software
#index345549
#!Ada is a well-documented attempt to make software technology more capital intensive. Its development has taught us a lot, including the fact that we have a great deal more to learn. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*ACM IEEE 20th Design Automation Conference
#@
#t1983
#cComputer
#index339000


#*Fault-Tolerant VLSI Processor Arrays Via Laser Welding'' Arnold L. Rosenberg.
#@L A Rosenberg
#t1984
#c
#index116815
#!We study here a strategy for constructing fault-tolerant VLSI processor arrays that achieves tolerance to faults by running buses past the implemented PEs and configuring the fault-free ones into an array of the desired structure by ``welding'''' PEs into the bank of buses. We build here on earlier studies that have shown this strategy to be competitive in terms of area-efficiency and that have presented and analyzed fault-tolerant ``welded'''' implementations of linear arrays and tree-structured arrays. In this paper, we present and validate a methodology for designing fault-tolerant ``welded'''' implementations of a large variety of families of networks. For a large class of array structures (including, for instance, binary trees, rectangular grids, and cube-connected cycles), the designs produced by the methodology are optimal in area consumption (to within a constant factor) among such ``welded'''' fault-tolerant designs. Moreover, for the ``denser'''' of these arrays (all but the trees), the area of a fault-tolerant ``welded'''' design is just a small constant factor greater than the area of an arbitrary fault-free collinear layout of the array. We illustrate the methodology by deriving ``welded'''' fault-tolerant implementations of tree-structured arrays and rectangular-grid arrays.


#*The 1940 and 1950 Public Use Sample Project: Data quality issues
#@Richard M. Cohn,Howard R. Prouse
#t1981
#cProceedings of the joint conference on Easier and more productive use of computer systems. (Part - I): Information processing in the social sciences and humanities - Volume 1981
#index548384
#!The 1940 and 1950 Public Use Sample Project is the creation of 1/100 household samples from the 1940 and 1950 Censuses of Population. The data source for the samples is the microfilmed original Population Schedules which contain the census enumerator's recording of household information. The procedure to sample the universe of household listings and transcribe the sample households' data is described in the paper. A pretest of the 1940 Public Use Sample included a comparison of three methods of sampling and transcription. The results of this comparison are reported. The applicability of these procedures to similar projects is discussed.


#*A class of cellular computer architectures to support physical design automation (vlsi layout, integrated circuit, routing)
#@Robin Arthur Rutenbar
#t1984
#c
#index189713


#*Schreier-Zassenhaus theorem for algebras, part II
#@František Šik
#t1983
#cCzechoslovak Mathematical Journal
#index454702


#*The discovery of linear programming
#@Robert Dorfman
#t1984
#cIEEE Annals of the History of Computing
#index178691


#*Computers in crisis: how to avert the coming worldwide computer systems collapse
#@Jerome T. Murray,Marilyn J. Murray
#t1984
#c
#index155389


#*Gr&ouml;&szlig;tintegration in der Bauelementetechnologie und deren Auswirkungen auf die Proze&szlig;technik
#@Fritz A. Lohmann
#t1981
#cFachtagung Proze&szlig;rechner 1981, GI, VDI/VDE-GMR, KfK
#index278415


#*Operating system support for database management
#@Michael Stonebraker
#t1981
#cCommunications of the ACM
#index319143
#%114594
#%118678
#%320173
#%324042
#!Several operating system services are examined with a view toward their applicability to support of database management functions. These services include buffer pool management; the file system; scheduling, process management, and interprocess communication; and consistency control.


#*On the extremely fair treatment of probabilistic algorithms
#@Amir Pnueli
#t1983
#cProceedings of the fifteenth annual ACM symposium on Theory of computing
#index545291
#%233266
#%236516
#%316045
#%383370
#%545635
#%550295
#!A proof system based on linear temporal logic for the qualitative verification of concurrent probabilistic programs is proposed. The concept of extreme fairness is introduced as an approximation to the notion of probabilistic executions. The proof system proposed is shown to be relatively complete with respect to validity over all extremely fair computations. The proof methodology is demonstrated by proving correctness of a new probabilistic algorithm for solving the mutual exclusion problem ([CLP]).


#*On notions of information transfer in VLSI circuits
#@Alfred V. Aho,Jeffrey D. Ullman,Mihalis Yannakakis
#t1983
#cProceedings of the fifteenth annual ACM symposium on Theory of computing
#index548211
#%544688
#%546355
#%547657
#%553204
#%549277
#%549993
#!Several papers have recently dealt with techniques for proving area-time lower bounds for VLSI computation by &ldquo;crossing sequence&rdquo; methods. A number of natural questions are raised by these definitions. 1.Is the fooling set approach the most powerful way to get information-transfer-based lower bounds? We shall show it is not, and offer a candidate for the title &ldquo;most powerful.&rdquo; Of course, without a precise definition of &ldquo;information transfer argument,&rdquo; there could be other contenders. 2.Are the notions of the three papers cited equivalent? We shall exhibit certain inequivalences among the three notions, although open questions remain. However, we can resolve an open question of Papadimitriou and Sipser [PS] concerning the relationship between nondeterministic and deterministic communication complexity.


#*Logical correctness by construction
#@S. M. Leinwand
#t1982
#cProceedings of the 19th Design Automation Conference
#index553518
#%551446
#%553497
#%553681
#!A novel methodological approach to the design of large-scale-integrated systems proposed correctness by construction. By using a restricted repertoire of admissible combination rules, it is possible to guarantee that only designs suitable for implementation are generated. This paper addresses the complementary issue of logical correctness by construction - prohibiting "meaningless" constructs from occurring. The presented approach is based on defining &ldquo;meaning&rdquo; in terms of a catalog of standard operators. Admissible compositions are restricted so that only constructs belonging to this catalog may be generated. This approach is mainly intended for the data-path of digital systems. There, repetitive and regular compositions provide a suitable environment for using catalogs of operators. The paper focuses on the description of operators relevant to the design at Register Transfer Level. Manipulation rules are used for describing their properties. Rules basic to logical correctness by construction are shown to be: contractions, expansions and transformations into canonical forms.


#*A method for adaptive performance improvement of operating systems
#@David Reiner,Tad Pinkerton
#t1981
#cProceedings of the 1981 ACM SIGMETRICS conference on Measurement and modeling of computer systems
#index551398
#%192954
#%274825
#%314874
#%328722
#%331351
#%331474
#%545774
#%617678
#%554531
#%552168
#!This paper presents a method for dynamic modification of operating system control parameters to improve system performance. Improved parameter settings are learned by experimenting on the system. The experiments compare the performance of alternative parameter settings in each region of a partitioned load-performance space associated with the system. The results are used to modify important control parameters periodically, responding to fluctuations in system load and performance. The method can be used to implement adaptive tuning, to choose between alternative algorithms and policies, or to select the best fixed settings for parameters which are not modified. The method was validated and proved practical by an investigation of two parameters governing core quantum allocation on a Sperry Univac 1100 system. This experiment yielded significant results, which are presented and discussed. Directions for future research include automating the method, determining the effect of simultaneous modifications to unrelated control parameters, and detecting dominant control parameters.


#*Virtual memory management for database systems
#@Irving L. Traiger
#t1982
#cACM SIGOPS Operating Systems Review
#index111439
#%304023
#%319143
#!Over the last several years, a number of hardware and software systems have been developed which map entire files directly into the virtual memory address spaces used by programs. Since all file contents are directly addressable, there is no need for a programmer to issue explicit file system actions, such as Read or Write. In addition, all of the buffer management problems are eliminated, since programmers do not have to squeeze pieces of large files into small virtual spaces. Although these advantages are tempting, we find that database systems have gone their own way. In this paper, we will look at two particular approaches to database system design, and see how (and why) they interface to file systems as they do. We will then look at the potential advantages and implications of working more closely with virtual memory management, and describe some of the functions and constraints that would have to be supported by a generalized page manager.


#*The Complexity of the Inequivalence Problem for Regular Expressions with Intersection
#@Martin Fürer
#t1980
#cProceedings of the 7th Colloquium on Automata, Languages and Programming
#index359255


#*The subjective nature of programming complexity
#@Daniel G. McNicholl,Ken Magel
#t1982
#cProceedings of the 1982 conference on Human factors in computing systems
#index551942
#%622654
#!One of the more difficult problems confronting software engineers today is the construction of accurate predictive models of the software development process, [2],[8] and [9]. It has long been recognized that one of the most essential elements of any successful model of this process is a quantification of the complexity of software systems. During the past several years a great deal of work has been performed by researchers such as Halstead [3], McCab [5], and others in an attempt to develop metrics which adequately capture the complexity of software systems. Yet one very important aspect of software development complexity seems to have been overlooked in the rush to develop software complexity metrics, q.e. it's psychological nature. A basic tenet of our research is that the effort to develop a software system is a function of it's 'perceived' complexity; which in turn is dependent upon both the physical nature of the software system being developed and the psychological nature of the individual(s) performing the development. The immediate goal of the research reported on in this paper was to examine this dual dependency. In order to do so we collected data from two sections (same instructor) of a college sophomore - level class on PL/I which consisted of fifty-six students. During this class each student was given six written programming assignments which were relatively simple in scope.


#*A topology for semicustom array-structured LSI devices, and their automatic customisation
#@P. Jennings
#t1983
#cProceedings of the 20th Design Automation Conference
#index555026
#%545512
#%549495
#%551586
#%551977
#%553804
#%554155
#%554767
#!This paper describes the design of a topology for array-structured (both Gate-Array and Polycell) semicustom LSI, in the context of a CMOS gate-array fabricated to test both the topology and the unique functional cells. Design emphasis has been placed on 100% routability, which is achieved by use of interdigitating cell terminals. Also described is the structure and operation of an automatic customisation software package which has been developed for the array, and which utilises the topological advantages to achieve track densities which are comparable with state-of-the-art algorithms. Examples are cited which show that this methodology is economical in both its speed of operation and its silicon-area utilisation.


#*Fast transient security evaluation of power systems by using pattern recognition techniques
#@Sasan Mokhtari
#t1983
#c
#index190849


#*An information theory based complexity measure
#@Eli Berlinger
#t1980
#cProceedings of the May 19-22, 1980, national computer conference
#index55057
#%345542
#%339148
#%303868
#%69690
#%347981
#%321608
#%622654
#!There have been numerous measures proposed to measure program complexity. Some are completely heuristic, comparing certain measurable program features against a set of predefined standards. Some are topological, based on the number of regions on the control or data graph of the programs or a combination of the above, and of course, there is Halstead's Software Physics.


#*Information systems: A disciplined approach to design
#@S. Imtiaz Ahmad
#t1982
#cProceedings of the thirteenth SIGCSE technical symposium on Computer science education
#index552473
#%179828
#%326404
#!This paper discusses an approach to information system design. It discusses specific factors which should be considered and the steps which should be followed during the phases dealing with study of the situation and analysis of requirements, and external design. For illustration of this disciplined approach, the paper provides examples of organizations such as a medical/dental office, a pharmacy, a retail store, and a repair shop. Details of typical requirements are then derived for these example organizations, followed by a proposal for an external design configuration.


#*Execution environments in programming languages and operating systems
#@Robert Winslow Schwanke
#t1982
#c
#index185965


#*Fast algorithms for the multidimensional discrete fourier transform
#@Abderrezak Guessoum
#t1984
#c
#index196004


#*Fast algorithms under the extended riemann hypothesis: A concrete estimate
#@Eric Bach
#t1982
#cProceedings of the fourteenth annual ACM symposium on Theory of computing
#index554229
#!Several results in theoretical computer science use the following theorem: For a positive integer q, let Z-&-bull;q denote the multiplicative group of all integers x, 0-&-lt;x-&-lt;q, that are relatively prime to q. Let G be a proper subgroup of Z-&-bull;q. Then, assuming the Extended Riemann Hypothesis, there is a constant C such that if q is sufficiently large, Z-&-bull;q-&-minus;G contains a positive integer N-&-le;C (logeq)2. We show that for q-&-ge;106, one may take C-&-equil;60. As an application, we discuss a deterministic polynomial-time primality test. Miller proved that such algorithms must exist if the ERH is true, but we are unable to specify one without the concrete information given above. We eliminate this difficulty, and show how to implement a fast primality test.


#*Computational procedures for solving generalized shortest-path and bottleneck transportation problems
#@Parviz Partow-Navid
#t1981
#c
#index192593


#*Proceedings of the 21st conference on Winter simulation
#@Edward A. MacNair,Kenneth J. Musselman,Philip Heidelberger
#t1989
#cWinter Simulation Conference
#index458543


#*Aggregate manpower requirements for strategic project planning
#@Boma T. Afiesimama
#t1987
#cComputers and Industrial Engineering
#index179552


#*The architecture and programming of the Ametek series 2010 multicomputer
#@C. L. Seitz,W. C. Athas,C. M. Flaig,A. J. Martin,J. Seizovic,C. S. Steele,W-K. Su
#t1988
#cProceedings of the third conference on Hypercube concurrent computers and applications: Architecture, software, computer systems, and general issues - Volume 1
#index487164
#%122465
#%161597
#!During the period following the completion of the Cosmic Cube experiment [1], and while commercial descendants of this first-generation multicomputer (message-passing concurrent computer) were spreading through a community that includes many of the attendees of this conference, members of our research group were developing a set of ideas about the physical design and programming for the second generation of medium-grain multicomputers. Our principal goal was to improve by as much as two orders of magnitude the relationship between message-passing and computing performance, and also to make the topology of the message-passing network practically invisible. Decreasing the communication latency relative to instruction execution times extends the application span of multicomputers from easily partitioned and distributed problems (eg, matrix computations, PDE solvers, finite element analysis, finite difference methods, distant or local field many-body problems, FFTs, ray tracing, distributed simulation of systems composed of loosely coupled physical processes) to computing problems characterized by &ldquo;high flux&rdquo; [2] or relatively fine-grain concurrent formulations [3, 4] (eg, searching, sorting, concurrent data structures, graph problems, signal processing, image processing, and distributed simulation of systems composed of many tightly coupled physical processes). Such applications place heavy demands on the message-passing network for high bandwidth, low latency, and non-local communication. Decreased message latency also improves the efficiency of the class of applications that have been developed on first-generation systems, and the insensitivity of message latency to process placement simplifies the concurrent formulation of application programs. Our other goals included a streamlined and easily layered set of message primitives, a node operating system based on a reactive programming model, open interfaces for accelerators and peripheral devices, and node performance improvements that could be achieved economically by using the same technology employed in contemporary workstation computers. By the autumn of 1986, these ideas had become sufficiently developed, molded together, and tested through simulation to be regarded as a complete architectural design. We were fortunate that the Ametek Computer Research Division was ready and willing to work with us to develop this system as a commercial product. The Ametek Series 2010 multicomputer is the result of this joint effort.


#*An overview of DARK
#@R. van Scoy,J. Bamberger,R. Firth
#t1989
#cACM SIGAda Ada Letters
#index457591
#%185146
#%316041
#!Ada is now being mandated for a large number of DoD development projects as the sole programming language to be used for developing software. Many of these projects are trying to build distributed real-time systems. Many project managers and contractors are anxious to support this effort, to reap the advantages of Ada, and to use the newer techniques of software engineering that Ada can support. This transition, however, has not always been smooth; some serious problems have been encountered. This paper discusses several of thes e problems and describes a prototype software artifact, called the Distributed Ada Real-Time Kernel (DARK), built to address these concerns and to support execution of real-time Ada applications in a distributed, embedded environment. This prototype is not intended to solve all the problems of real-time, embedded systems, but it does provide one viable, near-term option demonstrating that Ada can be used in real-time systems today.


#*Complexity of quantifier elimination in the theory of ordinary differential equations
#@D. Yu. Grigoryev
#t1987
#cProceedings of the European Conference on Computer Algebra
#index263690


#*Online access to knowledge: system design
#@Charles T. Meadow,Barbara A. Cerny,Christine L. Borgman,Donald O. Case
#t1989
#cJournal of the American Society for Information Science
#index482722


#*The annotated &ldquo;The American Black Chamber&rdquo;
#@D. Kahn
#t1987
#cCryptology: yesterday, today, and tomorrow
#index176457


#*HQ-MAC; Ein Konzept zur schmalbandigen, kompatiblen HQTV-&Uuml;bertragung
#@M. Silverberg,W. Boie
#t1987
#cAachener Symposium f&uuml;r Signaltheorie: Mehrdimensionale Signale und Bildverarbeitung
#index571630


#*PC AT graphics must link performance and compatibility
#@T. Williams
#t1987
#cComputer Design
#index172425


#*Efficient parallel solution of linear systems
#@V Pan,J Reif
#t1985
#cProceedings of the seventeenth annual ACM symposium on Theory of computing
#index171861
#%163362
#%171731
#%457304
#!The most efficient known parallel algorithms for inversion of a nonsingular n &times; n matrix A or solving a linear system Ax = b over the rationals require &Ogr;(log n)2 time and M(n)n0.5 processors (where M(n) is the number of processors required in order to multiply two n &times; n rational matrices in time &Ogr;(log n).) Furthermore, all known polylog time algorithms for those problems are unstable: they require the calculation to be done with perfect precision; otherwise they give no results at all. This paper describes parallel algorithms that have good numerical stability and remain efficient as n grows large. In particular, we describe a quadratically convergent iterative method that gives the inverse (within the relative precision 2-nO(1)) of an n &times; n rational matrix A with condition &le; n0(1) in &Ogr;(log n)2 time using M(n) processors. This is the optimum processor bound and the factor n0.5 improvement of known processor bounds for polylog time matrix inversion. It is the first known polylog time algorithm that is numerically stable. The algorithm relies on our method of computing an approximate inverse of A that involves &Ogr;(log n) parallel steps and n2 processors. Also, we give a parallel algorithm for solution of a linear system Ax = b with a sparse n &times; n symmetric positive definite matrix A. If the graph G(A) (which has n vertices and has an edge for each nonzero entry of A) is s(n)-separable, then our algorithm requires only &Ogr;((log n)(log s(n))2) time and |E| + M(s(n)) processors. The algorithm computes a recursive factorization of A so that the solution of any other linear system Ax = b&prime; with the same matrix A requires only &Ogr;(log n log s(n)) time and |E| + s(n)2 processors.


#*What's new in FoxBASE+ version 2
#@George F. Goley
#t1987
#cData Based Advisor
#index171649


#*Security mechanisms in a transport layer protocol
#@Victor L. Voydock,Stephen T. Kent
#t1985
#cComputers and Security
#index159267


#*Modulation of the Intensity of Formalized Attributes
#@Anio O. Arigoni
#t1988
#cProceedings of the 2nd International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems: Uncertainty and Intelligent Systems
#index355476


#*Board-level computers
#@J Hindin
#t1986
#cComputer Design
#index176783


#*Mapping the Interface Description Language Type Model into C
#@K. Shannon,Richard Thomas Snodgrass
#t1989
#cIEEE Transactions on Software Engineering
#index473169
#%144562
#%149776
#%151297
#%151679
#%156713
#%178360
#%179752
#%182954
#%183516
#%192174
#%452292
#%472874
#%621401
#!The Interface Description Language (IDL) is a notation for describing the characteristics of data structures passed among collections of cooperating processes in a programming environment. The authors discuss a mapping from IDL to C data structures and macro definitions that supports the full language and is type safe and run-time efficient, but is not particularly compile-time efficient nor easy to use. They then propose that the mapping be performed in a preprocessor, thereby achieving efficiency and ease of use as well.


#*Type inference for record concatenatiOn and multiple inheritance
#@M. Wand
#t1989
#cProceedings of the Fourth Annual Symposium on Logic in computer science
#index474313


#*The location of central structures in trees
#@Rex K. Kincaid,Timothy J. Lowe,Thomas L. Morin
#t1988
#cComputers and Operations Research
#index177539


#*The scientific community metaphor
#@William A. Kornfeld,Carl E. Hewitt
#t1988
#cDistributed Artificial Intelligence
#index455566


#*Keeping score one score later - Two decades of the Simulation Games journal
#@R. D. Duke,N. K. Kemeny
#t1989
#cSimulation and Gaming
#index472112


#*An empirical study of the effect of granularity on parallel algorithms on the connection machine
#@Sam H. Noh,Dipak Ghosal,Ashok K. Agrawala
#t1989
#c
#index510852


#*User Reference Manual for Task Level Data Flow Language: Version 1
#@Nicolas Graner,Jit Biswas
#t1986
#c
#index193614


#*Modeling the user's plans and goals
#@Sandra Carberry
#t1988
#cComputational Linguistics
#index450035
#%159044
#%311680
#!This work is an ongoing research effort aimed both at developing techniques for inferring and constructing a user model from an information-seeking dialog and at identifying strategies for applying this model to enhance robust communication. One of the most important components of a user model is a representation of the system's beliefs about the underlying task-related plan motivating an information-seeker's queries. These beliefs can be used to interpret subsequent utterances and produce useful responses. This paper describes the IREPS system, emphasizing its dynamic construction of the task-related plan motivating the information-seeker's queries and the application of this component of a user model to handling utterances that violate the pragmatic rules of the system's world model. By reasoning on a model of the user's plans and goals, the system often can deduce the intended meaning of faulty utterances and allow the dialogue to continue without interruption. Some limitations of current plan inference systems are discussed. It is suggested that the problem of detecting and recovering from discrepancies between the system's model of the user's plan and the actual plan under construction by the user requires an enriched model that differentiates among its components on the basis of the support the system accords each component as a correct and intended part of the user's plan.


#*Contrasting translation, verification and synthesis in software and firmware engineering
#@R. A. Mueller,G. R. Johnson
#t1989
#cTutorial: microprogramming and firmware engineering
#index485034


#*Multi-thread input
#@P P Tanner
#t1987
#cACM SIGGRAPH Computer Graphics
#index154549
#%144165
#%151925
#%181451
#%183827
#%547632
#%175207
#%182815
#!Implementors of interactive computer workstations have tended to shy away from making several devices simultaneously available to a user of their systems. The principal reason for this reluctance has been the difficulty faced by an application program in analyzing the several streams of input that such a configuration would present. Recently systems have been developed that support such multi-thread input. This paper discusses the requirements of multi-thread input and gives examples of how the requirements are being met by the experimental systems.


#*New Trellis codes based on lattices and cosets
#@A.R. Calderbank,N. J. A. Sloane
#t1987
#cIEEE Transactions on Information Theory
#index146174


#*On numerical modelling of one-dimensional stochastic wave problems
#@I O Yaroshchuk
#t1986
#cUSSR Computational Mathematics and Mathematical Physics
#index158969


#*Some informational requirements for convergence
#@Donald G. Saari
#t1987
#cJournal of Complexity
#index150841


#*Robust shrinkage estimators of the location parameter for elliptically symmetric distributions
#@Dominique Cellier,Dominique Fourdrinier,Christian Robert
#t1989
#cJournal of Multivariate Analysis
#index514822


#*SIMD language design using prescriptive semantics
#@A. Stewart
#t1988
#cBIT
#index451477


#*The Datar story
#@Ted Paull,John Vardalas
#t1987
#cCIPS Review
#index172268


#*Built-in Self Testing of Embedded Memories
#@Sunil Jain,Charles Stroud
#t1986
#cIEEE Design Test
#index351437
#!The authors present a built-in self-test (BIST) method for testing embedded memories. Two algorithms are proposed for self-testingof embedded bedded RAMs, both of which can detect a large variety of stuck-at and non-stuck-at faults. The hardware implementationof the methods requires a hardware test-pattern generator, which produces address, data, and read/write inputs. The outputresponses of the memory can be compressed by using a parallel input signature analyzer, or they can be compared with expectedresponses by an output comparator. The layout of memories has been considered in the design of additional BIST circuitry.The authors conclude by evaluating the two schemes on the basis of area overhead, performance degradation, fault coverage,test application time, and testing of self-test circuitry. The BIST overhead is very low and test time is quite short. Sixdevices, with one of the test schemes, have been manufactured and are in the field.


#*Managing Your Office with Macintosh (Chilton Needlework Series)
#@Phillip I. Good
#t1985
#c
#index15473


#*A digital imaging processing method for gastric endoscope picture
#@H. Kodama,F. Yano,S. P. Ninomija,Y. Sakai,S. Ninomiya
#t1988
#cProceedings of the Twenty-First Annual Hawaii International Conference on Applications Track
#index480139


#*Exercises for introducing software engineering concepts in a data stuctures course
#@Anita Zoe Leibowitz
#t1986
#cACM SIGCSE Bulletin
#index179392


#*Introduction to computers and programming: Pascal
#@Peter P Smith
#t1986
#c
#index178806


#*Searching techniques for databases of protein secondary structures
#@P. J. Artymiuk,D. W. Rice,E. M. Mitchell,P. Willet
#t1989
#cJournal of Information Science
#index453478


#*Efficient structures for geometric data management
#@Oliver Gunther
#t1987
#c
#index200356


#*Some remarks concerning B-splines
#@E. T. Y. Lee
#t1985
#cComputer Aided Geometric Design
#index151081


#*Application of numbered graphs in the design of multi-stage telecommand codes
#@S. Ganesan,M. O. Ahmad
#t1985
#cGraph theory with applications to algorithms and computer science
#index161916


#*A Software Development Environment based on Graph Technology
#@Manfred Nagl
#t1986
#cProceedings of the 3rd International Workshop on Graph-Grammars and Their Application to Computer Science
#index266206


#*VAMPIX, a multimicroprocessor control system adaptable to special complex machines
#@D. Flego,H. Schweinzer
#t1987
#cMicroprocessing and Microprogramming
#index165050


#*First steps towards fully abstract semantics of object-oriented languages
#@P. M. Yelland
#t1989
#cThe Computer Journal
#index487810


#*Group technology cell formation- some new insights
#@R. Meenakshi Sundaram,Shong-Shun Fu
#t1987
#cComputers and Industrial Engineering
#index152392


#*The Trillium user interface design environment
#@D. A. Henderson, Jr.
#t1986
#cACM SIGCHI Bulletin
#index180639
#!Trillium is a computer-based environment for simulating and experimenting with interfaces for simple machines. For the past four years it has been use by Xerox designers for fast prototyping and testing of interfaces for copiers and printers. This paper defines the class of &ldquo;functioning frame&rdquo; interfaces which Trillium is used to design, discusses the major concerns that have driven the design of Trillium, and describes the Trillium mechanisms chosen to satisfy them.


#*A branch-and-bound approach to the bicriterion scheduling problem invloving total flowtime and range of lateness
#@Tapan Sen,Farhad M. E. Raiszadeh,Parthasarati Dileepan
#t1988
#cManagement Science
#index458393


#*Mental images and the architecture of concepts
#@J. A. Makowsky
#t1988
#cA half-century survey on The Universal Turing Machine
#index456383


#*The Semantics of Priority and Fairness in occam
#@Geoff Barrett
#t1989
#cProceedings of the 5th International Conference on Mathematical Foundations of Programming Semantics
#index560614


#*Level number sequences for trees
#@P. Flajolet,H. Prodinger
#t1987
#cDiscrete Mathematics
#index173657


#*Proceedings of the 14th annual international symposium on Computer architecture
#@D. St. Clair
#t1987
#cInternational Symposium on Computer Architecture
#index160695


#*R&uuml;stungshaushalt 1987 und Informationstechnik
#@Karlheinz Hug,Thomas Ludwig,Cornelia Teller
#t1986
#cUmdenken in der Informatik [2. Jahrestagung des Forums Informatiker f&uuml;r Frieden und gesellschaftliche Verantwortung e.V.
#index378814


#*A special case of dynamic pricing policy
#@Birger Wernerfelt
#t1986
#cManagement Science
#index168477


#*The heart-lung pump/human interface: a real-time microcomputer-based simulation
#@Richard M. Campbell
#t1989
#c
#index187014


#*Forth for IBM mainframe computers
#@S. N. Baranoff
#t1989
#cJournal of FORTH Application and Research
#index478646


#*Affect-chaining and dependency oriented flow analysis applied to queries of programs
#@Mariam Kamkar,Nahid Shahmehri,Peter Fritzson
#t1988
#cProceedings of the 1988 ACM SIGSMALL/PC symposium on ACTES
#index453435
#%166278
#%203914
#%204331
#%252881
#%317235
#%321608
#%324621
#!Most of the work on static program flow analysis has been done in the context of code optimization. The situation is different for an application such as an interactive query tool for programmer support. Primarily this is because the information wanted is different from what is needed for optimization, but also because incremental flow analysis algorithms are much more relevant in this context. In this paper we introduce the concept of affect-chaining, which is the process of analysing flow of data between variables in a program. The objective is to help the user to better understand data flow and data dependencies in programs not only during design and coding but also during test, debugging and maintenance. We present both forward- and backward- versions of affect-chaining analysis together with efficient algorithms. A long term goal of the work presented in this paper is to combine results from static analysis of a program and information from the run-time state during execution of the same program. The idea is, that this combination will enable an interactive query tool to answer questions about possible reasons for unexpected program behavior, and also to inform about possible consequences of a program change which may be considered. Another goal is to develop better estimates of software complexity based on affect-chaining dependencies.


#*Computational vision and regularization theory
#@Tomaso Poggio,Vincent Torre,Christof Koch
#t1987
#cReadings in computer vision: issues, problems, principles, and paradigms
#index176361


#*On the intersection of edges of a geometric graph by straight lines
#@N Alon,M A Perles
#t1986
#cDiscrete Mathematics
#index152641


#*Semigroups of tolerance relations
#@B. M. Schein
#t1987
#cDiscrete Mathematics
#index169446


#*Application input drivers
#@Jeremy Sagan
#t1987
#cBYTE
#index151246


#*Analysing nets by the invariant method
#@G. Memmi,J. Vautherin
#t1987
#cAdvances in Petri nets 1986, part I on Petri nets: central models and their properties
#index165158


#*Fundamentals in computer understanding: speech and vision
#@Jean-Paul Haton
#t1987
#c
#index179434


#*Wissensgesteuerte Bildfolgenauswertung zur automatischen F&uuml;hrung von Stra&szlig;enfahrzeugen in Echtzeit
#@Klaus-Dieter Kuhnert,Alfred Zapp
#t1985
#cMustererkennung 1985, DAGM-Symposium
#index573419


#*Konzeption einer neuen Ada-Programmierumgebung f&uuml;r die Bildfolgenauswertung
#@Helmut Faasch,Volker Haarslev
#t1985
#cMustererkennung 1985, DAGM-Symposium
#index563192


#*Computer aided signal box design at Belgian railways
#@P. J. Damas,P. Maebe
#t1987
#cComputers in railway management
#index164908


#*Towards more powerful conceptual schema languages
#@P. Creasy
#t1989
#cProceedings of the tenth international conference on Information Systems
#index478675


#*The complexity of Gentzen systems for propositional logic
#@A. Urquhart
#t1989
#cTheoretical Computer Science
#index456673


#*Deep knowledge representation techniques
#@Anthony G. Cohn
#t1986
#cProc. of the fifth technical conference of the British Computer Society Specialist Group on Expert Systems on Expert systems 85
#index165306


#*Display proximity in multicue information integration: the benefits of boxes
#@Barbara J. Barnett,Christopher D. Wickens
#t1988
#cHuman Factors
#index172882


#*Solving the problem of data security
#@John Francis,Jim Mann
#t1986
#cCIPS Review
#index181865


#*Scratchpad II: an abstract datatype system for mathematical computation
#@Richard D. Jenks,Robert S. Sutor,Stephen M. Watt
#t1988
#cMathematical aspects of scientific software
#index149832


#*Metainterpreters for expert system construction
#@Leon Sterling,Randall D. Beer
#t1989
#cJournal of Logic Programming
#index475926


#*Dynamic modeling and control of robotic manipulators (robotics, control engineering, nonlinear control)
#@Vassilios Dimitrios Tourassis
#t1985
#c
#index191687


#*Three bus interface designs for the PC
#@James R. Drummond
#t1987
#cBYTE
#index151828


#*Disk Striping
#@Kenneth Salem,Hector Garcia-Molina
#t1986
#cProceedings of the Second International Conference on Data Engineering
#index368234


#*Optimal complexity recovery of band- and energy-limited signals II
#@M. A. Kowalski,F. Stenger
#t1989
#cJournal of Complexity
#index475940


#*Articulated figure positioning by multiple constraints
#@Norman I. Badler,Kamran H. Manoocherhri,Grahm Walters
#t1987
#cIEEE Computer Graphics and Applications
#index148760


#*The introduction of robotic technology: perceptions of the work force of an aerospace defense company
#@William Burford Rose, Jr.
#t1988
#c
#index204913


#*Call for Papers ITC '87 Integration of Test with Design And Manufacturing
#@
#t1986
#cIEEE Design Test
#index343969


#*An approach to the automated acquisition of production rules from repertory grid data
#@Kenneth Michael Ford
#t1987
#c
#index188695


#*Communications software
#@
#t1988
#cPersonal Computing
#index182821


#*A supercomputer programming system
#@Adeeb Zarea Aliabadi
#t1986
#c
#index203574


#*Software tutorials for DOS, Wordperfect, TWIN, and dBase III Plus
#@D. Swabey,D. P. Curtin
#t1987
#c
#index470317


#*Software quality assurance plans applied to CA.ST.OR
#@M. Afzali,A. Chaudouet-Miranda,M. Herve
#t1987
#cEdited papers presented at the 1st International Conference on Reliability and robustness of engineering software
#index159615


#*Configuring graphics systems components
#@David B. Arnold,Graham J. Reynolds
#t1988
#cSoftware Engineering Journal
#index467721


#*Cognitive and psychological computation with neural models
#@James A. Anderson
#t1988
#cArtificial neural networks: theoretical concepts
#index512258


#*Parabolic wave equation approximations in heterogenous media
#@A. Bamberger,B. Engquist,L. Halpern,P. Joly
#t1988
#cSIAM Journal on Applied Mathematics
#index154834


#*Breaking the Ong-Schnorr-Shamir Signature Scheme for Quadratic Number Fields
#@Dennis Estes,Leonard M. Adleman,Kireeti Kompella,Kevin S. McCurley,Gary L. Miller
#t1985
#cAdvances in Cryptology
#index263229


#*Aspekte der Datenbank-Anbindung in workstation-orientierten Ingenieuranwendungen
#@Christoph Hübel,Bernd Sutter
#t1989
#cGI - 19. Jahrestagung, I, Computergest&uuml;tzter Arbeitsplatz
#index260852


#*The scattering matrix associated with a stationary stochastic process: system theoretic properties and role in realization
#@Yehuda Avniel
#t1986
#cModelling and applications of stochastic processes
#index167292


#*Learning regular languages from counterexamples
#@Oscar H. Ibarra,Tao Jiang
#t1988
#cProceedings of the first annual workshop on Computational learning theory
#index473865


#*Concurrent programming
#@André Schiper
#t1989
#c
#index457097


#*Typical weaknesses in operating system software
#@Dena Tensa
#t1987
#cInformation Age
#index166250


#*Development of an object-oriented DBMS
#@David Maier,Jacob Stein,Allen Otis,Alan Purdy
#t1986
#cACM SIGPLAN Notices
#index151679
#%151297
#%179100
#%173037
#%358759
#%439341
#%178659
#%545819
#%545982
#%238352
#%554098
#%159559
#%550887
#%371795
#%551550
#%374988
#%367948
#%550841
#!We describe the results of developing the GemStone object-oriented database server, which supports a model of objects similar to that of Smalltalk-80. We begin with a summary of the goals and requirements for the system: an extensible data model that captures behavioral semantics, no artificial bounds on the number or size of database objects, database amenities (concurrency, transactions, recovery, associative access, authorization) and an interactive development environment. Object-oriented languages, Smalltalk in particular, answer some of these requirements. We discuss satisfying the remaining requirements in an object oriented context, and report briefly on the status of the development efforts. This paper is directed at an audience familiar with object-oriented languages and their implementation, but perhaps unacquainted with the difficulties and techniques of database system development. It updates the original report on the project [CM], and expands upon a more recent article [MDP].


#*PHRED: a generator for natural language interfaces
#@P. S. Jacobs
#t1988
#cNatural language generation systems
#index457545


#*A framework of composite information systems for strategic advantage
#@Stuart E. Madnick,Y. Richard Wang
#t1988
#cProceedings of the Twenty-First Annual Hawaii International Conference on Decision Support and Knowledge Based Systems Track
#index467809


#*Evaluating computer education programs in the schools
#@Karen Billings
#t1986
#cTopics in computer education: national educational computer policy alternatives
#index153749


#*Retrofitting the VAX-11/780 Microarchitecture for IEEE Floating Point Arithmetic Implementation Issues, Measurements, and Analysis
#@David B. Aspinwall,Yale N. Patt
#t1985
#cIEEE Transactions on Computers
#index157926
#!The VAX-11/7801 was designed specifically to implement the VAX architecture. As such, it does not support the IEEE standard for floating point arithmetic. A project was undertaken to provide this support by modifying the 11/780 microarchitecture. Our objective was to produce a microengine that would efficiently execute the VAX instruction set, modified to handle VAX floating point instructions in accordance with the IEEE standard. Our methodology was to make minimal changes to the 11/780 hardware, relying primarily on changes to the microcode. This paper describes the modifications required to implement the IEEE standard, examines the various design alternatives available to us, presents measurements of our implementation, and analyzes our results. We also offer some comments on the matter of retrofitting an existing architecture to a new unintended use.


#*Solving sparse linear systems by an ABS-method that corresponds to LU-decomposition
#@K. H. Phua
#t1988
#cBIT
#index470744


#*A protocol for wait-free, atomic, multi-reader shared variables
#@Richard Newman-Wolfe
#t1987
#cProceedings of the sixth annual ACM Symposium on Principles of distributed computing
#index165434
#%169502
#%320699
#%335624
#%314817
#%334601
#%329642
#%330671


#*Application of the modified gauss-newton algorithm to linear adaptive equalizers
#@Kent Lynn Torell
#t1989
#c
#index200607


#*1985 DP salary survey
#@
#t1985
#cDatamation
#index161071


#*The object-oriented classification paradigm
#@Peter Wegner
#t1987
#cResearch directions in object-oriented programming
#index155704


#*MacApp - ein objektorientiertes Rahmenprogramm zur Gestaltung graphischer Benutzungsoberfl&auml;chen
#@Oliver Juwig
#t1988
#cGraphik im B&uuml;robereich, GI-Fachgespr&auml;ch
#index263106


#*National Science Foundation support for computer and information science and engineering
#@Harold E Bamford,Charles N Brownstein
#t1986
#cInformation Processing and Management: an International Journal
#index150086


#*Learning to Program: Macintosh Pascal Supplement
#@Israel Urieli,Andy Noori
#t1987
#c
#index7907


#*A corporate online database: perspectives on an in-house text retrieval system - Part II: operating the system
#@N. Audino,J. Borbely
#t1989
#cDatabase
#index453849


#*Applications generators: dBase III Plus versus System Builder
#@Roger Woods
#t1986
#cMini-Micro Software
#index176118


#*Research and Development in Expert Systems VI: Proceedings of Expert Systems, the Ninth Annual Technical Conference of the BCS Specialist Group on Expert Systems
#@Nigel Shadbolt
#t1989
#c
#index244341


#*Symmetry-curvature duality
#@Michael Leyton
#t1987
#cComputer Vision, Graphics, and Image Processing
#index173505


#*What you need to know about hypertext
#@P. Saffo
#t1987
#cPersonal Computing
#index178602


#*Tracking three-dimensional moving light displays
#@Michael Jenkin
#t1986
#cProc. of the ACM SIGGRAPH/SIGART interdisciplinary workshop on Motion: representation and perception
#index144820


#*Constructing transpose-orthogonal Latin squares
#@Sandra C. McLaurin,Douglas D. Smith
#t1989
#cJournal of Combinatorial Theory Series A
#index467003


#*Invariants of Chromatic Graphs
#@Teresa M Przytycka,J. H. Przytycki
#t1988
#c
#index204175
#!In the paper we construct abstract algebras which yield invariants of graphs (including graphs with colored edges --- chromatic graphs). We analyse properties of those algebras. We show that various polynomials of graphs are yielded by models of the algebras (including Tutte and matching polynomials). In particular we consider a generalization of Tutte''s polynomial to a polynomial of chromatic graphs. We analyse relation of graph polynomials with recently discovered link polynomials. \n It is known that computing of the Tutte polynomial is NP-hard. We show that a part of Tutte polynomial (and its generalization) can be computed faster than in exponential time.


#*On the bound states of the nonlinear Schro&uml;dinger equation with a linear potential
#@H. A. Rose,M. I. Weinstein
#t1988
#cPhysica D
#index487010


#*Algorithm directed performance evaluation (measurement)
#@Thomas Marvin Bottegal
#t1985
#c
#index205446


#*Automatic synthesis of concurrent control for multiprocessor systems of general topology through fine-grain mapping
#@L. Shih
#t1989
#c
#index471763


#*Materials for information and communication
#@John S Mayo
#t1986
#cScientific American
#index165010


#*An optimization of queries in distributed database systems
#@Chin-Wang Chung,Keki B Irani
#t1986
#cJournal of Parallel and Distributed Computing
#index176958


#*A pipelined recursive residue number system digital filter
#@M A Soderstrand,B Sinha
#t1986
#cResidue number system arithmetic: modern applications in digital signal processing
#index144695


#*dBase III tips and traps
#@Dick Andersen,Cynthia Cooper,Bill Demsey
#t1986
#c
#index164664


#*Expert form feature modelling shell
#@J. J. Shah,M. T. Rogers
#t1988
#cComputer-Aided Design
#index459740


#*QN3D: A three-dimensional quasi-neutral hybrid particle-in-cell code with applications to the tilt mode instability in field reversed configurations
#@E. J. Horowitz
#t1989
#cJournal of Computational Physics
#index487222


#*Applying formal specification to software development in industry
#@Ian Hayes
#t1987
#cSpecification case studies
#index529851


#*Partial evaluation of metaprograms in a &ldquo;Multiple Worlds" logic language
#@G. Levi,G. Sardu
#t1988
#cNew Generation Computing
#index457444


#*Solar cell produces hydrogen from seawater
#@W. Worthy
#t1989
#cChemical Engineering News
#index450948


#*Guest Editor's Introduction: The Fourth International Conference on Data Engineering
#@J. V. Carlis
#t1989
#cIEEE Transactions on Knowledge and Data Engineering
#index443336


#*WORM technology: the state-of-the-art
#@Nancy K. Herther
#t1987
#cDatabase
#index182294


#*Synopsis of recent progress on camera calibration for 3D machine vision
#@Roger Tsai
#t1989
#cThe robotics review 1
#index467171


#*Implementing direct manipulation query languages using an adequate data model
#@Rainer Gimnich
#t1988
#cSelected Contributions from the on 7th Interdisciplinary Workshop on Informatics and Psychology: Visualization in Human-Computer Interaction
#index359789


#*Structuring meta knowledge&mdash;a knowledge representation system for cooperative systems
#@A. L. Rector
#t1988
#cProceedings of Expert Systems '87 on Research and Development in Expert Systems IV
#index471955


#*Spreadsheet calculations of probabilities from the F, t, χ2, and normal distribution
#@Frank G. Landram,James R. Cook,Marvin Johnston
#t1986
#cCommunications of the ACM
#index182135
#%329136
#!By computing probabilities from the normalization of the F distribution (instead of by numerical integration methods), statistical capabilities in spreadsheet operations can be greatly expanded and enhanced.


#*Tones of voice: the role of intonation in computer speech understanding
#@Christopher Longuet-Higgins
#t1986
#cComputer speech processing
#index161546


#*Finite-element semi-discretization of linearized compressible and resistive MHD
#@W Kerner,A Jakoby,K Lerbinger
#t1986
#cJournal of Computational Physics
#index177199


#*Use of a general-purpose multi-microprocessor system in robot control and artificial intelligence applications
#@G. Kinnemann,H.-H. Lange
#t1987
#con Artificial Intelligence and Information-Control systems of Robots-87
#index470501


#*Low cost local area networks
#@Stephen P.M. Bridges
#t1986
#c
#index176523


#*Remark on &ldquo;Algorithm 569: COLSYS: Collocation Software for Boundary-Value ODEs [D2]&rdquo;
#@J.-Fr. Hake
#t1986
#cACM Transactions on Mathematical Software (TOMS)
#index325442
#%323523
#%324578


#*Computer-aided data acquisition and instruction
#@William G Culbreth
#t1985
#cFiftieth annual meeting of the Pacific Southwest Section of the American Society? on Computer-aided processes in instruction and research
#index155144


#*A note on the Chebyshev coefficients of the general order derivative of an infinitely differentiable function
#@Andreas Karageorghis
#t1988
#cJournal of Computational and Applied Mathematics
#index469123


#*Unranking and ranking spanning trees of a graph
#@C. J. Colbourn,R. P. Day,L. D. Nel
#t1989
#cJournal of Algorithms
#index457851


#*Software quality&mdash;the theoretical view
#@R. L. Glass
#t1987
#cSystem Development
#index159916


#*An object-oriented class library for C++ programs
#@K. E. Gorlen
#t1987
#cSoftware&mdash;Practice Experience
#index158488


#*Divergence-free velocity fields in nonperiodic geometries
#@L. S. Tuckerman
#t1989
#cJournal of Computational Physics
#index459939


#*Structuring techniques, an introduction using Turbo Pascal
#@Andrew C. Staugaard, Jr.
#t1989
#c
#index454323


#*On certain bandwidth restricted versions of the satisfiability problem of propositional CNF formulas
#@V. Arvind,S. Biswas
#t1987
#cProc. of the seventh conference on Foundations of software technology and theoretical computer science
#index149709


#*Toward High Confidence Software
#@J. P. Cavano
#t1985
#cIEEE Transactions on Software Engineering
#index350610
#!Moving toward high confidence software that can meet ever increasing demands for critical DOD applications will require planning, specifying, selecting, and managing the necessary development and testing activities that will ensure the success of the software project. In order to trust the decisions being made, there must be evidence (i.e., an information base of data and facts) that techniques and tools being chosen for application on critical projects will perform as expected. Today, these expectations are mostly intuitive; there is little hard evidence available to guide acquisition managers and software developers in making necessary decisions.


#*Object recognition in multi-resolution systems
#@V. Cantoni,L. Carrioli,M. Ferretti,L. Lambardi,K. Matthews
#t1988
#cProceedings of the NATO Advanced Research workshop on Real-time object measurement and classification
#index147077


#*A simple proof of the regularity theorem for the variational inequality of the obstacle problem
#@B Gustafsson
#t1986
#cNon-Linear Analysis
#index184595


#*President's choice: products with punch
#@M Antonoff
#t1987
#cPersonal Computing
#index180260


#*Evaluation transformers&mdash;a model for the parallel evolution of functional languages
#@Geoffrey L. Burn
#t1987
#cProc. of a conference on Functional programming languages and computer architecture
#index149430


#*Indirect naming in distributed programming languages
#@D. D. Jung,E. Sibert
#t1989
#cACM SIGPLAN Notices
#index478864
#%155388
#%158029
#%171332
#%191749
#%318723
#%319232
#%326751
#%330862
#%332514
#%621765
#%546061
#!Direct naming of processes in message communication is not desirable in distributed programming, because it requires a priori knowledge of sending and receiving process names. This not only complicates the construction of library or utility programs, but also is not suitable for a dynamic process creation environment. Indirect naming of processes in distributed message communication can be achieved either by introducing channels (ports) or by using process variables. This paper discusses how a new distributed programming language, COPL, achieves indirect naming effectively by using process variables without introducing shared objects, such as channels, in a distributed environment where dynamic process acitivation and selection of communicating partners are important.


#*An unpredictability approach to finite-state randomness
#@Mary G. O'Connor
#t1988
#cJournal of Computer and System Sciences
#index471764


#*Transputer-based experiments with the ZAPP architecture
#@D L McBurney,M R Sleep
#t1987
#cVolume I: Parallel architectures on PARLE: Parallel Architectures and Languages Europe
#index183864


#*RSPACE: a set of programs to define completely the reaction space of J. B. Thompson, Jr.
#@A. Colombi
#t1989
#cComputers Geosciences
#index485317


#*Access to college science: microcomputer-based laboratories for the naive science learner
#@Ronald K. Thornton
#t1987
#cCollegiate Microcomputer
#index160747


#*On the order of the largest induced tree in a random graph
#@Z Palka,A Ruciński
#t1986
#cDiscrete Applied Mathematics
#index152243


#*Bidding for contracts
#@William Samuelson
#t1986
#cManagement Science
#index153937


#*Computer-Vision Update
#@R. M. Haralick,Alan K. Mackworth,S. L. Tanimoto
#t1989
#c
#index203561


#*On a natural extension of Jacob's ranks
#@Jacques Justin,Giuseppe Pirillo
#t1986
#cJournal of Combinatorial Theory Series A
#index146432


#*Toward a Real-Time Dataflow Language
#@A. A. Faustini
#t1986
#cIEEE Software
#index353189
#!This extension of the Lucid language seeks a high-level, real-time software-oriented tool with a formal mathematical semantics in which real time is part of correctness.


#*NOVA: state assignment of finite state machines for optimal two-level logic implementations
#@T. Villa,A. Sangiovanni-Vincentelli
#t1989
#cProceedings of the 26th ACM/IEEE Design Automation Conference
#index479475
#%201552
#!The problem of encoding the states of a synchronous Finite State Machine (FSM), so that the area of a two-level implementation of the combinational logic is minimized, is addressed. As in previous approaches, the problem is reduced to the solution of the combinatorial optimization problems defined by the translation of the cover obtained by a multiple-valued logic minimization or by a symbolic minimization into a compatible Boolean representation. In this paper we present algorithms for their solution, based on a new theoretical framework that offers advantages over previous approaches to develop effective heuristics. The algorithms are part of NOVA, a program for optimal encoding of control logic. Final areas averaging 20% less than other state assignment programs and 30% less than the best random solutions have been obtained. Literal counts averaging 30% less than the best random solutions have been obtained.


#*Design Automation TC Newsletter
#@
#t1988
#cIEEE Design Test
#index439180


#*Scientific and technical text processing using wordstar: a guide for beginning and advanced users
#@Charles P McKeague
#t1985
#c
#index147060


#*A parallel statistical cooling algorithm
#@E L Aarts,F J de Bont,J A Habers,P M van Laarhoven
#t1986
#c3rd annual symposium on theoretical aspects of computer science on STACS 86
#index181653


#*Adaptive nonparametric estimation of a multivariate regression function
#@Y. P. Mack,Hans-Georg Müller
#t1987
#cJournal of Multivariate Analysis
#index167847


#*Detection of the P and T waves in an ECG
#@F. Gritzali,G. Frangakis,G. Papakonstantinou
#t1989
#cComputers and Biomedical Research
#index484363


#*Hermes space shuttle: exploration of reentry aerodynamics
#@J. Argyris,I. St. Doltsinis,H. Friz
#t1989
#cComputer Methods in Applied Mechanics and Engineering
#index484252


#*Co-operation of a Macintosh laboratory for Rensselaer's technical writing program
#@Sharon Roy
#t1988
#cProceedings of the 16th annual ACM SIGUCCS Conference on User Services
#index468932
#!Rensselaer Polytechnic Institute's Macintosh Laboratory is a partnership between Information Technology Services and the Department of Language Literature and Communication that attempts to meet a variety of instructional needs. One of the great promises of microcomputers has been to ease the integration of computing into the curriculum by allowing individual departments to design their own computing environments. Unfortunately, that promise has eluded many departments because their programs and their budgets are not large enough to justify the cost of microcomputer laboratories solely for their use. When a department does manage to obtain a private facility, they often have neither the interest nor the staff to keep it open for general campus use. Here at Rensselaer, most faculty who want to use microcomputers in their teaching schedule time in the public microcomputer sites operated by ITS and scheduled through the Registrar's Office. The Registrar's Office has identified a growing demand for these facilities, but the special requests we receive indicate that these general purpose labs are often inadequate for special subject-area needs. An equipment grant from Apple Computer provided an opportunity to serve the specialized needs of the Department of Language, Literature and Communication as well as the general campus need for microcomputer access though a jointly operated Macintosh Laboratory. This paper describes the configuration of the lab and its local area network and some of the problems we encountered in setting it up. But the focus is on the way the lab is actually used in the instructional program of LL C and some of the administrative problems and successes we have encountered in our cooperative venture.


#*scLASERplus professional publishing software
#@
#t1986
#cMini-Micro Software
#index170507


#*Principles of computer science
#@Cullen Schaffer
#t1988
#c
#index185197


#*Identification of partially obscured objects in two and three dimensions by matching noisy characteristic
#@Jacob T. Schwartz,Micha Sharir
#t1987
#cInternational Journal of Robotics Research
#index169679


#*Knowledge-based animation
#@David Zeltzer
#t1986
#cProc. of the ACM SIGGRAPH/SIGART interdisciplinary workshop on Motion: representation and perception
#index145556


#*Networking the OSI model
#@Lefkon
#t1988
#c
#index462498


#*Robust microprocessor control of robot manipulators
#@Mark W. Spong,James S. Thorp,Jeffrey M. Kleinwaks
#t1987
#cAutomatica (Journal of IFAC)
#index155064


#*The Trellis programming environment
#@Patrick D. O'Brien,Daniel C. Halbert,Michael F. Kilian
#t1987
#cACM SIGPLAN Notices
#index180670
#%144536
#%151297
#%180833
#%180761
#!The Trellis programming environment supports programming in Trellis/Owl, an object-based language with multiple inheritance and compile-time type-checking. Trellis is composed of a number of integrated tools that share a common programming environment database. It is a highly interactive, easy-to-use programming environment, providing various programming aids, incremental compilation, and good debugging support. Trellis is both integrated and open-ended. Trellis was specifically designed to support the object-oriented programming methodology. Thus it provides tools to manage the use of types and inheritance. Trellis takes advantage of the strong-typing features of the Trellis/Owl language to provide more support for the programmer by keeping track of cross-references and inconsistencies in code.


#*Capturing the local structure of image discontinuities in two dimensions
#@Yvan Leclerc
#t1987
#cReadings in computer vision: issues, problems, principles, and paradigms
#index162113


#*Molecular recognition: 3d surface structure comparison by gnomonic
#@P. L. Chau,P. M. Dean
#t1987
#cJournal of Molecular Graphics
#index168736


#*Question classification in rule-based systems
#@M. L. G. Shaw,B. R. Gaines
#t1987
#cProceedings of Expert Systems '86, The 6Th Annual Technical Conference on Research and development in expert systems III
#index148953


#*Quadtree Traversal Algorithms for Pointer-Based and Depth-First Representations
#@D. R. Fuhrmann
#t1988
#cIEEE Transactions on Pattern Analysis and Machine Intelligence
#index477912
#%185853
#%318760
#%333034
#!Simple top-down pointer-based quadtree traversal algorithms for four-neighbor traversal, eight-neighbor traversal, and connected-component labeling are proposed. It is shown that for this class of algorithms there exist efficient pointer-based representations that can require as little as 2N bytes, where N is total number of nodes in the tree. The algorithms can also be implemented using a depth-first quadtree representation, at the cost of additional nonrecursive walks over the data structure to locate the arbitrary sons of interior nodes.


#*On the linear complexity of cascaded sequences
#@R Vogel
#t1985
#cProc. of the EUROCRYPT 84 workshop on Advances in cryptology: theory and application of cryptographic techniques
#index146922


#*Computational acoustics
#@R. L. Sterberg
#t1988
#c
#index482198


#*Coping with down time
#@B. Canning
#t1988
#cIMC Journal
#index479936


#*Trace theory
#@A Mazurkiewicz
#t1987
#cAdvances in Petri nets 1986, part II on Petri nets: applications and relationships to other models of concurrency
#index172367


#*Analysis of simulation data using sandie
#@A. Thesen
#t1989
#cProceedings of the 21st conference on Winter simulation
#index487949
#!Sandie is a PC based system designed to perform many of the data analysis chores of simulators. We first show how Sandie is used to analyze input data and to fit theoretical distributions to empirical data. We then show how Sandie can be used to perform simple simulations. Finally, we show how to use Sandie to analyze output data. Special care was made in the development of Sandie to design an easy-to-use system that would serve as an aid in the development of an intuitive "sense of numbers". Pull down menus and a dynamic help-line constantly inform the user of all currently operative options.


#*Designing software and using computer networks to teach basic writing
#@Robert Delius Royar, Jr.
#t1987
#c
#index189543


#*Libraries and the economic development of Ghana
#@A. A. Alemna
#t1989
#cASLIB Proceedings
#index457604


#*Under the hood: hard disk maintenance software
#@L. Brett Glass
#t1989
#cBYTE
#index485286


#*Rectilinear Shortest Paths and Minimum Spanning Trees in the Presence of Rectilinear Obstacles
#@Ying-Fung Wu,Peter Widmayer,Martine D. F. Schlag,C. K. Wong
#t1987
#cIEEE Transactions on Computers
#index142934
#!We study the rectilinear shortest paths and minimum spanning tree (MST) problems for a set of points in the plane in the presence of rectilinear obstacles. We use the track graph, a suitably defined grid-like structure, to obtain efficient solutions for both problems. The track graph consists of rectilinear tracks defined by the obstacles and the points for which shortest paths and a minimum spanning tree are sought. We use a growth process like Dijkstra's on the track graph to find shortest paths from any point in the set to all other points (the one-to-all shortest paths problem). For the one-to-all shortest paths problem for n points we derive an O(n min {log n, log e} + (e + k) log t) time algorithm, where e is the total number of edges of all obstacles, t is the number of extreme edges of all obstacles, and k is the number of intersections among obstacle tracks (all bounds are for the worst case). The MST for the points is constructed also in time O(n log n + (e + k) log t) by a hybrid method of searching for shortest paths while simultaneously constructing an MST. An interesting application of the MST algorithm is the approximation of Steiner trees in graphs.


#*Intrinsic Topology of Medial Axis
#@Zhangzheng Yu
#t1989
#cMustererkennung 1989, 11. DAGM-Symposium
#index569552


#*Heuristic graph displayer for G-BASE
#@Hiroyuki Watanabe
#t1989
#cInternational Journal of Man-Machine Studies
#index457140


#*The art of C programming
#@Robin Jones,Ian Stewart
#t1986
#c
#index146169


#*Speech technology and its applications
#@Denis Johnston
#t1986
#cData Processing
#index148358


#*Comments on &ldquo;A quantity discount pricing model to increase vendor profits&rdquo;
#@Prafulla N. Joglekar
#t1988
#cManagement Science
#index478554


#*Gripe: a graphical interface to a knowledge based system which reasons about protein topology
#@Kathryn Seifert,Christopher Rawlings
#t1988
#cProceedings of the Fourth Conference of the British Computer Society on People and computers IV
#index481489


#*Using discrete-event computer simulation to test control systems
#@T. I. Miles,H. Siddeley
#t1989
#cProceedings of the 21st conference on Winter simulation
#index483368
#!The material handling control system of an automated manufacturing facility is tested during the commissioning of the plant. This leads to protracted commissioning periods as well as the possibility of costly equipment damage. The testing is performed in a modular fashion so that complex interaction are often overlooked.It is suggested that simulation can play a valuable part in speeding up the commissioning stage of plant startup by interfacing the control system to a computer simulation of the factory. The control system receives information about the state of the manufacturing system from the simulation and the simulation receives information from the controller on what to do next. By developing a complete simulation model and running the simulation for long periods of simulated time, the control system can be tested rigorously prior to the plant startup.The emphasis of this paper is on some of the important practical concerns of linking a discrete-event simulation system to a controller. The impact this has on the simulation model will be discussed in conjunction with two small example problems. The examples will include some of the code used to connect the controller and the simulation.


#*Financial impact of information processing
#@Donald H Bender
#t1986
#cJournal of Management Information Systems
#index163769


#*Binary search revisited: another advantage of Fibonacci search
#@S. Nishihara,H. Nishnio
#t1987
#cIEEE Transactions on Computers
#index170760


#*Real-time interfacing: engineering aspects of microprocessor peripheral systems
#@J. E. Cooling
#t1986
#c
#index145001


#*Comparison of algorithms controlling concurrent access to a database: a combinatorial approach
#@D. Arques,J. Francon,M.T. Guichet,P. Guichet
#t1988
#cTheoretical Computer Science
#index453959


#*Computer based support of reasoning in the presence of fuzziness and uncertainty
#@Amitava Dutta,Amit Basu
#t1986
#cDecision Support Systems
#index174123


#*Whither the white knight: CDROM in technical services
#@Brian Campell
#t1987
#cDatabase
#index174489


#*MS-DOS Desktop Reference Guide
#@G. Held,C. DeVoney
#t1988
#c
#index474097


#*Extending APICS certification to help American companies get there]
#@Salvatore F Runfola
#t1986
#cProduction and Inventory Management
#index156557


#*A C++ toolkit
#@Jon Udell
#t1988
#cBYTE
#index473886


#*Pattern storage and associative memory in quasi-neural network
#@M R B Forshaw
#t1986
#cPattern Recognition Letters
#index145764


#*Ready or not, here we come: students' assessment of a computer information systems program
#@L. Scarborough,K. A. Forcht,J. Pierson
#t1989
#cCollegiate Microcomputer
#index463597


#*Greedy algorithm and symmetric matroids
#@André Bouchet
#t1987
#cMathematical Programming: Series A and B
#index183806


#*Using microcomputers to help staff reduce violent behavior
#@James M Gardner
#t1985
#cComputers in Human Services
#index162932


#*Text structure recognition in optical reading
#@R. Ingold
#t1989
#cStructured documents
#index455640


#*An overview of OBJ2
#@K. Futatsugi
#t1988
#cProceedings of the first Franco-Japanese Symposium on Programming of future generation computers
#index458678


#*Matrix analysis of the static properties of protocol correctness
#@Yu. V. Avetov,Yu. A. Golovin,A. A. Sukonshchikov
#t1988
#cAutomatic Control and Computer Sciences
#index472119


#*Can Redundancy and Masking Improve the Performance of Synchronizers?
#@Lindsay Kleeman,Antonio Cantoni
#t1986
#cIEEE Transactions on Computers
#index154876
#!This paper considers the possibility of achieving improvements in the reliability of synchronizing an asynchronous signal, by exploiting redundancy and masking. Redundancy and masking techniques have been applied successfully to mask both permanent and transient hardware faults. However, it is shown in this paper that redundancy and masking techniques are ineffective against synchronization failures which arise because of metastable behavior of synchronizing elements.


#*Goal programming method of weighted residuals and optimal control problems
#@K. Y. K. Ng
#t1987
#cIEEE Transactions on Systems, Man and Cybernetics
#index177585


#*Ada software metrics and their limitations
#@Ronald J. Leach
#t1987
#cProceedings of the Joint Ada conference fifth national conference on Ada technology and fourth Washington Ada Symposium
#index284244


#*Essentials of BASIC with structure
#@Colelman Barnett
#t1986
#c
#index177061


#*A Computer-Aided Prototyping System
#@Luqi,Mohammad Ketabchi
#t1988
#cIEEE Software
#index445576
#%150506
#%165266
#%181125
#%183061
#%370805
#%482845
#%449383
#!A description is given of an approach to rapid prototyping that uses a specification language (the Prototype-System Description Language, PSDL) integrated with a set of software tools. including an execution support system, a rewrite system, a syntax-directed editor with graphics capabilities, a software base, a design database, and a design-management system. The prototyping language lets the designer use dataflow diagrams with nonprocedural control constraints as part of the specification of a hierarchically structured prototype. The resulting description is free from programming-level details, in contrast to prototypes constructed with a programming language. The discussion covers the language and method, rewrite subsystem, design manager, software base, and execution support.


#*CAD-Based 3D Object Representation for Robot Vision
#@Bir Bhanu,Chih-Cheng Ho
#t1987
#cComputer
#index164230


#*Roles of simulation in the application of expert systems in emergency management operations
#@A Ben Clymer
#t1986
#cProceedings of a Symposium held at the Department of Commerce on Theory and application of expert systems in emergency management operations
#index157400


#*Efficient C
#@Thomas Plum,Jim Brodie
#t1985
#c
#index154224


#*An Introduction to IEEE Software
#@B. D. Shriver
#t1985
#cIEEE Transactions on Software Engineering
#index338362


#*Current research into chemical and textual information retrieval at the department of information studies, University of Sheffield
#@Michael F. Lynch,Peter Willett
#t1987
#cInformation Processing and Management: an International Journal
#index177914


#*Software quality assurance in a changing development environment
#@Harry Kalmbach
#t1986
#con AFIPS Conference Proceedings; vol. 55 1986 National Computer Conference
#index159278


#*Some results on V-ary asymmetric tries
#@Wojciech Szpankowski
#t1988
#cJournal of Algorithms
#index174348


#*The systems analyst of the 1990's
#@D. J. McCubbray
#t1988
#cProceedings of the ACM SIGCPR conference on Management of information systems personnel
#index451416
#%163758
#%182501
#%323556


#*Point representation and hashing of an interval
#@Ronald E. Barkley,T. Paul Lee
#t1989
#cInformation Processing Letters
#index453562


#*M&ouml;glichkeiten der Kontrolle und Analyse von Umweltdaten durch Kopplung von Datenbank- und Expertensystemen
#@Manfred Tischendorf
#t1989
#cInformatik im Umweltschutz, 4. Symposium
#index273354


#*What's in a name?
#@P. Bonner
#t1989
#cPC/Computing
#index457787


#*Different perspectives on information systems: problems and solutions
#@Kalle Lyytinen
#t1987
#cACM Computing Surveys (CSUR)
#index184302
#%147533
#%147680
#%147948
#%149328
#%149900
#%151480
#%156124
#%158115
#%158192
#%160709
#%168928
#%171801
#%176509
#%178077
#%181765
#%553931
#%612636
#%577319
#%434650
#%326404
#%553861
#%322845
#%332317
#%473384
#%330572
#%316853
#%236177
#%471417
#%315868
#%315129
#%327392
#%324964
#%335487
#%433474
#!The paper puts information systems (IS) research dealing with IS problems into perspective. IS problems are surveyed and classified. Using the IS research framework suggested by Ives, Hamilton, and Davis, research into IS problems is classified into several perspectives whose relevance in coping with the problems is discussed. Research perspectives focusing on IS operations environment, IS development process, IS development organization, IS development methods, and IS theories are distinguished. The paper concludes with suggestions for future research and how to deal with IS problems in practice.


#*Automated interpretation of digital images of hydrographic charts
#@Kelvin J. Goodson
#t1987
#c
#index204129


#*Operational analysis of communication networks with lockups
#@B. V. Ivanovskii
#t1988
#cAutomatic Control and Computer Sciences
#index453162


#*A note on an error estimate for least squares approximation
#@C L Frenzen
#t1986
#cBIT
#index145297


#*Two characterizations of the logarithmic alternation hierarchy
#@K J Lange
#t1986
#cProceedings of the 12th symposium on Mathematical foundations of computer science 1986
#index181852


#*Reveur-3 the implementation of a general completion procedure parametrized by built-in theories and strategies
#@Claude Kirchner,Hélène Kirchner
#t1987
#cScience of Computer Programming
#index182389


#*RegionMaker
#@Howard Katz
#t1987
#cBYTE
#index160989


#*Heuristics for intermediate level road finding algorithms
#@Sridhar Vasudevan,Robert L. Cannon,James C. Bezdek,William L. Cameron
#t1988
#cComputer Vision, Graphics, and Image Processing
#index462821


#*Non-sequential processes
#@C. Fernández
#t1987
#cAdvances in Petri nets 1986, part I on Petri nets: central models and their properties
#index178653


#*The high level language and operating system support features of advanced microprocessors - Part 1: high level language support features
#@K. W. Ng,K. Y. Mok
#t1987
#cMicroprocessing and Microprogramming
#index163841


#*A new fixed point approach for stable networks stable marriages
#@T. Feder
#t1989
#cProceedings of the twenty-first annual ACM symposium on Theory of computing
#index468314
#%143762
#%155905
#%157795
#%160349
#%168193
#%174916
#%205265
#%478308
#!In a network stability problem, the aim is to find stable configurations for a given network of Boolean gates. For general networks, the problem is known to be computationally hard. Mayr and Subramanian [22,23] introduced an interesting class of networks by imposing fanout restrictions at each gate, and showed that network stability on this class of networks is still sufficiently rich to express as special cases the well-known stable marriage and stable roommate problems. In this paper we study the sequential and parallel complexity of network stability on networks with restricted fanout. Our approach builds on structural properties of these networks, and exposes close ties with the theory of retracts and isometric embeddings for product graphs. This structure gives then new efficient algorithms for questions of representation, enumeration and optimality in stable matching.


#*Quorum consensus in nested transaction systems
#@Kenneth J. Goldman,Nancy A. Lynch
#t1987
#cProceedings of the sixth annual ACM Symposium on Principles of distributed computing
#index163935
#%149142
#%159660
#%547401
#%320363
#%184491
#%552884
#%326589
#%174956
#%333180


#*Soziale Beherrschbarkeit offener Netze
#@Wilhelm Steinmüller
#t1985
#cDatenschutz und Datensicherung im Wandel der Informationstechnologien, 1. GI-Fachtagung
#index277975


#*Problem-solving with diagrammatic representations
#@Brian V. Funt
#t1987
#cReadings in computer vision: issues, problems, principles, and paradigms
#index160009


#*Conjugacy and gradients in variational theory and analysis
#@M. R. Hestenes
#t1987
#cProceedings of the ACM conference on History of scientific and numeric computation
#index147067


#*Tomography in projective spaces: a heuristic for limited angle reconstructive models
#@Pablo M. Salzberg
#t1988
#cSIAM Journal on Matrix Analysis and Applications
#index474187


#*The genus of the product of a group with an Abelian group
#@Tomaz Pisanski
#t1989
#cEuropean Journal of Combinatorics
#index452633


#*Implementation of an ADI method on parallel computers
#@Raad A. Fatoohi,Chester E. Grosch
#t1987
#cJournal of Scientific Computing
#index181354


#*The Merlin-Randell problem of train journeys
#@M Koutny
#t1986
#cActa Informatica
#index173720


#*A method of multistage switching network state mapping for control and simulation purposes
#@S Kaczmarek
#t1985
#cProc. of the IFIP TC 6 international in-depth symposium on Networks in office automation
#index156745


#*REBUS&mdash;Knowledge representation tools for expert systems
#@V. F. Khoroshevsky,V. Y. Sherstnev
#t1987
#con Artificial Intelligence and Information-Control systems of Robots-87
#index480385


#*Tele-cybernetics: implications for the international marketplace
#@G. A. Mihram,D. Mihram
#t1988
#cProceedings of the Twenty-First Annual Hawaii International Conference on Applications Track
#index477324


#*Software design for real-time multiprocessor VMEbus systems
#@Walter S. Heath
#t1987
#cIEEE Micro
#index163759


#*Topological analysis of large networks
#@Yevgeny Zeldin
#t1987
#cApplied Mathematics and Computation
#index175213


#*Hypertrees and Bonferroni inequalities
#@Ioan Tomescu
#t1986
#cJournal of Combinatorial Theory Series B
#index153661


#*Mathematical Software: Plod
#@Elvira Argon,I-Lok Chang,Gamini Gunaratna,David K. Kahaner,Martin A. Reed
#t1988
#cIEEE Micro
#index446229
#%171519
#!The authors present Plod (plotted solutions of ordinary differential equation), mathematical software Fortran package designed by integrating large systems of equations that are unstable with respect to initial conditions (stiff). It is intended for microcomputer users unfamiliar with programming techniques. The hardware needed to run Plod is described. Plod is designed to be used in two interactive steps, and an example of each is given. Graphics capabilities and extensibility are briefly considered.


#*Introduction to real-time software design (2nd ed.)
#@S. T. Allworth R. N. Zobel
#t1987
#c
#index161643


#*A stand-alone in-circuit emulator
#@F Ergincan,A Saatci
#t1986
#cMicroprocessing and Microprogramming
#index170369


#*The role of geometric modeling in computer integrated manufacturing
#@A. L. Ali,D. L. Ali,K. S. Ali
#t1988
#cComputers and Industrial Engineering
#index474131


#*Maximal Dense Intervals of Grammar Forms
#@Valtteri Niemi
#t1988
#cProceedings of the 15th International Colloquium on Automata, Languages and Programming
#index363855


#*Curve fitting algorithm for rough cutting
#@L Piegl
#t1986
#cComputer-Aided Design
#index145557


#*The specification of user-requirements for data processing systems
#@Herbert Kargl
#t1989
#cAngewandte Informatik
#index456762


#*Your office is where you are
#@Philip J. Stone,Robert Luchetti
#t1985
#cHarvard Business Review
#index172848


#*Using computers for instructional delivery and diagnosis of student learning in elementary schools
#@James E. Bruno
#t1987
#cComputers in the Schools
#index148775


#*Efficient motion planning for an L-shaped object
#@D. Halperin,M. Overmars
#t1989
#cProceedings of the fifth annual symposium on Computational geometry
#index468614
#%145286
#%168488
#%170372
#%333699
#%474244
#%469003
#%481269
#!We present an algorithm that solves the following motion-planning problem. Given an L-shaped body L and a 2-dimensional region with n point obstacles, decide whether there is a continuous motion connecting two given positions and orientations of L during which L avoids collision with the obstacles. The algorithm requires &Ogr;(n2 log2 n) time and &Ogr;(n2) storage. The algorithm is a variant of the cell-decomposition technique of the configuration space ([SS, LS]) but it employs a new and efficient technique for obtaining a compact representation of the free space, which results in a saving of an order of magnitude. The approach used in our algorithm seems applicable to motion-planning of certain robotic arms whose spaces of free placements have a structure similar to that of the L-shaped body.


#*An algorithm for technology choice in local area network design
#@Ann S. Marucheck,Joanne M. Sulek
#t1987
#cManagement Science
#index159600


#*Open fullscreen systems
#@Martin Gfeller,Monika Stengl
#t1986
#cACM SIGAPL APL Quote Quad
#index172033
#%550441
#%180833
#%548900
#!A general scheme is given for designing APL systems which are both open and fullscreen oriented. Such systems guide the user by presenting her visually the data she is working with, but do not restrict her from using APL to accomplish a task. The system is extensible and modeless in the sense that any commands can be entered at any time during the work with the system. Syntactic abbreviations yield a command language which is easy to learn for users not familiar with APL, but is just APL for those who know it. Finally, some design considerations and requirements are given for screen driver tools which can be used to implement such systems.


#*School psychology and computerized data handling systems: A confrontation
#@Patricia Nolen,Michael Spencer
#t1986
#cComputers in the Schools
#index160155


#*Algorithmic algebraic number theory
#@M. Pohst,H. Zassenhaus
#t1989
#c
#index479564


#*Specification and Verification of Concurrent Programs by forall-Automata
#@Zohar Manna,Amir Pnueli
#t1987
#cTemporal Logic in Specification
#index278186


#*An adaptive characteristic Petrov-Galerkin finite element method for convection-dominated linear and nonlinear parabolic problems in two space variables
#@L Demkowicz,J T Oden
#t1986
#cComputer Methods in Applied Mechanics and Engineering
#index172206


#*Language Processing
#@Edward T Cremmins
#t1985
#cBulletin of the American Society for Information Science
#index164169


#*Inherent Ambiguities in Recovering 3-D Motion and Structure from a Noisy Flow Field
#@G. Adiv
#t1989
#cIEEE Transactions on Pattern Analysis and Machine Intelligence
#index460586
#%184268
#%206115
#!One of the major areas in research on dynamic scene analysis is recovering 3-D motion and structure from optical flow information. Two problems which may arise due to the presence of noise in the flow field are examined. First, motion parameters of the sensor or a rigidly moving object may be extremely difficult to estimate because there may exist a large set of significantly incorrect solutions which induce flow fields similar to the correct one. The second problem is in the decomposition of the environment into independently moving objects. Two such objects may induce optical flows which are compatible with the same motion parameters, and hence, there is no way to refute the hypothesis that these flows are generated by one rigid object. These ambiguities are inherent in the sense that they are algorithm-independent. Using a mathematical analysis, situations where these problems are likely to arise are characterized. A few examples demonstrate the conclusions. Constraints and parameters which can be recovered even in ambiguous situations are presented.


#*Generation of Topological Boundary Representations from Octree Encoding
#@Tosiyasu Kunii,Toshiaki Satoh,Kazunori Yamaguchi
#t1985
#cIEEE Computer Graphics and Applications
#index342631
#!By generating a sequence of Euler operations, the algorithms presented here make it possible to convert octree models to a variety of boundary representation models.


#*Data compression for a source with Markov characteristics
#@J. A. Llewellyn
#t1987
#cThe Computer Journal
#index147435


#*Evolution of interactional human behavior with age: a theoretical/experimental approach
#@Alberto Silvestri,Ezio Lefons,Piero de Giacomo
#t1988
#cCybernetics and Systems
#index183833


#*Instant Pascal illustrated: fear and loathing on the Apple II
#@Scott Kronick
#t1986
#c
#index149812


#*A classification methodology and retrieval model to support software reuse
#@Daniel Lee Ruble
#t1987
#c
#index195579


#*Generating qualitative representations of continuous physical processes
#@M. Kokar
#t1987
#cProceedings of the Second International Symposium on Methodologies for intelligent systems
#index152105


#*Negligence: liability for defective software
#@Jim Prince
#t1985
#cEthical issues in the use of computers
#index159086


#*Analyzing stochastic events in multi-channel patch clamp data
#@T. R. Chay,H. S. Kang,S. C. Chay
#t1988
#cBiological Cybernetics
#index154134


#*Temporal Issues in Qualitative Reasoning
#@Roy Leitch,Mark Wiegand
#t1989
#c5. &Ouml;sterreichische Artificial Intelligence-Tagung
#index370792


#*Why using just-in-time is getting back to basics for American industry
#@James B. Byard
#t1987
#cIndustrial Engineering
#index163141


#*Description of organic reactions based on imaginary transition structures. 6. Classification and enumeration of two-string reactions with one common node
#@Shinsaku Fujita
#t1987
#cJournal of Chemical Information Computer Sciences
#index178406


#*A Framework of Expert System with Strategic Knowledge
#@Daisuke Tomoda,Minoru Tanaka,Tadao Ichikawa
#t1986
#cProceedings of the Second International Conference on Data Engineering
#index567361


#*Matrix method for finding sets of contiguous non-zero elements in a 2-dimensional array
#@M. M. Ferguson, Jr.
#t1986
#cPattern Recognition
#index146643


#*Storage hierarchies
#@E. I. Cohen,G. M. King,J. T. Brady
#t1989
#cIBM Systems Journal
#index468362


#*Projectively invariant classes of geometric continuity for CAGD
#@L. Ramshaw
#t1989
#cComputer Aided Geometric Design
#index474917


#*Technology of structural dynamic modeling
#@B. K. Belikov,A. A. Boltyanskii,B. A. Gulyaev
#t1988
#cAutomatic Control and Computer Sciences
#index480926


#*C1 trivariate polynomial interpolation
#@K. L. Rescorla
#t1987
#cComputer Aided Geometric Design
#index175154


#*Synthesis of queueing networks with block and state-dependent routing
#@S Balsamo,G Iazeolla
#t1986
#cComputer Systems Science and Engineering
#index148440


#*Accelerating UDFs
#@Steve Steiner
#t1988
#cData Based Advisor
#index164392


#*On the application of fast Fourier transforms and power spectrum analysis to incorrectly posed Fredholm integral equations
#@J P Schaffer,E J Shaughnessy,P L Jones
#t1986
#cIntegral methods in science and engineering
#index150743


#*A :20piano movers' '
#@J H Davenport
#t1986
#cACM SIGSAM Bulletin
#index173077
#%179908
#%548899
#!As has been pointed out [Schwartz amp; Sharir, 1983b], various problems of motion planning can be expressed as cylindrical algebraic decompositions [Collins, 1975; Arnon et al., 1984]. The purpose of this note is to discuss a particularly simple such problem, and show what actually happens during the decomposition (as far as we could take it). There is no pretence at originality, except perhaps in the conclusions.


#*INIS: descriptive cataloguing samples
#@CORPORATE International Atomic Energy Agency-INIS
#t1985
#c
#index169662


#*Managing campus-wide information systems: issues and problems
#@T. J. Foley
#t1989
#cProceedings of the 17th annual ACM SIGUCCS conference on User Services
#index465659
#%183214
#!The spread of computer networks and microcomputers has lead to the rapid expansion of communication via computer conferencing, electronic mail, computer bulletin boards, and other forms of electronic communications such as on-line surveys. Many campuses have implemented or are in the process of implementing campus-wide information systems which make access to information services as easy as using the campus phone system. Lehigh has implemented an information system that has received wide acceptance by the campus community, as over 6000 individuals or 85% of the campus voluntarily opened accounts on the system. The following issues and problems related to the system's management are discussed: Information Management, Censorship, Special Requests, Security, Encouraging Innovative Uses, and Training.


#*The white screen problem
#@H. S. Wilf
#t1989
#cAmerican Mathematical Monthly
#index472084


#*The role of electrochemical migration and moisture adsorption on the reliability of metallized ceramic substrates
#@G. W. Warren,P. Wynblatt,M. Zamanzadeh
#t1989
#cJournal of Electronic Materials
#index454281


#*Applying software reliability models to decision support
#@Carl K Chang,Kwang Ya Fang,Jeffrey C Yang
#t1986
#con AFIPS Conference Proceedings; vol. 55 1986 National Computer Conference
#index158835


#*Nolin's theory of algorithms and manipulation of sets
#@F Le Berre
#t1986
#cAlgebraic methods in semantics
#index154665


#*Automatic identification of writers
#@Frans J. Maarse,Lambert R. B. Schomaker,Hans-Leo Teulings
#t1988
#cConference of the Dutch Psychonomic Society on Human-computer interaction: psychonomic aspects
#index476206


#*Making Prolog parallel
#@D. Eadline
#t1989
#cAI Expert
#index480836


#*Properties of the Euler totient function modulo 24 and some of its cryptographic implications
#@R. N. Gorgui-Naguib,S. S. Dlay
#t1988
#cLecture Notes in Computer Science on Advances in Cryptology-EUROCRYPT'88
#index476721


#*FORTUNE: a documentation support system for software engineers
#@Douglas Mullin
#t1987
#cProc. of the 1st European Software Engineering Conference on ESEC '87
#index173184


#*Acceptable Legal Standards for Software
#@Doris L. Carver
#t1988
#cIEEE Software
#index443629
#!The author discusses the legal issues that are involved in software protection. She discusses legal actions open to users who get a system that does not perform as expected and have exhausted all remedies that do not involve litigation. She examines how the law treats software, covering liability limitations and court actions regarding fraud or misrepresentation as well as injury and damage caused by software. The author discusses the inadequacy of current laws and offers recommendations for remedying the situation.


#*Solving "simple" problems with simple solutions: an illustration
#@Selwyn Becker
#t1985
#cIssue 35 (Spring 1985)
#index307287


#*Hornlog: a graph-based interpreter for general horn clauses
#@Jean H. Gallier,Stan Raatz
#t1987
#cJournal of Logic Programming
#index182585


#*Walsh-spectral test for GFSR pseudorandom numbers
#@Shu Tezuka
#t1987
#cCommunications of the ACM
#index174480
#%81323
#%320689
#%323098
#!By applying Weyl's criterion for k-distributivity to GFSR sequences, we derive a new theoretical test for investigating the statistical property of GFSR sequences. This test provides a very useful measure for examining the k-distribution, that is, the statistical independence of the k-tuple of successive terms of GFSR sequences. In the latter half of this paper, we describe an efficient procedure for performing this test and furnish experimental results obtained from applying it to several GFSR generators with prime period lengths.


#*Relativized Arthur-Merlin versus Merlin-Arthur games
#@M. Santha
#t1989
#cInformation and Computation
#index456534


#*Efficient Parallel Convex Hull Algorithms
#@R. Miller,Q. F. Stout
#t1988
#cIEEE Transactions on Computers
#index460023
#%144427
#%152518
#%162084
#%174641
#%175114
#%177286
#%184456
#%194960
#%270681
#%317222
#%327028
#%472963
#%545164
#%476223
#%486902
#%483343
#!Parallel algorithms are presented to identify (i.e. detect and enumerate) the extreme points of the convex hull of a set of planar points using a hypercube, pyramid, tree, mesh-of-trees, mesh with reconfigurable bus, exclusive-read-exclusive-write parallel random-access machine (EREW PRAM), and modified AKS network. It is shown that the problem of identifying the convex hull for a set of planar points given arbitrarily, cannot be solved faster than sorting.


#*Dynamic theory of quasilinear parabolic equations&mdash;I. Abstracts evolution equations
#@Herbert Amann
#t1988
#cNon-Linear Analysis
#index481855


#*Human experts and expert systems
#@P. N. Johnson-Laird
#t1989
#cIntelligent Systems in a Human Context: Development, Implications, and Applications
#index470914


#*Techniques for design and testing of iterative and systolic arrays
#@Hasan Ali Elhuni
#t1986
#c
#index171046


#*Computers in gastroenterology
#@F. R. Vicary
#t1988
#c
#index486092


#*Randomized parallel speedups for list ranking
#@Uzi Vishkin
#t1987
#cJournal of Parallel and Distributed Computing
#index147752


#*The CMU-CAM System
#@Andrzej Strojwas
#t1986
#cIEEE Design Test
#index352733
#!In developing a system for computeraided manufacturing of VLSI circuits at Carnegie-Mellon University, we devoted a majoreffort to the computational efficiency of algorithms implemented. The resulting software can be used for a variety of real-lifetasks such as optimal process design, process diagnosis, and process control in commercial fabrication lines?providing anattractive externsion for CAM systems currently being introduced in VLSI fabrication processes.


#*A programmable filter implemented with two asynchronous microprocessors
#@A. P. Clarke,W. Marwood
#t1989
#cJournal of Microcomputer Applications
#index482251


#*Making the move to OS/2
#@Robert E. Shostak,John Socha,Linda Dudinyak,David P. Reed
#t1988
#cBYTE
#index169155


#*Ho&uml;lder's inequality for functions of linearly dependent arguments
#@F. Avram,M. S. Taqqu
#t1989
#cSIAM Journal on Mathematical Analysis
#index453903


#*The existence of symmetric skew balanced starters for odd prime powers
#@J. E. Yu,F. K. Hwang
#t1988
#cEuropean Journal of Combinatorics
#index152481


#*Telecommunications systems and services directory (4th ed)
#@John Krol
#t1989
#c
#index455722


#*A class of parallel iterative methods implemented on multiprocessors
#@A. Chronopoulos
#t1987
#c
#index184021


#*State determination in hard-embedded systems
#@Stuart Roland Faulk
#t1989
#c
#index198479


#*File processing&mdash;a correctness approach
#@Richard M. Plishka
#t1988
#cACM SIGCSE Bulletin
#index480312
#%162490
#%320383
#%323556
#!This paper describes an upper-division course in file processing which is intended to satisfy the requirements of both theoretical and applications-oriented curricula. It emphasizes file processing concepts from a software engineering perspective. Attention is paid to the system life cycle and a correctness approach to design and coding.


#*Computer Society President's Message. Planning Committee's Interim Report
#@R. L. Russo
#t1987
#cComputer
#index344105


#*Real-time personal computing: for data acquisition and control
#@Babu Joseph
#t1989
#c
#index469789


#*A moving-mesh finite element method with local refinement for parabolic partial differential equations
#@S Adjerid,J E Flaherty
#t1986
#cComputer Methods in Applied Mechanics and Engineering
#index164339


#*C for professional programmers
#@Keith Tizzard
#t1986
#c
#index150430


#*Automata on infinite objects and their applications to logic and programming
#@M. Nivat,A. Saoudi
#t1989
#cInformation and Computation
#index487078


#*Predictions
#@Lucinda Dickinson Conger
#t1987
#cOnline
#index167600


#*The appeal of parallel distributed processing
#@J. L. McClelland,D. E. Rumelhart,G. E. Hinton
#t1986
#cParallel distributed processing: explorations in the microstructure of cognition, vol. 1: foundations
#index509991


#*Advanced Turbo Basic program design
#@R. Alonso
#t1988
#c
#index460523


#*An evaluation of selected aspects of the state-mandated computer literacy program as implemented in woodville, texas
#@Thomas Wyatt Harvey, Jr.
#t1989
#c
#index190740


#*JSP and JSD: the Jackson approach to software development (2nd ed)
#@John R. Cameron
#t1989
#c
#index454262


#*SAUCI: a knowledge-based interface architecture
#@S. W. Tyler
#t1988
#cProceedings of the SIGCHI conference on Human factors in computing systems
#index476607
#%145405
#%174529
#%183944
#%202677
#%321909
#%329731
#%549126
#!Most current approaches to the design of the human-computer interface result in systems that are difficult for users to master. This can be attributed to the absence of several key features, including: interface modularity; adaptability to the individual user; direct support of user intentions; and an intelligent advising capability. An architecture for the interface which facilitates the attainment of these four criteria is proposed. The architecture relies upon production system rules and various kinds of knowledge bases to tailor the user-computer dialogue to the ongoing context of the interaction. A prototype of this architecture has been implemented in LOOPS for interfacing to the UNIX system, and has been shown to enhance substantially the performance of novice users of the system.


#*C traps pitfalls
#@Andrew Koeinig
#t1988
#c
#index466738


#*Programming environments for parallel machines
#@R. Triolet
#t1987
#cINRIA Conference on Supercomputing: state-of-the-art
#index522698


#*Valences: A new Relationship Concept for the Entity-Relationship Model
#@Peter Baumann
#t1989
#cProceedings of the Eight International Conference on Enity-Relationship Approach to Database Design and Querying
#index267573


#*Programming with active data
#@C. Jesshope,P. Miller,J. Yantchev
#t1989
#con Parcella '88: Fourth International Workshop on Parallel Processing by Cellular Automata and Arrays
#index456827


#*WordStar 2000 handbook
#@Greg M. Perry
#t1988
#c
#index165200


#*Osage Glass, Inc v Donovan (Missouri)
#@
#t1986
#cTrade Secret Law Reporter
#index161589


#*Matrices satisfying AB-BA=I
#@Henry Heatherly
#t1987
#cAmerican Mathematical Monthly
#index162281


#*Implementation of technical rules in a feature based modeller
#@F.-L. Krause,F. H. Vosgerau,N. Yaramanoglu
#t1989
#cIntelligent CAD systems II: implementational issues
#index473060


#*APL arrays and their editor
#@W Gfeller
#t1986
#cACM SIGPLAN Notices
#index168525
#!APL arrays can be perceived to consist of several parts. This concept is extended and rationalized. Together with keyed indexing, it allows to treat all entities in an APL system as arrays. The human interface to such a system is a recursive array editor (ae), which is isomorphic to the APL language.Finally, a design of such an editor for a workstation with bitmapped display is presented.


#*Nonparametric estimation from time series residuals
#@P M Robinson
#t1986
#cCahiers du Centre d'Etudes de Recherche Operationelle
#index180246


#*Automating code generation for computer-based training development
#@Robert A. Bryant
#t1989
#cEducational Technology
#index476523


#*Exposing Useful Trends in Metric Data Through Group Level Analysis
#@Dennis G. Kafura,James Canning
#t1985
#c
#index185584


#*Estimating disk head movement in batched searching
#@Y. P. Manolopoulos,J. G. Kollias
#t1988
#cBIT
#index143623


#*Using probability-density functions in the framework of evidential reasoning
#@Pascal Fua
#t1986
#cProceedings of the nternational Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems-Selected and Extended Contributions
#index373654


#*The Metaview System for Many Specification Environments
#@Paul G. Sorenson,Jean-Paul Tremblay,Andrew J. McAllister
#t1988
#cIEEE Software
#index440942
#%192132
#%549333
#!The use of metasystems, which can automatically generate the major parts of a software-development environment, for computer-aided software (CASE) engineering is discussed. One such system, called Metaview, is considered. Environment definition and tool development using Metaview are examined.


#*The effect of trial repetition and explanatory feedback in computer-assisted instruction on the science and computer attitudes and performance of less successful students in secondary science
#@Bonnie Jean Myers
#t1989
#c
#index203645


#*A computationally economic three-dimensional magnetic modelling system
#@Munna Lal Mishra
#t1985
#c
#index186427


#*PARAGON: a language using type hierarchies for the specification, implementation and selection of abstract data types
#@Mark S. Sherman
#t1985
#cSpringer Lecture Notes In Computer Science; Vol. 189
#index163489


#*A nonlinear singular integro-differential equation arising in surface chemistry
#@Jean Duchon,Raoul Robert
#t1986
#cSIAM Journal on Mathematical Analysis
#index175997


#*The face lattice of hyperplane arrangements
#@G. M. Ziegler
#t1989
#cDiscrete Mathematics
#index454973


#*SRM 1970: Succinonitrile triple-point standard&mdash;A temperature reference standard
#@B W Mangum,Samir El-Sabban
#t1985
#cJournal of Research of the National Institute of Standards and Technology
#index165613


#*Approximate controllability for trajectories of semilinear control systems
#@K. Naito
#t1989
#cJournal of Optimization Theory and Applications
#index480464


#*A conceptual model for inexact reasoning in rule-based systems
#@L. C. van der Gaag
#t1989
#cInternational Journal of Approximate Reasoning
#index460412


#*Inserting injection operations to denotational specifications
#@M Takeichi
#t1986
#cNew Generation Computing
#index158037


#*Minimum Resource Zero-Knowledge Proofs (Extended Abstract)
#@Joe Kilian,Silvio Micali,Rafail Ostrovsky
#t1989
#cProceedings of the 9th Annual International Cryptology Conference on Advances in Cryptology
#index259740


#*Improvements in NHMEAN method
#@F. Costa Nicolau,M. P. Brito
#t1989
#cProceedings of the conference on Data analysis, learning symbolic and numeric knowledge
#index523417


#*On deciding the confluence of a finite string-rewriting system on a given congruence class
#@F. Otto
#t1987
#cJournal of Computer and System Sciences
#index163829


#*On small packing and covering designs with block size 4
#@A Hartman
#t1986
#cDiscrete Mathematics
#index147451


#*Advanced interactive COBOL for micros: a practical approach
#@Joseph J. LeBert
#t1988
#c
#index465648


#*CABRI, an interactive system for graphy manipulation
#@M Dao,M Habib,J P Richard,D Tallot
#t1987
#cInternational Workshop WG '86 on Graph-theoretic concepts in computer science
#index145803


#*An integrated approach to logical design of relational database schemes
#@Catriel Beeri,Michael Kifer
#t1986
#cACM Transactions on Database Systems (TODS)
#index602063
#%144237
#%163687
#%204293
#%236388
#%326368
#%382715
#%624972
#!We propose a new approach to the design of relational database schemes. The main features of the approach are the following: A combination of the traditional decomposition and synthesis approaches, thus allowing the use of both functional and multivalued dependencies. Separation of structural dependencies relevant for the design process from integrity constraints, that is, constraints that do not bear any structural information about the data and which should therefore be discarded at the design stage. This separation is supported by a simple syntactic test filtering out nonstructural dependencies. Automatic correction of schemes which lack certain desirable properties.


#*Regular augmentation of automata and transducers
#@V Koubek,A Říha
#t1986
#cProceedings of the 12th symposium on Mathematical foundations of computer science 1986
#index174812


#*Issues of interaction: keyboarding, word processing and composing
#@C. S. Dybdahl,D. G. Shaw
#t1989
#cJournal of Research on Computing in Education
#index451444


#*Integrating computers into the elementary and middle school
#@Nancy Roberts
#t1988
#c
#index474930


#*System EXPRESSes it your way
#@Karen Watterson
#t1987
#cData Based Advisor
#index172578


#*Implementing the RSA cryptosystem
#@A. Jung
#t1987
#cComputers and Security
#index146513


#*A Prolog-based expert system for modeling with partial differential equations
#@Mark F. Russo,Richard L. Peskin,A. Daniel Kowalski
#t1987
#cSimulation
#index161069


#*Local area networks in integrated production facilities
#@A N Domaratskii,V V Nikiforov,V M Ponomarev
#t1986
#cAutomatic Control and Computer Sciences
#index173008


#*Micro-mainframe link from NCC
#@
#t1987
#cMini-Micro Software
#index148292


#*Multi-dimensioned intertwined basin boundaries: basin structure of the kicked double rotor
#@C. Grebogi,E. Kostelich,E. Ott,J. A. Yorke
#t1987
#cPhysica D
#index183684


#*Detecting leftmost maximal periodicities
#@M. G. Main
#t1989
#cDiscrete Applied Mathematics
#index478132


#*A time-implicit Monte Carlo collision algorithm for particle-in-cell electron transport models
#@C W Cranfill,J U Brackbill,S R Goldman
#t1986
#cJournal of Computational Physics
#index161146


#*Properties and algorithms for a traffic matrix determination problem (telecommunications networks, transportation polytope, kruithof's method, quadratic norm)
#@Narayan Subramanian
#t1985
#c
#index198484


#*Foundations for the Arcadia environment architecture
#@Richard N. Taylor,Frank C. Belz,Lori A. Clarke,Leon Osterweil,Richard W. Selby,Jack C. Wileden,Alexander L. Wolf,Michael Young
#t1989
#cProceedings of the third ACM SIGSOFT/SIGPLAN software engineering symposium on Practical software development environments
#index480202
#%142949
#%144910
#%145405
#%145826
#%147623
#%151795
#%152442
#%152552
#%158500
#%159784
#%160881
#%161226
#%169701
#%169841
#%170157
#%178738
#%179812
#%180120
#%182205
#%182577
#%183874
#%184297
#%322883
#%326589
#%330862
#%466926
#%470775
#%553411
#%550064
#%548050
#%552021
#%552271
#%550429
#%546861
#%484707
#!Early software environments have supported a narrow range of activities (programming environments) or else been restricted to a single &ldquo;hard-wired&rdquo; software development process. The Arcadia research project is investigating the construction of software environments that are tightly integrated, yet flexible and extensible enough to support experimentation with alternative software processes and tools. This has led us to view an environment as being composed of two distinct, cooperating parts. One is the variant part, consisting of process programs and the tools and objects used and defined by those programs. The other is the fixed part, or infrastructure, supporting creation, execution, and change to the constituents of the variant part. The major components of the infrastructure are a process programming language and interpreter, object management system, and user interface management system. Process programming facilitates precise definition and automated support of software development and maintenance activities. The object management system provides typing, relationships, persistence, distribution and concurrency control capabilities. The user interface management system mediates communication between human users and executing processes, providing pleasant and uniform access to all facilities of the environment. Research in each of these areas and the interaction among them is described.


#*Geostatistics utilizing imprecise (fuzzy) information
#@A. Bardossy,I. Bogardi,W. E. Kelly
#t1989
#cFuzzy Sets and Systems
#index466357


#*Detection and recognition of nasal consonants in continuous speech&mdash;preliminary results
#@R Gubrynowicz,L Le Guennec,G Mercier
#t1987
#cThe NATO Advanced Study Institute on new systems and architectures for automatic speech recognition and synthesis on New systems and architectures for automatic speech recognition and synthesis
#index158018


#*Super-exponentials nonprimitive recursive, but rudimentary
#@Cristian Calude
#t1987
#cInformation Processing Letters
#index147835


#*LISP: the language of artificial intelligence
#@A. A. Berk
#t1985
#c
#index149985


#*Redesign of Optimistic Methods: Improving Performance and Applicability
#@U. Prädel,Gunter Schlageter,Rainer Unland
#t1986
#cProceedings of the Second International Conference on Data Engineering
#index376230


#*Optimistic concurrency control for abstract data types
#@Maurice Herlihy
#t1987
#cACM SIGOPS Operating Systems Review
#index152740
#%149953
#%152100
#%193459
#%192444
#%249845
#%317485
#%173091
#%319217
#%545865
#%333180
#!A concurrency control technique is optimistic if it allows transactions to execute without synchronization, relying on commit-time validation to ensure serializability. This paper describes several new optimistic concurrency control techniques for objects in distributed systems, proves their correctness and optimality properties, and characterizes the circumstances under which each is likely to be useful. These techniques have the following novel aspects. First, unlike many methods that classify operations only as reads or writes, these techniques systematically exploit type-specific properties of objects to validate more interleavings. Necessary and sufficient validation conditions are derived directly from an object's data type specification. Second, these techniques are modular: they can be applied selectively on a per-object (or even per-operation) basis in conjunction with standard pessimistic techniques such as two-phase locking, permitting optimistic methods to be introduced exactly where they will be most effective. Third, when integrated with quorum-consensus replication, these techniques circumvent certain trade-offs between concurrency and availability imposed by comparable pessimistic techniques. Finally, the accuracy and efficiency of validation are further enhanced by some technical improvements: distributed validation is performed as a side-effect of the commit protocol, and validation takes into account the results of operations, accepting certain interleavings that would have produced delays in comparable pessimistic schemes.


#*The complexity of finding minimum-length generator sequences
#@Mark R. Jerrum
#t1985
#cTheoretical Computer Science
#index179916


#*CD-ROM and online searching
#@Betsy Reifsnyder
#t1989
#cDatabase
#index459176


#*Implementing parallel algorithms in concurrent prolog: The maxiflow experience
#@L Hellerstein,E Shapiro
#t1986
#cJournal of Logic Programming
#index175250


#*Autonomous Mobile Robot Navigation and Learning
#@C. R. Weisbin,G. de Saussure,J. R. Einstein,F. G. Pin,E. Heer
#t1989
#cComputer
#index481869
#%171864
#%185045
#!Research focused on the development and experimental validation of intelligent control techniques for autonomous mobile robots able to plan and perform a variety of assigned tasks in unstructured environments is presented. In particular, an autonomous mobile robot, HERMIES-IIB intelligence experiment series, is described. It is a self-powered, wheel-driven platform containing an onboard 16-node Ncube hypercube parallel processor interfaced to effectors and sensors through a VME-based system containing a Motorola 68020 processor, a phased sonar array, dual manipulator arms, and multiple cameras. Research on navigation and learning is examined.


#*User interface toolkits; present and future (panel session)
#@Owen Densmore,David Goldsmith,Andrew Schulert,Smokey Wallace
#t1988
#cProceedings of the 15th annual conference on Computer graphics and interactive techniques
#index328245


#*Transaction processing and consistency control of replicated copies during failures in distributed databases
#@Bharat Bhargava
#t1987
#cJournal of Management Information Systems
#index154752


#*Homogeneous multiprocessor system: a status report
#@N. J. Dimopoulos,K. F. Li,E. C.-H. Wong,R. V. Dantu,J. W. Atwood
#t1989
#cComputer Systems Science and Engineering
#index450721


#*Psychovisual issues in the display of medical images
#@S M Pizer
#t1986
#cProceedings of the NATO Advanced Study Institute (NATO ASI Series) on Pictorial information systems in medicine
#index178693


#*A formal model of diagnostic inference. I. Problem formulation and decomposition
#@James A. Reggia,Dana S. Nau,Pearl Y. Wang
#t1985
#cInformation Sciences: an International Journal
#index178199


#*Mathematical programming solutions for fishery management
#@João Lauro,D. Facó
#t1988
#cMathematical models for decision support
#index467440


#*High-volume production of large full-color liquid-crystal displays
#@William C. Schneider,Griffith L. Resor
#t1989
#cInformation Display
#index459245


#*Color and the computer
#@H. John Durrett
#t1987
#c
#index149466


#*The non-classical 10-arc of PG(4,9)
#@D G Glynn
#t1986
#cDiscrete Mathematics
#index179489


#*The database group at ISS, National University of Singapore
#@D. Narasimhalu
#t1989
#cACM SIGMOD Record
#index482662
#!The database group is headed by Dr. A Desai Narasimhalu. It comprises nine staff members, together with a collaborative member and three undergraduate students from the Department of Information Systems and Computer Science. The group's main research areas are listed below.


#*Towards a formal specification of the ICL Data Dictionary
#@Bernard Sufrin
#t1987
#cSpecification case studies
#index538545


#*Strategies for end-user computing: an integrative framework
#@M. Alavi,R. R. Nelson,I. R. Weiss
#t1989
#cEnd-user computing: Concepts, issues, and applications
#index477030


#*Online maintenance features of authority files: survey of vendors and in-house systems
#@Agnes M. Grady
#t1988
#cInformation Technology and Libraries
#index459689


#*Turbo Pascal programming visual masters
#@Donald D. Spencer
#t1987
#c
#index458428


#*Decomposition of multiattribute fuzzy utility functions
#@G. V. Merkuryeva,A. N. Borisov
#t1987
#cFuzzy Sets and Systems
#index178014


#*On vi-products of commutative automata
#@F Gécseg
#t1986
#cActa Cybernetica
#index166864


#*The day the Friedmans had a typo in their photo
#@Louis Kruh
#t1989
#cCryptology: machines, history and methods
#index450360


#*A Formal Model for Software Project Management
#@Lung-Chun Liu,Ellis Horowitz
#t1989
#cIEEE Transactions on Software Engineering
#index468210
#%148457
#%148597
#%153456
#%153852
#%155256
#%178738
#%185213
#%324964


#*An entity-relationship framework for information resource management
#@R. W. Blanning
#t1988
#cInformation and Management
#index487851


#*Effect of die-attach temperature (455:9DC) on the bondability of bond finger of gold packages
#@K. C. Lee,L. K. Kim,S. J. Hu
#t1987
#cJournal of Electronic Materials
#index167172


#*Computer simulation of bacterial survival data from a complex dilution experiment
#@Jack Hachigian
#t1985
#cProceedings of the 17th conference on Winter simulation
#index96899
#!A computer simulation is provided to generate bacterial survival data using the Weibull model (the exponential being an option). The simulation provides data when serial dilution is used before or after exposure to a bactericide allows for incubation as well. The simulation should be useful in all sterilization studies - whether of medical services, food, pharmaceuticals, or space vehicles. The algorithm, upon which the simulation is based, adheres faithfully to the probabilistic description of the experiment. The simulation should also be useful to both statisticians and microbiologists.


#*Fault diagnosis and design-for-testability for integrated sequential circuits
#@Tao Li
#t1985
#c
#index202923


#*Morphological parsing and the lexicon
#@Jorge Hankamer
#t1989
#cLexical representation and process
#index473517


#*Building blocks for distributed system design
#@Bernd Baumgarten,Peter Ochsenschläger,Rainer Prinoth
#t1985
#cProceedings of the IFIP WG6.1 Fifth International Conference on Protocol Specification, Testing and Verification V
#index371307


#*Drawing trees nicely with T2EX
#@A. Brüggemann-Klein,D. Wood
#t1989
#cElectronic Publishing&mdash;Origination, Dissemination, and Design
#index481638


#*Iterative systems of equations
#@V E Căzănescu
#t1986
#cProceedings of the 12th symposium on Mathematical foundations of computer science 1986
#index148088


#*Full abstraction and semantic equivalence
#@Ketan Mulmuley
#t1987
#cAcm Doctoral Dissertation Award; Vol. 1986
#index154850


#*Programming considerations for documentation and maintenance
#@Stephen C. Fleming
#t1987
#cProceedings of the international conference on APL: APL in transition
#index172706
#!The intent of this paper is to create, or reinforce among programmers an awareness of some simple measures which can be taken during application system development, which can save valuable time later, when somebody else is called upon to document, fix, enhance, or otherwise read and work with their programs. Although the paper describes several approaches to system documentation, it is not expected that any programmer will henceforth develop his applications exclusively around and according to the needs of the technical writer or maintenance analyst. The hope is that by describing a broad range of techniques, individual programmers can select those which best suit their style and approach, while minimizing the imposition of rigid and burdensome &ldquo;standards&rdquo;. The premise being that some, any, assistance provided to future readers, is better than none.


#*An eye for fractals
#@Michael McGuire
#t1988
#cThe Science of Fractal Images
#index465831


#*Review of expert systems in auditing
#@D. E. O'Leary,P. R. Watkins
#t1989
#cExpert Systems Review
#index464499


#*A-V Online: Now on compact laserdisk (CDROM)
#@James C Johnstone
#t1986
#cDatabase
#index177743


#*On n-domination, n-dependence and forbidden subgraphs
#@J. F. Fink,M. S. Jacobson
#t1985
#cGraph theory with applications to algorithms and computer science
#index172399


#*Pull-Down Menus in C
#@James L. Pinson
#t1987
#cBYTE
#index180103


#*Principles and applications of pencil tracing
#@Mikio Shinya,T. Takahashi,Seiichiro Naito
#t1987
#cACM SIGGRAPH Computer Graphics
#index149602
#%334528
#%173224
#%152490
#%552170
#%172075
#%554954
#!Pencil tracing, a new approach to ray tracing, is introduced for faster image synthesis with more physical fidelity. The paraxial approximation theory for efficiently tracing a pencil of rays is described and analysis of its errors is conducted to insure the accuracy required for pencil tracing. The paraxial approimation is formulated from a 4x4 matrix (a system matrix) that provides the basis for pencil tracing and a variety of ray tracing techniques, such as beam tracing, ray tracing with cones, ray-object intersection tolerance, and a lighting model for reflection and refraction. In the error analysis, functions that estimate approximation errors and determine a constraint on the spread angle of a pencil are given.The theory results in the following fast ray tracing algorithms; ray tracing using a system matrix, ray interpolation, and extended 'beam tracing' using a 'generalized perspective transform'. Some experiments are described to show their advantages. A lighting model is also developed to calculate the illuminance for refracted and reflected light.


#*Verifying Safety and Deadlock Properties of Networks of Asynchronously Communicating Processes
#@Fredrik Orava
#t1989
#cProceedings of the IFIP WG6.1 Ninth International Symposium on Protocol Specification, Testing and Verification IX
#index365567


#*Multigrid method for elasticity problems
#@Jin-xian Wang,Yu-xia Huang,Jia-yao Gong
#t1986
#cJournal of Computational Mathematics
#index164650


#*Why functional programming matters
#@J. Hughes
#t1989
#cThe Computer Journal
#index457630


#*Part 9: flow reviews systematically improve manufacturing process logistics
#@Jim Johnstone,Jim Koenig
#t1987
#cIndustrial Engineering
#index175954


#*Soar/PSM-E: investigating match parallelism in a learning production sytsem
#@Milind Tambe,Dirk Kalp,Anoop Gupta,Charles Forgy,Brian Milnes,Allen Newell
#t1988
#cACM SIGPLAN Notices
#index468634
#%142775
#!Soar is an attempt to realize a set of hypotheses on the nature of general intelligence within a single system. Soar uses a production system (rule based system) to encode its knowledge base. Its learning mechanism, chunking, adds productions continuously to the production system. The process of searching for relevant knowledge, matching, is known to be a performance bottleneck in production systems. PSM-E is a C-based implementation of the OPS5 production system on the Encore Multimax that has achieved significant speedups in matching. In this paper we describe our implementation, Soar/PSM-E, of Soar on the Encore Multimax that is built on top of PSM-E. We first describe the extensions and modifications required to PSM-E in order to support Soar, especially the capability of adding productions at run time as required by chunking. We present the speedups obtained on Soar/PSM-E and discuss some effects of chunking on parallelism. We also analyze the performance of the system and identify the bottlenecks limiting parallelism. Finally, we discuss the work in progress to deal with some of them.


#*Wide-spectrum support for software reusability
#@M. D. Lubars
#t1988
#cSoftware reuse: emerging technology
#index451924


#*Parametric adiabatic perturbations on the sine-Gordon breather solution
#@S. Pagano,M. Salerno,M. R. Samuelsen
#t1987
#cPhysica D
#index177189


#*A double integral containing the modified Bessel function: Asymptotics and computation
#@N M Temme
#t1986
#cMathematics of Computation
#index154541


#*Ashley,K. D.-But, see, accord: generating blue book citations in HYPO
#@K. D. Ashley,E. L. Rissland
#t1987
#cProceedings of the 1st international conference on Artificial intelligence and law
#index159548
#%461394
#!An interesting and important aspect of legal reasoning is the use of citations to precedent cases as justifications for legal conclusions. In this paper, we describe the standard use of citations as described in the attorney's &ldquo;Blue Book&rdquo; and how HYPO, a program that models case-based legal reasoning, generates and uses citations in a very similar way to analyze fact situations and to communicate with an attorney/user. More specifically, we describe how, given a fact situation (&ldquo;cfs&rdquo;), HYPO dynamically generates the citations to cases in its Case Knowledge Base (&ldquo;CKB&rdquo;) by (1) analyzing the factual features of the cfs to see what dimensions apply, (2) retrieving and constructing a &ldquo;neighborhood&rdquo; of citable cases around the cfs (the &ldquo;Claim Lattice&rdquo;) and (3) constructing the &ldquo;Cites Display&rdquo;, a network of citations to the most on point cases (&ldquo;mopc&rdquo;) that is a skeletal frame for a legal argument about the cfs.


#*Improvements in spectral collocation discretization through a multiple domain technique
#@M G Macaraeg,C L Streett
#t1986
#cApplied Numerical Mathematics
#index152043


#*An efficient algorithm for the &ldquo;optimal&rdquo; stable marriage
#@Robert W. Irving,Paul Leather,Dan Gusfield
#t1987
#cJournal of the ACM (JACM)
#index160349
#%157795
#%168193
#%319449
#%457887
#%163009
#%170184
#!In an instance of size n of the stable marriage problem, each of n men and n women ranks the members of the opposite sex in order of preference. A stable matching is a complete matching of men and women such that no man and woman who are not partners both prefer each other to their actual partners under the matching. It is well known [2] that at least one stable matching exists for every stable marriage instance. However, the classical Gale-Shapley algorithm produces a marriage that greatly favors the men at the expense of the women, or vice versa. The problem arises of finding a stable matching that is optimal under some more equitable or egalitarian criterion of optimality. This problem was posed by Knuth [6] and has remained unsolved for some time. Here, the objective of maximizing the average (or, equivalently, the total) &ldquo;satisfaction&rdquo; of all people is used. This objective is achieved when a person's satisfaction is measured by the position of his/her partner in his/her preference list. By exploiting the structure of the set of all stable matchings, and using graph-theoretic methods, an O(n4) algorithm for this problem is derived.


#*Cognitive ergonomics: an approach for the design of user-oriented interactive systems
#@N A Streitz
#t1986
#cseminar of The International Union of Psychological Science (IUPsyS) on Man-computer interaction research (MACINTER-I): Proceedings of the first network
#index161266


#*Conditions for the existence of solutions of the three-dimensional planar transportation problem
#@M Vlach
#t1986
#cDiscrete Applied Mathematics
#index148020


#*On the range of the lewy complex
#@Paulo Domingos Cordaro
#t1985
#c
#index203519


#*Multitasking across a LAN for communications switching
#@Michael Purser
#t1986
#cComputer Communications
#index145708


#*Dielectric tensor of weakly relativistic electron distributions separable in momentum and pitch angle
#@P A Robinson
#t1986
#cAustralian Journal of Physics
#index163154


#*Introduction to Computer Architecture Organization
#@H. Lorin
#t1988
#c
#index457774


#*A new parallel inference mechanism based on sequential processing
#@Y Sohma,K Satoh,K Kumon,H Masuzawa,A Itashiki
#t1986
#cProc. of the IFIP TC 10 working conference on Fifth generation computer architectures
#index157752


#*Halfplanar range search in linear space and O(n0.695) query time
#@H Edelsbrunner,E Welzl
#t1986
#cInformation Processing Letters
#index151224


#*The Ada software repository and software reusability
#@Richard Conn
#t1987
#cProceedings of the Joint Ada conference fifth national conference on Ada technology and fourth Washington Ada Symposium
#index279407


#*Electronic materials surface processing with excimer lasers
#@D J Elliott,B P Piwczyk
#t1986
#cMicroelectronic Engineering
#index161244


#*Synthesis by phase modulation and its implementation in hardware
#@Sergio Cavaliere,Gianfranco Evangelista,Aldo Piccialli
#t1988
#cComputer Music Journal
#index175900


#*Canonical numbering and coding of reaction center graphs and reduced reaction center graphs abstracted from imaginary transition structures. A novel approach to the linear coding of reaction types
#@Shinsaku Fujita
#t1988
#cJournal of Chemical Information Computer Sciences
#index480117


#*PAM&mdash;a noniterative approximate solution method for closed multichain queueing networks
#@Ching Tarng Hsieh,Simon S. Lam
#t1989
#cPerformance Evaluation
#index478904


#*Least-squares fitting using orthogonal multinomials
#@Richard H. Bartels,John J. Jezioranski
#t1985
#cACM Transactions on Mathematical Software (TOMS)
#index602274
#!Forsythe has given a method for generating basis polynomials in a single variable that are orthogonal with respect to a given inner product. Weisfeld later demonstrated that Forsythe's approach could be extended to polynomials in an arbitrary number of variables. In this paper we sharpen Weisfeld's results and present a method for computing weighted, multinomial, least-squares approximations to given data.


#*Expert System Based Configuration of VSAM Files
#@Karlheinz Allgeyer,Klaus Kratzer
#t1987
#cProceedings of the Third International Conference on Data Engineering
#index362490


#*The feasibility of UNIX-based LANS for schools
#@William D. McInerney,Larry Stuber
#t1989
#cEducational Technology
#index479567


#*Data flow dynamics
#@Frank Sweet
#t1985
#cDatamation
#index150676


#*Jim Farrell's final report
#@
#t1988
#cIEEE Micro
#index442496


#*Numerical solution of random singular integral equation appearing in crack problems
#@M Sambandham,T S Srivatsan,A T Bharucha-Reid
#t1986
#cIntegral methods in science and engineering
#index145130


#*Role-based requirements definition for software factories using reusable requirements package
#@Sanjay Dewal,Udo Kelter
#t1989
#cProceedings of the fourth conference on Software engineering environments: research and practice
#index526419


#*On the periodic nonlinearity and the multiplicity of solutions
#@Kung- Ching Chang
#t1989
#cNon-Linear Analysis
#index485991


#*The uses of simulations in teacher preparation: past, present, and future
#@Donald R. Cruickshank
#t1988
#cSimulation and Gaming
#index484232


#*Plancherel-Rotach-type asymptotics for orthogonal polynomials associated with exp(-x6/6)
#@Rong-Chyu Sheen
#t1987
#cJournal of Approximation Theory
#index157931


#*Serializability with constraints
#@Toshihide Ibaraki,Tiko Kameda,Toshimi Minoura
#t1987
#cACM Transactions on Database Systems (TODS)
#index606100
#%160099
#%179435
#%317485
#%356519
#%464397
#%549099
#!This paper deals with the serializability theory for single-version and multiversion database systems. We first introduce the concept of disjoint-interval topological sort (DITS, for short) of an arc-labeled directed acyclic graph. It is shown that a history is serializable if and only if its transaction IO graph has a DITS. We then define several subclasses of serializable histories, based on the constraints imposed by write-write, write-read, read-write, or read-read conflicts, and investigate inclusion relationships among them. In terms of DITS, we give a sufficient condition for a class of serializable histories to be polynomially recognizable, which is then used to show that a new class of histories, named WRW, can be recognized in polynomial time. We also present NP-completeness results for the problem of testing membership in some other classes. In the second half of this paper, we extend these results to multiversion database systems. The inclusion relationships among multiversion classes defined by constraints, such as write-write and write-read, are investigated. One such class coincides with class DMVSR, introduced by Papadimitriou and Kanellakis, and gives a simple characterization of this class. It is shown that for most constraints, multiversion classes properly contain the corresponding single-version classes. Complexity results for the membership testing are also discussed.


#*Functional programming for concurrent and distributed computing
#@F. W. Burton
#t1987
#cThe Computer Journal
#index167503


#*The CAO/FAO and the importance of risk management
#@I Carlisle
#t1986
#cCIPS Review
#index185272


#*The parascope editor: an interactive parallel programming tool
#@V. Balasundaram,K. Kennedy,U. Kremer,K. McKinley,J. Subhlok
#t1989
#cProceedings of the 1989 ACM/IEEE conference on Supercomputing
#index455679
#%146000
#%146189
#%158469
#%160970
#%163816
#%182166
#%184250
#%190431
#%197592
#%202908
#%441492
#%453305
#%454571
#%480367
#%457923
#%475673
#%463479
#!The ParaScope project is building an integrated collection of tools to help scientific programmers develop correct and efficient parallel programs. The centerpiece of this collection is the ParaScope Editor, an intelligent interactive editor for parallel FORTRAN programs. The ParaScope Editor displays data dependencies, which correspond to potential data races among the iterations of a parallel loop, to assist the user in determining the correctness of a proposed parallelization. In addition, it uses dependencies to support a variety of program transformations selectable by the programmer. The eventual goal for the ParaScope Editor is to support arbitrary editing changes by performing full incremental data dependence analysis in response to program changes. In addition, it will understand and recognize when synchronization correctly prevents race conditions. The ParaScope Editor is a new kind of program construction tool; one that not only manages text, but also presents the user with insights into the semantic structure of the program being constructed.


#*Representation of vague information
#@Ewa Orlowska
#t1988
#cInformation Systems
#index461112


#*Effect of visual presentation of different dialogue structures on human-computer interaction
#@J. Kaster,H. Widdel
#t1987
#cSelected papers from the International Scientific Conference on Work with display units 86
#index158403


#*Atomic Remote Procedure Call
#@Kwei-Jay Lin,John D. Gannon
#t1985
#cIEEE Transactions on Software Engineering
#index156005
#!Remote procedure call (RPC) is a programming primitive that makes building distributed programs easier. Atomicity, whkh implies totality and serializability, has been recognized as an important property to assure consistency in spite of computing node crashes. We have implemented an atomk remote procedure call mechanism which provides users a simple and reliable language primitive. Concurrency is controlled by attaching a call graph path identifier to each message representing a procedure call. Procedures keep their last accepted calling message paths to compare against incoming message paths. Only calls that can be serialized are accepted. Associated states of static variables are saved in backup processors on procedure entry and restored to corresponding variables in case of procedure crash. Detailed concurrency control and recovery algorithms are given, and illustrated with examples.


#*Facilitating Mixed Language Programming in Distrbuted Systems
#@Roger Hayes,Richard D. Schlichting
#t1987
#cIEEE Transactions on Software Engineering
#index147478
#!An approach for facilitating mixed language programming in distributed systems is presented. It is based on adding a generic remote procedure call facility to each language, and the use of a type system to describe procedural interfaces, as well as data to be transferred between procedures. This type scheme also specifies a machine-independent representation for all data. By defining standard mappings for each programming language, the data conversions required for cross-langauge calls may be performed, automatically in most cases, by active agents that provide the interface between program components written in different languages. When necessary, explicit control of the conversation is possible. A prototype implementation of a system based on this approach has been constructed on a collection of machines running Berkeley UNIX®.


#*Artificial intelligence: An introduction
#@Patrick H Winston
#t1986
#cComputers and People
#index159558


#*Correlations in space and time for a soft-mode phase-transforming system
#@S. L. Mair
#t1987
#cAustralian Journal of Physics
#index155848


#*Boolean comparison by simulation
#@E. P. Stabler,H. Bingol
#t1987
#cProceedings of the 24th ACM/IEEE Design Automation Conference
#index172187
#%553227
#%545586
#%549519
#%548596
#!The development of high speed, large capacity hardware systems for logic simulation makes Boolean comparison of logic networks feasible for designs of practical importance. Boolean comparison provides a complete check of functional equivalence of two logic networks and is a valuable tool in design verification. This paper describes virtual logic that controls the Boolean comparison process and provides large reductions in the required number of test cases for many practical design problems. The virtual logic is simulated by the logic simulation system at the same time as the two models are simulated for test cases. The virtual logic has the task of generating new test cases such that the entire input space is covered but minimizing the number of test vectors required. Multivalued logic simulation and other techniques are used to achieve the reductions. Since the entire Boolean comparison task is completed without assistance of a general purpose host system the usual communication overhead is avoided. The techniques described are suitable for high speed logic simulators. The simulation system for the work described here was the Engineering Verification Engine (EVE) developed by IBM but other simulation systems provide similar capability.


#*Stochastic model for boundary detection
#@D. Geman
#t1987
#cImage and Vision Computing
#index149896


#*DASP: a general-purpose MIMD parallel computer using distributed associative processing
#@Y. K. Park,C. Walter,H. Yee,T. Roden,S. Berkovich
#t1989
#cProceedings of the 1989 ACM/IEEE conference on Supercomputing
#index468170
#%147875
#%161597
#%177074
#%203499
#%323187
#%330831
#%547217
#!This paper presents a general purpose MIMD (Multiple Instruction Stream Multiple Data Stream) loosely-coupled parallel computer called DASP (Distributed Associative Processor). The DASP organization partitions the communication and application functions. The communication functions are performed by custom-made communication handlers called Network Communication Modules, while application functions are performed by any general purpose processor suitable for the application. The communication subsystem of DASP takes advantage of the properties of loosely-coupled MIMD parallel computers: the very short inter-processor distances and the locality of task reference. By pipelining the time slices of the bus hierarchically with the CITO (Content Induced Transaction Overlap) protocol, DASP provides virtual full-connectivity to the application processors without physical full connections; thus, its architecture exhibits a very high degree of extensibility and modularity. Analytical and simulation results have validated the DASP approach. A prototype has been constructed and several algorithms have been successfully implemented on the prototype.


#*A software development environment to support abstraction mechanisms
#@Yoshiaki Fukazawa
#t1986
#cBulletin of Centre for Informatics
#index150472


#*Metalevel description in WSM
#@Sun Sook Yoon,Yoshiaki Fukazawa,Shinichi Yamada
#t1985
#cBulletin of Centre for Informatics
#index158744


#*Coordinate transformation: A solution algorithm for one class of robots
#@L Sciavicco,B Siciliano
#t1986
#cIEEE Transactions on Systems, Man and Cybernetics
#index155458


#*The Herbert J. Ryser Memorial Issue, Part 1
#@Marshall Hall, Jr.
#t1988
#cJournal of Combinatorial Theory Series A
#index151442


#*Toward high-performance knowledge workers
#@Douglas C. Engelbart
#t1988
#cComputer-supported cooperative work: a book of readings
#index537352


#*On Matijasevitch's nontraditional approach to search problems
#@A. Blass,Y. Gurevich
#t1989
#cInformation Processing Letters
#index475414


#*Managing resources in a parallel machine
#@Arvind,D. E. Culler
#t1986
#cProc. of the IFIP TC 10 working conference on Fifth generation computer architectures
#index184341


#*Research activities and their methodologies in mental health computing
#@Carole Siegel,Mary Jane Alexander
#t1987
#cComputers in Human Services
#index181071


#*Options multiply for nonimpact page printers
#@T Williams
#t1985
#cComputer Design
#index175438


#*Business file processing
#@James Bradley
#t1988
#c
#index171952


#*Concurrency control and object-oriented databases
#@Andrea H. Skarra,Stanley B. Zdonik
#t1989
#cObject-oriented concepts, databases, and applications
#index464049


#*Synthesis of parallel programs invariants
#@E P Gribomont
#t1985
#cProceedings of the International Joint Conference on Theory and Practice of Software Development (TAPSOFT) on Formal Methods and Software, Vol.2: Colloquium on Software Engineering (CSE)
#index174723


#*Virus versus vaccine
#@Hamilton Quant
#t1989
#cInformation Age
#index484725


#*Resolving adversarial conflicts: an approach integration case-based and analytic methods
#@E. P. Sycara
#t1987
#c
#index152545


#*The University of Salford LISP/PROLOG system
#@D. Bailey
#t1985
#cSoftware&mdash;Practice Experience
#index165442


#*Identification of linear periodically time-varying systems using white-noise test inputs
#@A. D. Sams,V. Z. Marmarelis
#t1988
#cAutomatica (Journal of IFAC)
#index471799


#*Variational penalty method in interpolation and smoothing problems on an arbitrary mesh of observations
#@P N Vabishchevich
#t1986
#cUSSR Computational Mathematics and Mathematical Physics
#index176962


#*The serial correlation coefficients for waiting times in the stationary GI/M/m queue
#@D. A. Stanford,B. Pagurek,C. M. Woodside
#t1988
#cQueueing Systems: Theory and Applications
#index462075


#*A theory for algorithm-based fault tolerance in array processor systems (checks, bounds, graph-theoretic, errors)
#@Prithviraj Banerjee
#t1985
#c
#index197548


#*Virtual Memory Management in Chorus
#@Vadim Abrossimov,Marc Rozier,Michel Gien
#t1989
#cProceedings of the European Workshop on Process in Distributed Operating Systems and Distributed Systems Management
#index365167


#*Gypsy calling: freedom, but no free lunch
#@J. L. Miller
#t1988
#cIssue 54 (November 1988)
#index487713


#*Delta Prolog: a distributed backtracking extension with events
#@Luis Moniz Pereira,Luis Monteiro,Jose Cunha,Joaquim N Aparicio
#t1986
#cProceedings on Third international conference on logic programming
#index149089


#*A method of refining averaged systems of differential equations
#@V. A. Zabolotnov
#t1987
#cUSSR Computational Mathematics and Mathematical Physics
#index176510


#*Structure and motion from optical flow under orthographic projection
#@Ken-ichi Kanatani
#t1986
#cComputer Vision, Graphics, and Image Processing
#index144995


#*An advisory system for digital logic simulation
#@B. A. Antao,J. R. Cantwell,A. J. Brodersen,J. R. Bourne
#t1989
#cProceedings of the 2nd international conference on Industrial and engineering applications of artificial intelligence and expert systems - Volume 2
#index455218


#*Theories of possibility: meta-axiomatics and semantics
#@Ladislav J. Kohout
#t1988
#cFuzzy Sets and Systems
#index156014


#*The use of Kalman filtering and correlation techniques in analytical calibration
#@H C Smit,Diane Lambert
#t1986
#cJournal of Research of the National Institute of Standards and Technology
#index147132


#*Entropy-minimizing and risk-sensitive control rules
#@P. Whittle
#t1989
#cSystems Control Letters
#index468218


#*Inclusion isotonicity of circular complex centered forms
#@Paul G. Bao,Jon Rokne
#t1987
#cBIT
#index159380


#*CNF satisfiability test by counting and polynomial average time
#@Kazuo Iwama
#t1989
#cSIAM Journal on Computing
#index470314


#*Real-time 4D animation on a 3D graphics workstation
#@C. M. Beshers,S. K. Feiner
#t1989
#cProceedings on Graphics interface '88
#index533064


#*On the evaluation of the n-fold convolution power of sums of rectangular pulse functions
#@R. Lasser
#t1987
#cSignal Processing
#index145202


#*Optimal kernels for a general sampling theorem
#@W. Engels,E. L. Stark,L. Vogt
#t1987
#cJournal of Approximation Theory
#index160690


#*Optimistic recovery in distributed systems
#@Rob Strom,Shaula Yemini
#t1985
#cACM Transactions on Computer Systems (TOCS)
#index152501
#%552437
#%552549
#%583297
#%547167
#%331657
#%319217
#%459796
#!Optimistic Recovery is a new technique supporting application-independent transparent recovery from processor failures in distributed systems. In optimistic recovery communication, computation and checkpointing proceed asynchronously. Synchronization is replaced by causal dependency tracking, which enables a posteriori reconstruction of a consistent distributed system state following a failure using process rollback and message replay. Because there is no synchronization among computation, communication, and checkpointing, optimistic recovery can tolerate the failure of an arbitrary number of processors and yields better throughput and response time than other general recovery techniques whenever failures are infrequent.


#*Semantic specification using tree manipulation languages
#@Randall P. Meyer
#t1988
#c
#index451928


#*The IBM RT personal computer
#@Richard O Simpson
#t1986
#cBYTE
#index159127


#*Numerical analysis for compressible viscous isentropic stationary flows
#@O. Pironneau,J. Rappaz
#t1989
#cIMPACT of Computing in Science and Engineering
#index486449


#*Convergence of the vortex method for vortex sheets
#@R. E. Caflisch,J. S. Lowengrub
#t1989
#cSIAM Journal on Numerical Analysis
#index485897


#*Structural organization of management in a computer network
#@V. I. Udalov
#t1988
#cAutomatic Control and Computer Sciences
#index450111


#*Renormalization group formulation of large-eddy simulations
#@A. Yakhot,S. A. Orszag,V. Yakot,M. Israeli
#t1989
#cJournal of Scientific Computing
#index478838


#*Design of a Viterbi decoder with microprocessor-based serial implementation
#@F.-J. García-Ugalde,R. H. Morelos-Zaragoza
#t1988
#cProceedings of the 4th International Conference, AAECC-4 on Applicable algebra, error-correcting codes, combinatorics and computer algebra
#index464128


#*HARP: a tableau-based theorem prover
#@F. Oppacher,E. Suen
#t1988
#cJournal of Automated Reasoning
#index453494


#*Decomposition method of descent for minimizing the sum of convex nonsmooth functions
#@K. C. Kiwiel
#t1987
#cJournal of Optimization Theory and Applications
#index143258


#*Computers in the classroom--What shall I do?: a guide
#@Walter J Burke
#t1986
#c
#index178883


#*Two methods for analyzing pleural smears for the presence of abnormalities
#@M M M Pahlplatz,M W Katzko,G H F M Hesselmans,P s Oud,G P Vooys
#t1986
#cPattern Recognition Letters
#index174464


#*Termination conventions and comparative semantics
#@E. C. R. Hehner,A. J. Malton
#t1987
#cProceedings of the NATO Advanced Study Institute on Logic of programming and calculi of discrete design
#index171184


#*Minimization of resource consumption under a given deadline in the two-processor flow-shop scheduling problem
#@Adam Janiak
#t1989
#cInformation Processing Letters
#index483507


#*Expert system development: letting the domain specialist directly author knowledge bases
#@Stanley Tuhrim,James A. Reggia,Marianne Floor
#t1987
#cExpert systems: the user interface
#index183398


#*Self-dual sequences
#@Tuvi Etzion
#t1987
#cJournal of Combinatorial Theory Series A
#index158445


#*The Ubik configurator
#@Peter de Jong
#t1988
#cProceedings of the ACM SIGOIS and IEEECS TC-OA 1988 conference on Office information systems
#index173181
#%162828
#%182928
#%181387
#%605791
#%178515
#%332180
#!Ubik is a system within which organizational structure, concepts, and actions are described and organizational applications are executed. Ubik represents an organization not with one global model, but with multiple overlapping models which can be physically distributed within multiple knowledge bases. There is a basic computational object in Ubik called the Ubik Configurator. The Configurator is used to specify organizational concepts, handlers, goals, and constraints. Configurators are linked together in lattices within a model. There are different types of models built using the configurator. Ubik models support the communication between distributed applications and the control of the parallel execution of applications. Development models support the continual evolution necessary in a large organization to cope with the changing external environment. Due process models support the resolving of conflicts between conflicting models. Organizational models describe the end-users organization and applications.


#*Media technology
#@Andrew Lippman,Marvin Minsky,David Zeltzer,Walter Bender
#t1988
#cACM SIGGRAPH 88 panel proceedings
#index389204


#*Bringing image processing into focus
#@Gerald H Moody
#t1986
#cCIM Review
#index164949


#*On the asymptotic approximation of integrals
#@W H Reid,S J Skates
#t1986
#cSIAM Journal on Applied Mathematics
#index182542


#*Cycle Time Properties Of The FDDI Token Ring Protocol
#@K. C. Sevcik,M. J. Johnson
#t1987
#cIEEE Transactions on Software Engineering
#index176756
#!The FDDI Token Ring Protocol controls communication over fiber optic rings with transmission rates in the range of 100 megabits per second. It is intended to give guaranteed response to time-critical messages by using a "timed token" protocol, in which non-critical messages may be transmitted only if recent movement of the token among stations has been sufficiently fast relative to a "target" token rotation time (TTRT).


#*Concept of a wide-area computer network
#@E A Yakubaitis
#t1986
#cAutomatic Control and Computer Sciences
#index180272


#*Generalized lower bounds derived from Hastad's main lemma
#@Shlomo Moran
#t1987
#cInformation Processing Letters
#index165790


#*Visual impairment and computer displays: the effects of foreground and background color on oral reading speed
#@J. Richard Dennis
#t1988
#c
#index197964


#*C tools for scientists and engineers
#@Louis Backer
#t1989
#c
#index458891


#*The construction and smoothness of invariant manifolds by the deformation method
#@Jerrold Marsden,Jürgen Scheurle
#t1987
#cSIAM Journal on Mathematical Analysis
#index154058


#*Computer engineering: circuits, programs, and data
#@P. P. Silvester,D. A. Lowther
#t1989
#c
#index455163


#*Causal and non-causal relationships and dynamic model construction in a managerial advisory system
#@David B. Paradice,James F. Courtney
#t1987
#cJournal of Management Information Systems
#index144438


#*A Review of Macsyma
#@R. J. Fateman
#t1989
#cIEEE Transactions on Knowledge and Data Engineering
#index441876
#%143607
#%150227
#%150752
#%155685
#%160232
#%165567
#%166932
#%172631
#%173164
#%179608
#%183831
#%204482
#%205145
#%261422
#%321664
#%329807
#%332263
#%548414
#%545173
#%550577
#%478201
#!The successes and failures of the Macsyma algebraic manipulation system are reviewed from the point of view of one of the original contributors. A retrospective examination is provided of some of the controversial ideas that worked, and some that did not. Input/output, language semantics, knowledge-adjunction, mathematical semantics, the model of the user, and other issues are considered. Possible future directions for algebraic manipulation system building are discussed.


#*A sufficient condition for the evadability of differential evasion games
#@J. Yong
#t1988
#cJournal of Optimization Theory and Applications
#index162378


#*Mixed product and asynchronous automata
#@C. Duboc
#t1986
#cTheoretical Computer Science
#index157376


#*Mobile Radio for Voice and Data in Information Network
#@Lennart Björk
#t1988
#cProceedings of the IFIP TC6 International Conference on Information Network and Data Communication II
#index371768


#*Optimistic implementation of bulk data transfer protocols
#@J. B. Carter,W. Zwaenepoel
#t1989
#cProceedings of the 1989 ACM SIGMETRICS international conference on Measurement and modeling of computer systems
#index480281
#%146156
#%179540
#%184898
#%331846
#%464299
#%546608
#!During a bulk data transfer over a high speed network, there is a high probability that the next packet received from the network by the destination host is the next packet in the transfer. An optimistic implementation of a bulk data transfer protocol takes advantage of this observation by instructing the network interface on the destination host to deposit the data of the next packet immediately into its anticipated final location. No copying of the data is required in the common case, and overhead is greatly reduced. Our optimistic implementation of the V kernel bulk data transfer protocols on SUN-3/50 workstations connected by a 10 megabit Ethernet achieves peak process-to-process data rates of 8.3 megabits per second for 1-megabyte transfers, and 6.8 megabits per second for 8-kilobyte transfers, compared to 6.1 and 5.0 megabits per second for the pessimistic implementation. When the reception of a bulk data transfer is interrupted by the arrival of unexpected packets at the destination, the worst-case performance of the optimistic implementation is only 15 percent less than that of the pessimistic implementation. Measurements and simulation indicate that for a wide range of load conditions the optimistic implementation outperforms the pessimistic implementation.


#*Chordal graph recognition is in NC
#@Anders Edenbrandt
#t1987
#cInformation Processing Letters
#index167104


#*A constructive method for computing the tension parameters in convexity-preserving spline-in-tension interpolation
#@N. S. Sapidis,P. D. Kaklis,T. A. Loukakis
#t1988
#cNumerische Mathematik
#index486204


#*A general subdivision theorem for Be&acute;zier triangles
#@H. -P. Seidel
#t1989
#cMathematical methods in computer aided geometric design
#index454290


#*Object-oriented systems analysis: modeling the world in data
#@Sally Shlaer,Stephen J. Mellor
#t1988
#c
#index169380


#*Node partition formula for directed graph reliability
#@J. A. Buzacott
#t1987
#cNetworks
#index185257


#*Computational abstractions for finite element programming
#@John Wesley Baugh, Jr.
#t1989
#c
#index194443


#*GTEX&mdash;A group technology expert system
#@Luca Bonani,Paolo Calvo,Giovanni Contri
#t1988
#cProceedings of the 1st international conference on Industrial and engineering applications of artificial intelligence and expert systems - Volume 1
#index479614
#%144934
#%148467
#%181387
#!In this paper we describe GTEX, an expert system that solves the problem of modifying the production plant layout, from job-shop to cells layout in the medium and short term, using Group Technology criteria. We also describe and discuss the development methodologies and the A.I. technology impact on the problem solution. Though the Group Technology problem has been deeply investigated in the past years, this project represents a new approach to it in that the solution is achieved by introducing hypothetical reasoning, heuristic criteria integrated with simple algorithms and interaction with the user. At present a first release of the system is under test against real production data supplied by a manufacturing company.


#*Interactive fuzzy decision making for generalized multiobjective linear fractional programming problems with fuzzy parameters
#@H. Yano,M. Sakawa
#t1989
#cFuzzy Sets and Systems
#index477274


#*Computing in Civil Engineering: Computers in Engineering Practice
#@Thomas O. Barnwell, Jr.
#t1989
#c
#index241384


#*Binary picture thinning by an iterative parallel two-subcycle operation
#@Satoshi Suzuki,Abe Keiichi
#t1987
#cPattern Recognition
#index148911


#*The computer and the mind
#@P. N. Johnson-Laird
#t1988
#c
#index454272


#*Interconnection patterns for parallel computers
#@L. G. Valiant
#t1986
#cProceedings of the fourth MIT conference on Advanced research in VLSI
#index157240


#*Parasitic waves and solitons in the numerical solution of the Korteweg-de Vries and modified Korteweg-de Vries equation
#@M. F. Maritz,S. W. Schoombie
#t1987
#cJournal of Computational Physics
#index173750


#*A clinical field study of eight automated psychometric procedures: the Leicester/DHSS project
#@J. Graham Beaumont,Christopher C. French
#t1987
#cInternational Journal of Man-Machine Studies
#index163041


#*A Wirelist Compare Program for Verifying VLSI Layouts
#@K. L. Kodandapani,Edward McGrath
#t1986
#cIEEE Design Test
#index348770
#!We will describe a wirelist compare program that, together with a VLSI node extractor, is used to verify VLSI IC layout connectivity.Engineers at Digital Equipment Corporation have successfully used this tool in a production environment to debug layout errors.The program is based on a graph isomorphism algorithm and provides graphical and textual guides to pinpoint errors. We willexamine this algorithm, its error outputs, and provide run-time statistics.


#*Global model hourglassing control
#@J. C. Schulz
#t1987
#cComputer Methods in Applied Mechanics and Engineering
#index171060


#*Pointwise circumscription
#@V. Lifschitz
#t1987
#cReadings in nonmonotonic reasoning
#index176898


#*Prototype software complexity metrics tools
#@C. C. Cook,M. Nanja
#t1987
#cACM SIGSOFT Software Engineering Notes
#index164970
#%148069
#%326409
#%166312
#!Software Complexity Metrics Tool (SCMT) is a prototype, menu-driven program that assists in the collection, analysis, and display of software complexity and program error data. For example, using SCMT a user can investigate relationships between software complexity metrics and the number of errors in a program or can begin to develop predictive models for identifying error-prone modules.SCMT is written in C and runs under UNIX trade;. Although designed specifically for C software, its concepts and techniques apply to software in any programming language.


#*Anforderungen an DV-Systeme aus der Sicht von Arbeitnehmern
#@Gerhard Rohde
#t1987
#cSch&ouml;be Neue Computerwelt, Zur gesellschaftlichen Verantwortung der Informatiker [3. Jahrestagung des Forums Informatiker f&uuml;r Frieden und gesellschaftliche Verantwortung e.V.
#index371144


#*Robust stabilization of linear systems with norm-bounded time-varying uncertainty
#@Kemin Zhou,Pramod P. Khargonekar
#t1988
#cSystems Control Letters
#index163365


#*Perception of organization in a random stimulus
#@Beverly J. Smith
#t1986
#cPapers from the second workshop Vol. 13 on Human and Machine Vision II
#index178318


#*A deterministic view of random sampling and its use in geometry
#@B. Chazelle,J. Friedman
#t1988
#cProceedings of the 29th Annual Symposium on Foundations of Computer Science
#index39061
#!A number of efficient probabilistic algorithms based on the combination of divide-and-conquer and random sampling have been recently discovered. It is shown that all those algorithms can be derandomized with only polynomial overhead. In the process. results of independent interest concerning the covering of hypergraphs are established, and various probabilistic bounds in geometry complexity are improved. For example, given n hyperplanes in d-space and any large enough integer r, it is shown how to compute, in polynomial time, a simplicial packing of size O(r/sup d/) that covers d-space, each of whose simplices intersects O(n/r) hyperplanes. It is also shown how to locate a point among n hyperplanes in d-space in O(log n) query time, using O(n/sup d/) storage and polynomial preprocessing.


#*The classification of surfaces
#@Peter Andrews
#t1988
#cAmerican Mathematical Monthly
#index465962


#*Computer organization architecture
#@J. Adair
#t1988
#c
#index480199


#*On the algebra of interactive fuzzy numbers
#@J. J. Buckley
#t1989
#cFuzzy Sets and Systems
#index471120


#*An historical perspective on clinical laboratory information systems
#@T. L. Lincoln
#t1987
#cProceedings of ACM conference on History of medical informatics
#index161403
#!The clinical laboratory environment represents a microcosm in which practical solutions to operational problems in medical informatics have gone hand in hand with the development of laboratory instrumentation and computer technologies. These achievements follow a typical pattern in technological development, leading from the specific to the inclusive. The history of laboratory computing offers insights, not only for the past, but also for the future.


#*Investigation and solution of integer systems of linear equations
#@S. L. Blyumin,Yu. I. Denisenko,S. P. Milovidov
#t1989
#cUSSR Computational Mathematics and Mathematical Physics
#index484832


#*Breaking out
#@Edward Batutis
#t1986
#cBYTE
#index183848


#*Propositional Temporal Interval Logic is PSPACE Complete
#@A. A. Aaby,K. T. Narayana
#t1988
#cProceedings of the 9th International Conference on Automated Deduction
#index561873


#*The use of airborne imaging spectrometer (AIS) data to differentiate marsh vegetation
#@Michael F Gross,Vytautas Klemas
#t1986
#cRemote Sensing of Environment
#index172042


#*A global adaptive model following control in conjunction with local open-loop and closed-loop compensations for a robot manipulator
#@Domingo L. Uy
#t1987
#c
#index196424


#*Test generation for digital systems
#@Jacob A. Abraham,Vinod K. Agarwal
#t1986
#cFault-tolerant computing: theory and techniques; vol. 1
#index163823


#*Extraneous fixed points, basin boundaries and chaotic dynamics for Schro&uml;der and Ko&uml;nig rational iteration functions
#@E. R. Vrscay,W. J. Gilbert
#t1988
#cNumerische Mathematik
#index469478


#*Survival: a tale of a senior project
#@Elaine Anderson
#t1987
#cACM SIGCSE Bulletin
#index184637
#%152079
#!In 1984 the Computer Information Systems Department at Humboldt State University implemented a B.S. degree program in Computer Information Systems. Prior to that year the program had been offered under the auspices of a Business Administration degree as a concentration. In the evolvement of the program since 1984. The faculty of the department determined that a senior project course would form an appropriate capstone course for all CIS majors. The course and its incorporation into the degree program will occur in 1987/88. It so happened that Bailes and Sayers' paper [1] and the opportunity to apply their guidance occurred at the beginning of the spring semester. The story of our experiment with the course using a variation of the "contract" suggested by Bailes and Sayer, as written by the three students involved, follows.One semester, three graduating seniors found themselves with class schedule conflicts that prevented their taking a particular required course. When it became obvious that they could not schedule the conflicting class, the chair of their department assigned to them a senior project. The guidelines for the project were adapted from ones outlined in the SIGCSE Bulletin Vol. 18 No. 4, December 1986. The students could do whatever they wanted for a project so lon g as the department chair approved, and they fulfilled the objectives. Here is what these graduating seniors did.


#*CP/M 80 systems programming
#@G R Brookes,G A Manson,J A Thompson
#t1985
#c
#index181787


#*Datenschutz und ISDN
#@Frank Hagl
#t1989
#cDie W&uuml;rde der Menschen ist unverNETZbar [5. Jahrestagung des Forums InformatikerInnen f&uuml;r Frieden und gesellschaftliche Verantwortung e.V.
#index355975


#*Optimal placement for hierarchical VLSI layout design
#@M. Mir,M. H. Imam
#t1989
#cMicroprocessing and Microprogramming
#index469943


#*Time series analysis of rhythmic bacterial resistance development to antibiotics
#@Miguel A. L. Nicolelis,Luiz Anthonio Baccala
#t1988
#cComputers and Biomedical Research
#index151181


#*Application of overlapping technique in selection of scientific journals for a particular discipline-methodological approach
#@Nevenka Pravdic,Vesna Oluic-Vukovic
#t1987
#cInformation Processing and Management: an International Journal
#index161627


#*A programmable interactive automated deduction system for propositional logic
#@James David Shelley
#t1987
#c
#index201917


#*Painting a new picture
#@Frank Sweet
#t1985
#cDatamation
#index166253


#*Stochastic systems with small noise, analysis and simulation; a phase locked loop example
#@P. Dupuis,H. J. Kushner
#t1987
#cSIAM Journal on Applied Mathematics
#index162783


#*Learning iteration recursion from examples
#@Susan Wiedenbeck
#t1989
#cInternational Journal of Man-Machine Studies
#index457956


#*Stream vectors in three dimensional aerodynamics
#@F EI Dabaghi,O Pironneau
#t1986
#cNumerische Mathematik
#index144285


#*Healthcare cost containment: the private sector
#@M K Kerrigan
#t1986
#cHoneywell Source
#index177803


#*Link Models for Networks with Dynamic Topologies
#@Robert L. Moose,Richard E. Nance
#t1987
#c
#index190413
#!Dynamic hierarchical networks represent an architectural strategy for employing adaptive behavior in applications sensitive to highly variable external demands or uncertain internal conditions. The characteristics of such architectures are described, and the significance of adaptive capability is discussed. The necessity for assessing the tradeoffs between performance improvements (reduced and bounded message transmission time, increased throughput) and the added costs (reconfiguration delays, redundant links, etc.) leads to the use of complex queueing models. The assumptions underlying the general model are stated, and a class of applicable models (queues in random environments or RE-queues) is introduced. Matrix-geometric methods are reviewed in terms of their suitability for addressing several variations of a subclass of RE-queue models. Matrix-geometric techniques are considered to offer the greatest promise for obtaining usable results for assessing the cost/benefit tradeoffs.


#*On two methods for approximating minimal surfaces in parametric form
#@Takuya Tsuchiya
#t1986
#cMathematics of Computation
#index165532


#*The latent damage system: a jurisprudential analysis
#@R. E. Susskind
#t1989
#cProceedings of the 2nd international conference on Artificial intelligence and law
#index474358
#!This paper brings together the findings of two projects in the field of AI and law. The first of these was a jurisprudential inquiry into expert systems in law sometimes referred to as the Oxford Project. This work in fact originated in Glasgow University in 1981, was developed in the course of doctoral legal research at Oxford University from 1983 to 1986, and culminated in the publication of Expert Systems in Law: A Jurisprudential Inquiry (Oxford University Press, 1987) by R E Susskind. The second project was work on The Latent Damage System, the UK's first commercially available expert system in law. The development of that system has been fully documented in a case study by P N Capper and R E Susskind: Latent Damage Law &mdash; The Expert System (Butterworths , 1988), and a copy of the system itself is packaged with the book. The purpose of this paper is to examine the Latent Damage Project from the perspective of the Oxford Project &mdash; the findings and methodology of a jurisprudential inquiry into expert systems in law are used to analyse the development and operation of one of the world's first operational systems. The paper is structured in four parts. The first offers a brief overview of the Oxford and Latent Damage Projects. This is not undertaken in detail, as these projects have been documented extensively elsewhere. However, sufficient background information is given so that the paper can be read as a self-contained piece. The central arguments and findings are presented in Part Two, which lays bare the jurisprudential foundations of The Latent Damage System. It does so in terms of the theories of jurisprudence that the Oxford Project established must underlie any expert system in law. Part Three examines the extent to which the development of The Latent Damage System was conditioned by the teachings of jurisprudence. Finally, in Part Four, the users, function and scope of The Latent Damage System are pinpointed. The purpose of this paper is not to demonstrate the power of The Latent Damage System by placing it within a jurisprudential framework. The power of the system is, in fact, best illustrated by running it and assessing its utility in practice. The overriding aim of the discussion here is to consider the relevance of the findings and recommendations of a highly academic project for those whose orientation is that of building real-life, commercial, practical systems.


#*Knowledge-based tools to promote shared goals and terminology between interface designers
#@Robert Neches
#t1988
#cACM Transactions on Information Systems (TOIS)
#index162803
#%553954
#!Two tools that support cooperation are described: one for the construction of consistent and principled human-computer interfaces and the other for the construction of AI knowledge bases. These tools provide a central repository for design knowledge that otherwise would not be easily shared among users. The AI knowledge representation technology upon which the tools are founded is first described. A knowledge-based approach to interface construction is discussed, and how that approach applies to detecting design conflicts and inconsistencies stemming from two different kinds of team communication failure is illustrated. Next, a knowledge acquisition aid that is utilized within the interface construction paradigm and that also illustrates the same approach to supporting cooperative work is described. Finally, four sources of difficulty in team design efforts, which this approach seeks to address, are reviewed.


#*Lenstra's factorisation method based on elliptic curves
#@N M Stephens
#t1986
#cLecture notes in computer sciences; 218 on Advances in cryptology---CRYPTO 85
#index142909


#*Mental models: theory and application in human factors
#@John R. Wilson,Andrew Rutherford
#t1989
#cHuman Factors
#index472866


#*Integrating distributed array processing into EMAS 2900
#@M W Brown
#t1986
#cSoftware&mdash;Practice Experience
#index165759


#*The MINDS system: using context and dialog to enhance speech
#@Sheryl R. Young
#t1989
#cProceedings of the workshop on Speech and Natural Language
#index519937
#%174126
#%181385
#%466605
#!Contextual knowledge has traditionally been used in multi-sentential textual understanding systems. In contrast, this paper describes a new approach toward using contextual, dialog-based knowledge for speech recognition. To demonstrate this approach, we have built MINDS, a system which uses contextual knowledge to predictively generate expectations about the conceptual content that may be expressed in a system user's next utterance. These expectations are expanded to constrain the possible words which may be matched from an incoming speech signal. To prevent system rigidity and allow for diverse user behavior, the system creates layered predictions which range from very specific to very general. Each time new information becomes available from the ongoing dialog, MINDS generates a different set of layered predictions for processing the next utterance. The predictions contain constraints derived from the contextual, dialog level knowledge sources and each prediction is translated into a grammar usable by our speech recognizer, SPHINX. Since speech recognizers use grammars to dictate legal word sequences and to constrain the recognition process, the dynamically generated grammars reduce the number of word candidates considered by the recognizer. The results demonstrate that speech recognition accuracy is greatly enhanced through the use of predictions.


#*Vowel normalization by frequency warped spectral matching
#@H Matsumoto,H Wakita
#t1986
#cSpeech Communication
#index155847


#*Remarks on codes from Hermitian curves
#@H. J. Tiersma
#t1987
#cIEEE Transactions on Information Theory
#index172392


#*Dialing for data
#@Fredric Paul
#t1988
#cPC/Computing
#index467523


#*The solution of the problem of minimizing generalized Treffetz functionals as a variational problem with constraints
#@V. Ya. Tereshchenko
#t1987
#cUSSR Computational Mathematics and Mathematical Physics
#index181644


#*Micro View
#@
#t1989
#cIEEE Micro
#index444225


#*Fuzzy Stone-C&caron;ech-type compactifications
#@Y.-M. Liu,M.-K. Luo
#t1989
#cFuzzy Sets and Systems
#index459961


#*Pirates, hacks and Trojans
#@T. Parker
#t1987
#cComputer Language
#index156645


#*A computer assisted PERT simulation
#@David A. Ameen
#t1987
#cJournal of Systems Management
#index173466


#*A parallel branch and bound algorithm for test generation
#@S. Patil,P. Banerjee
#t1989
#cProceedings of the 26th ACM/IEEE Design Automation Conference
#index482481
#%477034
#%553311
#!For circuits of VLSI complexity, test generation time can be prohibitive. Most of the time is consumed by hard-to-detect (HTD) faults which might remain undetected even after a large number of backtracks. We identify the problems inherent in a uniprocessor implementation of a test generation algorithm and propose a parallel test generation algorithm which tries to achieve a high fault coverage for HTD faults in a reasonable amount of time. A dynamic search space allocation strategy is used which ensures that the search spaces allocated to different processors are disjoint. The parallel test generation algorithm has been implemented on an Intel iPSC/2 hypercube. Results are presented using the ISCAS combinational benchmark circuits which conclusively prove that parallel processing of HTD faults does indeed result in high fault coverage which is otherwise not achievable by a uniprocessor algorithm in limited CPU time. The parallel algorithm exhibits superlinear speedups in some cases due to search anomalies.


#*Bounds for bounded motion around a perturbed fixed point
#@R. van Damme,T. P. Valkering
#t1988
#cZeitschrift f&uuml;r Angewandte Mathematik und Physik (ZAMP)
#index478755


#*ACE: a color expert system for user interface design
#@Barbara J. Meier
#t1988
#cProceedings of the 1st annual ACM SIGGRAPH symposium on User Interface Software
#index459365
#%155436
#%157050
#%164685
#%168050
#%193043
#%544673
#!Color is used in computer graphics to code information, to call attention to items, to signal a user, and to enhance display aesthetics, but using color effectively and tastefully is often beyond the abilities of application programmers because the study of color crosses many disciplines, and many aspects, such as human color vision, are not completely understood. We compiled a comprehensive set of guidelines for the proper use of color, but even these guidelines cannot provide all of the aesthetic and human factors knowledge necessary for making good color selections. Furthermore, programmers may misinterpret or ignore the guidelines. To alleviate some of these problems, we have implemented ACE, A Color Expert system which embodies the color rules and applies them to user interface design. The goal of the implementation was to test whether an automated mechanism would be a viable solution to the problem of choosing effective and tasteful colors. Our implementation is written in OPS5, a production system programming language, which allowed us encode rules in a similar fashion to our existing set of guidelines. ACE takes a user interface specification and uses our color rules as constraints to determine the best colors for particular items. While ACE is only a prototype, we learned that an expert system is a viable method for choosing an initial set of colors that can be &ldquo;tweaked&rdquo; by a human expert. We also learned that much more research needs to be performed in the areas of visual color relationships and how they can be used to provide the most effective user interface.


#*Compiler molds microcode to any architecture
#@M. Andrews,G. Wey,K. Edwards
#t1988
#cComputer Design
#index163069


#*Maintaining availability in partitioned replicated databases
#@A. El Abbadi,S. Toueg
#t1989
#cACM Transactions on Database Systems (TODS)
#index477762
#%123550
#%144061
#%150252
#%155427
#%156026
#%157343
#%167762
#%175162
#%247066
#%254107
#%317485
#%320363
#%331657
#%333180
#%552884
#!In a replicated database, a data item may have copies residing on several sites. A replica control protocol is necessary to ensure that data items with several copies behave as if they consist of a single copy, as far as users can tell. We describe a new replica control protocol that allows the accessing of data in spite of site failures and network partitioning. This protocol provides the database designer with a large degree of flexibility in deciding the degree of data availability, as well as the cost of accessing data.


#*From the Editor-in-Chief
#@
#t1989
#cIEEE Micro
#index441349


#*The complexity of generating an exponentially distributed variate
#@Philippe Flajolet,Nasser Saheb
#t1986
#cJournal of Algorithms
#index167980


#*Printer fonts
#@M. Parker
#t1988
#cOutput hardcopy devices
#index455650


#*Parallel algorithm development workbench
#@S. Arya,B. Gaither
#t1988
#cProceedings of the 1988 ACM/IEEE conference on Supercomputing
#index471480
#%145912
#!This paper proposes an approach, and a resulting tool, for developing algorithms for parallel processors. The problems in developing efficient algorithms for parallel systems are discussed. The objectives of this approach are to support the evaluation of the expected efficiency of algorithms on various interconnection network architectures before detailed code is written, optimization of interconnection network facility usage, and efficient evaluation of and tuning of codes (both systems and applications) to the CPU hardware. This proposed approach can be extended for the evaluation of alternative processor architectures as well. This approach and associated tool will take information about computation and communication times and provide information about elapsed time, idle spots, conflicts, and deadlocks. This is achieved by modeling various aspects of the system in different levels of detail. The Communications Network is modeled by a discrete event simulation with stochastic service assumptions. These stochastic service assumptions can be refined by the invocation of a cluster model which takes into account more details of resource contention and delays within a group of processors. Finally, a trace driven model of internal CPU timing can be used to replace statistical assumptions and represent precise timing of application code such as information on the extent to which chaining occurs and the utilization of functional units. These components work together to achieve the objectives discussed above. The proposed tool uses hierarchical simulation and provides a workbench environment for algorithm development. Transfer of data is represented via a high level notation which is independent of Interconnection Network architecture. The types of instrumentation and statistics required are discussed, as well as techniques under investigation for graphical representation of results. The structure of the simulator hierarchy, methods for extending the use of the model to evaluate real code, and the role of the modeling tool when used as part of a debugging environment are discussed. The processor model and the interpreter have currently been implemented. The remaining portions of the workbench are under incremental implementation.


#*Performance-driven placement of cell based IC's
#@M. A. B. Jackson,E. S. Kuh
#t1989
#cProceedings of the 26th ACM/IEEE Design Automation Conference
#index480118
#%90291
#%172163
#%544687
#!The increasingly important role of the interconnect in the timing performance of present and future integrated circuit technologies underscores the need to reconsider conventional physical design CAD tools, and devise new ways to influence performance during layout. Interconnects are not perfect conductors, they introduce parasitic elements that load the logic gates and distort the temporal properties of the design as viewed by the logic designer. Cell placement that minimizes wirelength as the sole objective does not solve the problem, leaving a margin for performance improvement that has not been fully exploited. This paper presents a novel approach to performance-driven placement, combining timing analysis and physical design to dynamically optimize the performance of the chip during placement. The ideas are embodied in a program named Allegro, and preliminary results tested on Sea-of-Gate designs are encouraging.


#*The use of Cornu spirals in drawing planar curves of controlled curvature
#@D. S. Meek,D. J. Walton
#t1989
#cJournal of Computational and Applied Mathematics
#index461605


#*Tolerant planning and negotiation in generating coordinated movement plans in an automated factory
#@J. B. H. Kwa
#t1988
#cProceedings of the 1st international conference on Industrial and engineering applications of artificial intelligence and expert systems - Volume 1
#index451750
#%178172
#!Plan robustness is important for real world applications where modelling imperfections often result in execution deviations. The concept of tolerant planning is suggested as one of the ways to build robust plans. Tolerant planning achieves this aim by being tolerant of an agent's own execution deviations. When applied to multi-agent domains, it has the additional characteristic of being tolerant of other agents' deviant behaviour. Tolerant planning thus defers dynamic replanning until execution errors become excessive. The underlying strategy is to provide more than ample resources for agents to achieve their goals. Such redundancies aggravate the resource contention problem. To counter this, the iterative negotiation mechanism is suggested. It requires agents to be skillful in negotiating with other agents to resolve conflicts in such a way as to minimize compromising one's own tolerances and yet being benevolent in helping others find a feasible plan.


#*Invariante Mustererkennung im Frequenzbereich bei Grauwertbildern
#@U. Schramm,M. Fröder,A. Scheibinger
#t1987
#cMustererkennung 1987, 9. DAGM-Symposium
#index559263


#*Experiencing artificial intelligence: an interactive approach to the IBM PC
#@John J. Morone,Mark R. Hilbush
#t1987
#c
#index169171


#*Designing data base systems for maintainability: case study: IDMS and IMS
#@E D Zeisler
#t1986
#cThe Institute of Electrical and Electronics Engineers, Inc on Conference on software maintenance--1985
#index162175


#*Cognition personal structure
#@James C. Mancuso
#t1988
#c
#index465808


#*Using database machines in embedded computer systems
#@Csaba Egyhazy
#t1985
#cInformation and Management
#index142786


#*Concurrency control in a VLSI design database
#@I. Widya,T. G. R. van Leuken,P. van der Wolf
#t1988
#cProceedings of the 25th ACM/IEEE Design Automation Conference
#index83781
#%75462
#%320363
#%157343
#%317485
#!This paper explores a concurrency control mechanism which is suitable for the protection of VLSI design data against interfering concurrent accesses. VLSI design transactions are typically of long duration with frequent concurrent read-write and read-read accesses. A version mechanism is known to be very effective in long duration transaction systems with frequent concurrent read-write accesses. Although a design version mechanism, which is offered to the designers to maintain the evolution of design objects, has different aims than a version mechanism for concurrency control, a two-version mechanism fits very well in the former. This paper shows that a two-version two-phase locking mechanism, slightly adapted to a design system, is sufficient. The existence of a design manager, which prevents certain sequences of design transactions, simplifies the concurrency control protocol significantly.


#*Computational experience with generalized simulated annealing over continuous variables
#@D. G. Brooks,W. A. Verdini
#t1988
#cAmerican Journal of Mathematical and Management Sciences
#index482770


#*Parallel processor balance through loop spreading
#@Y. Wu,T. Lewis
#t1989
#cProceedings of the 1989 ACM/IEEE conference on Supercomputing
#index487951
#%162585
#%169135
#%189540
#%190431
#%202908
#%441113
#%463479
#!When the number of processors P is less than the number of tasks N in a parallel loop, the loop has to be executed in &lceil;N/P&rceil; rounds and the last round executes only (N mod P) tasks. In many cases, in the last round all but a few processors are idle, which causes a significant drop in performance. This performance drop becomes more and more detrimental as the number of processors increases. Loop spreading is a technique for restructuring parallel loops so as to balance parallel tasks on multiple processors. A spread loop runs at least as fast as the non-spread loop even when N mod P = 0, and shows no performance drop when N changes. We show how the method keeps the performance of the matrix multiplication and a simplex algorithm from decreasing as the size of input changes.


#*Clock system design
#@Kenneth D. Wagner
#t1988
#cIEEE Design Test
#index446508
#%171594
#%179622
#%181709
#%550160
#!Provides a framework for understanding system timing and then describes how the computer clock system executes the timing specifications. He examines clock generation and the construction of clock-distribution networks, which are integral to any clock system. Examples from contemporary high-speed systems highlight several common methods of clock generation, distribution, and tuning. Tight control of system clock skew is stressed.


#*Best match searching
#@Peter Willett
#t1988
#cDocument retrieval systems
#index533095


#*Decentralized resource allocation algorithms with applications to flow control of communication networks
#@Beverly Ann Sanders
#t1985
#c
#index195184


#*On a Constraint Equation for the Estimation of Displacement Rates in Image Sequences
#@H.-H. Nagel
#t1989
#cIEEE Transactions on Pattern Analysis and Machine Intelligence
#index467941
#%142951
#%167606
#%172313
#!The commonly used constraint equation Delta g/sup T/u+g/sub t/=0 for the estimation of optical flow can only be justified by assumptions that are, in general, far too restrictive for image sequences of real world scenes. B.G. Schunck (1985, 86) recently argued that a constraint equation for the estimation of what he called image flow has to include a term containing the divergence of this image flow without presenting, however, a stringent derivation based on perspective projection from 3-D scene space. The present author derives a constraint equation based on a combination of perspective projection and notions from differential geometry. In addition, he demonstrates the quantitive effects of taking into account radiometric considerations based on the use of Lambertian reflection properties and isotropic illumination in scene space.


#*Ranging Errors with Verging Stereo Cameras
#@Eric Krotkov,Ralf Kories
#t1987
#cMustererkennung 1987, 9. DAGM-Symposium
#index567362


#*Modeling for text compression
#@Timothy Bell,Ian H. Witten,John G. Cleary
#t1989
#cACM Computing Surveys (CSUR)
#index483769
#%147435
#%152978
#%153705
#%154193
#%155485
#%155656
#%157355
#%160916
#%161947
#%163491
#%163624
#%169231
#%170324
#%170641
#%171190
#%176837
#%179695
#%189350
#%319258
#%328492
#%333373
#%333769
#%456367
#%457329
#%461711
#%469620
#%542148
#%595133
#%484424
#%593140
#!The best schemes for text compression use large models to help them predict which characters will come next. The actual next characters are coded with respect to the prediction, resulting in compression of information. Models are best formed adaptively, based on the text seen so far. This paper surveys successful strategies for adaptive modeling that are suitable for use in practical text compression systems. The strategies fall into three main classes: finite-context modeling, in which the last few characters are used to condition the probability distribution for the next one; finite-state modeling, in which the distribution is conditioned by the current state (and which subsumes finite-context modeling as an important special case); and dictionary modeling, in which strings of characters are replaced by pointers into an evolving dictionary. A comparison of different methods on the same sample texts is included, along with an analysis of future research directions.


#*Uncertainty models in information and database systems
#@Billy P Buckles,Frederick E Petry
#t1985
#cJournal of Information Science
#index168187


#*Managing Replicated Files in Partitioned Distributed Database Systems
#@Sushil Jajodia
#t1987
#cProceedings of the Third International Conference on Data Engineering
#index384469


#*Reasoning about systolic algorithms
#@S Purushothaman
#t1986
#c
#index180629


#*On fuzzy differential equations
#@Ouyang He,Wu Yi
#t1989
#cFuzzy Sets and Systems
#index478624


#*Well-structured knowledge bases
#@K. Pedersen
#t1989
#cAI Expert
#index462546


#*Stable families of behavioural equivalences
#@M. Livesey
#t1989
#cTheoretical Computer Science
#index452134


#*A note on economic models for R D project selection in the presence of project interactions
#@P M Goldstein,H M Singer
#t1986
#cManagement Science
#index143216


#*Parallel Query Processing for Complex Objects
#@Setrag Khoshafian,Patrick Valduriez,George P. Copeland
#t1988
#cProceedings of the Fourth International Conference on Data Engineering
#index376781


#*The effects of computer-assisted teaching on achievement levels of preschoolers
#@Alan Reeves
#t1989
#c
#index189963


#*On the asymptotic information storage capacity of neural networks
#@G. Palm
#t1988
#cProceedings of the NATO Advanced Research Workshop on Neural computers
#index142983


#*Similarity retrieval of iconic image database
#@Suh-Yin Lee,Man-Kwan Shan,Wei-Pang Yang
#t1989
#cPattern Recognition
#index465623


#*Call for Papers
#@
#t1986
#cIEEE Software
#index336414


#*The Morgan corporation
#@J. Senn
#t1989
#cEnd-user computing: Concepts, issues, and applications
#index476895


#*Advances in synchrotron X-ray polycrystalline diffraction
#@William Parrish
#t1988
#cAustralian Journal of Physics
#index484444


#*Towards functional programming in Prolog
#@Antonio L. Furtado
#t1988
#cACM SIGPLAN Notices
#index163196
#%156901
#%313666
#%171655
#%168224
#%174797
#%473284
#!The integration of functional and logic programming is attempted, using the strategy to add a functional component to Prolog. The component takes the form of extended computable expressions, allowing user-defined functions and operators as well as a number of functional forms. The problem of evaluating expressions combining functions and predicates is investigated. Examples are provided to illustrate the discussion. The paper includes a prototype implementation.


#*The nature of speech
#@F. Nolan
#t1986
#cElectronic speech recognition: techniques, technology, and applications
#index157515


#*First program
#@Malcolm Rubel
#t1989
#cData Based Advisor
#index451185


#*The Johnson-Lindenstrauss Lemma and the sphericity of some graphs
#@P. Frankl,H. Maehara
#t1987
#cJournal of Combinatorial Theory Series A
#index177616


#*Efficient Text Searching of Regular Expressions (Extended Abstract)
#@Ricardo A. Baeza-Yates,Gaston H. Gonnet
#t1989
#cProceedings of the 16th International Colloquium on Automata, Languages and Programming
#index366928


#*Recognizing primes in random polynomial time
#@L. Adleman,M. Huang
#t1987
#cProceedings of the nineteenth annual ACM symposium on Theory of computing
#index157910
#%175886
#!This paper is the first in a sequence of papers which will prove the existence of a random polynomial time algorithm for the set of primes. The techniques used are from arithmetic algebraic geometry and to a lesser extent algebraic and analytic number theory. The result complements the well known result of Strassen and Soloway that there exists a random polynomial time algorithm for the set of composites.


#*Finite element methods for the incompressible nuclear waste-disposal contamination porous media
#@R. E. Ewing,Y. Yuan,G. Li
#t1989
#cNumerical analysis 1987
#index476558


#*The constraint method of attrition
#@D. S. Hartley, III
#t1989
#cProceedings of the 21st conference on Winter simulation
#index457392
#!Helmbold demonstrated a relationship between a ratio containing initial force sizes and casualties, herein called the Helmbold ratio, and the initial force ratio in a large number of historical battles. This paper examines some of the complexity of the Helmbold ratio using analytical and simulation techniques and demonstrates that a constraint model of attrition captures some aspects of historical data. The effect that the constraint model would have on warfare modeling is uncertain. However, some speculation has been attempted concerning its use in large scale simulations.


#*Inside Macintosh X-Ref Book
#@
#t1988
#c
#index15672


#*A note on probabilities in proofreading
#@Fasheng Liu
#t1988
#cAmerican Mathematical Monthly
#index451915


#*Hidden variable fractal interpolation functions
#@M. F. Barnsley,J. Elton,D. Hardin,P. Massopust
#t1989
#cSIAM Journal on Mathematical Analysis
#index450958


#*Comments on "Number of faults per line of code"
#@F Stetter
#t1986
#cIEEE Transactions on Software Engineering
#index178759


#*An analytical model for a class of processor-memory interconnection networks
#@R. Conterno,R. Melen
#t1987
#cIEEE Transactions on Computers
#index178420


#*Design of microwave transistor amplifiers
#@M. Runham,A. J. Baden Fuller
#t1989
#cComputer-Aided Design
#index471385


#*Modular feedback logic for discrete event systems
#@P. J. Ramadge,W. M. Wonham
#t1987
#cSIAM Journal on Control and Optimization
#index169631


#*Privacy and security issues in information systems
#@R Turn,W H. Ware
#t1985
#cEthical issues in the use of computers
#index166188


#*The Cognitive Computer: On Language, Learning, & Artificial Intelligence
#@Roger C. Schank,Peter Childers
#t1985
#c
#index13497


#*Special Issue: Database Management
#@Ann P. Kearns
#t1987
#cJournal of Management Information Systems
#index184248


#*Folding polynomials and their dynamics
#@William Douglas Withers
#t1988
#cAmerican Mathematical Monthly
#index474189


#*Iterative regularization of a method for solving optimal control problem
#@S. V. Solodova
#t1989
#cUSSR Computational Mathematics and Mathematical Physics
#index482128


#*The Monte Carlo processor: designing and implementing a language for Monte Carlo work
#@David G. Grier
#t1986
#cProceedings of the Seventeenth Symposium on the interface of computer sciences and statistics on Computer science and statistics
#index152207


#*Concepts of Enterprise Systems Architecture/370
#@K. E. Plambeck
#t1989
#cIBM Systems Journal
#index476780
#%164527
#%331907
#%478605
#%625954


#*A new method in order of determine the most significant members within a large sample, in problems of surface approximations
#@Mira Bozzini,Flavia de Tisi,Licia Lenarduzzi
#t1986
#cSIAM Journal on Scientific and Statistical Computing
#index180003


#*On considering microcomputer software for purchase
#@Felix Chu
#t1986
#cComputers in Libraries
#index179109


#*Modularity in tangential k-blocks
#@Geoff Whittle
#t1987
#cJournal of Combinatorial Theory Series B
#index148036


#*Updating derived relations
#@Neil Coburn
#t1988
#c
#index457387


#*Success lies in attention to detail
#@John Voelcker
#t1987
#cIEEE Spectrum
#index170426


#*Decision support and knowledge-based systems
#@Robert W. Blanning,David R. King
#t1989
#cJournal of Management Information Systems
#index477435


#*Interactive retrieval office documents
#@W. B. Croft,R. Krovetz
#t1988
#cProceedings of the ACM SIGOIS and IEEECS TC-OA 1988 conference on Office information systems
#index184789
#%143335
#%144692
#%150176
#%184716
#!Office information systems are being used to describe and store documents with complex structure and multimedia content. Users of these systems can potentially make very complex specifications of the structure, layout and content of the documents they wish to retrieve. Although these complex queries could be more effective in identifying relevant documents, it is important that a well-defined model of retrieval is used, both as the basis for the retrieval strategies and the user interface. In this paper, we present a system (OFFICER) for the retrieval of office documents that is based on a model of plausible inference. The OFFICER query interface allows the specification of uncertain queries and combines uncertainties in the matching of queries and documents to produce an overall ranking for the documents.


#*Differential Hebbian learning
#@B Kosco
#t1987
#cAIP Conference Proceedings 151 on Neural Networks for Computing
#index179721


#*Formal semantics for database schemas
#@D. A. Simovici,D. C. Stefanescu
#t1989
#cInformation Systems
#index487744


#*A study of the worst-case of shell-sort
#@J M Incerpi
#t1986
#c
#index172923


#*On visible surface generation by a priori tree structures
#@H. Futchs,Z. M. Kedem,B. F. Naylor
#t1988
#cTutorial: computer graphics; image synthesis
#index465111


#*Learning from solution paths: an approach to the credit assignment problem
#@Derek Sleeman,Pat Langley,Tom M. Mitchell
#t1989
#cReadings from the AI magazine
#index528857


#*Smartcom III: a powerful, flexible program...but not designed for online searching
#@Alan King
#t1988
#cDatabase
#index185157


#*A computer system for simulating human facial expression
#@Bruce W. Weide
#t1989
#c
#index204675


#*A Real Time Sectional Image Measuring System Using Time Sequentially Coded Grating Method
#@M. Matsuki,T. Ueda
#t1989
#cIEEE Transactions on Pattern Analysis and Machine Intelligence
#index462892
#!A real-time sectional image measuring system is developed using the time-sequentially-coded grating method, and its application to automatic 3D image data measuring systems is studied. A PLZT electron shutter array is used to project time-sequentially-coded grating patterns on the object. The sectional image is calculated from deformed grating images which are picked up by a TV camera. This system takes about 530 ms to project the 100-slit time-sequentially-coded grating patterns and about 30 ms to calculate one sectional image.


#*The Integration of Logical and Algebraic Types
#@John W. Gray
#t1988
#cWorkshop on Categorial Methods in Computer Science: With Aspects from Topology
#index265706


#*On the relation of the probability theory and the fuzzy sets theorem
#@B. Y. Kovalerčuk,D. I. Shapiro
#t1988
#cComputers and Artificial Intelligence
#index480986


#*Pade&acute; approximants to matrix stieltjes series: convergence and relates properties
#@Sankar Basu
#t1989
#cSIAM Journal on Matrix Analysis and Applications
#index477321


#*Automated circuit diagnosis using first order logic tools
#@Barbara Smith,Ralph Wilkerson,Gerald E. Peterson
#t1988
#cProceedings of the 1st international conference on Industrial and engineering applications of artificial intelligence and expert systems - Volume 1
#index467418
#%153962
#%154617
#%177827
#%181308
#%183574
#!While numerous diagnostic expert systems have been successfully developed in recent years, they are almost uniformly based on heuristic reasoning techniques (i.e., shallow knowledge) in the form of rules. This paper reports on an automated circuit diagnostic tool based on Reiter's theory of diagnosis. In particular, this is a theory of diagnosis based on deep knowledge (i.e., knowledge based on certain design information) and using first order logic as the representation language. The inference mechanism which is incorporated as part of the diagnostic tool is a refutation based theorem prover using rewriting systems for Boolean algebra developed by Hsiang. Consequently, the diagnostic reasoning tool is broadly based on Reiter's model, but incorporates complete sets of reductions for Boolean algebra to reason over equational descriptions of the circuits to be analyzed. The refutational theorem prover uses an associative commutative identity unification algorithm described by Hsiang, but requires additional focusing techniques in order to be appropriate for diagnosing circuits. A prototype version of the mainline diagnostic program has been developed, and has been successfully demonstrated on several small but nontrivial combinational circuit examples.


#*An abstract machine based execution model for computer architecture design and efficient implementation of logic programs in parallel
#@Manuel Victor Hermenegildo
#t1986
#c
#index189611


#*A numerical approach to the inverse Toeplitz Eigenproblem
#@Dirk P. Laurie
#t1988
#cSIAM Journal on Scientific and Statistical Computing
#index485878


#*A nonlinear Runge-Kutta formula for initial value problems
#@D. J. Evans,B. B. Sanugi
#t1987
#cACM SIGNUM Newsletter
#index161651
#!New non-linear Runge-Kutta methods for solving initial value problems are shown to be obtained by the strategic use of geometric mean (GM) rather than arithmetic mean averaging of the functional values in the standard integration formula.


#*Data-driven software design using inversion
#@R. Storer
#t1988
#cInformation and Software Technology
#index177105


#*Altering without change
#@J. A. Zimmer
#t1989
#cJournal of Software Maintenance: Research and Practice
#index483798


#*The inverse problem for linear Boolean nets
#@E. R. Caianiello,M. Marinaro,R. Tagliaferri
#t1989
#cNeural Computers
#index463775


#*Adaptive tensor product grids for singular problems
#@J. R. Rice
#t1987
#cAlgorithms for approximation
#index175760


#*Some open problem
#@H Segur
#t1986
#cPhysica D
#index156258


#*Value added reselling and public domain data
#@Lizzie Davenport,Blaise Cronin
#t1989
#cPost-professionalism: transforming the information heartland
#index480867


#*A simple expert system
#@B. I. Blum
#t1988
#cACM SIGBIO Newsletter
#index161180
#!Expert systems are one field of artificial intelligence (AI) that has received considerable recent attention. These systems generally are written in Lisp or Prolog -- languages that are interpretive, have flexible data accessing mechanisms, and use powerful string manipulation tools. This raises two questions: what are expert systems, and can they be implemented using MUMPS? Some answers are presented in this paper.


#*Two standards means problems: a case study on formal protocol descriptions
#@A. Fantechi,S. Gnesi,C. Laneve
#t1989
#cComputer Standards Interfaces
#index474635


#*Multi-speaker experiments with the morphic generator grammatical inference methodology
#@E. Vidal,E. Segarra,P. García,I. Galiano
#t1988
#cProceedings of the NATO Advanced Study Institute on Recent advances in speech understanding and dialog systems
#index482692


#*Invited talk: the memory-refresh problem
#@Nicholas Pippenger
#t1988
#cProceedings of the fifth MIT conference on Advanced research in VLSI
#index464815


#*A Study on Imai-Hirakawa Trellis-Coded Modulation Schemes
#@Kazuhiko Yamaguchi,Hideki Imai
#t1988
#cProceedings of the 6th International Conference, on Applied Algebra, Algebraic Algorithms and Error-Correcting Codes
#index372993


#*The periodic balanced sorting network
#@Martin Dowd,Yehoshua Perl,Larry Rudolph,Michael Saks
#t1989
#cJournal of the ACM (JACM)
#index471590
#%178700
#%314358
#%318870
#%463337
#%546291
#%547656
#%550517
#!A periodic sorting network consists of a sequence of identical blocks. In this paper, the periodic balanced sorting network, which consists of log n blocks, is introduced. Each block, called a balanced merging block, merges elements on the even input lines with those on the odd input lines. The periodic balanced sorting network sorts n items in O([log n]2) time using (n/2)(log n)2 comparators. Although these bounds are comparable to many existing sorting networks, the periodic structure enables a hardware implementation consisting of only one block with the output of the block recycled back as input until the output is sorted. An implementation of our network on the shuffle exchange interconnection model in which the direction of the comparators are all identical and fixed is also presented.


#*An Ada-LISP interface generator
#@Souripriya Das,Stephen R. Schach
#t1987
#cACM SIGAda Ada Letters
#index180127
#!It has been recognized that neither of the two major programming approaches, procedural and non-procedural, can be optimal for every application. The availability of both paradigms in the same environment enables the programmer to choose the appropriate paradigm for each subtask, thereby leading to more efficient programs. In this paper we describe a system that has been developed for interfacing Franz LISP, a language particularly suitable for the non-procedural style of programming, and Ada, a powerful procedural language. This system enables the user to call Ada subprograms from within the Franz LISP environment. The system incorporates a generator which takes as input certain information about the Ada subprogram and then dynamically generates an Ada main unit which is utilized for interfacing. The system allows the user to take advantage of the power of the Ada programming language from within the Franz LISP environment.


#*Semantical constructions for categories of behavioural specifications
#@F. Orejas,M. P. Nivela,H. Ehrig
#t1989
#cCategorical methods in computer science with aspects from topology
#index477409


#*The problem of determining the size of a complete set of reductions
#@L. Wos
#t1989
#cJournal of Automated Reasoning
#index480999


#*Why computers are never likely to be smarter than people
#@P. J. Marcer
#t1989
#cAI Society
#index486541


#*OCR:the Kurzweil data entry machine
#@S Hockey
#t1986
#cLiterary Linguistic Computing
#index177985


#*Every polynomial-time 1-degree collapses iff P=PSPACE
#@S. A. Fenner,S. A. Kurtz
#t1989
#cProceedings of the 30th Annual Symposium on Foundations of Computer Science
#index47943
#!A set A is m-reducible (or Karp-reducible) to B if and only if there is a polynomial-time computable function f such that for all x, x in A if and only if f(x) in B. Two sets are 1-equivalent if each is m-reducible to the other by one-one reductions; p-invertible equivalent iff each is m-reducible to the other by one-one, polynomial-time invertible reductions; and p-isomorphic iff there is an m-reduction from one set to the other that is one-one, onto, and polynomial-time invertible. It is proved that the following statements are equivalent: (1) P=PSPACE. (2) Every two 1-equivalent sets are p-isomorphic. (3) Every two p-invertible equivalent sets are p-isomorphic.


#*A Note on Nondeterminism in Small, Fast Parallel Computers
#@I. Parberry
#t1989
#cIEEE Transactions on Computers
#index450498
#%163074
#%169204
#%180812
#%544896
#!Nondeterministic analogues of the well-known language classes NC and SC called NNC and NSC, respectively, are investigated. NC is the class of languages that can be accepted by small, fast parallel computers; SC is the class of languages that can be recognized by a deterministic Turing machine in polynomial time and polylog tape-head reversals. Adding nondeterminism to SC leaves it in the domain of parallel computation since NSC contained in POLYLOGSPACE. That is, NSC is a subset of the class of languages computable by fast parallel computers. Adding nondeterminism to NC appears to make it much more powerful since NNC=NP. It is clear that NSC contained in NNC, and probable that NSC contained in/implied by NNC. Further evidence for this conjecture is provided by showing that NSC is precisely the class of languages recognizable in simultaneous polynomial time and polylog reversals by a nondeterministic Turing machine with a read-only input tape and a single read-write work tape; it is known that NNC is similar, but is recognizable by a Turing machine with two read-write tapes.


#*The Sprite Network Operating System
#@John K. Ousterhout,Andrew R. Cherenson,Frederick Douglis,Michael N. Nelson,Brent B. Welch
#t1988
#cComputer
#index184898
#%151906
#%162511
#%163157
#%167164
#%167911
#%328436
#!A description is given of Sprite, an experimental network operating system under development at the University of California at Berkeley. It is part of a larger research project, SPUR, for the design and construction of a high-performance multiprocessor workstation with special hardware support of Lisp applications. Sprite implements a set of kernel calls that provide sharing, flexibility, and high performance to networked workstations. The discussion covers: the application interface: the basic kernel structure; management of the file name space and file data, virtual memory; and process migration.


#*A note on `implementable decimal arithmetic algorithms'
#@G. Chroust
#t1988
#cMicroprocessing and Microprogramming
#index474069


#*The Turing programming language: design and definition
#@Richard C. Holt,Philip A. Matthews,J. Alan Rosselet,James R. Cordy
#t1987
#c
#index144793


#*Support system for OCCAM objects on transputers
#@Ian Thomas
#t1989
#cMicroprocessors Microsystems
#index480327


#*Performance evaluation of threshold-based ATM cell scheduling policies under Markov modulated Poisson traffic using stochastic Petri nets
#@Boudewijn R. Haverkort,Hessel P. Idzenga,Byung G. Kim
#t1994
#cProceedings of the Second IFIP Workshop on Performance Modelling and Evaluation of ATM Networks: ATM Networks, Performance Modelling and Analysis, Volume 1
#index557924


#*Expert systems authoring tools for the microcomputer: two-examples
#@Joseph M. Ferrara,James D. Parry,Margaret M. Lubke
#t1990
#cExpert systems and intelligent computer-aided instruction
#index518418


#*Reengineering als Lehrgegenstand: Zweck und gestaltung
#@Lothar Schmitz
#t1994
#cSoftware Engineering im Unterricht der Hochschulen SEUH '94, Workshop des German Chapter of the ACM und der Gesellschaft f&uuml;r Informatik (GI) am
#index370656


#*Mites in der hourse
#@Susan N. Bjørner
#t1991
#cDatabase
#index536294


#*Description and interpretation of population growth data of Berlin
#@K. F. Albrecht
#t1991
#cSystems Analysis Modelling Simulation
#index522944


#*The mechanization of office work
#@Vincent E. Giuliano
#t1991
#cComputerization and controversy: value conflicts and social choices
#index520720


#*The &ldquo;SUPER&rdquo; project
#@M. Andersson,A-M. Auddino,Y. Dupont,E. Fontana,M. Gentile,S. Spaccapietra
#t1993
#cACM SIGMOD Record
#index209428
#%438833


#*Structure of four family of layered copper-oxide high Tc superconductors
#@Peter Norman
#t1990
#cAustralian Journal of Physics
#index481028


#*Correctness verification of concurrent controller specifications
#@M. T. L. Schaefer,W. U. Klein
#t1992
#cProceedings of the conference on European design automation
#index224018
#%206111


#*Depth-from-Focus zur Bestimmung der Konzentration und Gr&ouml;szlig: e von Gasblasen
#@Peter Geißler,Bernd Jähne
#t1993
#cMustererkennung 1993, Mustererkennung im Dienste der Gesundheit, 15. DAGM-Symposium
#index562574


#*Artificial intelligence and software engineering
#@Charles Rich,Richard C. Waters
#t1990
#cAI in the 1980s and beyond
#index482231


#*Analysis of parallel discrete systems by discrete stochastic and fuzzy Petri nets
#@Vladimír Olej,Ján Chmúrny,Igor Morkiš
#t1991
#cComputers and Artificial Intelligence
#index530872


#*Occurrence-based word categorization
#@Peter Allan Bensch
#t1993
#c
#index227281


#*Moving mountains: transitioning from a paper to a computer based administrative system
#@Sandra E. Jacques
#t1991
#cProceedings of the 19th annual ACM SIGUCCS conference on User services
#index517898


#*A technology integration model for middle schools
#@Judith Zorfass,Arlene R. Remz,Shira E. Persky
#t1991
#cT.H.E. Journal (Technological Horizons in Education)
#index528354


#*A multifactor problem of non-linear programming with a decreasing input function
#@A. A. Egorushkin,N. B. Zyabrev,A. N. Tikhonov
#t1990
#cUSSR Computational Mathematics and Mathematical Physics
#index460479


#*Iterative design of an interface for easy 3-D direct manipulation
#@Stephanie Houde
#t1992
#cProceedings of the SIGCHI conference on Human factors in computing systems
#index535530
#%458921
#%479695
#!Although computer tools for 3-D design applications are now widely available for use on personal computers, they are unnecessarily difficult to use. Conventions for establishing and manipulating views of 3-D objects require engineering-oriented dialogues that are foreign to most users. This paper describes the iterative design and testing of a new mechanism for moving 3-D objects with a mouse-controlled cursor in a space planning application prototype. Emphasis was placed on developing a design which would make 3-D interaction more intuitive by preserving users' experiences with moving objects in the real, physical world. Results of an informal user test of the current interface prototype are presented and implications for the development of a more general direct manipulation mechanism are discussed.


#*SQL--the Standard Handbook; Based on the New SQL Standard (ISO 9075: 1992 (E))
#@S. J. Cannan,G. A. M. Otten
#t1993
#c
#index241278


#*An optimization technique for protocol conformance testing using multiple UIO sequences
#@W.-H. Chen,C.-S. Lu,E. R. Brozovsky,J.-T. Wang
#t1990
#cInformation Processing Letters
#index485460


#*The rank of a fuzzy matrix and its evaluation
#@S. Kaguei,A. Ohsato
#t1990
#cFuzzy Sets and Systems
#index519557


#*The structure of a knowledge base for cataloging rules
#@Ling Hwey Jeng
#t1991
#cInformation Processing and Management: an International Journal
#index532321


#*Sonic flux formulae
#@P. L. Roe
#t1992
#cSIAM Journal on Scientific and Statistical Computing
#index514795


#*Multisecret Threshold Schemes
#@Wen-Ai Jackson,Keith M. Martin,Christine M. O'Keefe
#t1993
#cProceedings of the 13th Annual International Cryptology Conference on Advances in Cryptology
#index265212


#*Translating TROLL light concepts to Maude
#@G. Denker,M. Gogolla
#t1994
#cSelected papers from 9th workshop on Specification of abstract data types : recent trends in data type specification: recent trends in data type specification
#index603938


#*Integrierter Einsatz von Parallelrechnern mit gemeinsamem und verteiltem Speicher - Alliant FX/2800, iPSC/2, iPSC/860*
#@Thomas Bemmerl,Bernhard Ries
#t1991
#cAnwendungen, Architekturen, Trends, Seminar
#index569205


#*Standardisation of interworking between frame relaying and broadband-ISDN
#@Reijo Juvonen
#t1993
#cInterworking in broadband networks: heterogeneity and global networking
#index216122


#*An evaluation of functional unit lengths for single-chip processors
#@Matthew K. Farrens,Andrew R. Pleszkun
#t1990
#cProceedings of the 23rd annual workshop and symposium on Microprogramming and microarchitecture
#index90129
#%204587
#%487034
#%551005
#%591593
#%319066
#%480648
#%580721
#!When designing a pipelined single-chip processor (SCP) with pipelined functional units of varying length, the processor issue logic must deal with scheduling of the result bus. In order to prevent serious performance degradation due to result bus conflicts, some pipeline scheduling techniques developed in the 1970's may need to be incorporated into the issue logic. Since this is a non-trivial complication of the issue logic, a set of simulations were performed in order to evaluate the effectiveness of the combination of multiple length functional units and scheduling techniques. Analysis of the simulation results indicates that providing relatively short multiple length functional units is not worthwhile. Multiple length functional unit configurations employing result bus scheduling do perform slightly better than uniform length configurations, but the difference is often less than 1%. Thus, the SCP designer should not waste valuable time improving the performance of each functional unit, but rather should produce a good design for the most complicated unit and design all other units to match it.


#*Algorithms for the polar decomposition
#@Walter Gander
#t1990
#cSIAM Journal on Scientific and Statistical Computing
#index474727


#*Passive dynamic walking
#@Tad McGeer
#t1990
#cInternational Journal of Robotics Research
#index473089


#*Minimum vertex weighted deficiency of (g,f)-factors: a greedy algorithm
#@R. P. Anstee
#t1993
#cDiscrete Applied Mathematics
#index227092


#*Transformational Design in a Theorem Prover
#@Holger Busch
#t1992
#cProceedings of the IFIP TC10/WG 10.2 International Conference on Theorem Provers in Circuit Design: Theory, Practice and Experience
#index359881


#*Book production and publishing in Nigeria
#@J. I. Iwe
#t1990
#cASLIB Proceedings
#index487188


#*Tailoring search strategy for literature on economic justification of computer integrated manufacturing
#@Janardan Kulkarni,Hamid R. Parsaei
#t1990
#cComputers and Industrial Engineering
#index534390


#*Ein Prototyp f&uuml;r ein integriertes Fuzzy-Neuro System
#@Werner Hauptmann,Kai Heesche
#t1994
#cProceedings of Fuzzy Logik, Theorie und Praxis, 4. Dortmunder Fuzzy-Tage
#index357130


#*Undocumented error messages
#@Tim Colling
#t1992
#cData Based Advisor
#index513511


#*Keeping in touch electronically
#@Thierry Pun
#t1991
#c(Fall 1991)
#index535009


#*An automated vision-guided teacup attachment system for dairy cows
#@Bin Xu
#t1992
#c
#index224751


#*C++ programming with MacApp
#@David A. Wilson,Larry S. Rosenstein,Don Shafer
#t1990
#cAddison-Wesley Macintosh Inside Out Series
#index511430


#*The emergent scientific epistemology and international relations
#@Henry Longley Hamman
#t1993
#c
#index206152


#*Real-time POSIX
#@Richard Marlon Stein
#t1992
#cBYTE
#index227711


#*Ein Coprocessor Communication System als Basis f&uuml;r modulare Workstations
#@T. H. Jensen,Christian Müller-Schloer
#t1990
#cArchitektur von Rechensystemen, Tagungsband, 11. ITG/GI-Fachtagung
#index560485


#*In pursuit of a single login
#@Robert G. Moskowitz
#t1994
#cNetwork Computing
#index229373


#*The Design and Implementation of Concurrent Input/Output Facilities in ACT++ 2.0
#@Dennis G. Kafura,Manibrata Mukherji
#t1992
#c
#index185973
#!ACT++ 2.0 is the most recent version of a class library for concurrent programming in C++. Programs in ACT++ consist of a collection of active objects called actors. Actors execute concurrently and cooperate by sending request and reply messages. An agent, termed the behavior of an actor, is responsible for processing a single request message and for specifying a replacement behavior which processes the next available request message. One of the salient features of ACT++ is its realization of I/O as an actor operation. A special type of actor, called an interface actor, provides a high level interface for a file. Interface actors are sent request messages whenever I/O is necessary and can also transparently perform asynchronous I/O. ACT++ has been implemented on the Sequent Symmetry multiprocessor using the PRESTO threads package.


#*Detection of the glottal closure by jumps in the statistical properties of the speech signal
#@E. Moulines,R. Di Francesco
#t1990
#cSpeech Communication
#index535336


#*Preconditioned iterative methods for indefinite symmetric Toeplitz systems
#@Paul Concus,Paul E. Saylor
#t1990
#cIterative methods for large linear systems
#index452208


#*A machine level based-similarity coefficient for forming manufacturing cells
#@Gürsel A. Süer,Marcos Ortega
#t1994
#cSelected papers from the 16th annual conference on Computers and industrial engineering
#index593865


#*Automated Software Quality Measurement: Computer-Assisted Information Resource Management of Applications in IBM Mainframe Environments
#@Jonesk,K. Jones
#t1993
#c
#index238599


#*A microcomputer based decision support tool for assigning dock doors in freight yards
#@Louis Y. Tsui,Chia-Hao Chang
#t1990
#cComputers and Industrial Engineering
#index544028


#*Automatic Parallelization Techniques for the EM-4
#@Lubomir Bic,Mayez Al-Mouhamed
#t1993
#cProceedings of the 1993 International Conference on Parallel Processing - Volume 02
#index422957
#!This paper presents a Data-Distributed Execution (DDE) approach that exploits iteration-level parallelism in loops operating over arrays.


#*Transform representation of acoustic subword spectra with application to automatic speech recognition
#@V. R. Algazi
#t1993
#c
#index191367


#*Computer program construction
#@Ali Mili,Jules Desharnais,Fatma Mili,Marc Frappier
#t1994
#c
#index590172


#*Specification and design methodologies for semihard real-time control systems
#@Alice H. Muntz
#t1990
#c
#index520412


#*Learning GNU Emacs
#@Debra Cameron Bill Rosenblatt
#t1991
#c
#index525315


#*An efficient strategy for non-Horn deductive databases
#@Robert Demolombe
#t1991
#cTheoretical Computer Science
#index521723


#*Generalizations of Opt P to the polynomial hierarchy
#@Mark W. Krentel
#t1992
#cTheoretical Computer Science
#index517896


#*Virus protection software: summary of features and performance tests
#@
#t1990
#cRogue programs: viruses, worms and Trojan horses
#index469790


#*Pitch accent in context: predicting intonational prominence from text
#@Julia Hirschberg
#t1993
#cArtificial Intelligence
#index224738


#*Special issue: Network management
#@Helen Hodge
#t1990
#cComputer Communications
#index521210


#*Modeling as framework for knowledge acquisition methodologies and tools
#@Brian R. Gaines,Mildred L. G. Shaw,J. Brian Woodward
#t1993
#cKnowledge acquisition as modeling
#index208020


#*Decision procedures for elementary sublanguages of set theory. XV. multilevel syllogistic extended by the predicate finite and the operators Singleton and Pred
#@D. Cantone,V. Cutello
#t1990
#cJournal of Automated Reasoning
#index458608


#*A polynomial time algorithm for unidimensional unfolding representations
#@Jean-Paul Doignon,Jean-Claude Falmagne
#t1994
#cJournal of Algorithms
#index218150


#*Langwidere: A New Facial Animation System
#@David R. Forsey,Carol L. Wang
#t1994
#c
#index188474
#!This paper presents Langwidere, a facial animation system. Langwidere is the basis for a flexible system capable of imitating a wide range of characteristics and actions, such as speech or expressing emotion. Langwidere integrates a hierarchical spline modeling system with simulated muscles based on local area surface deformation. The multi-level shape representation allows control over the extent of deformations, at the same time reducing the number of control vertices needed to define the surface. The head model is constructed from a single closed surface allowing the modeling of internal structures such as tongue and teeth, rather than just a mask. Simulated muscles are attached to various levels of the surface with more rudimentary levels substituting for bone such as the skull and jaw. The combination of a hierarchical model and simulated muscles provides precise, flexible surface control and supports easy generation of new characters with a minimum of recoding.


#*Using CAD/CAM in the design of a robotic micromanipulator
#@Chang-Soo Han,Alfred E. Traver,Delbert Tesar
#t1990
#cComputer-Aided Engineering Journal
#index479766


#*Graphical Query Specification with Participation Constraints
#@Bogdan D. Czejdo,Ralph P. Tucci,David W. Embley,Stephen W. Liddle
#t1993
#cProceedings of the Fifth International Conference on Computing and Information
#index371824


#*Multiplicative complexity of bilinear algorithms for cyclic convolution over finite fields
#@Salvatore D. Morgera
#t1990
#cMultidimensional Systems and Signal Processing
#index482381


#*Playing detective with full text searching software
#@Darrell R. Raymond,Heather J. Fawcett
#t1990
#cACM SIGDOC Asterisk Journal of Computer Documentation
#index464001
#!Searching large text databases often resembles detective work. We explored this notion with an experiment in which subjects used powerful full text searching software to solve problems about the Arthur Conan Doyle story The Hound of the Baskervilles. The experiment was conducted in two parts: in the first part subjects attempted to teach themselves about the software using only the documentation; in the second part, subjects used the software to answer questions such as What brand of cigarette does Watson smoke? The experiment provided a great deal of feedback about the usability of the software and the documentation. Among the results that have wider implications are the need for better display of context, and a need for careful documentation of the characteristics of full text searching.


#*The computer enhancement of speech signals
#@Homam Sabih Dabis
#t1991
#c
#index227789


#*Fach&uuml;bergreifende Integration von Umweltdaten
#@Thomas Bandholtz
#t1994
#cIntegration von Umweltdaten, 2. Workshop 1994
#index273763


#*Partitions of natural numbers by arithmetic progressions
#@K. R. S. Sastry
#t1993
#cMathematics and Computer Education
#index217163


#*The problems of designing a conversation scheme for concurrent object oriented languages
#@A. Romanovsky
#t1994
#cMicroprocessing and Microprogramming
#index596029


#*Progress on HPCC and NII
#@Marianne Winslett
#t1994
#cACM SIGMOD Record
#index217725
#!In this issue we briefly touch on the continuing turmoil over NSF, ARPA, and HPCC, and the brighter news regarding the US National Information Infrastructure plan. We then describe funding opportunities from NSF, ARPA, the National Security Agency, the National Center for Automated Information Research, the Air Force, and NASA.


#*Qualitative-numeric simulation with Q3
#@Daniel Berleant,Benjamin Kuipers
#t1993
#cRecent advances in qualitative physics
#index230254


#*Quantifying the unimportance of prior probabilities in a computer vision problem
#@David B. Sher,Jonathan J. Hull
#t1990
#cPattern Recognition Letters
#index454458


#*The Logic Programming Tutor
#@Jocelyn Paine
#t1992
#c
#index619412


#*A simple proof of a theorem of Statman
#@Harry G. Mairson
#t1992
#cTheoretical Computer Science
#index537531


#*On the mechanical theory for biological pattern formation
#@D. E. Bentil,J. D. Murray
#t1993
#cPhysica D
#index210891


#*Computers and the teaching of history and archaeology in higher education
#@P. Perkins,D. A. Spaeth,R. H. Trainor
#t1992
#cComputers Education
#index220767


#*On Claw Free Families
#@Wakaha Ogata,Kaoru Kurosawa
#t1991
#cProceedings of the International Conference on the Theory and Applications of Cryptology: Advances in Cryptology
#index268036


#*Asynchronous Transfer Mode Networks: Performance Issues
#@Raif O. Onvural
#t1993
#c
#index607473
#!:This updated version of the bestselling first edition is a one-source reference to ATM architecture, it provides a comprehensive review of current and emerging ATM standards, including P-NNI. Unlike traditional standards, this book is easy to follow and serves as a readily accessible reference for system designers, researchers, marketing staff and graduate students of high-speed networking.


#*Representing Geometric Objects Using Constraint Description Graphs
#@Borut Zalik,Nikola Guid,Aleksander Vesel
#t1992
#cProceedings of the 5th international conference on Industrial and engineering applications of artificial intelligence and expert systems
#index277042


#*Computer simulation of oscillatory behavior in cerebral cortical networks
#@Matthew A. Wilson,James M. Bower
#t1990
#cAdvances in neural information processing systems 2
#index530951


#*Computer analysis of classroom questions
#@John H. Degolyer
#t1992
#c
#index225303


#*A study of measures for research in hypertext navigation
#@David G. Hendry,T. T. Carey,S. T. TeWinkel
#t1990
#cProceedings of the IFIP TC13 Third Interational Conference on Human-Computer Interaction
#index263259


#*Special issue: adaptive optical signal processing and control
#@Mo Jamshidi,Michael C. Roggemann,Byron M. Welsh
#t1992
#cComputers and Electrical Engineering
#index214676


#*Caching and Lemmaizing in Model Elimination Theorem Provers
#@Owen L. Astrachan,Mark E. Stickel
#t1992
#cProceedings of the 11th International Conference on Automated Deduction: Automated Deduction
#index562597


#*Inferential security in individual computing environments
#@Cleopas O. Angaye,Steven C. Hansen
#t1994
#cACM SIGICE Bulletin
#index210216
#%478156
#%314158
#%332957
#%461336
#!Inference is a powerful act of the mind that combines known data using human judgement in such a way as to extend knowledge, i.e., creation of new information. People can use the information stored in a computer or the behavior of the computer to gain knowledge for which they have no authorization. This is considered a security or confidentiality breach and is the subject of the area of computer security known as inferential security. This paper provides an overview of inferential security breach and some of the known closed form methods for perpetrating this type of security breach. Some of the concerns for the user of individual computing environments (ICE's) are addressed.


#*The Total Delay Fault Model and Statistical Delay Fault Coverage
#@Eun Sei Park,M. Ray Mercer,Thomas W. Williams
#t1992
#cIEEE Transactions on Computers
#index515262
#%548491
#%532084
#%550584
#%547554
#!Delay testing at the operational system clock rate can detect system timing failures caused by delay faults. However, delay fault coverage in terms of the percentage of the number of tested faults may not be an effective measure of delay testing. A quantitative delay fault coverage model to provide a figure of merit for delay testing is presented. System sensitivity of a path to a delay fault along that path and the effectiveness of a delay test are described in terms of the propagation delay of the path under test and the delay defect size. A new statistical delay fault coverage model is established. A defect level model is also proposed as a function of the yield of a manufacturing process and the new statistical delay fault coverage. A new delay testing strategy driven by the defect level for delay faults is proposed.


#*Computing edge-connectivity in multigraphs and capacitated graphs
#@Hiroshi Nagamochi,Toshihide Ibaraki
#t1992
#cSIAM Journal on Discrete Mathematics
#index526216


#*From under the rubble: computing and the resuscitation of Romania
#@Seymour E. Goodman
#t1991
#cCommunications of the ACM
#index517175
#!How does an entire country return to life? The dictatorship of Nicolae and Elena Ceaucescu turned Romania into a political, social and economic wasteland that was vividly pictured in the world media after the overthrow of the Stalinist couple in December 1989. Their regime left the country in shambles: with an old or mangled physical plant, a currency worthless abroad and nearly worthless at home, a legacy of secret police abuses, terrible health and sanitary conditions, and a highly centralized, warped, and inefficient scientific and industrial infrastructure.


#*Polynomial size &OHgr;-branching programs and their computational power
#@Christoph Meinel
#t1990
#cInformation and Computation
#index480305


#*Center creates interactive discs with desktop video system
#@Elizabeth Greenfield
#t1991
#cT.H.E. Journal (Technological Horizons in Education)
#index542835


#*Nonnegative estimation of variance components in unbalanced mixed models with two variance components
#@Thomas Mathew,Bimal Kumar Sinha,Brajendra C. Sutradhar
#t1992
#cJournal of Multivariate Analysis
#index539392


#*Multisensory scientific data sensualization through virtual reality technology
#@Tetsuro Ogi,Michitaka Hirose
#t1994
#cProceedings of the conference on Virtual reality software and technology
#index600358


#*Bounding the solution of interval linear equations
#@E. R. Hansen
#t1992
#cSIAM Journal on Numerical Analysis
#index534283


#*Growth of low dislocation density InP single crystals by the phosphorus vapor controlled LEC method
#@K. Kohiro,K. Kainosho,O. Oda
#t1991
#cJournal of Electronic Materials
#index520241


#*On embedding of graphs into Euclidean spaces of small dimension
#@J. Reiterman,V. Rödl,E. Šiňajová
#t1992
#cJournal of Combinatorial Theory Series B
#index206587


#*On Ground AC-Completion
#@Claude Marché
#t1991
#cProceedings of the 4th International Conference on Rewriting Techniques and Applications
#index263295


#*Multiple-scale solution of initial-boundary value problems for weakly nonlinear wave equations on the semi-infinite line
#@S. C. Chikwendu,C. V. Easwaran
#t1992
#cSIAM Journal on Applied Mathematics
#index530208


#*An efficient external sort algorithm with no additional space
#@F. C. Lin
#t1992
#cThe Computer Journal
#index535043


#*On the numerical inversion of Laplace transforms: comparison of three new methods on characteristic problems from applications
#@Dean G. Duffy
#t1993
#cACM Transactions on Mathematical Software (TOMS)
#index212020
#%161220
#%178565
#%598692
#%458883
#%471018
#!Three frequently used methods for numerically inverting Laplace transforms are tested on complicated transforms taken from the literature. The first method is a straightforward application of the trapezoidal rule to Bromwich's integral. The second method, developed by Weeks [22], integrates Bromwich's integral by using Laguerre polynomials. The third method, devised by Talbot [18], deforms Bromwich's contour so that the integrand of Bromwich's integral is small at the beginning and end of the contour. These methods are also applied to joint Laplace-Fourier transform problems. All three methods give satisfactory results; Talbot's, however, has an accurate method for choosing required parameters.


#*The solvent selection expert system for azeotropic and extractive distillation
#@Ronald W. Larsen
#t1994
#c
#index187261


#*Optimal Parametric Search on Graphs of Bounded Tree-Width
#@David Fernández-Baca,Giora Slutzki
#t1994
#cProceedings of the 4th Scandinavian Workshop on Algorithm Theory
#index382838


#*Reality versus imagination
#@Paul Brown
#t1992
#cACM SIGGRAPH 92 Visual Proceedings
#index85572


#*Student participation, interaction, and regulation in a computer-mediated communication environment
#@Lorena Ferguson Ruberg
#t1994
#c
#index201362


#*The MacIntosh Bible/Software Disks
#@David Mark
#t1992
#c
#index10464


#*A Formal Specification of an Oscilloscope
#@Norman Delisle,David Garlan
#t1990
#cIEEE Software
#index442539
#%144779
#!This case study presents the development of an abstract oscilloscope specification, using Z notation. A description is given of the problem and its context. An abstract model of an oscilloscope that clarifies its user-accessible functions is described. Issues that must be addressed to scale up this specification to deal with more complicated, realistic oscilloscopes are discussed. The use of formal models and formal reasoning in this specification is examined.


#*Integration of knowledge in a multiple classifier system
#@Yi Lu
#t1994
#cProceedings of the 7th international conference on Industrial and engineering applications of artificial intelligence and expert systems
#index596508


#*Zum Headbegriff in der Morphologie
#@Reinhild Barkey,Wolf Paprotté
#t1990
#cSprache und Computer - Lexikon und Lixikographie, Vortr&auml;ge im Rahmen der Jahrestagung 1990 der Gesellschaft f&uuml;r Linguistische Datenverabeitung (GLDV) e.V.
#index368336


#*Finite Automata as Characterizations of Minor Closed Tree Families (Extended Abstract)
#@Arvind Gupta
#t1993
#cProceedings of the 20th International Colloquium on Automata, Languages and Programming
#index375185


#*A genetic algorithm for channel routing in vlsi circuits
#@Jens Lienig,K. Thulasiraman
#t1993
#cEvolutionary Computation
#index352620
#!A new genetic algorithm for channel routing in the physical design process of VLSI circuits is presented. The algorithm is based on a problem-specific representation scheme and problem-specific genetic operators. The genetic encoding and our genetic operators are described in detail. The performance of the algorithm is tested on different benchmarks, and it is shown that the results obtained using the proposed algorithm are either qualitatively similar to or better than the best published results.


#*A simplified finite element model of multilink robots with flexible links
#@Antonio Ficola,Michele La Cava,Pietro Muraca
#t1994
#cMathematics and Computers in Simulation
#index585403


#*Redefining the "Level" of the "Word"
#@Melissa Macpherson
#t1991
#cProceedings of the First SIGLEX Workshop on Lexical Semantics and Knowledge Representation
#index570758


#*Effectiveness of an Interactive communication system in the supervision of student teachers
#@Barbara Clawson,Mildred Johnson
#t1991
#cComputers in the Schools
#index516269


#*ACCESSING REPLICATED DATA IN AN INTERNETWORK
#@Richard Golding,Darrell D. E. Long
#t1990
#c
#index188724
#!When accessing a replicated data object across an internetwork, the time to access different replicas is non-uniform. Further, the probability that a particular replica is inaccessible is much higher in an internetwork than in a local-area network because of partitions and the many intermediate hosts and networks that can fail. We report three replica-accessing algorithms which can be tuned to minimize either the time spent on the access or the number of messages sent. We have obtained performance results for these algorithms by simulation. We find an inverse relationship between the time spent processing an access and the number of messages required to complete the access.


#*Shared Generation of Authenticators and Signatures (Extended Abstract)
#@Yvo Desmedt,Yair Frankel
#t1991
#cProceedings of the 11th Annual International Cryptology Conference on Advances in Cryptology
#index266896


#*User modelling for graphical design in complex dynamic environments: concepts and prototype implementations
#@Gunilla A. Sundström
#t1993
#cInternational Journal of Man-Machine Studies
#index209088


#*Letter to Brian Skyrms
#@Robert Stalnaker
#t1994
#cProbability and conditionals: belief revision and rational decision
#index582708


#*Using discrete event modeling for effective computer animation control
#@Paul A. Fishwick,Hanns-Oskar A. Porr
#t1991
#cProceedings of the 23rd conference on Winter simulation
#index289790
#%145299
#%148760
#%148922
#%161575
#%163946
#%164088
#%173679
#%285396
#%526250
#%551008
#%538349
#%518624
#%534241
#%548238


#*Discussion
#@William T. Tucker
#t1992
#cTechnometrics
#index216872


#*Model reference adaptive control algorithm for inaccessible system parameters and singularities
#@Wajih Kanso
#t1994
#cSystems Analysis Modelling Simulation
#index207976


#*Integration of conjunction and disjunction and its applications in knowledge representations
#@Honghua Dai,Zhuo Peng Feng,Zonghao Hua
#t1993
#cProceedings of the third international conference on Young computer scientists
#index228690


#*Achieving Dependability Throughout the Development Process: A Distributed Software Experiment
#@John P. J. Kelly,Susan C. Murphy
#t1990
#cIEEE Transactions on Software Engineering
#index459897
#%166636
#%173247
#%466334
#!Distributed software engineering techniques and methods for improving the specification and testing phases are considered. To examine these issues, an experiment was performed using the design diversity approach in the specification, design, implementation, and testing of distributed software. In the experiment, three diverse formal specifications were used to produce multiple independent implementations of a distributed communication protocol in Ada. The problems encountered in building complex concurrent processing systems in Ada were also studied. Many pitfalls were discovered in mapping the formal specifications into Ada implementations.


#*Urgent research issues in software process engineering
#@Gernot Starke
#t1993
#cACM SIGSOFT Software Engineering Notes
#index215656
#%163591
#%164937
#%208281
#%357720
#%520020
#%355516
#%355802
#!This paper outlines the major problems and research directions in software process engineering. These problems concern the terminology and language of models; the difference between type and instance; the inherent reflexivity of detailed process models and the dynamic aspects of process models. Furthermore human factors are shown to impose major difficulties on process engineers.


#*Turbo C++ programming
#@Ben Ezzell
#t1990
#c
#index543477


#*Hard Real Problems in Heterogeneous Distributed Systems (Panel)
#@Patricia G. Selinger
#t1993
#cProceedings of the 2nd International Conference on Parallel and Distributed Information Systems
#index381744


#*Applications of the Probabilistic Neural Network
#@Anthony Zaknich,Yianni Attikiouzel
#t1992
#c
#index186829
#!Specht introduced a one pass learning algorithm called the Probabilistic Neural Network (PNN) for classification, mapping and associative memory. This paper describes how the standard PNN and a modified version was used by CIIPS to develop a number of successful applications for industry and agriculture. Brief introductions to the PNN and modified PNN algorithms are given, as well as summaries of some other applications reported in the literature.


#*Parallel natural processing using transition networks
#@John Baker,Stephen B. Seidman
#t1990
#cProceedings of the first conference of the North American Transputer Users Group on Transputer research and applications 1
#index523806


#*Align and Distribute-based Linear Loop Transformations
#@Jordi Torres,Eduard Ayguadé,Jesús Labarta,Mateo Valero
#t1993
#cProceedings of the 6th International Workshop on Languages and Compilers for Parallel Computing
#index369925


#*Some Observations About the Nature of Computer Science
#@Juris Hartmanis
#t1993
#cProceedings of the 13th Conference on Foundations of Software Technology and Theoretical Computer Science
#index255572


#*Numerical solution of eigenvalue problems using spectral techniques
#@Y. Y. Su,B. Khomami
#t1992
#cJournal of Computational Physics
#index527115


#*Microsoft Works 3.0 MAC Version: Tutorial & Applications
#@William Robert Pasewark
#t1994
#c
#index622079


#*Symbolic Bisimulations (Abstract)
#@Matthew Hennessy
#t1993
#cProceedings of the 18th International Symposium on Mathematical Foundations of Computer Science
#index366199


#*Fuzzy lattices
#@Naseem Ajmal,K. V. Thomas
#t1994
#cInformation Sciences&mdash;Intelligent Systems: An International Journal
#index211532


#*Performance analysis of a multiclass priority-based slotted-ring LAN
#@Sarit Mukherjee,Satish K. Tripathi,Dipak Ghosal
#t1991
#c
#index525940


#*Information sharing
#@David Makowsky
#t1991
#cComputers under attack: intruders, worms, and viruses
#index523771


#*A room with a view: give users access to their data
#@Dave Menninger
#t1993
#cData Based Advisor
#index208673


#*Developing Windows 3.1 Applications with Microsoft C - C Plus Plus, 2nd edition
#@Brent E. Rector
#t1992
#c
#index620455


#*A method for the associative storage of analog vectors
#@Amir Atiya,Yaser Abu-Mostafa
#t1990
#cAdvances in neural information processing systems 2
#index528845


#*Training prospective elementary mathematics teachers using interactive multimedia
#@Gary G. Bitter
#t1994
#cComputers in the Schools
#index591689


#*Adoption of supplemental work-at-home: a comparative analysis
#@Linda Elizabeth Duxbury,D. Roland Thomas,Christopher Alan Higgins
#t1991
#cProceedings of the twelfth international conference on Information systems
#index212157


#*A scalable systolic multiprocessor system for analysis of biological sequences
#@Raj K. Singh,Stephen G. Tell,C. Thomas White,Doug Hoffman,Vernon L. Chi,Bruce W. Erickson
#t1993
#cProceedings of the 1993 symposium on Research on integrated systems
#index211084


#*Quattro Pro 3, 1st edition
#@Mary V. Campbell,David R. Campbell
#t1992
#c
#index245046


#*Inductive data types for predicate transformers
#@Oege de Moor
#t1992
#cInformation Processing Letters
#index539976


#*MicroComputers and Mathematics
#@J. W. Bruce,P. Rippon,P. J. Giblin
#t1994
#c
#index246221
#!:Only fundamental knowledge of mathematics is assumed and programming restricted to basic BASIC in a work containing many exercises and projects for multi-level usage as a textbook for algorithmic mathematics.


#*On a possible interpretation of market dynamics based on the internal model principle
#@Renzo Mosetti
#t1990
#cApplied Mathematics and Computation
#index526263


#*High-Performance Computer System "SIBERIA"
#@Nikolay Mirenkov
#t1990
#cProceedings of the Joint International Conference on Vector and Parallel Processing
#index573385


#*Gee, would HP really do that?
#@Bill Sharp
#t1991
#cMarketing Computers
#index538337


#*Second Order E-Matching as a Tool for Automated Theorem Proving
#@Régis Curien
#t1993
#cProceedings of the 6th Portuguese Conference on Artificial Intelligence: Progress in Artificial Intelligence
#index364859


#*Compact cylindrical chromatic scheduling
#@D. dee Werra,Ph. Solot
#t1991
#cSIAM Journal on Discrete Mathematics
#index529868


#*AI on a chip
#@Jessica Keyes
#t1991
#cAI Expert
#index510518


#*Damage detection for autonomous underwater vehicles
#@S. E. Dunn
#t1993
#c
#index186051


#*An analysis of MIPS and SPARC instruction set utilization on the SPEC benchmarks
#@Robert F. Cmelik,Shing I. Kong,David R. Ditzel,Edmund J. Kelly
#t1991
#cProceedings of the fourth international conference on Architectural support for programming languages and operating systems
#index532020
#%195336
#%319907
#%475349
#%544563
#%547602
#%546764


#*Imagining the world
#@Raymond Ga Côté
#t1993
#cBYTE
#index212771


#*Abstract analysis with aspect
#@Daniel Jackson
#t1993
#cProceedings of the 1993 ACM SIGSOFT international symposium on Software testing and analysis
#index217586
#%87407
#%144536
#%509871
#%484756
#%470900
#%522802
#%480038
#%233515
#!Aspect is a static analysis technique for detecting bugs in code based on three forms of abstraction: declarative specification, data abstraction and partiality (ignoring some behavioural details). Together, they bring efficiency (the checker runs almost as fast as a type checker), modularity (a procedure can be analysed independently of the procedures it calls) and incrementality (allowing the checking of incomplete programs). Aspect can detect errors that are not detectable by other static means, especially errors of omission, which are pervasive but usually hard to detect.


#*Dromions and a boundary value problem for the Davey-Stewartson 1 equation
#@F. A. Grünbaum
#t1990
#cPhysica D
#index480762


#*Improved resolution from subpixel shifted pictures
#@Hanoch Ur,Daniel Gross
#t1992
#cCVGIP: Graphical Models and Image Processing
#index536059


#*Database systems for programmable logic controllers
#@Gultekin Ozsoyoglu,W. Hou,Ade Ola
#t1990
#cProceedings of the fifth international conference on Statistical and scientific database management
#index467845


#*Development of Satellite Communication Networks Based on LOTOS
#@Angel Fernández,Carlos Miguel,Leon Vidaller,Juan Quemada
#t1992
#cProceedings of the IFIP TC6/WG6.1 Twelth International Symposium on Protocol Specification, Testing and Verification XII
#index363538


#*Robust disturbance decoupling problem for parameter dependent families of linear systems
#@G. Conte,A. M. Perdon
#t1993
#cAutomatica (Journal of IFAC)
#index207072


#*Population-Based Incremental Learning: A Method for Integrating Genetic Search Based Function Optimization and Competitive Learning
#@Shummet Baluja
#t1994
#c
#index121720
#!Genetic algorithms (GAs) are biologically motivated adaptive systems which have been used, with varying degrees of success, for function optimization. In this study, an abstraction of the basic genetic algorithm, the Equilibrium Genetic Algorithm (EGA), and the GA in turn, are reconsidered within the framework of competitive learning. This new perspective reveals a number of different possibilities for performance improvements. This paper explores population-based incremental learning (PBIL), a method of combining the mechanisms of a generational genetic algorithm with simple competitive learning. The combination of these two methods reveals a tool which is far simpler than a GA, and which out-performs a GA on large set of optimization problems in terms of both speed and accuracy. This paper presents an empirical analysis of where the proposed technique will outperform genetic algorithms, and describes a class of problems in which a genetic algorithm may be able to perform better. Extensions to this algorithm are discussed and analyzed. PBIL and extensions are compared with a standard GA on twelve problems, including standard numerical optimization functions, traditional GA test suite problems, and NP-Complete problems.


#*Analytic Models of Adaptive Load Sharing Schemes in Distributed Real-Time Systems
#@K. G. Shin,C. J. Hou
#t1993
#cIEEE Transactions on Parallel and Distributed Systems
#index448433
#%149322
#%149540
#%154896
#%162995
#%164107
#%173142
#%175673
#%182231
#%449275
#%547996
#%478672
#%486220
#%451735
#%457625
#!In a distributed real-time system, nonuniform task arrivals may temporarily overload some nodes while leaving some other nodes idle. As a result, some of the tasks on anoverloaded node may miss their deadlines even if the overall system has the capacity tomeet the deadlines of all tasks. A decentralized, dynamic load sharing (LS) scheme hasbeen proposed as a solution to this problem. Analytic queuing models to comparativelyevaluate this LS scheme as well as three other schemes-no LS, LS with random selectionof a receiver node, and LS with perfect information- are developed. The evolution of anode's load state is modeled as a continuous-time semi-Markov process, wherecumulative execution time (CET), rather than the commonly-used queue length (QL), isemployed to describe the workload of a node. The proposed scheme is compared againstother LS schemes. The validity of analytic models is checked with simulations. Bothanalytic and simulation results indicate that by using judicious exchange/use of stateinformation and Bayesian decision mechanism, the proposed scheme makes a significantimprovement over other existing LS schemes in minimizing the probability of dynamicfailure.


#*Three-dimensional object recognition
#@Patrick J. Flynn,Anil K. Jain
#t1994
#cHandbook of pattern recognition and image processing (vol. 2): computer vision
#index216355


#*Causal Probabilistic Networks with Both Discrete and Continuous Variables
#@K. G. Olesen
#t1993
#cIEEE Transactions on Pattern Analysis and Machine Intelligence
#index439545
#%142940
#%154813
#%475410
#%469828
#%455254
#%479299
#!An extension of the expert system shell known as handling uncertainty by general influence networks (HUGIN) to include continuous variables, in the form of linear additive normally distributed variables, is presented. The theoretical foundation of the method was developed by S.L. Lauritzen, whereas this report primarily focus on implementation aspects. The approach has several advantages over purely discrete systems. It enables a more natural model of of the domain in question, knowledge acquisition is eased, and the complexity of belief revision is most often reduced considerably.


#*Prefab programming: apps without coding
#@David Baum
#t1993
#cDatamation
#index217686


#*Modeling using regularity criterion based constructed neural networks
#@Andreas Bastian,Jorge Gasós
#t1994
#cSelected papers from the 16th annual conference on Computers and industrial engineering
#index599443


#*C++ Complete: Reference & Tutorial to the Proposed C++ Standard
#@Anthony Rudd
#t1994
#c
#index609141
#!:This combined tutorial and reference uses a unique approach to learning C++. Introduces object-oriented programming concepts along with C++ language, allowing programmers to utilize C++ as it was intended and not just as an extension of C. Provides a compact, detailed description of the program elements and syntax in understandable form. Each section contains explanatory examples of how to use specific features of C++ and every chapter concludes with a fully-worked example illustrating the use of the features covered. The chapter on Class Design includes a 25-page worked example of a complete yet concise class implementation.


#*Computer graphics techniques: theory and practice
#@David F. Rogers,Rae A. Earnshaw
#t1990
#c
#index538658


#*Algorithm 684: C1- and C2-interplation on triangles with quintic and nonic bivariate polynomials
#@Albrecht Preusser
#t1990
#cACM Transactions on Mathematical Software (TOMS)
#index458359
#%154190
#%161966
#%318523
#%324847
#%457253
#%457877
#%594187


#*Reflections on some recent widespread computer break-ins
#@Brian Reid
#t1991
#cComputers under attack: intruders, worms, and viruses
#index543317


#*Domains of Higher-Dimensional Automata
#@Eric Goubault
#t1993
#cProceedings of the 4th International Conference on Concurrency Theory
#index269655


#*Identification of active contrasts in unreplicated factorial experiments
#@Wei-Yin Loh
#t1992
#cComputational Statistics Data Analysis
#index220492


#*The security impact of networks, telecommunications, and office automation
#@Harold Joseph Highland
#t1992
#cComputers and Security
#index539511


#*The Visual Guide to Visual C++: The Pictorial Encyclopedia to the Windows Programming Language, 1st edition
#@Steve Oualline,Nicolaisen
#t1994
#c
#index250420
#!:A uniquely visual reference for Visual C++--written for new and experienced programmers alike--featuring a complete overview of tools and features in each class of the Visual C++ Foundation Class Library, including names and prototypes, descriptions, parameters, return values, notes, and examples. Disk contains all files necessary to complete the examples in the book.


#*WaveLan: a network with no strings attached
#@Wayne Rash, Jr.
#t1991
#cBYTE
#index534762


#*The evolution of the knowledge/data model
#@Walter D. Potter,Krys J. Kochut,John A. Miller,Veena P. Gandham,Ramakrishna V. Polamraju
#t1993
#cInternational Journal of Expert Systems
#index207605


#*Assisting people with functional impairments
#@Arthur D. Fisk
#t1990
#cHuman Factors
#index524138


#*Real-time fault-tolerant communication in computer networks
#@Qin Zheng
#t1993
#c
#index208478


#*A Comparative Analysis of Regional Correlation, Dynamic Time Warping, and Skeletal Tree Matching for Signature Verification
#@M. Parizeau,R. Plamondon
#t1990
#cIEEE Transactions on Pattern Analysis and Machine Intelligence
#index466244
#!A report is presented on a comparative study of three different signal matching algorithms in the context of signature verification: regional correlation, dynamic time warping, and skeletal tree matching. The algorithm performances are compared in a single experimental protocol over the same database. Algorithm performance is analyzed in terms of verification error rates, execution time, and number and sensitivity of algorithm parameters. Three different script types (normal signatures, handwritten passwords, and initials) and three different signal representation spaces (position, velocity, and acceleration) are considered. Verification errors show that no algorithm consistently outperforms the others in all circumstances.


#*Numerical computation of the incomplete Lipschitz-Hankel integral Jeo(a, z)
#@Steven L. Dvorak,Edward F. Kuester
#t1990
#cJournal of Computational Physics
#index452213


#*A new scheme for the approximation of advection-diffusion equations by collocation
#@Daniele Funaro
#t1993
#cSIAM Journal on Numerical Analysis
#index216887


#*Constraint propagation as an embedded filtering technique for solving constraint satisfaction problems
#@Patrick Hing-sun Ngai
#t1991
#c
#index511962


#*Applications of computer graphics to the evaluation and treatment of major craniofacial malformations
#@Court B. Cutting
#t1991
#c3D imaging in medicine
#index226978


#*Development of optimum scheduling strategies for test facilities
#@R. Meenakshi Sundaram,Lester Blair
#t1992
#cProceedings of the 14th annual conference on Computers and industrial engineering
#index222345


#*Rete: a fast algorithm for the many pattern/many object pattern match problem
#@Charles L. Forgy
#t1991
#cExpert systems: a software methodology for modern applications
#index512388


#*On probabilities induced by multi-valued mappings
#@Ronald R. Yager
#t1991
#cFuzzy Sets and Systems
#index510017


#*Mathcad 4.0: 32-bit power for ultimate math scratch pad
#@Barry Simon
#t1993
#cPC Magazine
#index226852


#*Distributed artificial intelligence for group decision support: integration of problem solving, coordination, and learning
#@Michael J. Shaw,Mark S. Fox
#t1993
#cDecision Support Systems
#index209725


#*Designing Object-Oriented User Interfaces, 1st edition
#@Dave Collins
#t1994
#c
#index621884


#*Non-simulation estimates in Monte-Carlo methods
#@A. I. Khisamutdinov,S. O. Shishmareva
#t1992
#cComputational Mathematics and Mathematical Physics
#index208225


#*ACM Algorithms Policy
#@Fred T. Krogh
#t1990
#cACM Transactions on Mathematical Software (TOMS)
#index327537
#%320741


#*A Comparison of Shared Virtual Memory and Message Passing Programming Techniques Based on a Finite Element Application
#@Rudolf Berrendorf,Michael Gerndt,Zakaria Lahjomri,Thierry Priol
#t1994
#cProceedings of the Third Joint International Conference on Vector and Parallel Processing: Parallel Processing
#index276053


#*Automating the conversion of text into hypertext
#@Thomas C. Rearick
#t1991
#cHypertext/hypermedia handbook
#index531536


#*Command and control
#@Donald Thwaites
#t1992
#cInteractive Learning International
#index221176


#*The information loop as a general analytic view
#@E. Burton Swanson
#t1991
#cInformation and Management
#index535631


#*Distributed communications
#@M. Kamrad,J. Cross
#t1990
#cACM SIGAda Ada Letters
#index510358
#!Communications among multiple Ada programs is a must, either as an explicit link or as an invisible link hidden beneath a distributed Ada veneer. Unisys has defined two Ada package specifications for inter-program communications, that are derived from the requirements developed at the Third International Workshop on Real-Time Ada Issues (RTAW3). Unisys is implementing these packages on several embedded real-time testbeds, both as standalone capabilities for application developers and as the communication layer supporting a distributed Ada system. These specifications are proposed as a basis for a secondary standard for inter-program communication for Ada9X. This paper describes how these specifications match the RTAW3 requirements and the motivation for their features. Some details of the specifications are interspersed throughout the text, with a full specification contained in the appendix.


#*Parallel object-oriented descriptions of graph reduction machines
#@David Bolton,Chris Hankin,Paul Kelly
#t1990
#cFuture Generation Computer Systems
#index541457


#*Linear Cryptanalysis Using Multiple Approximations
#@Burton S. Kaliski, Jr.,M. J. B. Robshaw
#t1994
#cProceedings of the 14th Annual International Cryptology Conference on Advances in Cryptology
#index262852


#*A memory organization for design cases
#@Weiyuan Wang
#t1993
#cProceedings of the third international conference on Young computer scientists
#index214297


#*On the number of list-colorings
#@Quentin Donner
#t1992
#cJournal of Graph Theory
#index228806


#*Uniform energy decay rates for Euler-Bernoulli equations with feedback operators in the Dirichlet/Neumann boundary conditions
#@J. Bartolomeo,R. Triggiani
#t1991
#cSIAM Journal on Mathematical Analysis
#index509863


#*Symmetric bipartite graphs of prime valency
#@P. Lorimer
#t1990
#cEuropean Journal of Combinatorics
#index517921


#*Catch as cache can
#@Steven J. Vaughan-Nichols
#t1991
#cBYTE
#index528644


#*A note on path-zero graphs
#@J. J. Seidel
#t1992
#cDiscrete Mathematics
#index526632


#*Context and application in software selection
#@John H. Ashford
#t1990
#cText retrieval: the state of the art
#index510588


#*Network and multidimensional representations of the declarative knowledge of human-computer interface design experts
#@Douglas J. Gillan,Sarah D. Breedin,Nancy J. Cooke
#t1992
#cInternational Journal of Man-Machine Studies
#index524902


#*Fuzzy regression analysis using neural networks
#@Hisao Isibuchi,Hideo Tanaka
#t1992
#cFuzzy Sets and Systems
#index528691


#*Ab initio molecular orbital calculations for 3,6-dihydro-1,2-dithiin and 3,6-dihydro-1,2-dioxin
#@Henry N. Po,Fillmore Freeman,Choonsun Lee,Warren J. Hehre
#t1993
#cJournal of Computational Chemistry
#index219431


#*CD-ROM: A Technical Guide
#@Linda W. Helgerson
#t1994
#c
#index617863


#*Universal graphs and induced-universal graphs
#@F. R.K. Chung
#t1990
#cJournal of Graph Theory
#index474357


#*Collection case resolution expert system
#@Amy Davis Zwemer
#t1991
#c
#index516499


#*MORE: Multimedia Object Retrieval Environment
#@Dario Lucarella,Stefano Parisotto,Antonella Zanzi
#t1993
#cProceedings of the fifth ACM conference on Hypertext
#index220551
#%152837
#%166471
#%171193
#%179415
#%206903
#%209185
#%211730
#%215611
#%223416
#%261674
#%474068
#%512091
#%533050
#%454245
#%475131
#%227953
#%519242
#%225616
#%465375
#%541260
#%455919
#%472907


#*Microsoft Macintosh QuickBASIC: a structured approach
#@Harvey M. Deitel,Paul J. Deitel
#t1990
#c
#index534969


#*UPSIDE DOWN: a cross-cultural experimental exercise
#@Joao S. Neves,Rajib N. Sanyal
#t1992
#cSimulation and Gaming
#index210959


#*Tree placement in Cascode-switch macros
#@Majid Sarrafzadeh
#t1991
#cIntegration, the VLSI Journal
#index509153


#*Computing the coefficients of a recurrence formula for numerical integration by moments and modified moments
#@M. Morandi Cecchi,M. Redivo Zaglia
#t1993
#cJournal of Computational and Applied Mathematics
#index224415


#*Higher-order and average reward myopic-affine dynamic models
#@M. J. Sobel
#t1990
#cMathematics of Operations Research
#index469864


#*On the robustness of linear stabilizing feedback control for linear uncertain systems: multi-input case
#@C. H. Chao,H. L. Stalford
#t1990
#cJournal of Optimization Theory and Applications
#index484514


#*Practitioner problems in need of database research
#@Gomer Thomas
#t1991
#cACM SIGMOD Record
#index513593
#!The bottlenecks between research and product development are well known. It typically takes a very long time for ideas coming out of research labs to make their way into products, and developers often face practical problems which do not seem to be addressed by currently available research results. The term &ldquo;technology transfer&rdquo; is often used to describe the process of overcoming these bottlenecks.


#*Performance Evaluation of a Dataflow Architecture
#@Dipak Ghosal,Laxmi N. Bhuyan
#t1990
#cIEEE Transactions on Computers
#index461857
#%158918
#%165382
#%181031
#%184096
#%283978
#%313666
#%317444
#%544732
#%550964
#!The formulation and validation of an analytical approach for the performance evaluation of the Manchester dataflow computer is discussed. The analytical approach is based on closed queuing network models. The average parallelism of the dataflow graph being executed on the dataflow architecture is shown to be related to the population of the closed network. The model of the dataflow computer is validated by comparing the analytical results to those obtained from the prototype Manchester dataflow computer and from simulation. The bottleneck centers in the prototype machine have been identified through the model, and various architectural modifications have been investigated from performance considerations.


#*New Constructions of Fail-Stop Signatures and Lower Bounds (Extended Abstract)
#@Eugène van Heijst,Torben P. Pedersen,Birgit Pfitzmann
#t1992
#cProceedings of the 12th Annual International Cryptology Conference on Advances in Cryptology
#index256673


#*Writing Tools and Text Processing (PANEL DISCUSSION)
#@Tina Buck,John Purvis
#t1991
#cJournal of Computing Sciences in Colleges
#index195305


#*Three-D Starter Kit for MAC Users, 2nd edition
#@Sean Wagstaff
#t1994
#c
#index626094


#*The Font Handler package
#@Hubert Rechsteiner,Francois Grize
#t1993
#cIssue 6 (Spring 1993)
#index222182


#*Implicit construction of McCulloch's G matrix for the numerical evaluation of Fisher information matrixes
#@Giovanni B. Moneta
#t1991
#cComputational Statistics Data Analysis
#index522055


#*Preservation properties in deductive databases
#@Marek A. Suchenek
#t1994
#cMethods of Logic in Computer Science
#index599216


#*A new bijection on rooted forests
#@Péter L. Erdős
#t1993
#cDiscrete Mathematics
#index206641


#*An almost-perfect printer/plotter
#@James M. Hansen
#t1992
#cBYTE
#index225838


#*A New Direction in Hydrodynamic Stability: Beyond Eigenvalues
#@Lloyd N. Trefethen,Anne E. Trefethen,Satish C. Reddy,Tobin A. Driscoll
#t1992
#c
#index123039
#!Fluid flows that are smooth at low speeds become unstable and then turbulent at higher speeds. This phenomenon has traditionally been investigated by linearizing the equations of flow and looking for unstable eigenvalues of the linearized problem, but the results agree poorly in many cases with experiments. Nevertheless, it has become clear in recent years that linear effects play a central role in hydrodynamic instability. A reconciliation of these findings with the traditional analysis can be obtained by considering the "pseudospectra" of the linearized problem, which reveal that small perturbations to the smooth flow in the form of streamwise vortices may be amplified by factors on the order of 10**5 by a linear mechanism, even though all the eigenmodes are stable. The same principles apply also to other problems in the mathematical sciences that involve non-orthogonal eigenfunctions.


#*Reactive C: an extension of C to program reactive systems
#@Frédéric Boussinot
#t1991
#cSoftware&mdash;Practice Experience
#index525220


#*Artificial evolution for computer graphics
#@Karl Sims
#t1991
#cProceedings of the 18th annual conference on Computer graphics and interactive techniques
#index521842
#%155763
#%160853
#%167263
#%182798
#%332787
#%458686
#%473461
#%474892
#%484623
#%513040
#%517247
#%555064
#!This paper describes how evolutionary techniques of variation and selection can be used to create complex simulated structures, textures, and motions for use in computer graphics and animation. Interactive selection, based on visual perception of procedurally generated results, allows the user to direct simulated evolutions in preferred directions. Several examples using these methods have been implemented and are described. 3D plant structures are grown using fixed sets of genetic parameters. Images, solid textures, and animations are created using mutating symbolic lisp expressions. Genotypes consisting of symbolic expressions are presented as an attempt to surpass the limitations of fixed-length genotypes with predefined expression rules. It is proposed that artificial evolution has potential as a powerful tool for achieving flexible complexity with a minimum of user input and knowledge of details.


#*Architectures for Executive Support Systems - Towards a Prototype Top Manager Workstation
#@Clive Holtham
#t1992
#cProceedings of the IFIP TC8/WG8.3 Working Conference on Decision Support Systems: Experiences and Expectations
#index560789


#*Identification of Multivariable Industrial Processes: For Simulation, Diagnosis and Control
#@Yucai Zhu,Ton Backx
#t1993
#c
#index235004


#*Validated solution of initial value problems for ODE
#@Hans J. Stetter
#t1990
#cComputer arithmetic and self-validating numerical methods
#index535548


#*WordPerfect 5.1 for Windows Desktop Publishing by Example
#@Webster & Associates Staff
#t1992
#c
#index243253


#*Linear Feature Extraction using the Multiresolution Fourier Transform
#@A. R. Davies,R. G. Wilson
#t1990
#c
#index193142
#!A hierarchical space-time image representation - the Multiresolution Fourier Transform (MFT) - is discussed, and its properties are used in order to define a spectrum based model for the class of simple linear features, such as straight lines and edges. The model is used to derive a method of identifying these features and estimating their parameters, ie position and orientation. Results are presented for this process using a test image. The effect of white noise is considered, and a correlation measure is defined to show the effect of the noise upon the model. A method of further improving the results for a noisy image, by smoothing with oriented ellipses is also considered.


#*Advantages and a defect of a potential method in domain optimization problems with a Neumann problem as a constraint (abstract)
#@Nobuo Fujii,Yoshito Goto
#t1992
#cJournal of Information Processing
#index210085


#*On graphs having &sgr;-polynomials of the same degree
#@Nian-Zu Li
#t1992
#cDiscrete Mathematics
#index222402


#*Capturing Design Dynamics the Concord Approach
#@Norbert Ritter,Bernhard Mitschang,Theo Härder,Michael Gesmann,Harald Schöning
#t1994
#cProceedings of the Tenth International Conference on Data Engineering
#index361720


#*StarBase v2.2 Implementation Details
#@Matthew Lehr
#t1993
#c
#index199760


#*The SEA CAB 500 Computer
#@Dimitri Starynkevitch
#t1990
#cIEEE Annals of the History of Computing
#index456782
#!The CAB 500 was planned by SEA as a low cost, simple to use computer, primarily for scientific calculations. The technology used was magnetic amplifiers, transistors, ferrite cores, and a magnetic drum, with input/output on perforated paper tape. It could be used in two modes: as a stored program computer or as a desk calculator. It was a micro-programmed machine, and a high-level language PAF (Programmation Automatique des Formules) was developed for it. It was launched in 1960 and over 100 were sold.


#*The thought experiment method: a new approach to qualitative reasoning
#@David Larry Hibler
#t1992
#c
#index540779


#*Computing services for disabled students in institutions of higher education
#@Sheryl Elaine Burgstahler
#t1992
#c
#index199057


#*Effort associated with a class of random optimization methods
#@Chang C. Y. Dorea
#t1991
#cMathematical Programming: Series A and B
#index540010


#*Amazing Clarion!
#@Mike Hanson
#t1990
#cData Based Advisor
#index466132


#*An $0(n \log^3 n)$ Algorithm for the Real Root and Symmetric Tridiagonal Eigenvalue Problems
#@H J Reif
#t1994
#c
#index113100
#!Given a univariate complex polynomial $f(x)$ of degree $n$ with rational coefficients expressed as a ratio of two integers $> 2^m$, the {\em root problem} is to find all the roots of $f(x)$ up to specified precision $2^{-\mu}$. In this paper we assume the arithmetic model for computation. We give an algorithm for the {\em real root problem}: where all the roots of the polynomial are real. Our real root algorithm has time cost of $O(n \log^2n(\log n+\log b)),$ where $b = m+\mu$. Our arithmetic time cost is thus $O(n \log^3n)$ even in the case of high precision $b \le n^{O(1)}$. This is within a small polylog factor of optimality, thus (perhaps surprisingly) upper bounding the arithmetic complexity of the real root problem to nearly the same as basic arithmetic operations on polynomials. The {\em symmetric tridiagonal} problem is given a $n \times n$ symmetric tridiagona matrix, with $3n$ nonzero rational entries each expressed as a ratio of two integers $> 2^m$, find all the eigenvalues up to specified precision $2^{-\mu}$. Using known efficient reductions from the symmetric tridiagonal eigenvalue problem to the real root problem, we also get an $O(n \log^2n(\log n+\log b))$ arithmetic time bound for the symmetric tridiagonal eigenvalue problem. We require only $\pi = O(n(b+n))$ bits of precision to carry out our computations. The Boolean complexity of our algorithms are a multiplicative factor of $M(\pi)$ more, where $M(\pi) = O(\pi (\log \pi)\log\log \pi)$ is the bit complexity for multiplication of integers of length $\pi.$ The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Reasoning with Negative Information, II: Hard Negation, Strong Negation and Logic Programs
#@David Pearce
#t1992
#cProceedings of the International Workshop on Nonclassical Logics and Information Processing
#index278638


#*Proceedings of the third annual ACM conference on Hypertext
#@
#t1991
#cConference on Hypertext and Hypermedia
#index531204


#*Parallel Distributed Belief Networks
#@Wilson X. Wen
#t1990
#cProceedings of the International Workshop on Parallelization in Inference Systems
#index272950


#*Stability estimates for obstacles in inverse scattering
#@Victor Isakov
#t1992
#cJournal of Computational and Applied Mathematics
#index532994


#*Pricing your EP P products&hellip; at profit
#@Dave D.W. Gater
#t1990
#cComputer Publishing
#index470250


#*A hierarchical approach to timing verification in CMOS VLSI design
#@H. G. Yang,D. M. Holburn
#t1991
#cProceedings of the conference on European design automation
#index302330
#%551998
#%545638
#%550160
#%469803
#%469107
#%473871
#%483922
#%485163
#!This paper describes a novel hierarchical approach to timing verification. Four types of relationship existing among signal paths are distinguished, based on a classification of the degree of interdependency in the circuit. In this way, irrelevant path delays can be excluded through consideration of the interaction between critical paths and others. Furthermore, under suitable conditions, bounded delay values for large hierarchical systems can be deduced using bounded delays determined for their constituent cells. Finally, we discuss the impact on design strategy of the hierarchical delay model presented in this paper.


#*Visualization and Virtual Reality: 3d Programming with Visual Basic for Windows, 1st edition
#@Lee A. Adams
#t1993
#c
#index616317


#*Inversion in finite fields using logarithmic depth
#@Joachim von zur Gathen
#t1990
#cJournal of Symbolic Computation
#index459972
#!Litow & Davida (1988) show that inverses in large finite fields of small characteristicp, say p=2, can be computed by Boolean circuits of (order-optimal) logarithmic depth. We note that their numerical approach can also be implemented purely algebraically, and that the resulting much simpler algorithm yields, also for large p, both arithmetic and Boolean reductions of inversion in F"p"n to inversion in F"p.


#*Demystifying the microcomputer&mdash;modem configuration (or, why doesn't my modem work?)
#@Larry L. Learn
#t1990
#cLibrary Hi Tech News
#index516140


#*Data exploration systems for databases
#@Richard J. Greene,Christopher W. Hield
#t1992
#cTelematics and Informatics
#index229764


#*Virtual reality and education
#@Sandra Helsel
#t1992
#cEducational Technology
#index513117


#*An eighth-order formula for the numerical integration of the one-dimensional Schro&uml;dinger equation
#@A. C. Allison,A. D. Raptis,T. E. Simos
#t1991
#cJournal of Computational Physics
#index512589


#*Efficacy of Ethics Codes for Computer Professionals (panel)
#@C. Dianne Martin,D. H. Martin
#t1992
#cProceedings of the IFIP 12th World Computer Congress on Education and Society - Information Processing '92 - Volume 2 - Volume 2
#index355859


#*Modeling and Investigation of a Primitive File Transfer Operation
#@Richard T. Hurley,James P. Black,J. W. Wong
#t1992
#cProceedings of the Fourth International Conference on Computing and Information: Computing and Information
#index366458


#*Personalized Communication Avoiding Node Contention on Distributed Memory Systems
#@Sanjay Ranka,Jhy-Chun Wang,Manoj Kumar
#t1993
#cProceedings of the 1993 International Conference on Parallel Processing - Volume 01
#index429471
#!In this paper, we present several algorithms for per forming all-to-many personalized communication on distributed memory parallel machines. Each proces sor sends a different message (of potentially different size) to a subset of all the processors involved in the collective communication. The algorithms are based on decomposing the communication matrix into a set of partial permutations. We study the effectiveness of our algorithms both from the view of static scheduling as well as runtime scheduling.


#*Invariants and paradigms of concurrency theory
#@Ryszard Janicki,M. Koutny
#t1992
#cFuture Generation Computer Systems
#index540145


#*The utilization of higher-order spectra to determine nonlinear radar cross sections
#@E. J. Powers,Sungbin Im
#t1994
#cProceedings of the Acoustics, Speech, and Signal Processing,1994. on IEEE International Conference - Volume 04
#index29792
#!The objective of this paper is to indicate how digital higher-order spectral analysis may be used to determine linear and cubic radar cross sections given time series data representing the transmitted and received signals. The approach utilizes an orthogonal Volterra-like model. In this case, the absolute value squared of the linear and cubic frequency-domain "orthogonal" kernels can be directly related to the linear and cubic radar cross sections, respectively. Of note is the fact that the approach makes no assumptions concerning the statistics of the transmitted signal.


#*A projection method for the floor planning problem
#@Andy Conn
#t1994
#c
#index204510


#*On the ordering of characteristic input-output modes in MIMO discrete-time systems
#@V. P. Deskov,G. M. Dimirovski,N. E. Gough
#t1993
#cProceedings of the IFAC workshop on Mutual impact of computing power and control theory
#index216045


#*Parallel Programming with Pure Functional Languages
#@Rachel Harrison
#t1991
#cResearch Directions in High-Level Parallel Programming Languages
#index355383


#*Rules and Strategies for Program Transformation
#@Alberto Pettorossi,Maurizio Proietti
#t1993
#cProceedings of the IFIP TC2/WG 2.1 State-of-the-Art Report on Formal Program Development
#index262867


#*A manager's guide to strategic potential of information systems
#@Mark C. S. Lee,Dennis A. Adams
#t1990
#cInformation and Management
#index531432


#*Farthest neighbors, maximum spanning trees and related problems in higher dimensions
#@Pankaj K. Agarwal,Jiří Matoušek,Subhash Suri
#t1992
#cComputational Geometry: Theory and Applications
#index218727


#*A new version of the Strang-Fix conditions
#@Rong-Qing Jia,Junjiang Lei
#t1993
#cJournal of Approximation Theory
#index216644


#*Parallel on-line parsing in constant time per word
#@Klaas Sikkel
#t1993
#cTheoretical Computer Science
#index212144


#*Best multipoint local Lp approximation
#@A. Alzamel,J. M. Wolfe
#t1990
#cJournal of Approximation Theory
#index481745


#*Power-law fluid flow of a hydromagnetic free jet
#@Magdy A. Ezzat
#t1994
#cJournal of Computational and Applied Mathematics
#index587989


#*A study of the effects of grammatik iv on selected writing errors made by business writing students
#@Sherry Morgan Williams
#t1993
#c
#index202639


#*New absorbing and ergodic doubly-linked list reorganizing heuristics
#@R. S. Valiveti,B. J. Oommen
#t1992
#cComputer science: research and applications
#index212940


#*A Topology Exploiting Genetic Algorithm to Control Dynamic Systems
#@Dirk Thierens,Leo Vercauteren
#t1990
#cProceedings of the 1st Workshop on Parallel Problem Solving from Nature
#index560177


#*Two-Dimensional Digital Filters
#@Wu-Sheng Lu,Andreas Antoniou
#t1992
#c
#index250317


#*Message-Task Scheduling in Ojbect-Oriented Heterogeneous Guru Distributed DBMS
#@R. C. Joshi,G. S. D. Verma,K. Singh
#t1994
#cProceedings of the 1994 International Conference on Parallel Processing - Volume 03
#index426287
#!Distributed Message-Task System (DMTS) is designed and implemented on GURU Distributed Database Management System (GURU DDBMS). It incorporates the advantages of Message Based Communication System (MBCS) and Distributed Shared Memory System (DSMS). The message carrying ordinary data is scheduled by the scheduler for the translation in the local DBMS environment, and later passed to the supervisor of the object as a simple message. The other kind of messages having the control instructions are first scheduled for the translation of the data conversions and later are rescheduled for the instruction translation in the local DBMS environment. The intelligent translator and mapper handle the objects and provide the exact meaning of the data and control instructions. Finally synchronously and asynchronously exited task scheduling policies and concurrency control procedures are suggested.


#*Partitioning Steiner triple systems into complete arcs
#@C. J. Colbourn,K. T. Phelps,M. J. de Resmini,A. Rosa
#t1991
#cDiscrete Mathematics
#index514966


#*The effects of image background on velocity computation of moving objects
#@S. A. Mahmoud,M. S. Afifi,R. J. Green
#t1990
#cJournal of Microcomputer Applications
#index460705


#*The Encapsulated Security Services Interface (ESSI)
#@Ping Lin
#t1993
#cProceedings of the IFIP TC11, Ninth International Conference on Information Security: Computer Security
#index270892


#*Issues in Modelling Techniques for the STEP Based Exchange of Robotics Data
#@Uri I. Kroszynski,Torben Sørensen,Erik Trostmann
#t1993
#cProceedings of the IFIP TC5/WG5.10 Working Conference on Interfaces in Industrial Systems for Production Engineering
#index269355


#*A localized approximation method for vortical flow
#@R. E. Caflisch,O. F. Orellana,M. Siegal
#t1990
#cSIAM Journal on Applied Mathematics
#index456428


#*In the News
#@
#t1992
#cIEEE Software
#index444681


#*An optimative routing method in network design
#@Xidong Jiang
#t1993
#cProceedings of the third international conference on Young computer scientists
#index223342


#*PC Learning Labs Teaches CC: Mail
#@PC Learning Labs
#t1993
#c
#index607122


#*A TDM-based multibus packet switch
#@Tak-Shing Yum,Yiu-Wing Leung
#t1992
#cProceedings of the eleventh annual joint conference of the IEEE computer and communications societies on One world through communications (Vol. 3)
#index522225


#*Independence-reducible database schemes
#@Edward P. F. Chan,Héctor J. Hernández
#t1991
#cJournal of the ACM (JACM)
#index523690
#%144106
#%146052
#%150955
#%153618
#%163824
#%168256
#%173220
#%174292
#%176852
#%177595
#%206578
#%231453
#%326368
#%463539
#%469966
#%478586
#%510183


#*Dimethylarsine: pyrolysis mechanisms and use for OMVPE growth
#@S. H. Li,C. A. Larsen,C. H. Chen,G. B. Stringfellow,D. W. Brown
#t1990
#cJournal of Electronic Materials
#index458537


#*Overview and general concepts: library LANs
#@Marshall Breeding
#t1992
#cLibrary LANs: case studies in practice and application
#index528717


#*One More Logic with Uncertainty and Resolution Principle for it
#@Konstantin Vershinin,Igor Romanenko
#t1992
#cProceedings of the 11th International Conference on Automated Deduction: Automated Deduction
#index557629


#*Tractable Flow Analysis for Anomaly Detection in Distributed Programs
#@Shing-Chi Cheung,Jeff Kramer
#t1993
#cProceedings of the 4th European Software Engineering Conference on Software Engineering
#index362983


#*OAL: an implementation of an actor language on a massively parallel message-passing architecture
#@Jean-Louis Giavitto,Cécile Germain,Julian Fowler
#t1991
#cProceedings of the 2nd European conference on Distributed memory computing
#index531687


#*Proceedings of the International Conference on Parallel Processing, 1993, Vol. III: Algorithms and Applications
#@Salim Hariri,P. Bruce Berra
#t1993
#c
#index254682


#*A Unified Framework for Multicast Forwarding
#@Zheng Wang,Jon Crowcroft
#t1993
#cProceedings of the 4th International Workshop on Network and Operating System Support for Digital Audio and Video
#index558976


#*Discourse
#@Barbara J. Grosz,Martha E. Pollack,Candace L. Sidner
#t1993
#cFoundations of cognitive neuroscience
#index222248


#*Robots Quest for Living M
#@Geoff L. Simons
#t1992
#c
#index607311


#*A decomposition of locally finite graphs
#@Bogdan Oporowski
#t1993
#cDiscrete Mathematics
#index219909


#*Noether's inequality for non-complete algebraic surfaces of general type
#@Shuichiro Tsunoda,De-Qi Zhang
#t1992
#cPublications of the Research Institute for Mathematical Sciences
#index210741


#*On a new characterization of the classical orthogonal polynomials
#@H. Dette,W. J. Studden
#t1992
#cJournal of Approximation Theory
#index218002


#*Energy Functions Associated with Error-Correcting Codes
#@C. Rentería,H. Tapia-Recillas
#t1993
#cProceedings of the 10th International Symposium on Applied Algebra, Algebraic Algorithms and Error-Correcting Codes
#index359346


#*Productivity measures for information systems
#@Richard A. Scudder,A. Ronald Kucic
#t1991
#cInformation and Management
#index537869


#*Navigating the Networks: Proceedings of the ASIS Mid-Year Meeting: Portland Oregon May 21-25, 1994
#@Deborah Lines Andersen,Mark D. Giguere,Thomas J. Galvin
#t1994
#c
#index249644


#*Walking an unknown street with bounded detour
#@Rolf Klein
#t1992
#cComputational Geometry: Theory and Applications
#index229850


#*Parallel Processing: From Applications to Systems, 1st edition
#@Dan I. Moldovan
#t1992
#c
#index616414
#!:This text provides one of the broadest presentations of parallel processing available, including the structure of parallel processors and parallel algorithms. The emphasis is on mapping algorithms to highly parallel computers, with extensive coverage of array and multiprocessor architectures. Early chapters provide insightful coverage on the analysis of parallel algorithms and program transformations, effectively integrating a variety of material previously scattered throughout the literature. Theory and practice are well balanced across diverse topics in this concise presentation. For exceptional clarity and comprehension, the author presents complex material in geometric graphs as well as algebraic notation. Each chapter includes well-chosen examples, tables summarizing related key concepts and definitions, and a broad range of worked exercises. Features: Overview of common hardware and theoretical models, including algorithm characteristics and impediments to fast performance Analysis of data dependencies and inherent parallelism through program examples, building from simple to complex Graphic and explanatory coverage of program transformations Easy-to-follow presentation of parallel processor structures and interconnection networks, including parallelizing and restructuring compilers Parallel synchronization methods and types of parallel operating systems Detailed descriptions of hypercube systems Specialized chapters on dataflow and on AI architectures


#*Proceedings of the 4th International Conference on Principles of Knowledge Representation and Reasoning, 1st edition
#@Jon Doyle,Pietro Torasso,Erik Sandewall
#t1994
#c
#index249029


#*Self-Defeating Reductionism
#@Pedro C. Marijaun
#t1993
#cACM SIGBIO Newsletter
#index309364


#*Node error assignment in expert networks
#@R. C. Lacher
#t1992
#cHybrid architectures for intelligent systems
#index208888


#*Basic aspects of the theory of generalized quantifiers
#@João Peres
#t1991
#cProceedings of the 2nd advanced school in artifical intelligence on Natural language processing
#index513467


#*Correcting problems with vacuum repair and calibration
#@John R. Stone
#t1990
#cInTech
#index522040


#*HIDEL: a language for hierarchical VLSI design
#@M. Ancona,L. de Floriana,A. Clematis,E. Puppo
#t1991
#cThe Computer Journal
#index528124


#*Simplify your searching with personalized system commands
#@Margaret Metcalf Carr
#t1992
#cOnline
#index523604


#*A parabolic inverse problem arising in a mathematical model for chromatography
#@Tsuyoshi Kimura,Takashi Suzuki
#t1993
#cSIAM Journal on Applied Mathematics
#index218487


#*Ein wissenbasierte Fehlerfr&uuml;hdiagnosesystem f&uuml;r Werkzeugmaschinen auf der Basis eines PC mit Signalprozessorkarte
#@D. Neumann,Rolf Isermann
#t1991
#cProze&szlig;rechnersysteme '91, Automatisierungs- und Leitsysteme in den neunziger Jahren
#index265023


#*Unifying tool, data and process flow management
#@Michael Rumsey,Colin Farquhar
#t1992
#cProceedings of the conference on European design automation
#index226043
#%518667
#%271995


#*Knowledge bases for user guidance in information seeking dialogues
#@Anne Tißen
#t1993
#cProceedings of the 1st international conference on Intelligent user interfaces
#index211328
#%181385
#%227313
#%450035
#%466991
#%541376


#*Fault-Tolerant Design Strategies for High Reliability and Safety
#@N. F. Vaidya,D. K. Pradhan
#t1993
#cIEEE Transactions on Computers
#index440649
#%180489
#%480507
#!Several fundamental results related to reliability and safety are analyzed. Modular redundant systems consisting of multiple identical modules and an arbiter are considered. It is shown that for a given level of redundancy, a large number of implementation alternatives exist with varying degree of reliability and safety. Strategies are formulated that achieve a maximal combination of reliability and safety. The effect of increasing the number of modules on system reliability and safety is analyzed. It is shown that when one considers safety in addition to reliability, it does not necessarily help to simply add modules to the system. Specifically, increasing the number of modules by just one does not always improve both reliability and safety. To improve reliability and safety simultaneously, at least two additional modules are required when the outputs of the individual modules do not have any redundant information (e.g., coding for error detection). However, it is shown that if the modules themselves have built-in error detection capability, addition of just one module may be sufficient to improve both reliability and safety.


#*Eldo-XL: a software accelerator for the analysis of digital MOS circuits by an analog simulator
#@Joel Besnard,Jacques Benkoski,Bernard Hennion
#t1991
#cProceedings of the conference on European design automation
#index301675
#!Eldo-XL is composed of a set of techniques developed on the basis of the Eldo analog simulator and integrated in it. Eldo-XL is targeted at the simulation of MOS digital circuits with minimal loss of accuracy compared to Eldo. The basis of Eldo-XL is a simpler MOS transistor model which allows the analytical solution of the nodal equations most of the time. The costly iterations associated the implicit solution are avoided and a large speed-up is obtained. The availability of a simpler relaxation algorithm can further enhance the performance on circuits with little feedback. All these acceleration techniques can be used on the digital part of a mixed analog/digital circuit without influencing the accuracy of the solution of the analog part. This paper presents the three techniques developed for Eldo-XL and attempts to show that a good efficiency can be reached without losing generality by combining a classical analog simulator with a dedicated evaluation engine for digital MOS circuits.


#*The subdifferential in Banach spaces
#@Volkmar Weckesser
#t1993
#cNonlinear Analysis: Theory, Methods Applications
#index207810


#*Automating fixture design&mdash;from imitating practice to understanding principles
#@A. Márkus,Zs. Ruttkay,J. Váncza
#t1990
#cComputers in Industry
#index479156


#*An EVES Data Abstraction Example
#@Mark Saaltink,Sentot Kromodimoeljo,Bill Pase,Dan Craigen,Irwin Meisels
#t1993
#cProceedings of the First International Symposium of Formal Methods Europe on Industrial-Strength Formal Methods
#index261760


#*On improving SGML
#@Michael J. Kaelbling
#t1990
#cElectronic Publishing&mdash;Origination, Dissemination, and Design
#index512622


#*Generalized probabilistic LR parsing of natural language (Corpora) with unification-based grammars
#@Ted Briscoe,John Carroll
#t1993
#cComputational Linguistics
#index304469
#%158817
#%162585
#%163706
#%167384
#%177209
#%177332
#%182619
#%540943
#%472680
#%487714
#%328087
#%316491
#%515912
#%478718
#%483152
#%321873
#%535948
#%519601
#%516985
#!We describe work toward the construction of a very wide-coverage probabilistic parsing system for natural language (NL), based on LR parsing techniques. The system is intended to rank the large number of syntactic analyses produced by NL grammars according to the frequency of occurrence of the individual rules deployed in each analysis. We discuss a fully automatic procedure for constructing an LR parse table from a unification-based grammar formalism, and consider the suitability of alternative LALR(1) parse table construction methods for large grammars. The parse table is used as the basis for two parsers; a user-driven interactive system that provides a computationally tractable and labor-efficient method of supervised training of the statistical information required to drive the probabilistic parser. The latter is constructed by associating probabilities with the LR parse table directly. This technique is superior to parsers based on probabilistic lexical tagging or probabilistic context-free grammar because it allows for a more context-dependent probabilistic language model, as well as use of a more linguistically adequate grammar formalism. We compare the performance of an optimized variant of Tomita's (1987) generalized LR parsing algorithm to an (efficiently indexed and optimized) chart parser. We report promising results of a pilot study training on 150 noun definitions from the Longman Dictionary of Contemporary English (LDOCE) and retesting on these plus a further 55 definitions. Finally, we discuss limitations of the current system and possible extensions to deal with lexical (syntactic and semantic) frequency of occurrence.


#*Radiosity
#@John Wallace,John Fujii
#t1992
#cBYTE
#index229632


#*An off-the shelf solution: a multiplatter CD-ROM LAN
#@Bonnie R. Nelson
#t1992
#cLibrary LANs: case studies in practice and application
#index517550


#*Defuzzification of fuzzy intervals
#@Renhong Zhao,Rakesh Govind
#t1991
#cFuzzy Sets and Systems
#index540150


#*Technological literacy: where do we all go from here?
#@John Beynon
#t1993
#cComputers into classrooms: more questions than answers
#index225262


#*Impossibility and optimally results on constructing pseudorandom permutations (extended abstract)
#@Yuliang Zheng,Tsutomu Matsumoto,Hideki Imai
#t1990
#cProceedings of the workshop on the theory and application of cryptographic techniques on Advances in cryptology
#index518135


#*Using a computer-based semantic mapping, reading, and writing approach with at-risk fourth graders
#@Richard Sinatra,Jeffrey Beaudry,Jeanne Pizzo,Gene Geisert
#t1994
#cJournal of Computing in Childhood Education
#index216408


#*Detection of outliers and robust estimation using fuzzy clustering
#@Bernard Van Cutsem,Isak Gath
#t1993
#cComputational Statistics Data Analysis
#index218794


#*Approved uniformity issues
#@P. D. Kenward,B. A. Wichmann
#t1991
#cACM SIGAda Ada Letters
#index518923


#*Solving two-point boundary value problems by means of deficient quartic splines
#@Anjula Saxena,Ezio Venturino
#t1994
#cApplied Mathematics and Computation
#index602811


#*Parallelism in Object-Oriented Query Processing
#@Kyung-Chang Kim
#t1990
#cProceedings of the Sixth International Conference on Data Engineering
#index372994


#*Bounds and approximations for the periodic on/off queue with applications to ATM traffic control
#@Kenn Kvols,Søren Blaabjerg
#t1992
#cProceedings of the eleventh annual joint conference of the IEEE computer and communications societies on One world through communications (Vol. 2)
#index518619


#*FMS tool change schemes and their characteristics
#@Hiroshi Katayama
#t1994
#cComputers and Industrial Engineering
#index602698


#*A high availability N hierarchical grid algorithm for replicated data
#@Akhil Kumar,Shun Yan Cheung
#t1991
#cInformation Processing Letters
#index541483


#*Young children's skill in using a mouse to control a graphical computer interface
#@Charles Crook
#t1992
#cComputers Education
#index217350


#*Attitudes toward integrating computers into the classroom: what parents, teachers and students report
#@Gayle V. Davidson,Scott D. Ritchie
#t1994
#cJournal of Computing in Childhood Education
#index218085


#*Robo-Mop Gets Wrung Out [Software-Related Patents]
#@
#t1994
#cComputer
#index443103
#!It's a mistake to underestimate the power of a US patent, especially in the hands of a direct competitor. One jury valued a software-related patent at $120 million-a large verdict for any kind of patent. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Randomized Signal Processing
#@Ivars Bilinskis,A. K. Mikelson
#t1992
#c
#index245397


#*USMARC Specifications for Record Structure, Character Sets and Exchange Media
#@of Congress Library
#t1994
#c
#index615389


#*The approximate solution of a pseudoparabolic equation
#@S. I. Lyashko
#t1991
#cComputational Mathematics and Mathematical Physics
#index209549


#*Management of data quality in a long-term epidemiologic study: the Framingham heart study
#@Keaven M. Anderson,Deborah C. Dumphy,Peter W. F. Wilson
#t1991
#cData quality control theory and pragmatics
#index516884


#*Metawissen als Teil von Umweltinformationssystem
#@Andreas Jaeschke,Andree Keitel,Roland Mayer-Föll,Franz Josef Radermacher,Jürgen Seggelke
#t1992
#cKonzeption und Einsatz von Umweltinformationssystemen, Proceedings [Umweltinformatik, Workshop, Schlo&szlig; Reisensburg, G&uuml;nzburg, Oktober 1990]
#index260392


#*Real-time data processing of the sensory data of a multi-fingered dextrous robot hand
#@Alois Knoll
#t1992
#cReal-time systems engineering and applications
#index536786


#*Guest Editorial: The Many Faces of Test
#@Kenneth D. Wagner
#t1990
#cIEEE Design Test
#index449565


#*Sums of games born on Days 2 and 3
#@David Moews
#t1991
#cTheoretical Computer Science
#index524799


#*Extended Fuzzy System Identification for Cable Adjustment Work in Daytime
#@M. Kaneyoshi,H. Tanaka,M. Kamei,H. Furuta
#t1993
#cProceedings of the IFIP WG7.5 Fifth Working Conference on Reliability and Optimization of Structural Systems VTakamatsu
#index264828


#*Keyboarding for Personal and Business Use, 10th edition
#@June Dostal
#t1993
#c
#index609022


#*Visibility preprocessing for interactive walkthroughs
#@Seth J. Teller,Carlo H. Séquin
#t1991
#cACM SIGGRAPH Computer Graphics
#index518769
#%144048
#%169316
#%237122
#%328601
#%480359
#!The number of polygons comprising interesting architectural models is many more than can be rendered at interactive frame rates. However, due to occlusion by opaque surfaces (e.g., walls), only a small fraction of a typical model is visible from most viewpoints.We describe a method of visibility preprocessing that is efficient and effective for axis-aligned or axial architectural models. A model is subdivided into rectangular cells whose boundaries coincide with major opaque surfaces. Non-opaque portals are identified on cell boundaries, and used to form an adjacency graph connecting the cells of the subdivision. Next, the cell-to-cell visibility is computed for each cell of the subdivision, by linking pairs of cells between which unobstructed sightlines exist.During an interactive walkthrough phase, an observer with a known position and view cone moves through the model. At each frame, the cell containing the observer is identified, and the contents of potentially visible cells are retrieved from storage. The set of potentially visible cells is further reduced by culling it against the observer's view cone, producing the eye-to-cell visibility. The contents of the remaining visible cells are then sent to a graphics pipeline for hidden-surface removal and rendering.Tests on moderately complex 2-D and 3-D axial models reveal substantially reduced rendering loads.


#*Measures of discord in the Dempster-Shafer theory
#@Arthur Ramer,George Klir
#t1993
#cInformation Sciences: an International Journal
#index210933


#*Dynamic and control behavior of multicomponent distillation
#@Y. S. Yiu,G. A. Carling,R. K. Wood
#t1990
#cSimulation
#index452995


#*Serial Communications; A C++ Developer's Guide
#@Mark Nelson
#t1992
#c
#index231831


#*The relative maximum genus of a graph
#@C. Paul Bonnington
#t1994
#cJournal of Combinatorial Theory Series B
#index219387


#*A multilevel neuromolecular architecture that uses the extradimensional bypass principle to facilitate evolutionary learning
#@Jong-Chen Chen,Michael Conrad
#t1994
#cProceedings of the NATO advanced research workshop and EGS topical workshop on Chaotic advection, tracer dynamics and turbulent dispersion
#index210597


#*Session 14: cluster computing
#@
#t1994
#cProceedings of the 1994 ACM/IEEE conference on Supercomputing
#index438612


#*Designing software for use by humans, not machines
#@L. Ruston,M. J. Muller,K. D. Cebulka
#t1991
#cProceedings of the 13th international conference on Software engineering
#index84788
#%142840
#%156381
#%231569
#%313950
#%541533


#*TBrowse and TBColumn basics
#@Dan D. Gutierrez
#t1993
#cData Based Advisor
#index213035


#*Data bases may spur PC use in health care
#@Ted Rand
#t1992
#cMarketing Computers
#index213819


#*International Perspectives: A HUMAN INTERFACE SOCIETY ABROAD
#@John Karat,Clare-Marie Karat
#t1993
#cACM SIGCHI Bulletin
#index109637
#!This issue's column features a contribution from Masaaki Kurosu describing the Technical Committee for Human Interface of the Society of Instrument and Control Engineers in Japan. We found it interesting to hear about the organization and activities of this committee, and found the similarities and differences to SIGCHI informative. While the SIGCHI community has had extensive contact with some of the overseas professional societies with similar interests (such as the HCI Specialists group of the British Computer Society), there are many organizations that we know relatively little about. We thank Masaaki for providing this glimpse at an activity in Japan, and will try and include reports of other overseas societies in future columns.


#*PARCS: Parallel Picture Archiving and Communication System
#@Marco Fruscione,L. Marenzi,Sergio Punzi,Paolo Stofella
#t1994
#cProceedings of the nternational Conference and Exhibition on High-Performance Computing and Networking Volume I: Applications
#index362092


#*Object-Oriented Database Design Methodologies: A Survey
#@Il-Yeol Song,E. K. Park
#t1992
#cSelected Papers from the First International Conference on Information and Knowledge Management, Expanding the Definition of Database
#index565602


#*Knowledge based lexicons
#@J. Terry Nutter
#t1990
#cProceedings of the first annual SNePS workshop on Current trends in SNePS---semantic network processing system
#index539439


#*The initial X-ray structure of Bovine lens leucine aminopeptidase to atomic resolution
#@Peter Rensis David
#t1991
#c
#index535502


#*Constraint based analysis tools for design
#@Alfredo Pérez,David Serrano
#t1993
#cProceedings on the second ACM symposium on Solid modeling and applications
#index216247
#%146285
#%169286
#%524610
#%530445


#*Layoffs and reeducation
#@
#t1993
#cComputer
#index447481


#*Microsoft Money 2.0
#@Stephen L. Nelson
#t1992
#c
#index512913


#*An efficient methodology for extraction and simulation of transmission lines for application specific electronic modules
#@S. Y. Kim,E. Tuncer,R. Gupta,B. Krauter,T. Savarino,D. P. Neikirk,L. T. Pillage
#t1993
#cProceedings of the 1993 IEEE/ACM international conference on Computer-aided design
#index93816
#%78460
#%279617
#%508909
#%289415


#*Parallel cardinality stacks and an application
#@Robert Kennedy
#t1991
#cInformation Processing Letters
#index530842


#*Text to screen revisited: copyright in the electronic age
#@John R. Garrett
#t1991
#cOnline
#index529119


#*Understanding digital troubleshooting (3rd ed.)
#@Don L. Cannon
#t1991
#c
#index518748


#*Pattern-directed invocation with changing equations
#@Yishai A. Feldman,Charles Rich
#t1991
#cJournal of Automated Reasoning
#index519237


#*Oscillations and synchronization in neural networks: an exploration of the labeling
#@Pierre Baldi,Amir Atiya
#t1991
#cInternational Journal of Neural Systems
#index514354


#*Microstructure-property relations in the complex perovskite lead magnesium niobate
#@Jie Chen
#t1991
#c
#index525936


#*Cooperative prototyping studies&mdash;users and designers a dental case record system
#@Susanne Bødker,Kaj Grønbæk
#t1990
#cStudies in computer supported cooperative work: theory, practice and design
#index524398


#*Investigation of sulfur-treated Gallium Arsenide surfaces
#@Jang Kyoo Shin
#t1991
#c
#index541461


#*Three lessons I learned from a year of computer-based instruction
#@Joseph J. D'Amico
#t1990
#cJournal of Computer Based Instruction
#index518461


#*A credit manager for traffic regulation in high-speed networks: a queueing analysis
#@Kin K. Leung,Raymond W. Yeung,Bhaskar Sengupta
#t1993
#cIEEE/ACM Transactions on Networking (TON)
#index226501
#%508948
#%459796


#*ON WEAK LEARNING
#@David P. Helmbold,Manfred K. Warmuth
#t1992
#c
#index203711
#!An algorithm is a weak learning algorithm if with some small probability it outputs a hypothesis with error slightly below 50%. This paper presents relationships between weak learning, weak prediction (where the probability of being correct is slightly larger than 50%), and consistency oracles (which decide whether or not a given set of examples is consistent with a concept in the class). Our main result is a simple polynomial prediction algorithm which makes only a single query to a consistency oracle and whose predictions have a polynomial edge over random guessing. We compare this prediction algorithm with several of the standard prediction techniques, deriving an improved worst case bound on Gibbs Algorithm in the process. We use our algorithm to show that a concept class is polynomially learnable if and only if there is a polynomial probabilistic consistency oracle for the class. Since strong learning algorithms can be built from weak learning algorithms, our results also characterizes strong learnability.


#*An Introduction to Statistics for Managers
#@Ann Spooner,Colin Lewis
#t1994
#c
#index250664


#*Some remarks on the behaviour of the solution in dynamic processes for rate-type models
#@Mircea Sofonea
#t1990
#cZeitschrift f&uuml;r Angewandte Mathematik und Physik (ZAMP)
#index536278


#*File Structures: A Conceptual Toolkit, 2nd edition
#@Michael J. Folk,Bill Zoellick
#t1991
#c
#index252637
#!:Based on the bestselling File Structures, Second Edition, this book takes an object-oriented approach to the study of file structures. It allows students and professionals to acquire the fundamental tools needed to design intelligent, cost-effective, and appropriate solutions to file structure problems. The book begins by presenting the software and hardware characteristics that combine to make file structure design important to application development. It continues with a thorough treatment of the tools that support effective use of files for storing and retrieving information. This book teaches design by putting the hands-on work of constructing and running programs at the center of the learning process. By following the many programming examples included in the book and in the exercise sets, readers will gain a significant understanding of object-oriented techniques and will see how C++ can be an effective software development tool.


#*Extending RISC-CLP (Real) to Handle Symbolic Functions
#@Olga Caprotti
#t1993
#cProceedings of the International Symposium on Design and Implementation of Symbolic Computation Systems
#index362164


#*Video: objects that cannot be taken apart with two hands
#@Jack Snoeyink
#t1993
#cProceedings of the ninth annual symposium on Computational geometry
#index218111
#%452310


#*A design rationale for a language-based editor
#@Jim Welsh,Brad Broom,Derek Kiong
#t1991
#cSoftware&mdash;Practice Experience
#index522235


#*The Challenges of Self-Test
#@
#t1990
#cIEEE Design Test
#index447582


#*The impact of codes of ethics on information systems personnel
#@Susan J. Harrington
#t1994
#cProceedings of the 1994 computer personnel research conference on Reinventing IS : managing information technology in changing organizations: managing information technology in changing organizations
#index224986
#%215909
#%220451
#%515801
#%470570
#!This research looks at the impact of company codes of ethics, as well as codes of ethics written specifically for information systems (I.S.) employees. Moreover, since the intent of ethics codes is to clarify responsibility, the personality characteristics of denial of responsibility and its interaction with exposure to codes of ethics was examined. The impact of codes and the personality characteristic of denial of responsibility were measured based on I.S. judgments concerning illegal software copying, computer cracking (sometimes called hacking), spreading viruses, corporate sabotage using the computer, and computer fraud. Denial of responsibility was found to be related to a variety of computer abuses and did interact with company codes of ethics to influence attitudes toward viruses and computer fraud.


#*Network configuration and initialization using mathematical morphology: theoretical study of measurement functions
#@M. Schmitt
#t1991
#cRevue Technique
#index518393


#*Data security in medical information systems: the Greek case
#@D. Gritzalis,A. Tomaras,S. Katsikas,J. Keklikoglou
#t1991
#cComputers and Security
#index530607


#*Exploring large hyperdocuments: fisheye views of nested networks
#@Emanuel G. Noik
#t1993
#cProceedings of the fifth ACM conference on Hypertext
#index227064
#%157475
#%163826
#%176701
#%179415
#%523247
#%508574
#%537792
#%451935
#%509020
#%525651
#%525094
#%473123
#%477794
#%513122
#%525981
#%541998
#%261871
#%485203


#*Natural gesture in virtual environments
#@Alan Wexelblat
#t1994
#cProceedings of the conference on Virtual reality software and technology
#index592906


#*A Specification-Based Data Model
#@Munish Gandhi
#t1992
#cProceedings of the 11th International Conference on the Entity-Relationship Approach: Entity-Relationship Approach
#index258828


#*Numerical calculation of the equation of flow in porous media: the lattice gas approach
#@Paul Papatzacos
#t1993
#cJournal of Computational Physics
#index224666


#*On the interaction of palladium with olefinic systems
#@Harrell Sellers
#t1990
#cJournal of Computational Chemistry
#index456323


#*Experiences with CCB-Directed Projects in the Classroom
#@James M. Purtilo,Stanley Siegel
#t1994
#cProceedings of the 7th SEI CSEE Conference on Software Engineering Education
#index570374


#*DB2 Developer's Guide, 2nd edition
#@Craig S. Mullins
#t1994
#c
#index621498
#!:DB2 Developers Guide, Third Edition is a comprehensive guide to DB2 for Developers and Administartors. It serves as the blueprint for implementing optimized DB2 application systems. The book shows readers how toCompletely updated and revised to cover the latest releases of DB2 on MVS and new features added to DB2 Version 4 and Version 5Comprehensive guide to DB2 that shows the reader how to build high-performance DB2 application systems and to administer and support large DB2 databasesIncludes information about accessing DB2 via the World Wide Web


#*A stream data type that supports goal-directed pattern matching on unbounded sequences of values
#@Kevin Nilsen
#t1990
#cComputer Languages
#index472382


#*An efficient second-order neural network architecture for orientation invariant character recognition
#@Russell Walker Duren
#t1991
#c
#index523093


#*Digitale Film&uuml;bertragung und Darstellung im X-Windows System
#@Bernd Lamparter,Wolfgang Effelsberg
#t1991
#cTelekommunikation und multimediale Anwendungen der Informatik, GI - 21. Jahrestagung
#index259414


#*Book review: Past, Present, Parallel: A Survey of Available Parallel Computing Systems by Arthur Trew & Greg Wilson (Eds.), (Springer-Verlag 1991)
#@
#t1991
#cACM SIGARCH Computer Architecture News
#index568783


#*CLOS and Smalltalk: a comparison
#@Pierre Cointe
#t1993
#cObject-oriented programming: the CLOS perspective
#index229347


#*The networked physician: practitioner of the future
#@Edward H. Shortliffe
#t1990
#cHealthcare information management systems
#index516262


#*Mul-T: a high-performance parallel Lisp
#@D. A. Kranz,R. H. Halstead, Jr.,E. Mohr
#t1990
#cProceedings of the US/Japan workshop on Parallel Lisp on Parallel Lisp: languages and systems
#index510728


#*Convergence of BDF approximations for nonsolvable differential algebraic equations
#@Stephen L. Campbell,Kenneth D. Clark
#t1990
#cApplied Numerical Mathematics
#index465760


#*Locating Perceptually Salient Points on Planar Curves
#@M. A. Fischler,H. C. Wolf
#t1994
#cIEEE Transactions on Pattern Analysis and Machine Intelligence
#index441282
#%151375
#%158607
#%159936
#%160161
#%164420
#%325793
#%536815
#%451047
#%540100
#!This paper describes the underlying ideas and algorithmic details of a computer program that performs at a human level of competence for a significant subset of the curve partitioning task. It extends and rounds out the technique and philosophical approach originally presented by Fischler and Bolles (1986). In particular, it provides a unified strategy for selecting and dealing with interactions between salient points, even when these points are salient at different scales of resolution. Experimental results are presented involving on the order of 1000 real and synthetically generated images.


#*The comparative effects of BASIC programming versus HyperCard programming on problem solving, computer anxiety, and performance
#@W. Michael Reed,Min Liu
#t1994
#cComputers in the Schools
#index592785


#*WordPerfect for Windows HyperGuide
#@D. F. Scott,Kelly Oliver,Seta Frantz
#t1993
#c
#index254105


#*A method for randomly generating capacitated networks
#@Kwang Shin,Steve Corder
#t1991
#cProceedings of the 23rd conference on Winter simulation
#index285028


#*Inertial manifolds and multigrid methods
#@R. Temam
#t1990
#cSIAM Journal on Mathematical Analysis
#index457439


#*Helping the user retrieve data from a CD-ROM
#@Susan Feinberg
#t1991
#cProceedings of the 9th annual international conference on Systems documentation
#index538402
#%148366
#%155436


#*Simulation of embedded memories by defective hashing
#@Leendert M. Huisman
#t1990
#cIBM Journal of Research and Development
#index473686
#%157833
#%173711
#%461629


#*On quasi-orthogonal polynomials
#@A. Draux
#t1990
#cJournal of Approximation Theory
#index452047


#*Resolution in microlithography
#@H. Sewell,A. R. Reinberg
#t1990
#cProceedings of the international conference on microlithography on Microcircuit engineering
#index518891


#*Toward workload characterization of video server and digital library applications (extended abstract)
#@Ann L. Drapeau,David A. Patterson,Randy H. Katz
#t1994
#cACM SIGMETRICS Performance Evaluation Review
#index229773
#%226038
#%475349


#*A sequence for using algorithms for the approximate solution in the Hybrid algorithm for solving the travelling salesman problem
#@I. Kh. Sigal
#t1991
#cUSSR Computational Mathematics and Mathematical Physics
#index526348


#*Machine vision monitoring of plant nutrition
#@Amots Hetzroni
#t1994
#c
#index192771


#*Testing geometric objects
#@Kathleen Romanik
#t1990
#cComputer Science Technical Report Series; Vol. CS-TR-2473
#index474163


#*Software
#@Richard Comerford
#t1992
#cIEEE Spectrum
#index524770


#*Networking from the ground up: implementing Macintosh networks in a newly-constructed arts library
#@Robert Skinner
#t1992
#cLibrary LANs: case studies in practice and application
#index521180


#*The OPAC and Image workstations
#@Wilma A. Bass
#t1993
#cHigh performance medical libraries: Advances in information management for the virtual era
#index229481


#*Bijection between indexed monomials and standard bitableaux
#@S. S. Abhyankar,D. M. Kulkarni
#t1990
#cDiscrete Mathematics
#index487500


#*How to achieve FAME
#@James H. Griesmer,Se June Hong,John K. Kastner
#t1992
#cManaging expert systems
#index520937


#*Local Kriging interpolation: application to scattered data on the sphere
#@Pierre Montés
#t1991
#cCurves and surfaces
#index516342


#*Optical waveguides in general purpose parallel computers
#@Martin H. Davis, Jr.
#t1992
#c
#index217226


#*A graphical query interface based on aggregation/generalization hierarchies
#@William J. Weiland,Ben Shneiderman
#t1993
#cInformation Systems
#index216518


#*The Mentat Programming Language Users Manual and Tutorial
#@A. S. Grimshaw,E. Loyot
#t1990
#c
#index194614


#*Transfer of technology: information technology challenges for the transnational organization
#@Karen D. Loch
#t1991
#cProceedings of the 1991 Information Resources Management Association international conference on Managing information technology in a global society
#index544081


#*Randomized Parallel Selection
#@Sanguthevar Rajasekaran
#t1990
#cProceedings of the Tenth Conference on Foundations of Software Technology and Theoretical Computer Science
#index262388


#*Some properties of BLUE in a linear model and canonical correlations associated with linear transformations
#@C. G. Khatri
#t1990
#cJournal of Multivariate Analysis
#index465383


#*Robust control for manipulators with uncertain dynamics
#@Rahmat Shoureshi,Michael E. Momot,M. D. Roesler
#t1990
#cAutomatica (Journal of IFAC)
#index468229


#*Distributed Artificial Intelligence for Runtime Feature-Interaction Resolution
#@Hugo Velthuijsen
#t1993
#cComputer
#index446435
#!The feature-interaction problem has many different instances. It is argued that some instances lend themselves to a distributed artificial intelligence (DAI) approach. The use of DAI techniques in current telecommunications systems appears quite natural in light of two trends in the way these systems are designed: the distribution of functionality and the incorporation of intelligence. The author illustrates the relevance of DAI techniques to the feature-interaction problem by discussing existing work (lodes, team-CPS, multistage negotiation, and negotiating agents) that address one or more instances of the problem. He further identifies the kind of cooperation and coordination that the feature-interaction problem requires and the interesting research problems it poses to distributed artificial intelligence.


#*Algebraic feature extraction of image for recognition
#@Zi-Quan Hong
#t1991
#cPattern Recognition
#index511626


#*Proof methods and pragmatics for parallel programming
#@Chris Tofts
#t1992
#c
#index222736


#*Approximation Through Local Optimality: Designing Networks with Small Degree
#@R. Ravi,Balaji Raghavachari,Philip N. Klein
#t1992
#cProceedings of the 12th Conference on Foundations of Software Technology and Theoretical Computer Science
#index261284


#*An improvement of the Boshier-Nomura bound
#@Akira Hiraki
#t1994
#cJournal of Combinatorial Theory Series B
#index229331


#*Desktop videoconferencing: what's wrong with this picture?
#@Jeff Moad
#t1994
#cDatamation
#index226672


#*The interpolation problem for k-sparse sums of eigenfunctions of operators
#@Dima Yu Grigoriev,Marek Karpinski,Michael F. Singer
#t1991
#cAdvances in Applied Mathematics
#index523486


#*Computer integrated quality assurance
#@Frederick Chen
#t1991
#cComputers in Industry
#index538923


#*Unix tools
#@Balachander Krishnamurthy
#t1990
#cSoftware&mdash;Practice Experience
#index475873


#*NC machining with G-buffer method
#@Takafumi Saito,Tokiichiro Takahashi
#t1991
#cProceedings of the 18th annual conference on Computer graphics and interactive techniques
#index541701
#%143593
#%163481
#%163762
#%463423
#!The G-buffer method is applied to NC machining. A total NC system is created that consists of all essential functions, such as tool path generation, path verification, and feed rate control. Moreover, any combination of object surface and tool shape is acceptable. By utilizing G-buffers created from a parallel projection, the required NC functions are realized as image processing operations. This ensures that the NC software is independent from surface description. Conventional rendering software can be used to make the G-buffers. Any surface can be milled if it can be rendered by parallel projection. Tool shape changes can be easily handled by changing the image processing filters. 3D examples of geometric surfaces, mesh data, and volume data are milled with this method, and the results show that the method is very effective.


#*ScanMan Color: handing it to Logitech
#@Ed Perratore
#t1992
#cBYTE
#index213575


#*Human arm kinematics
#@Kuniji Asano
#t1991
#cThe fifth international symposium on Robotics research
#index535717


#*A Paradigm for Distributed Deadlock Avoidance in Multicomputer Networks
#@J. P. Samantarai
#t1992
#cProceedings of the 6th International Parallel Processing Symposium
#index365464


#*The Software Bus&mdash;its objective: the mutual integration of distributed software engineering tools
#@Malcolm Verrall
#t1991
#cSoftware engineering environments
#index224933


#*Implementation of DESIRE in a 0.5 &mgr;m NMOS process
#@D. N. Nichols,A. M. Goethals,P. De Geyter,L. Van Den Hove
#t1990
#cProceedings of the international conference on microlithography on Microcircuit engineering
#index531476


#*EUODHILOS-II on Top of GNU Epoch
#@Takeshi Ohtani,Hajime Sawamura,Toshiro Minami
#t1994
#cProceedings of the 12th International Conference on Automated Deduction
#index565122


#*Random bits bytes
#@Harold Joseph Highland
#t1994
#cComputers and Security
#index592141


#*Exponential stability for time dependent potentials
#@Antonio Giorgilli,Eduard Zehnder
#t1992
#cZeitschrift f&uuml;r Angewandte Mathematik und Physik (ZAMP)
#index213788


#*Laboratory evaluation of adaptive controllers for synchronous generators
#@Q. H. Wu,B. W. Hogg
#t1991
#cAutomatica (Journal of IFAC)
#index527731


#*Computer Associates International Inc.
#@J. William Semich
#t1993
#cDatamation
#index223640


#*I'm a stranger here myself: a consideration of women in computing
#@Janet Cottrell
#t1992
#cProceedings of the 20th annual ACM SIGUCCS conference on User services
#index515619


#*Phenomena of Localization
#@Simone Pribbenow
#t1991
#cText Understanding in LILOG, Integrating Computational Linguistics and Artificial Intelligence, Final Report on the IBM Germany LILOG-Project
#index278257


#*Client-server architecture
#@Mary E. S. Loomis
#t1992
#cJournal of Object-Oriented Programming
#index536449


#*Towards an understanding of unbounded variables in asynchronous systems
#@Ambuj K. Singh
#t1992
#cInformation Processing Letters
#index530957


#*On the massively parallel solution of the assignment problem
#@Joel M. Wein,Stavros A. Zenios
#t1991
#cJournal of Parallel and Distributed Computing
#index531961


#*Automating road surface analysis
#@L. Donnell Payne
#t1992
#cProceedings of the 1992 ACM/SIGAPP Symposium on Applied computing: technological challenges of the 1990's
#index536756


#*An investigation of an artificial neural network approach to multiple criteria ranking of alternatives
#@David Paul Stephens
#t1992
#c
#index220544


#*Subgraphs of a hypercube containing no small even cycles
#@Fan R. K. Chung
#t1992
#cJournal of Graph Theory
#index214295


#*Approximate string matching using within-word parallelism
#@Alden H. Wright
#t1994
#cSoftware&mdash;Practice Experience
#index208915


#*Automated Generation of Test Purposes for the OSE Distributed Transaction Processing Protocol
#@R. M. Barker,F. A. Brady
#t1993
#cProceedings of the IFIP TC6/WG6.1 Thirteenth International Symposium on Protocol Specification, Testing and Verification XIII
#index359692


#*Software Engineering und formale Verfahren (Sitzungsbericht)
#@Erika Horn
#t1992
#cSoftware Engineering im Unterricht der Hochschulen - Studienf&uuml;hrer Software Engineering, Workshop des German Chapter of the ACM und der Gesellschaft f&uuml;r Informatik (GI) am
#index366132


#*Massively parallel simulated annealing and its relation to evolutionary algorithms
#@Günter Rudolph
#t1993
#cEvolutionary Computation
#index350984
#!Simulated annealing and single-trial versions of evolution strategies possess a close relationship when they are designed for optimization over continuous variables. Analytical investigations of their differences and similarities lead to a cross-fertilization of both approaches, resulting in new theoretical results, new parallel population-based algorithms, and a better understanding of the interrelationships.


#*A procedure to evaluate the mean transport time in multibuffer deflection-routing networks with nonuniform traffic
#@Joseph Bannister,Flaminio Borgonovo,Mario Gerla
#t1992
#cProceedings of the eleventh annual joint conference of the IEEE computer and communications societies on One world through communications (Vol. 3)
#index538308


#*A framework for the non-monolithic implementation of protocols in the x-kernel
#@Parag K. Jain,Norman C. Hutchinson,Samuel T. Chanson
#t1994
#cProceedings of the High-Speed Networking Symposium on USENIX 1994 High-Speed Networking Symposium
#index421137
#%146201
#%177830
#%192615
#%219711
#%221432
#%317300
#%469132
#%475668
#%525747
#!This paper describes a framework for splitting the implementation of network protocols in the x-kernel into a user-level library, which implements the majority of the protocol functionality, and a kernel component, which provides a fast track to demultiplex packets into the appropriate recipient address space. The design also provides the user with flexibility to decide which aspects of the protocol implementation should be in user space and which should be in the kernel. We implement an example TCP/UDP-IP-Ethernet protocol stack and report on its performance which is competitive with monolithic implementations. The kernel level demultiplexing of network packets is well structured, modular and scalable. The cost of demultiplexing is shown to be insensitive to the number of user-level instances of protocols. The performance of the approach on a multiprocessor system shows that non-monolithic protocol implementations are potentially more parallelizable than traditional monolithic ones.


#*Nonlinear fourier analysis for the infinite-interval Korteweg-de Vries equation II: numerical tests of the direct scattering transform
#@A. Provenzale,A. R. Osborne
#t1991
#cJournal of Computational Physics
#index519081


#*DISQUE: Ein verteilter Simulator f&uuml;r Warteschlangennetze auf Transputern
#@Jörg Richter
#t1991
#cParallele Datenverarbeitung mit dem Transputer, 3. Transputer-Anwender-Treffen
#index255693


#*Hard Disk Management with DOS 5, 3rd edition
#@Dan Gookin
#t1992
#c
#index624233


#*Shootout-89, An Evaluation of Knowledge-Based Weather Forecasting Systems
#@W. R. Moninger
#t1990
#cProceedings of the Fifth Annual Conference on Uncertainty in Artificial Intelligence
#index258997


#*Estimation of the optimum relaxation factors in partial factorization iterative methods
#@Z. I. Woźnicki
#t1993
#cSIAM Journal on Matrix Analysis and Applications
#index218196


#*The effects on decision task performance of computer synthetic voice output
#@Michael J. DeHaemer,William A. Wallace
#t1992
#cInternational Journal of Man-Machine Studies
#index535410


#*Robotic understanding
#@J. Feldman
#t1990
#cAI Magazine
#index458691


#*Dynamic routing in multiparented networks
#@Richard J. Gibbens,Frank P. Kelly,Stephen R. E. Turner
#t1993
#cIEEE/ACM Transactions on Networking (TON)
#index211771
#%209576


#*An experiment on measuring application performance over the Internet
#@Calton Pu,Frederick Korz,Robert C. Lehman
#t1991
#cACM SIGMETRICS Performance Evaluation Review
#index519061
#!The use of wide area networks (WANs) such as the Internet is growing at a tremendous rate.Such networks hold great promise for new types of distributed applications, which will be widely distributed, highly replicated, intensely interactive, and adaptive to many types of network conditions. Developing such applications will require a solid understanding of the performance and availability characteristics of WANs as they evolve. The ability to measure the effect of these conditions will, for example, be important for large-volume applications such as digital libraries, and for near-real-time applications such as collaborative research and teleconferencing.


#*Multimedia Synchronization: The Role of the Communication System
#@Theodoros Bozios,Nikos B. Pronios
#t1993
#cProceedings of the 2nd Intermational Conference on Broadband Islands: Towards Integration
#index557051


#*Representations of planar graphs
#@Graham R. Brightwell,Edward R. Scheinerman
#t1993
#cSIAM Journal on Discrete Mathematics
#index208580


#*Cluster validity based on the hard tendency of the fuzzy classification
#@F. F. Rivera,E. L. Zapata,J. M. Carazo
#t1990
#cPattern Recognition Letters
#index485555


#*Q-scale measures of fuzzy sets
#@Kai-Yuan Cai
#t1994
#cFuzzy Sets and Systems
#index211552


#*Modular communication subsystem implementation using a synchronous approach
#@Claude Castelluccia,Walid Dabbous
#t1994
#cProceedings of the High-Speed Networking Symposium on USENIX 1994 High-Speed Networking Symposium
#index432365
#%146201
#%475668
#!The lack of flexibility and performance of current communication subsystems has led researchers to look for new protocol architectures. A new design philosophy, flexible and efficient, referred to in the literature as "function-based communication model" is emerging and seems to be very promising. It consists of designing application-tailored communication subsystems adapted to the specific requirements of a given application. The flexibility of such a solution leads to very efficient implementations integrating only required functionalities. In this paper, we propose a flexible model which uses a synchronous language to synthesize communication subsystems from functional building blocks. We prove the feasibility of our approach by implementing a data transfer protocol using Esterel, a synchronous language. Communication subsystem specifications in our model are very modular; they are composed of parallel modules, implementing the di erent functionalities of the communication subsystem, which synchronize and communicate using signals. The Esterel compiler generates from this parallel specification a sequential automaton by resolving resource conflicts. The design flexibility of our approach is demonstrated; modules are selected according the application requirements and compiled to generate an integrated implementation.


#*International Conference on Simulation in Engineering Education, 1993
#@Charles E. Knadler
#t1993
#c
#index255042


#*Stochastic single machine scheduling with quadratic early-tardy penalties
#@John Mittenthal,M. Raghavachari
#t1993
#cOperations Research
#index212514


#*The influence of local loop characteristics on services in intelligent networks
#@Vasant Chandkumar Ramkumar
#t1991
#c
#index528673


#*Increasing user interaction during high-level synthesis
#@Robert A. Walker,Shivkumar Ramabadran,Rajive Joshi,Steinar Flatland
#t1991
#cProceedings of the 24th annual international symposium on Microarchitecture
#index509714
#%79445
#%85991
#%94422
#%162410
#%452662
#%466635
#%516487
#%543122


#*A model of explanation for financial knowledge-based systems
#@A. J. Feelders
#t1992
#cComputer Science in Economics and Management
#index226849


#*Reuse of Proofs in Software Verification
#@Wolfgang Reif,Kurt Stenzel
#t1993
#cProceedings of the 13th Conference on Foundations of Software Technology and Theoretical Computer Science
#index263969


#*Hypercomplex spectral transformations
#@Todd Anthony Ell
#t1992
#c
#index536602


#*CSCL: Experience in the Classroom
#@Tim Koschmann
#t1992
#cACM SIGCUE Outlook
#index311665


#*Line-oriented layout with TEX
#@Alan Hoenig
#t1990
#cTEX: applications, uses, methods
#index510628


#*On the complexity of equivalence between recursive and nonrecursive Datalog programs
#@Surajit Chaudhuri,Moshe Y. Vardi
#t1994
#cProceedings of the thirteenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems
#index229191
#%159977
#%166970
#%167001
#%176571
#%184030
#%213774
#%220239
#%237378
#%473970
#%242483
#%544764
#%486409
#%509504
#%485734
#%543245
#%509839
#%480188
#%470694
#%466046
#%474814
#%553848
#!In a previous paper, we have proved tight complexity bounds for the equivalence of recursive and nonrecursive Datalog programs: triply exponential time in general and doubly-exponential space for linear programs. In this paper, we show that under realistic restrictions on the classes programs under consideration, equivalence of recursive and nonrecursive programs can be less intractable; for the classes of programs we consider the complexity of equivalence ranges from NP to co-NEXPTIME.


#*Stratification and cut-elimination
#@Marcel Crabbé
#t1991
#cJournal of Symbolic Logic
#index511490


#*All-optical switching in nonlinear fibre loop mirror devices
#@B. K. Nayar,K. J. Blow,N. J. Doran
#t1991
#cOptical Computing Processing
#index541550


#*A Correctness Model for Pipelined Multiprocessors
#@Phillip J. Windley,Michael L. Coe
#t1994
#cProceedings of the Second International Conference on Theorem Provers in Circuit Design - Theory, Practice and Experience
#index567647


#*How to derive a new deductive and object-oriented database system from a well-defined F-logic database
#@Shieh-Loun Lee
#t1992
#c
#index522618


#*Intel, AT T, and AMD continue the chase
#@Bob Ryan
#t1993
#cBYTE
#index209907


#*Linguistico-statistical approach and logics applied in documentary system
#@Omar Larouk
#t1993
#cProceedings of the 1993 ACM/SIGAPP symposium on Applied computing: states of the art and practice
#index225145
#%148114
#%177439
#%480879
#%456525


#*Time series and dependent variables
#@Robert Savit,Matthew Green
#t1991
#cPhysica D
#index509654


#*The derivation of a high-speed sieve device
#@Cameron Douglas Patterson
#t1991
#c
#index198819


#*Mastering Today's Software: DOS 5.0, WordPerfect 5.1, Quattro Pro 4.0, Paradox 4.0
#@Edward G. Martin,Charles S. Parker
#t1993
#c
#index235260


#*Information retrieval based on fuzzy associations
#@S. Miyamoto
#t1990
#cFuzzy Sets and Systems
#index541390


#*The Use of Nonlinear Elimination in Steady-State Circuit \& Device Simulation
#@J D Rose,Paul Lanzkron,James Wilkes,Stephan Muller,Wolfgang Fichtner
#t1992
#c
#index115842
#!Certain problems in steady-state circuit and device simulation demonstrate slow convergence using global Newton''s method. We introduce a method that has been shown to be effective in solving these types of problems. The method is based on nonlinear elimination. We will outline how to implement the method and give various examples from both circuit and device simulation in which the method converges.


#*Hard disk management (3rd ed.)
#@Van Wolverton
#t1991
#c
#index532130


#*An octree algorithm for displaying implicitly defined mathematical functions
#@K. G. Suffern
#t1990
#cAustralian Computer Journal
#index463677


#*A SOR iterative algorithm for the finite difference and the finite element methods that is efficient and parallelizable
#@K. P. Wang,J. C. Bruch, Jr.
#t1994
#cAdvances in Engineering Software
#index586859


#*Lp-spectral estimation with an L&infin; -upper bound
#@R. E. Cole,R. K. Goodrich
#t1993
#cJournal of Optimization Theory and Applications
#index208918


#*Inside Adobe PhotoShop 3: With Cdrom, 2nd edition
#@Gary David Bouton,Barbara Mancuso Bouton
#t1994
#c
#index245861
#!:Written for the intermediate computer user and graphic arts professional, this tutorial and reference explains image types, acquisition techniques, and scanning methods. This book also discusses the tools, filters, and techniques used to create eye-catching special effects.Includes 16 full-color pages that illustrate what users can create with PhotoshopShows readers how to use Photoshop with other applications such as CorelDRAW!, Pixar Typestry, and Fractal Design PainterCD-ROM contains stock photos, textures, and shareware to help the reader complete the book's exercises


#*Using QEMM: Managing Memory with the Best-Selling Memory Management System
#@Phillip R. Robinson
#t1992
#c
#index238625


#*A global, dynamic register allocation and binding for a data path synthesis system
#@Nam-Sung Woo
#t1991
#cProceedings of the 27th ACM/IEEE Design Automation Conference
#index536813
#%74967
#%82793
#%150284
#%472931
#%482028
#%552466
#!We developed a new algorithm for efficient register allocation and binding used in data path synthesis. Our algorithm determines both the number of registers and the mapping from variables to registers simultaneously during data path allocation so that the cost, i.e., area, of the registers and connections to/from the registers can be minimized. The algorithm selects the &ldquo;best&rdquo; register for each input and/or output variable of operations. This register allocation/binding algorithm is used with a data path allocation algorithm that exploits trade-off among all kinds of hardware elements. We present experimental results of our algorithm.


#*Speech-based alarm displays
#@Neville Stanton
#t1993
#cInteractive speech technology: human factors issues in the application of speech input/output to computers
#index598050


#*A multigrid method for solving variational inequalities
#@V. G. Bel'skii
#t1991
#cComputational Mathematics and Mathematical Physics
#index213645


#*Plasma simulation of a Langmuir probe with normal magnetic field
#@R. J. Armstrong,K.-B. Liland,J. Trulsen
#t1992
#cProceedings of the eleventh annual international conference of the Center for Nonlinear Studies on Experimental mathematics : computational issues in nonlinear science: computational issues in nonlinear science
#index529739


#*An environment for processing images of historical documents
#@Rafael Dueire Lins,Mário Guimarães Neto,Leopoldo Fraņa Neto,Luciano Galdino Rosa
#t1994
#cMicroprocessing and Microprogramming
#index604386


#*On Single-Fault Set Diagnosability in the PMC Model
#@J. Stephens,V. Raghavan
#t1993
#cIEEE Transactions on Computers
#index439777
#%154620
#%155139
#%157161
#%527028
#%477768
#!A. Somani et al, (1987) introduced the single-fault set diagnosability measure and gave an O(n/sup 3.5/) algorithm for determining it in the PMC model. The authors present a new algorithm for the same problem with a time complexity of only O(n/sup 2.5/).


#*An analytical approach to performance/cost modeling of parallel computers
#@John B. Andrews,Constantine D. Polychronopoulos
#t1991
#cJournal of Parallel and Distributed Computing
#index532426


#*Interval choice under constraints on error functions
#@Rafig P. Agaev
#t1994
#cInformation Sciences&mdash;Informatics and Computer Science: An International Journal
#index223098


#*Precision synchronization of computer network clocks
#@David L. Mills
#t1994
#cACM SIGCOMM Computer Communication Review
#index207764
#%119562
#%146660
#%181301
#%519348
#%515678
#!This paper builds on previous work involving the Network Time Protocol, which is used to synchronize computer clocks in the Internet. It describes a series of incremental improvements in system hardware and software which result in significantly better accuracy and stability, especially in primary time servers directly synchronized to radio or satellite time services. These improvements include novel interfacing techniques and operating system features. The goal in this effort is to improve the synchronization accuracy for fast computers and networks from the tens of milliseconds regime of the present technology to the submillisecond regime of the future.In order to assess how well these improvements work, a series of experiments is described in which the error contributions of various modern Unix system hardware and software components are calibrated. These experiments define the accuracy and stability expectations of the computer clock and establish its design parameters with respect to time and frequency error tolerances. The paper concludes that submillisecond accuracies are indeed practical, but that further improvements will be possible only through the use of temperature-compensated local clock oscillators.


#*Key information liability issues facing managers: software piracy, proprietary databases, and individual rights to privacy
#@Detmar W. Straub, Jr.,Rosann Webb Collins
#t1990
#cMIS Quarterly
#index460561


#*A descriptive analysis of students' interaction with an integrated-media composing program
#@Arthur Conrad Johnson
#t1992
#c
#index221793


#*Detection of dry-etched induced damage by non-contact photo-thermal radiometry, photoluminescence and deep level transient spectroscopy
#@P. A. F. Herbert,G. M. Cream,I. Little
#t1991
#cMicroelectronic Engineering
#index516489


#*PIPADS&mdash;a low cost real-time visualization tool
#@A. Spray,H. Schröder,K. T. Lie,E. Plesner,P. Bray
#t1993
#cProceedings of the 1993 ACM/IEEE conference on Supercomputing
#index214886
#%173822
#%177286
#%551191
#%458168


#*Asymptotic analysis of the exponential penalty trajectory in linear programming
#@R. Cominetti,J. San Martín
#t1994
#cMathematical Programming: Series A and B
#index585005


#*X-REF: an extended reliability evaluation framework for computer systems using fuzzy logic
#@Anup Kumar,Rammohan K. Ragade
#t1994
#cJournal of Computer and Software Engineering
#index587935


#*CASE Support for the Software Process: Advances and Problems
#@Bernard Lang
#t1991
#cProceedings of the 3rd European Software Engineering Conference
#index360409


#*An IBIS and object-oriented approach to scientific research data management
#@Won Kim,Yongmoo Suh,Andrew B. Whinston
#t1993
#cJournal of Systems and Software
#index226954


#*Learner: a domain-independent concept acquisition system
#@Kunal Sen
#t1992
#c
#index209398


#*Analysis and modeling in software development
#@Timothy D. Korson,Vijay K. Vaishnavi
#t1992
#cCommunications of the ACM
#index530425


#*Microcontroller technology: the 68HC11
#@Peter Spasov
#t1993
#c
#index513276


#*New applications of a fast propositional calculus decision procedure
#@Shie-Jue Lee,David A. Plaisted
#t1990
#cProceedings of the eighth biennial conference of the Canadian Society for Computational Studies of Intelligence on CSCSI-90
#index481844


#*The characterization of two scientific workloads using the CRAY X-MP performance monitor
#@Elizabeth Williams,C. Thomas Myers,Rebecca Koskela
#t1990
#cProceedings of the 1990 ACM/IEEE conference on Supercomputing
#index509528
#!The weekend production period on a CRAY X-MP was monitored for several months at each of two supercomputing sites. The hardware performance monitor available on the X-MP was used to collect the data at each site. Various metrics are computed using the measured data. These metrics include rates, such as mops and Mflops, percent vectorization, average vector lengths, memory reference rates, memory contention, the operation mix, I/O rates, hardware metrics such as operations per clock period, and percentage of time waiting to issue an instruction that is waiting on some hardware component. These metrics are used in evaluating the performance of the workloads and the X-MP architecture. These metrics may also give insight into the design of similar register based architectures and may be useful in parameterizing models in future work.


#*Agentsheets: a tool for building domain-oriented visual programming environments
#@Alex Repenning
#t1993
#cProceedings of the INTERACT '93 and CHI '93 conference on Human factors in computing systems
#index221436
#%526207
#!Visual programming systems are supposed to simplify programming by capitalizing on innate human spatial reasoning skills. I argue that: (i) good visual programming environments should be oriented toward their application domains, and (ii) tools to build domain-oriented environments are needed because building such environments from scratch is very difficult. The demonstration illustrates how the visual programming system builder called Agentsheets addresses these issues and demonstrates several applications built using Agentsheets.


#*A nonlinear diffusion system on the discrete space-time lattice: as a simple model for migration processes
#@Yong Liu
#t1991
#cPhysica D
#index534661


#*Simulation optimization using simulated annealing
#@Jorge Haddock,John Mittenthal
#t1992
#cComputers and Industrial Engineering
#index224453


#*Software Architectures Supporting Tailor-Made Look and Feel of Customized Applications
#@Kai Mertins,A. Salisch,F. Duttenhofer
#t1991
#cProceedings of the IFIP TC5/WG5.7 Working Conference on New Approaches towards 'One-Of-A-Kind' Production
#index266648


#*Term rewriting properties of SOS axiomatisations
#@Doeko J.B. Bosscher
#t1994
#c
#index117306


#*Can stochastic renewal of maps be a model for cerebral cortex?
#@Ichiro Tsuda
#t1994
#cProceedings of the NATO advanced research workshop and EGS topical workshop on Chaotic advection, tracer dynamics and turbulent dispersion
#index215548


#*Effects of computer aided quality circles on organizational productivity and satisfaction
#@D. Elmuti,Y. Kathawala
#t1990
#cInformation and Management
#index530486


#*Paedagogische Theorien Der Interaktion Im Zeitalter Neuer Technologien: Versuch Einer Didaktischen Bewertung Von Interaktiven Computerlehr Lernprogrammen
#@Claudia de Witt
#t1992
#c
#index610234


#*A composite integration scheme for the numerical solution of systems of parabolic PDEs in one space dimension
#@John Carroll
#t1993
#cJournal of Computational and Applied Mathematics
#index227880


#*Checking approximate computations over the reals
#@S. Ar,M. Blum,B. Codenotti,P. Gemmell
#t1993
#cProceedings of the twenty-fifth annual ACM symposium on Theory of computing
#index226120
#%157161
#%451565
#%530338
#%516924
#%548902


#*Systolic loops
#@Michael Wolfe
#t1992
#cLanguages, compilers and run-time environments for distributed memory machines
#index516842


#*On multiple solutions for a class of semilinear wave equations
#@Juha Berkovits,Vesa Mustonen
#t1991
#cNonlinear Analysis: Theory, Methods Applications
#index542328


#*HP serves up two winning network printers
#@Richard Fox
#t1993
#cBYTE
#index223549


#*Interpolation of entire functions associated with some Freud weights, II
#@Radwan Al-Jarrah,Sayel Ali
#t1994
#cJournal of Approximation Theory
#index218834


#*AC Unification Through Order-Sorted AC1 Unification
#@Eric Domenjoud
#t1991
#cProceedings of the 4th International Conference on Rewriting Techniques and Applications
#index271948


#*Pavement network optimization and analysis
#@Chen Ping Wang
#t1992
#c
#index211951


#*Singularities of the X-ray transform and limited data tomography in R2 and R3
#@Eric Todd Quinto
#t1993
#cSIAM Journal on Mathematical Analysis
#index218046


#*Repairing the cracks in windows
#@Stan Miastkowski
#t1991
#cBYTE
#index514838


#*Complex object multi-level fixpoint queries
#@Jan Van den Bussche
#t1991
#cProceedings of the 3rd symposium on Mathematical fundamentals of database and knowledge base systems
#index542935


#*Kernel estimation in change-point hazard rate models
#@A. Antoniadis,G. Grégoire
#t1991
#cCurves and surfaces
#index517229


#*MVS/TSO mastering CLISTs
#@Barry K. Nirmal
#t1990
#c
#index524352


#*Network architectures for high performance computing environments
#@Ronald James Vetter
#t1992
#c
#index529444


#*On the deformation of image intensity and zero-crossing contours under motion
#@Jian Wu,K. Wohn
#t1991
#cCVGIP: Image Understanding
#index531844


#*An Automatic Knowledge Acquisition Tool
#@Nicholas V. Findler
#t1992
#cProceedings of the International Summer School on Advanced Topics in Artificial Intelligence
#index275125


#*The Hausdorff-Kuratowski hierarchy of &ohgr;-regular languages and a hierarchy of Muller automata
#@Rana Barua
#t1992
#cTheoretical Computer Science
#index523284


#*What Every Paradox 4.5 for Windows Programmer Should Know, with Disk
#@Mike Prestwood
#t1993
#c
#index610993


#*How to improve signature schemes
#@Gilles Brassard
#t1990
#cProceedings of the workshop on the theory and application of cryptographic techniques on Advances in cryptology
#index521283


#*Multiple knife-edge diffraction and radio propagation in urban environments
#@Howard Hao Xia
#t1991
#c
#index528172


#*Verification of a pipelined microprocessor using Clio
#@Mark Bickford,Mandayam Srivas
#t1990
#cProceedings of the Mathematical Sciences Institute workshop on Hardware specification, verification and synthesis: mathematical aspects
#index472755


#*A modified Adams method for nonstiff and mildly stiff initial value problems
#@J. R. Cash,S. Semnani
#t1993
#cACM Transactions on Mathematical Software (TOMS)
#index229258
#%168770
#%177495
#%182869
#%486285
#!Adams predictor-corrector methods, and explicit Runge&ndash;Kutta formulas, have been widely used for the numerical solution of nonstiff initial value problems. Both of these classes of methods have certain drawbacks, however, and it has long been the aim of numerical analysts to derive a class of formulas that has the advantages of both Adams and Runge&ndash;Kutta methods and the disadvantages of neither! In this paper we derive a class of modified Adams formulas that attempts to achieve this aim. When used in a certain precisely defined predictor-corrector mode, these new formulas require three function evaluations per step, but have much better stability than Adams formulas. This improved stability makes the modified Adams formulas particularly effective for mildly stiff problems, and some numerical evidence of this is given. We also consider the performance of the new class of methods on the well-known DETEST test set to show their potential on general nonstiff initial value problems.


#*Application of eigenvalue sensitivity and eigenvector sensitivity in eigencomputations
#@Purandar Sarmah
#t1993
#c
#index186396


#*Controlling key violations
#@Brian J. Smith
#t1991
#cData Based Advisor
#index539648


#*Qualitative shape&mdash;some computational aspects
#@Jan-Olof Eklundh,Tony Lindeberg,Harald Winroth
#t1992
#cProceedings of the international workshop on Visual form: analysis and recognition
#index526942


#*TeraNet: a multi-gigabits per second ATM network
#@Rafael Gidron
#t1992
#cComputer Communications
#index509929


#*Scheduling Instructions by Direct Placement
#@Robert Griesemer
#t1992
#cProceedings of the 4th International Conference on Compiler Construction
#index277200


#*Hierarchical composition of protocols
#@N. A. Anisimov
#t1990
#cAutomatic Control and Computer Sciences
#index528263


#*Automated tolerance analysis for mechanical assemblies modeled with geometric features and relational data structure
#@P. Treacy,J. B. Ochs,T. M. Ozsoy,Nanxin Wang
#t1991
#cComputer-Aided Design
#index512050


#*Discovery of knowledge associated with concept hierarchies in database
#@Xiaohua Hu,Nick Cercone,Jiawei Han
#t1993
#cProceedings of the third international conference on Young computer scientists
#index222383


#*Sorting and merging on the DAP
#@D. Bhagavathi,W. M. Denny,C. Grosch,P. J. Looges,S. Olariu
#t1992
#cProceedings of the 30th annual Southeast regional conference
#index622263
#%464828
#%467585
#%475020
#%542190
#!The sorting problem is of fundamental importance in non-numerical algorithms. Many applications require the ordering of data based the relationship of some set of keys with in the data. Merging is a natural companion of sorting, and is known to yield a very efficient sorting algorithm in sequential processing. Numerous sorting and merging techniques have been developed for many actual and theoretical models, we examine a number of these techniques for implementation on the Distributed Array of Processors, DAP.


#*Self-explained toolboxes
#@Gustavo Arango
#t1992
#cBuilding an object-oriented database system: the story of 02
#index518437


#*Slender jets and thin sheets with surface tension
#@Lu Ting,Joseph B. Keller
#t1990
#cSIAM Journal on Applied Mathematics
#index486913


#*Computing archive on CD-ROM
#@
#t1993
#cComputer
#index446689


#*Information technologies and rural economic development
#@Sherry Emery
#t1990
#cProceedings of the conference on Computers and the quality of life
#index452496


#*Die Realisierung eines Echtzeit-UNIX f&uuml;r den Einsatz in der Automatisierungstechnik
#@Roland Weigel
#t1991
#cProze&szlig;rechnersysteme '91, Automatisierungs- und Leitsysteme in den neunziger Jahren
#index278355


#*Exploiting parallelism in sequential programs using data and control flow analysis
#@Ghassan Morris Azar
#t1992
#c
#index536967


#*Shape and Nonrigid Motion Estimation Through Physics-Based Synthesis
#@D. Metaxas,D. Terzopoulos
#t1993
#cIEEE Transactions on Pattern Analysis and Machine Intelligence
#index439984
#%143918
#%144359
#%177630
#%229457
#%551707
#%514356
#%466541
#%450913
#%530637
#%535378
#%455993
#%539954
#%536679
#!A physics-based framework for 3-D shape and nonrigid motion estimation for real-time computer vision systems is presented. The framework features dynamic models that incorporate the mechanical principles of rigid and nonrigid bodies into conventional geometric primitives. Through the efficient numerical simulation of Lagrange equations of motion, the models can synthesize physically correct behaviors in response to applied forces and imposed constraints. Applying continuous Kalman filtering theory, a recursive shape and motion estimator that employs the Lagrange equations as a system model is developed. The system model continually synthesizes nonrigid motion in response to generalized forces that arise from the inconsistency between the incoming observations and the estimated model state. The observation forces also account formally for instantaneous uncertainties and incomplete information. A Riccati procedure updates a covariance matrix that transforms the forces in accordance with the system dynamics and prior observation history. Experiments involving model fitting and tracking of articulated and flexible objects from noisy 3-D data are described.


#*Branching Bisimulation for Context-free Processes
#@Didier Caucal
#t1992
#cProceedings of the 12th Conference on Foundations of Software Technology and Theoretical Computer Science
#index276093


#*Counting circular arc intersections
#@Pankaj K. Agarwal,Micha Sharir
#t1991
#cProceedings of the seventh annual symposium on Computational geometry
#index532118
#%116443
#%147056
#%147906
#%174344
#%381505
#%455276
#%460701
#%461823
#%526288


#*A logical query language for hypermedia systems
#@Catriel Beeri,Yoram Kornatzky
#t1994
#cInformation Sciences&mdash;Informatics and Computer Science: An International Journal
#index212469


#*Performance comparison of neural networks and pattern recognition techniques for classifying ultrasonic transducers
#@M. S. Obaidat,D. S. Abu-Saymeh
#t1992
#cProceedings of the 1992 ACM/SIGAPP Symposium on Applied computing: technological challenges of the 1990's
#index522203
#%146290
#%185023
#%454562
#%509576


#*Graphical Robot Simulation within the Framework of an intelligent TeleSensor Programming System
#@Bernhard Brunner,Klaus Arbler,Gerd Hirzinger
#t1993
#cGraphics and Robotics
#index568930


#*The construction of large sets of disjoint Mendelsohn triple systems of order 2n + 2
#@Qingde Kang
#t1991
#cDiscrete Mathematics
#index526426


#*Even With Windows World, Comdex Didn't Rise Again
#@
#t1991
#cIEEE Software
#index443930


#*A note on estimating &pgr; by a turtle tossing needles
#@Lei Zhang
#t1993
#cMathematics and Computer Education
#index210603


#*OASIS: an open architecture sieve system for problems in number theory
#@Allan Jeffrey Stephens
#t1990
#c
#index528004


#*Application of symbolic algebra to the analysisof plates on variable elastic foundation
#@Moshe Eisenberger
#t1990
#cJournal of Symbolic Computation
#index471376
#!The analysis of plates on elastic foundation is very common in engineering. Usually the Winklermodel is adopted, and it is assumed that the foundation stiffness is constant over the area of the plate. In many cases, such as large foundation mats and in vertical slurry walls, the foundation stiffness varies and approximate solutions are found. Using symbolic algebra, an approximate finite element displacement method is introduced to analyse the problem of plates on a variable Winkler elastic foundation. It is proposed to add to the conventional plate element stiffness matrix, another matrix that will account for the effect of the variable foundation. The solution using this approach is compared to the solutions which were obtained using other approximation techniques. With the proposed method the convergence is much faster, with fewer elements, and saves computer and data preparation time.


#*Rewrite systems
#@Nachum Dershowitz,Jean-Pierre Jouannaud
#t1991
#cHandbook of theoretical computer science (vol. B): formal models and semantics
#index534936


#*Behavior of the X-window System Under Normal Usage
#@L J Furlani
#t1994
#c
#index114805


#*Time-Constrained Automata (Extended Abstract)
#@Michael Merritt,Francesmary Modugno,Marc R. Tuttle
#t1991
#cProceedings of the 2nd International Conference on Concurrency Theory
#index264484


#*The computational complexity of abduction
#@Tom Bylander,Dean Allemang,Michael C. Tanner,John R. Josephson
#t1991
#cArtificial Intelligence
#index521988


#*Protocol Verification System for SDL Specifications Based on Acyclic Expansion Algorithm and Temporal Logic
#@Hironori Saito,Toru Hasegawa,Yoshiaki Kakuda
#t1991
#cProceedings of the IFIP TC6/WG6.1 Fourth International Conference on Formal Description Techniques for Distributed Systems and Communication Protocols: Formal Description Techniques, IV
#index354976


#*Fuzzy Engineering toward Human Friendly Systems: Proceedings of the International Fuzzy Engineering Symposium, November 13-15, 1991, Yokohama, Japan, 1st edition
#@Michio Sugeno,Toshiro Terano,M. Mukaidono
#t1992
#c
#index245927


#*Electronic imaging and image processing: an assessment of technology, applications, and products (vol. 1)
#@Terri C. Walker,Richard K. Miller
#t1991
#c
#index534776


#*Challenges in distributed systems
#@
#t1993
#cProceedings of the 1993 conference of the Centre for Advanced Studies on Collaborative research: distributed computing - Volume 2
#index304404


#*Spreadsheet-based interactive graphics: from prototype to tool
#@Nicholas Wilde,Clayton Lewis
#t1990
#cProceedings of the SIGCHI conference on Human factors in computing systems: Empowering people
#index482572
#%146852
#%181355
#%319507
#%450502
#%474439
#%485127
#!The NoPumpG prototype [7,8] suggested that the spreadsheet model of computation could simplify the creation of some types of interactive graphical application when compared with other approaches. We report here experience in developing an enhanced follow-on system, NoPumpII, and describe three applications developed using it. We conclude that (1) the potential advantages of the spreadsheet model are realized in this application experience, (2) revisions to the prototype design have permitted an increase in the complexity and scale of applications, and (3) there remain limitations in the current design which, if redressed, would further enlarge the scope of application. More generally we conclude that alternative computational models are an important area of exploration for HCI research.


#*Intelligent Decision Support: Handbook of Applications and Advances of the Rough Sets Theory
#@Roman Slowinski
#t1992
#c
#index624691


#*Visual Basic Power Programming
#@Namir Clement Shammas
#t1992
#c
#index612407


#*Assembler Language for the IBM System 370: A Modular Approach
#@David M. Collopy
#t1994
#c
#index612695


#*Approximation of upper Lyapunov exponents of bilinear stochastic differential systems
#@Denis Talay
#t1991
#cSIAM Journal on Numerical Analysis
#index526061


#*Structured sampling and reconstruction of illumination for image synthesis
#@Georgios Drettakis
#t1994
#c
#index187151


#*Tight bounds for weakly bounded protocols
#@Ewan Tempero,Richard Ladner
#t1990
#cProceedings of the ninth annual ACM symposium on Principles of distributed computing
#index472287
#%167332
#%321526
#%459796
#%468167
#%480934
#%485093


#*Generating languages of solid models
#@Jeff Heisserman,Robert Woodbury
#t1993
#cProceedings on the second ACM symposium on Solid modeling and applications
#index227666
#%181387
#%276908
#%487175
#%332787
#%513743
#%473144
#%510805
#%453302


#*In-trees and plane embeddings of outerplanar graphs
#@M. Syslo,P. Winter
#t1990
#cBIT
#index450977


#*Production Rule Verification for Quasi-Delay-Insensitive Circuits
#@James N. Cook
#t1993
#c
#index121023
#!No abstract available. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Detection of singular points in fingerprint images
#@V. S. Srinivasan,N. N. Murthy
#t1992
#cPattern Recognition
#index540072


#*Computer numerical control programming
#@Michael Sava,Joseph Pusztai
#t1990
#c
#index482993


#*An improved empirical force field for saturated hydrocarbons
#@Jan L. M. Dillen
#t1990
#cJournal of Computational Chemistry
#index469043


#*A simulated annealing heuristic for scheduling in a flowshop with bicriteria
#@Rajesh Gangadharan,Chandrasekharan Rajendran
#t1994
#cComputers and Industrial Engineering
#index596216


#*Distributed shared memory with versioned objects
#@Michael J. Feeley,Henry M. Levy
#t1992
#cconference proceedings on Object-oriented programming systems, languages, and applications
#index542976
#%167985
#%173570
#%177230
#%177780
#%183868
#%322589
#%328436
#%450521
#%452344
#%455846
#%487543
#%510916
#%536575


#*Cultural consumption, growth and chaos
#@Pasquale Lucio Scandizzo
#t1993
#cSimulation Practice and Theory
#index206445


#*Strings, trees, and patterns
#@Rakesh M. Verma
#t1992
#cInformation Processing Letters
#index531039


#*Quality assurance potential of analyst/designer workbenches
#@J. B. Cowan
#t1990
#cInformation and Software Technology
#index469776


#*Scheduling of OR-parllel Prolog on a scalable, reconfigurable, distributed-memory multiprocessor
#@J. Briat,M. Favre,C. Geyer,J. Chassin de Kergommeaux
#t1991
#cProceedings on Parallel architectures and languages Europe : volume II: parallel languages: volume II: parallel languages
#index535215


#*SPRAY RENDERING: A NEW FRAMEWORK FOR VISUALIZATION
#@Alex Pang,Kyle Smith
#t1993
#c
#index199412
#!We propose a new framework for doing scientific visualization that allows the users to freely explore their data set. This framework uses a metaphorical abstraction of a virtual can of spray paint that can be used to render data sets and make them visible. Different cans of spray paint may be used to color the data differently. Different types of spray paint may also be used to highlight different features in the data set. To achieve this, individual paint particles are endowed with intelligent behavior. This idea offers several advantages over existing methods: (1) it generalizes the current techniques of surface, volume and flow visualization under one coherent framework; (2) it works with regular and irregular grids as well as sparse and dense data sets; (3) it allows selective progressive refinement and can be implemented on parallel architectures in a straight forward manner; (4) it is modular, extensible and provides scientists with the flexibility for exploring relationships in their data sets in natural and artistic ways.


#*Service activities and regional development: a swiss case study
#@Antoine S. Bailly
#t1990
#cInformation society and spatial structure
#index527468


#*Characterization and modeling of MOS field-effect transistors in the 60-300 K temperature range
#@Cheng-Liang Huang
#t1991
#c
#index542217


#*Using ClarisWorks, 1st edition
#@Laurie Miller Love
#t1992
#c
#index625720


#*On the location of the zeros of a polynomial
#@Robert B. Gardner,N. K. Govil
#t1994
#cJournal of Approximation Theory
#index217485


#*Finite state machine synthesis with embedded test function
#@V. D. Agrawal,K.-T. Cheng
#t1990
#cJournal of Electronic Testing: Theory and Applications
#index460169


#*Knowledge strata: reactive planning with a multi-level architecture
#@Lee Spector,James Hendler
#t1990
#cComputer Science Technical Report Series; Vol. CS-TR-2564
#index526356


#*Procedure for Evaluating Human-Computer Interface Development Tools
#@Deborah Hix
#t1990
#c
#index185819
#!Human-computer interface development tools are interactive systems that support production and execution of the human-computer interface. With their recent proliferation, evaluations and comparisons are constantly done, but without a formal, structured approach. Addressing these problems is difficult, largely because of the relative newness of such tools, because of the many different kinds of systems that are called UIMS, and because of their inherent complexity. These tools are complex because human-computer interfaces, which produce tools, are complex.


#*Multivalued dependencies in fuzzy relational databases
#@R. C. Tripathy,P. C. Saxena
#t1990
#cFuzzy Sets and Systems
#index519264


#*Stress dynamics of information systems managers: a contingency model
#@Eldon Y. Li,Abraham Rami Shani
#t1991
#cJournal of Management Information Systems
#index532643


#*A Performance Analysis of Timed Synchronous Communication Primitives
#@Insup Lee,Susan B. Davidson
#t1990
#cIEEE Transactions on Computers
#index529626
#%160242
#%162808
#!The performance of two algorithms for timed synchronous communication between a single sender and a single receiver is analyzed. Each weakens the definition of correct timed synchronous communication in a different way, and exhibits a different undesirable behavior. Their sensitivity to various parameters is discussed. These parameters include how long the processes are willing to wait for communication to be successful, how well synchronized the processes are, the assumed upper bound on message delay, and the actual end-to-end message delay distribution. The fault tolerance of the algorithms is discussed and a mixed strategy is proposed that avoids some of the performance problems.


#*Higher speed transputer communication using shared memory
#@Luben K. Boianov,Alan Knowles
#t1991
#cMicroprocessors Microsystems
#index515846


#*The automatic generation of instruction-level error manifestations of hardware faults: a new fault-injection model
#@Charles Robert Yount
#t1993
#c
#index211624


#*Physically realistic motion synthesis in animation
#@J. Thomas Ngo,Joe Marks
#t1993
#cEvolutionary Computation
#index343672
#!Motion-synthesis problems arise in the creation of physically realistic animations involving autonomous characters. Trpically characters are required to perform goal tasks, subject to physical law and other constraints on their motion. Witkin and Kass (1988) dubbed this class of problems “Spacetime Constraints“ (SC) and presented results for specific problems involving an articulated figure. Their approach was based on a procedure for the local optimization of an initial approximate trajectory supplied by the user. Unfortunately, SC problems are typically multimodal and discontinuous, and the number of decision alternatives available at each time step can be exponential in the number of degrees of freedom in the system. Thus, constructing even coarse trajectories for subsequent optimization can be difficult. We present an algorithm that constructs such trajectories de novo, without directive input from the user. Rather than use a time-series representation, which might be appropriate for local optimization, our algorithm uses a stimulus-response model. Locomotive skills appropriate for the given articulated figure are acquired through repeated testing of (simulated) reality. Our initial implementation, which chooses stimulus-response parameters using a parallel genetic algorithm, succeeds in finding good, novel solutions for a test suite of SC problems involving unbranched 2-D linkages.


#*The relative useful information measure: some comments
#@T. O. Kvålseth
#t1991
#cInformation Sciences: an International Journal
#index534614


#*Trace-Based Debugging
#@Steven P. Reiss
#t1993
#cProceedings of the First International Workshop on Automated and Algorithmic Debugging
#index263056


#*Effect analysis in higher-order languages
#@Anne Neirynck Prakash Panangaden,Alan J. Demers
#t1990
#cInternational Journal of Parallel Programming
#index483823


#*Sign-nonsingular matrix pairs
#@Richard A. Brualdi,Keith L. Chavey
#t1992
#cSIAM Journal on Matrix Analysis and Applications
#index515591


#*Algorithmic determination of commutation relations for Lie symmetry algebras of PDEs
#@G. J. Reid,I. G. Lisle,A. Boulton,A. D. Wittkopf
#t1992
#cPapers from the international symposium on Symbolic and algebraic computation
#index529698
#%515456


#*Invariant Descriptors for 3D Object Recognition and Pose
#@David Forsyth,Joseph L. Mundy,Andrew Zisserman,Chris Coelho,Aaron Heller,Charles Rothwell
#t1991
#cIEEE Transactions on Pattern Analysis and Machine Intelligence
#index521976
#%169872
#%251783
#%457945
#%470709
#%528536
#!Invariant descriptors are shape descriptors that are unaffected by object pose, by perspective projection, or by the intrinsic parameters of the camera. These descriptors can be constructed using the methods of invariant theory, which are briefly surveyed. A range of applications of invariant descriptors in 3D model-based vision is demonstrated. First, a model-based vision system that recognizes curved plane objects irrespective of their pose is demonstrated. Curves are not reduced to polyhedral approximations but are handled as objects in their own right. Models are generated directly from image data. Once objects have been recognized, their pose can be computed. Invariant descriptors for 3D objects with plane faces are described. All these ideas are demonstrated using images of real scenes. The stability of a range of invariant descriptors to measurement error is treated in detail.


#*Summary of Mini-Symposium II.
#@Andrew Kusiak,Imre Horváth
#t1993
#cProceedings of the IFIP TC5/WG5.3/IFAC International Working Conference on Knowledge Based Hybrid Systems in Engineering and Manufacturing
#index265131


#*Impact of linguistics on informatics
#@Samer Attasi
#t1990
#cComputers and the Arabic language
#index517827


#*Computer Visualization: Graphics Techniques for Scientific and Engineering Analysis, 1st edition
#@Richard S. Gallagher
#t1994
#c
#index615754
#!:Computer Visualization presents a unified collection of computer graphics techniques for the scientific visualization of behavior. The book combines a basic overview of the fundamentals of computer graphics with a practitioner-oriented review of the latest 3-D graphics display and visualization techniques. Each chapter is written by well-known experts in the field.


#*Basic functions for managing the data resource
#@Jeffrey A. Hoffer
#t1991
#cProceedings of the 1991 Information Resources Management Association international conference on Managing information technology in a global society
#index523399


#*Coupling of two-dimensional hyperbolic and elliptic equations
#@F. Gastaldi,A. Quarteroni,G. Sacchi Landriani
#t1990
#cProceedings of the conference on Spectral and high order methods for partial differential equations
#index530861


#*On localization in the discrete nonlinear Schro&uml;dinger equation
#@O. Bang,J. J. Rasmussen,P. L. Christiansen
#t1993
#cPhysica D
#index207871


#*Digital Signal Transmission
#@C. C. Bissell
#t1992
#c
#index255325
#!:Aimed at enabling readers to understand the fundamental concepts and processes, this volume provides a thorough up-to-date foundation in the concepts of modern digital transmission for undergraduate study in telecommunications.


#*Rational Rose Essentials: Using the Booch Method, 1st edition
#@Iseult White
#t1994
#c
#index611344


#*Completeness in approximation classes
#@Pierluigi Crecenzi,Alessandro Panconesi
#t1991
#cInformation and Computation
#index537906


#*An approach to standard DDL for OODBMSs
#@Peter Moore,Andrew E. Wade
#t1991
#cComputer Standards Interfaces
#index525215


#*New clique and independent set algorithms for circle graphs
#@Alberto Apostolico,Mikhail J. Atallah,Susanne E. Hambrusch
#t1992
#cDiscrete Applied Mathematics
#index526813


#*Support of User Interface Design Aspects in a Framework for Distributed Cooperative Applications
#@Hans-Werner Gellersen
#t1994
#cProceedings of the Workshop on Software Engineering and Human-Computer Interaction
#index380114


#*Logicism, AI, and common sense: John McCarthy's program in philosophical perspective
#@Richmond H. Thomason
#t1991
#cArtificial intelligence and mathematical theory of computation: papers in honor of John McCarthy
#index514929


#*O2 an object-oriented data model
#@Christophe Lecluse,Philippe Richard,Fernando Velez
#t1990
#cAdvances in database programming languages
#index524333


#*Category Theory for the Configuration of Complex Systems
#@Gillian Hill
#t1993
#cProceedings of the Third International Conference on Methodology and Software Technology: Algebraic Methodology and Software Technology
#index370020


#*Discrete mathematics in manufacturing
#@Martin Grötschel
#t1992
#cProceedings of the second international conference on Industrial and applied mathematics
#index218844


#*Readings in Fuzzy Sets for Intelligent Systems
#@Michael DuBois
#t1993
#c
#index254870
#!:In recent years, fuzzy sets have become an important field, the development of which has been accelerated by the emergence of fuzzy control as a commercially successful methodology. This book makes available significant articles on fuzzy sets related to intelligent systems. The papers in this volume cover fundamental notions in fuzzy sets, fuzzy control, fuzzy logic and approximate reasoning, information processing, decision sciences, connections with operations research, and knowledge acquisition. Each chapter is introduced by the editors, who describe the relevance of each article and provide pointers to other literature and a short list of further readings. This collection will be of interest to researchers and professionals in artificial intelligence, engineering, decision sciences, and other fields concerned with management of uncertainty.


#*Tripping the light fantastic (a look at evolving photonic and optical-computing technologies)
#@Larry L. Learn
#t1991
#cLibrary Hi Tech News
#index514683


#*End Point Control of Compliant Robots
#@J. I. Arocena,R. W. Daniel,P. Elosegui
#t1991
#cThe 2nd International Symposium on Experimental Robotics II
#index360530


#*Experiential Logic
#@Zuoquan Lin
#t1992
#cProceedings of the IFIP TC12/WG12.3 International Workshop on Automated Reasoning
#index375665


#*Using fuzzy logic to represent security policies in the multipolicy paradigm
#@Hilary H. Hosmer
#t1992
#cACM SIGSAC Review
#index211550
#%151818
#%181681
#%246405
#%334794
#!Fuzzy logic is a promising way to represent non-traditional policies, like privacy, integrity and availability. Its vagueness and use of continuous data fit better with many non-military enterprise policy requirements. The theoretical foundation needed for development and assurance of computer systems has been worked out in an extensive literature, but more attention needs to be paid to its use in trusted systems. It is appropriate to use fuzzy logic for implementing aspects of the Multipolicy Paradigm.


#*Learn Generic CADD 6.0 in a Day/Book and Disk, 25th edition
#@Ralph Grabowski
#t1992
#c
#index613229


#*Determining whether a vote assignment is dominated
#@Sushil Jajodia,David Mutchler
#t1991
#cInformation Sciences: an International Journal
#index515813


#*Write Your Own Programming Language Using C++
#@Norman E. Smith
#t1992
#c
#index627025
#!:Learn how to create your own applications language that will work with your C++ or Turbo/Borland C++ programs. With this knowledge, you will be able to provide a useful set of commands to users of your programs to increase their speed, flexibility and ease of use. A companion diskette with source code examples is included.


#*DOS 5.0 for Beginners
#@Manfred Tornsdorf,H. Tornsdorf
#t1991
#c
#index246581


#*Limit theorems for recursive algorithms
#@P. Feldman,S. T. Rachev,L. Rüschendorf
#t1994
#cJournal of Computational and Applied Mathematics
#index597718


#*Solaris porting guide
#@Michele Ann Goodman,Manoj Goyal,Robert A. Massoudi
#t1993
#c
#index519604


#*Criteria for Sequence Set Design in CDMA Communications
#@Robert A. Scholtz
#t1993
#cProceedings of the 10th International Symposium on Applied Algebra, Algebraic Algorithms and Error-Correcting Codes
#index356260


#*How to avoid inadequate evaluation of software for learning
#@Kate Beattie
#t1994
#cProceedings of the IFIP TC3/WG3.2 Working Conference on the Seign, Implementation and Evaluation of Interactive Multimedia in University Settings: Designing for Change in Teaching and Learning
#index266012


#*Requirement Specification For Real-Time and Hybrid Systems
#@Heping He,Hussein Zedan
#t1993
#cProceedings of the IFIP TC6/WG6.1 Sixth International Conference on Formal Description Techniques, VI
#index356037


#*Access Ordering Algorithms for a Multicopy Memory
#@Steven A. Moyer
#t1992
#c
#index203321


#*An analysis of the factors that contribute to instructional use of computers in high school mathematics
#@Doreen Loberg Klages
#t1994
#c
#index198862


#*Small human groups in isolated and confined environments: conflict and communication structures and dynamics
#@Robert Barry Owen
#t1993
#c
#index201193


#*A tool for the rapid evaluation of input devices using Fitts' law models
#@I. Scott MacKenzie,William Buxton
#t1993
#cACM SIGCHI Bulletin
#index207042
#%470127
#%470457
#%212779
#%527216
#%528106
#%458302
#%465982
#!A tool for building Fitts' law models is described. MODEL BUILDER runs on the Apple Macintosh using any device which connects to the Apple Desktop Bus. After 16 blocks of trials taking about 4--5 minutes, the program provides an immediate (albeit tentative) statistical analysis, showing the coefficients in the prediction equation, the coefficient of correlation, and a regression line with scatter points. MODEL BUILDER can be retrieved anonymously by researchers, educators, developers, or anyone with access to INTERNET through file-transfer-protocol (FTP).


#*Competitive algorithms for server problems
#@Mark S. Manasse,Lyle A. McGeoch,Daniel D. Sleator
#t1990
#cJournal of Algorithms
#index452167


#*Some perspectives on the eigenvalue problem
#@David S. Watkins
#t1993
#cSIAM Review
#index224839


#*Polymorphic Typing by Abstract Interpretation
#@Bruno Monsuez
#t1992
#cProceedings of the 12th Conference on Foundations of Software Technology and Theoretical Computer Science
#index264802


#*A Proposed Testing and Analysis Research Initiative
#@Leon Osterweil,Lori A. Clarke
#t1992
#cIEEE Software
#index449904
#!The steps being taken to develop a US software research agenda and to bridge the gap between testing and analysis researchers and practitioners are discussed. The current software reliability crisis and the obstacles to developing more effective testing and analysis technology and transferring it to industry are reviewed. Nine research areas most likely to yield important results are outlined. A major initiative in testing and analysis to provide the needed resources, an organizing framework, and an impetus to broaden and intensify critical testing and analysis research is discussed.


#*An O(n2) active set method for solving a certain parametric quadratic program
#@M. J. Best,N. Chakravarti
#t1992
#cJournal of Optimization Theory and Applications
#index525007


#*Analytic Proof Systems for Classical and Modal Logics of Restricted Quantification
#@Ian P. Gent
#t1993
#c
#index185544
#!This thesis is a study of the relationship between proof systems for propositional logic and for logics of restricted quantification incorporating restriction theories. Such logics are suitable for the study of special purpose reasoning as part of a larger system, an important research topic in automated reasoning. Also, modal and sorted logics can be expressed in this way. Thus, results on restricted quantification apply to a wide range of useful logics. D''Agostino''s "expansion systems" are used to generalise results to apply to a variety of tableau-like propositional proof systems.


#*Task Sharing and Intervention in Human-Robot Cooperating Systems
#@Yasuyoshi Yokokohji,Tsuneo Yoshikawa
#t1993
#cThe 3rd International Symposium on Experimental Robotics III
#index377522


#*A Prolog simulation for combustion control
#@Terence C. Fogarty
#t1990
#cSimulation
#index481376


#*Minimizing mean flow time in two-machine open shops and flow shops
#@Jianzhong Du,Joseph Y.-T. Leung
#t1993
#cJournal of Algorithms
#index222564


#*Convex duality and generalized solutions in optimal control problem for stopped processes: the deterministic model
#@Hang Zhu
#t1992
#cSIAM Journal on Control and Optimization
#index523555


#*Special volume on natural language processing
#@Daniel G. Bobrow,Fernando C. N. Pereira,Barbara J. Grosz
#t1993
#cArtificial Intelligence
#index220664


#*Software creativity
#@Robert L. Glass
#t1994
#c
#index225448


#*Object classes and image contours in model-based vision
#@David Jay Kriegman
#t1990
#c
#index510594


#*Molecular computing
#@Michael Conrad
#t1990
#cAdvances in computers
#index526668


#*Natural Language Processing: The Plnlp Approach
#@Karen Jensen,George E. Heidorn,Stephen D. Richardson
#t1992
#c
#index236020


#*Gateway's stylish systems boast computing muscle on a budget
#@David DeJean
#t1991
#cPC/Computing
#index523029


#*Scalable Spin Locks for Multiprogrammed Systems
#@Robert W. Wisniewski,Leonidas I. Kontothanassis,Michael L. Scott
#t1994
#cProceedings of the 8th International Symposium on Parallel Processing
#index374078


#*Configurable CMOS multiplier/divider circuits for analog VLSI
#@Mohammed Ismail,Robert Brannen,Shigetaka Takagi,Nobuo Fujii,Nabil I. Khachab,Ronny Khan,Oddvar Aaserud
#t1994
#cAnalog Integrated Circuits and Signal Processing
#index214332


#*Algorithm 697: univariate interpolation that has the accuracy of a third-degree polynomial
#@Hiroshi Akima
#t1991
#cACM Transactions on Mathematical Software (TOMS)
#index508564
#%534924


#*Efficient and exact data dependence analysis
#@Dror E. Maydan,John L. Hennessy,Monica S. Lam
#t1991
#cACM SIGPLAN Notices
#index515470
#%146000
#%160970
#%171660
#%184117
#%205823
#%446062
#%485263


#*Theoretical aspects of industrial design
#@David A. Field,Vadim Komkov
#t1992
#cSiam Proceedings Series
#index221688


#*Data Mining: the search for knowledge in databases.
#@Marcel Holsheimer,Arno P.J.M. Siebes
#t1994
#c
#index124843


#*On maximum norm convergence of multigrid methods for two-point boundary value problems
#@Arnold Reusken
#t1992
#cSIAM Journal on Numerical Analysis
#index533062


#*The art of LISP programming
#@Robin Jones,Clive Maynard,Ian Stewart
#t1990
#c
#index475313


#*Computing probabilities for probabilistic influence diagrams
#@Chiu-Cheng Chyu
#t1991
#c
#index532861


#*Visualization and Virtual Reality: Programming with Visual Basic for Windows
#@Lee A. Adams
#t1993
#c
#index619695


#*A multiparadigmatic visual environment for adaptive access to databases
#@T. Catarci,S. K. Chang,M. F. Costabile,S. Levialdi,G. Santucci
#t1993
#cINTERACT '93 and CHI '93 conference companion on Human factors in computing systems
#index78076
#%229154
#%466991


#*Graphs with edge-preserving majority functions
#@Hans-Jürgen Bandelt
#t1992
#cDiscrete Mathematics
#index525181


#*Design of an array processor for image processing
#@De-Lei Lee
#t1991
#cJournal of Parallel and Distributed Computing
#index532422


#*Remote control software
#@Bob Bayley
#t1993
#cPC/Computing
#index220630


#*Solving Linear Recurrences with Loop Raking
#@Guy E. Blelloch,Siddhartha Chatterjee,Marco Zagha
#t1992
#cProceedings of the 6th International Parallel Processing Symposium
#index363924


#*Multicycles and RTL Logic Satisfiability
#@Odile Millet
#t1992
#cProceedings of the Second International Symposium on Formal Techniques in Real-Time and Fault-Tolerant Systems
#index268244


#*A direct method for the characterization and computation of bifurcation points with corank 2
#@Basem S. Attili
#t1992
#cComputing
#index526508


#*A study of particle phenomena in computer disk drives
#@Chuen-Jinn Tsai
#t1990
#c
#index517144


#*On replete graphs
#@M. Frick
#t1992
#cJournal of Graph Theory
#index215490


#*Diagnosis and Debugging as Contradiction Removal in Logic Programs
#@Luís Moniz Pereira,Carlos Viegas Damásio,José Júlio Alferes
#t1993
#cProceedings of the 6th Portuguese Conference on Artificial Intelligence: Progress in Artificial Intelligence
#index383807


#*The effect of domain knowledge on elementary school children's search behavior on an information retrieval system: the science library catalog
#@Sandra Goldstein Hirsh
#t1995
#cConference companion on Human factors in computing systems
#index590470
#%601703


#*Polyhedral analysis and decompositions for capacitated plant location-type problems
#@Bintong Chen,Monique Guignard
#t1998
#cDiscrete Applied Mathematics
#index88195


#*Retrospective: active messages: a mechanism for integrating computation and communication
#@Thorsten von Eicken,David E. Culler,Klaus Erik Schauser,Seth Copen Goldstein
#t1998
#c25 years of the international symposia on Computer architecture (selected papers)
#index77991


#*Configurations of planes in PG(5,2)
#@Ron Shaw
#t1999
#cDiscrete Mathematics
#index299358


#*Design of activity-based costing in a small company: a case study
#@A. Gunasekaran,D. Singh
#t1999
#cComputers and Industrial Engineering
#index283045


#*A Query Language and Interface for Integrated Media and Alphanumeric Database Systems
#@Jia-Ling Koh,Arbee L. P. Chen,Paul C. M. Chang,James C. C. Chen
#t1997
#cProceedings of the 8th International Conference on Database and Expert Systems Applications
#index571640


#*Fibrational Control Structures
#@Claudio Hermida,John Power
#t1995
#cProceedings of the 6th International Conference on Concurrency Theory
#index272869


#*Automatic Prototype Extracion for Adaptive OCR
#@George Nagy,Yihong Xu
#t1997
#cProceedings of the 4th International Conference on Document Analysis and Recognition
#index358581
#!A Bayesian method of isolating character bitmaps from paragraph-length samples of heavily degraded text images is demonstrated. The method requires a transcript of the text, but it is sufficiently robust to tolerate errors in transcripts obtained from multifont commercial OCR software. The resulting prototypes (labeled character images) are used to recognize additional text in the same document.


#*A kinetic model for beer production under industrial operational conditions
#@B. de Andrés-Toro,J. M. Girón-Sierra,J. A. López-Orozco,C. Fernández-Conde,J. M. Peinado,F. Garcia-Ochoa
#t1998
#cSelected papers on Second international symposium mathematical modelling and simulation in agricultural and bio-industries
#index286363


#*The effect of accompanying media on spatial models derived from text
#@David VanEsselstyn
#t1998
#cCHI 98 conference summary on Human factors in computing systems
#index85167


#*Uniform approaches to the verification of finite state systems
#@Sandeep Kumar Shukla
#t1997
#c
#index79305


#*On Feature Selection: A New Filter Model
#@Marc Sebbna
#t1999
#cProceedings of the Twelfth International Florida Artificial Intelligence Research Society Conference
#index273782


#*The LyriC language: querying constraint objects
#@Alexander Brodsky,Yoram Kornatzky
#t1995
#cProceedings of the 1995 ACM SIGMOD international conference on Management of data
#index605591
#%162331
#%184117
#%275322
#%361560
#%462768
#%487947
#%585826
#%606054
#!We propose a novel data model and its language for querying object-oriented databases where objects may hold spatial, temporal or constraint data, conceptually represented by linear equality and inequality constraints. The proposed LyriC language is designed to provide a uniform and flexible framework for diverse application realms such as (1) constraint-based design in two-, three-, or higher-dimensional space, (2) large-scale optimization and analysis, based mostly on linear programming techniques, and (3) spatial and geographic databases. LyriC extends flat constraint query languages, especially those for linear constraint databases, to structurally complex objects. The extension is based on the object-oriented paradigm, where constraints are treated as first-class objects that are organized in classes. The query language is an extension of the language XSQL, and is built around the idea of extended path expressions. Path expressions in a query traverse nested structures in one sweep. Constraints are used in a query to filter stored constraints and to create new constraint objects.


#*Interpolation and denoising of nonuniformly sampled data using wavelet-domain processing
#@Hyeokho Choi
#t1999
#cProceedings of the Acoustics, Speech, and Signal Processing, 1999. on 1999 IEEE International Conference - Volume 03
#index419393
#!We link concepts from nonuniform sampling, smoothness function spaces, interpolation, and denoising to derive a suite of multiscale, maximum-smoothness interpolation algorithms. We formulate the interpolation problem as the optimization of finding the signal that matches the given samples with smallest norm in a function smoothness space. For signals in the Besov space B/sub q//sup /spl alpha// (L/sub p/), the optimization corresponds to convex programming in the wavelet domain; for signals in the Sobolev space W/sup /spl alpha//(L/sub 2/), the optimization reduces to a simple weighted least-squares problem. An optional wavelet shrinkage regularization step makes the algorithm suitable for even noisy sample data, unlike classical approaches such as bandlimited and spline interpolation.


#*Can System Integrators Learn from Baggage Crisis?
#@Editor: Will Tracz
#t1995
#cComputer
#index439941


#*Algebraic algorithm design and local search
#@Robert Park Graham, Jr.
#t1996
#c
#index188394


#*Prentice Hall Custom Test: Macintosh with Dice
#@
#t1999
#c
#index8828


#*TTTC Newsletter
#@
#t1999
#cIEEE Design Test
#index439046


#*Microsoft Windows NT Server Enterprise Training with Cdrom
#@Microsoft Corporation
#t1997
#c
#index236364
#!:This Microsoft Press exclusive provides complete self-paced training for support professionals preparing for the Microsoft Certified Professional exam on Microsoft Windows NT Server 4.0 Enterprise Technologies. Experience Level: Intermediate/ Advanced


#*Chaos in a variable mass relaxation oscillator model for the leaky tap
#@Gerado I. Sánchez-Ortiz,Alvaro L. Salas-Brito
#t1995
#cPhysica D
#index592090


#*Correctness of Programs and Protocols through Randomization (Extended Abstract)
#@Michael O. Rabin
#t1997
#cProceedings of the Third Asian Computing Science Conference on Advances in Computing Science
#index383052


#*Confidence relations and ordinal information
#@Gert De Cooman
#t1998
#cInformation Sciences: an International Journal
#index81501


#*An optimal solution procedure for the multiple tour maximum collection problem using column generation
#@Steven E. Butt,David M. Ryan
#t1999
#cComputers and Operations Research
#index286752


#*Affine analysis of image sequences
#@Larry S. Shapiro
#t1995
#c
#index593953


#*Demiclosedness principle and asymptotic behavior for asymptotically nonexpansive mappings
#@Pei-Kee Lin,Kok-Keong Tan,Hong-Kun Xu
#t1995
#cNonlinear Analysis: Theory, Methods Applications
#index601231


#*Combined log system
#@David Beckett
#t1995
#cProceedings of the Third International World-Wide Web conference on Technology, tools and applications
#index589902


#*Two Applications of an Incremental Analysis Engine for (Constraint) Logic Programs
#@Andrew D. Kelly,Kim Marriott,Harald Søndergaard,Peter J. Stuckey
#t1996
#cProceedings of the Third International Symposium on Static Analysis
#index255872


#*Computing the minimum diameter for moving points: an exact implementation using parametric search
#@Jörg Schwerdt,Michiel Smid,Stefan Schirra
#t1997
#cProceedings of the thirteenth annual symposium on Computational geometry
#index94296
#%593389
#%568999
#%600460
#%144427


#*Implementing Microsoft Exchange Server 6, 10th edition
#@Shannon R. Turlington,Kevin Schuler
#t1997
#c
#index243593
#!:The focus is on how small- to medium-sized businesses and home users can put Microsoft Exchange Server to work to meet their needs. Using real-life, business-oriented scenarios to illustrate concepts, this book covers all the steps required to install, plan, and implement an MS Exchange Server strategy and to use its key technologies right away. The CD-ROM contains the EarthLink TotalAccess Internet connection package with Internet Explorer 4.


#*Fast Methods with Magic Sampling for Knowledge Discovery in Deductive Databases with Large Deduction Results
#@Chien-Le Goh,Masahiko Tsukamoto,Shojiro Nishio
#t1998
#cProceedings of the Workshops on Data Warehousing and Data Mining: Advances in Database Technologies
#index275839


#*Real-Time Adaptive Smoothing with a 1-D Nonlinear Relaxation
#@K. Wiehler,Rolf-Rainer Grigat,Josef Heers,Christoph Schnörr,H. Siegfried Stiehl
#t1998
#cMustererkennung 1998, 20. DAGM-Symposium
#index555519


#*Reliable solutions of elliptic boundary value problems with respect to uncertain data
#@I. Hlaváček
#t1997
#cProceedings of the second world congress on Nonlinear Analysts: part 6
#index89593


#*Implementing Cdf Channels
#@Michele J. Petrovsky
#t1998
#c
#index608293
#!:Written specifically for the web developer/programmer, Michele Jo Petrovsky's Implementing CDF Channels includes instructions for establishing traditional netcasting as the basis for CDF, and then demonstrates how CDF can take netcasting even further. You'll find step-by-step examples of CDF, plus instructions for successful implementation of CDF on your web site. Also included are a comprehensive glossary, useful quick references for Netcasting and CDF, as well as over 150 helpful illustrations.


#*A system to project injury and illness incidence during military operations
#@Christopher G. Blood,Edward R. O'Donnell
#t1995
#cJournal of Medical Systems
#index595805


#*Rational Krylov: A Practical Algorithm for Large Sparse Nonsymmetric Matrix Pencils
#@Axel Ruhe
#t1998
#cSIAM Journal on Scientific Computing
#index279426
#!The rational Krylov algorithm computes eigenvalues and eigenvectors of a regular not necessarily symmetric matrix pencil. It is a generalization of the shifted and inverted Arnoldi algorithm, where several factorizations with different shifts are used in one run. It computes an orthogonal basis and a small Hessenberg pencil. The eigensolution of the Hessenberg pencil approximates the solution of the original pencil. Different types of Ritz values and harmonic Ritz values are described and compared. Periodical purging of uninteresting directions reduces the size of the basis and makes it possible to compute many linearly independent eigenvectors and principal vectors of pencils with multiple eigenvalues. Relations to iterative methods are established.Results are reported for two large test examples. One is a symmetric pencil coming from a finite element approximation of a membrane; the other is a nonsymmetric matrix modeling an idealized aircraft stability problem.


#*A Bi-Directional Multilayer Perceptron
#@M. Jedra,A. El Ouardighi,A. Essaid,M. Limouri
#t1999
#cNeural Processing Letters
#index282544
#%181029
#%537573
#%471174
#!We present in this paper a new neural net called Bi-directional Multi Layer Perceptron (BMLP). Its structure is identical to the one of the classical Multi Layer Perceptron (MLP) but it differs in its neurons. Those neurons possess the bi-directional connections. The BMLP is capable to implement non linear transformations and their reverses for functional approximation problems.


#*Understanding Large-Scale Behavior Patterns in Complex systems
#@R. Buhr
#t1996
#cProceedings of the 2nd IEEE International Conference on Engineering of Complex Computer Systems
#index115144
#!Understanding how a complex system works as a whole can be difficult because it requires blending information about structure and behavior into a coherent whole that can be understood without reference to details of how its parts are constructed, behave internally, or interact. The problem is doubly difficult for software systems, because we do not any good large-scale models of such systems to keep in the mind's eye. We have details in code files, low level diagrams of software details (for example, class inheritance hierarchies), and system views of hardware environments, but these are not enough. We suggest that models of whole systems that we can diagram and hold in the mind's eye are so important for human understanding of complex systems of all kinds that, if they do not exist, they must be invented. Use case maps are an example of a model invented for this purpose. While use case maps were invented to deal with the problems of understanding software systems, they are useful for complex systems of all kids. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Demystifying TCP/IP, 2nd edition
#@Paul L. Schlieve
#t1997
#c
#index622506
#!:The revision of this title highlights the new communications topics relative to the Internet. Demystifying is a series highlighting various communications topics targeted for the professional who does not have in-depth technical background in communications technology.


#*On models, modelling and the distinctive nature of model-based reasoning
#@
#t1999
#cAI Communications
#index9577
#%222919
#%513895
#%174130
#%164574
#%588998
#!What are models and how is the relatively new technology of Model-Based Reasoning different from conventional modelling in science and engineering? These questions are explored in this paper by examining the fundamental nature of models. We explore model characteristics, different classes of model and various dimensions of the modelling space. Our analysis puts models into a general framework from which emerges the interesting case of qualitative models. Inevitably, such a broad treatment must be a personal view but the objective is to draw attention to key issues. Our aim is to increase understanding of the modelling process and clarify the options available for model builders. We argue that the technology known as Model-Based Reasoning, which uses explicit, executable models is a powerful and widely applicable approach that has much potential for managing the complexity encountered in many application domains. The advantages of the method include an emphasis on principled model design, the ability to guarantee completeness of the solutions and powerful reuse and automation opportunities.


#*Advances in fractal compression for multimedia applications
#@John Kominek
#t1997
#cMultimedia Systems
#index83095
#%445663
#%508813
#!Fractal image compression is a promising new technology but is not without problems. Most critically, fast encoding is required for it to find wide use in multimedia applications. This is now within reach: recent methods are five orders of magnitude faster than early attempts. Beginning with the basic ideas and problems, this paper explains how to accelerate fractal image compression.


#*The irredundant Ramsey number s(3,7)
#@Guantao Chen,Cecil C. Rousseau
#t1995
#cJournal of Graph Theory
#index606981


#*Lotus Domino Administration in a Nutshell: A Desktop Quick Reference
#@Greg G. Neilson
#t1999
#c
#index247457
#!:Domino is one of the most effective platforms for developing and deploying e-business applications, allowing new communities of developers to enjoy its collaborative capabilities. With over 55 million seats worldwide, Domino already provided a strong foundation for messaging and Web applications, and the release of R5 builds on that to make Domino easier to use than ever before. For example, Lotus Domino R5 has been expanded to interact with most browsers and other non-Notes clients, so you can choose your favorite language to design Web applications. With R5 you can also centrally modify client configurations instead of hopping from one terminal to the next throughout the company. And the new Domino Adminstrator interface enables you to visually monitor the health and status of the Domino servers in your network from a single screen. All this capability implies complexity, and it's easy to forget which menu you need. Here's where Lotus Domino Administration in a Nutshell can help. It's a quick reference you'll turn to again and again to find solutions to your organization's administrative problems. This book covers: An overview of Domino architecture and key concepts R5 administration tools Domino directory and console commands Database properties and Access Control Configuring Domino Enterprise Connection Services (DECS) Supporting the Notes client Domino for IIS Windows NT integration Whether you're looking to change messaging servers, modify your administration tasks to a simpler and more efficient level, or ensure the security and flexibility of your Web application server, Lotus Domino Administrtion in aNutshell will give you the help you need to make the most of this reliable and scalable integrated server platform.


#*On the Complexity of Counting the Number of Vertices Moved by Graph Automorphisms
#@Antoni Lozano,Vijay Raghavan
#t1998
#cProceedings of the 18th Conference on Foundations of Software Technology and Theoretical Computer Science
#index268287


#*Growth and characterization of InTlSb for IR-detectors
#@N. H. Karam,R. Sudharsanan,T. Parodos,M. A. Dodd
#t1996
#cJournal of Electronic Materials
#index602504


#*Experimental Results about MPI Collective Communication Operations
#@Massimo Bernaschi,Giulio Iannello,Mario Lauria
#t1999
#cProceedings of the 7th International Conference on High-Performance Computing and Networking
#index558964


#*Panel Position Paper
#@M. Konrad
#t1995
#cProceedings of the 2nd IEEE Software Engineering Standards Symposium
#index119975


#*User-space migration
#@Dejan Milojičić,Frederick Douglis,Richard Wheeler
#t1999
#cMobility: processes, computers, and agents
#index280605


#*A CD-ROM tower alternative
#@Rich Harada
#t1998
#cStorage Management Solutions
#index331728


#*Linkages in locally semicomplete digraphs and quasi-transitive digraphs
#@Jørgen Bang-Jensen
#t1999
#cDiscrete Mathematics
#index286687


#*LITOS-A und LITOR-A - Eine Methode und ein Werkzeug f&uuml;r die Analyse- und Definitionsphase von Software-Projekten
#@Hannes Färberböck,Ernest Wallmüller
#t1995
#cGI/OCG/&Ouml;GI-Jahrestagung 1985, Wirtschaftsuniversit&auml;t Wien, &Uuml;bersichtsbeitr&auml;ge und Fachgespr&auml;che zu den Themenschwerpunkten Softwaretechnologie / Standardsoftware / B&uuml;rokommunikation / Bildschirmtext
#index257683


#*A Case of Multiagent Decision Support: Using Autonomous Agents for Urban Traffic Control
#@Sascha Ossowski,José Cuena,Ana García-Serrano
#t1998
#cProceedings of the 6th Ibero-American Conference on AI: Progress in Artificial Intelligence
#index358654


#*Nontrivial monotone weakly symmetric boolean functions with six variables are elusive
#@Sui-Xiang Gao,Xiao-Dong Hu,Weili Wu
#t1999
#cTheoretical Computer Science
#index296240


#*Interpolation of sparse multivariate polynomials over large finite fields with applications
#@Ming-Deh A. Huang,Ashwin J. Rao
#t1999
#cJournal of Algorithms
#index288374


#*On the topological design of a computer network
#@S. K. Srivatsa,P. Seshaiah
#t1995
#cComputer Networks and ISDN Systems
#index591350


#*&ldquo;Brownian strings&rdquo;: segmenting images with stochastically deformable contours
#@Robert P. Grzeszczuk,David N. Levin
#t1997
#cIEEE Transactions on Pattern Analysis and Machine Intelligence
#index87645


#*An optimal parallel algorithm for volume ray casting
#@Vineet Goel,Amar Mukherjee
#t1995
#cProceedings of the 9th International Symposium on Parallel Processing
#index366500
#!Volume rendering by ray casting is a computationally expensive problem. For interactive volume visualization, rendering has to be done in real time (3D frames/sec). Since the typical 3D dataset size is at least 128/sup 3/, the use of parallel processing is imperative. We present an O(log n) EREW algorithm for volume rendering using O(n/sup 3/) processors which can be optimized to O(log/sup 3/ n) time using O(n/sup 3//log/sup 3/ n) processors. We have implemented our algorithm on MasPar MPl200. The implementation results show that a frame from 123/sup 3/ data size is generated in about 3 seconds using 4096 processors.


#*Multi-Agent Negotiation Algorithms for Resources Cost Estimation: A Case Study
#@José Manuel Fonseca,Eugenio Oliveira,Adolfo Steiger-Garção
#t1997
#cProceedings of the 8th Portuguese Conference on Artificial Intelligence: Progress in Artificial Intelligence
#index371775


#*Geometrical analysis of a certain dynamical system
#@Dmytryi N. Kravchuk
#t1997
#cNonlinear Analysis: Theory, Methods Applications
#index79945


#*Directional selectivity in the retina
#@Norberto M. Grzywacz,Evelyne Sernagor,Franklin R. Amthor
#t1998
#cThe handbook of brain theory and neural networks
#index291815


#*Computer-based learning and assessment: a palaeontological case study with outcomes and implications
#@A. P. Boyle,D. N. Bryon,C. R. C. Paul
#t1997
#cComputers Geosciences
#index83532


#*Generic electronic payment services: framework and functional specification
#@Alireza Bahreman
#t1996
#cProceedings of the 2nd conference on Proceedings of the Second USENIX Workshop on Electronic Commerce - Volume 2
#index430532
#%430532
#!We present a framework for integrating electronic payments with applications. We call it the Generic Electronic Payment Services (GEPS). There are five payment services identified in our framework. The model provides maximum transparency to the application developer, while maintaining maximum consistency for the end-user. This is achieved by a layered model where the application (top layer) is isolated from the details of the payment services (lower layer). We also believe that this framework makes it possible for new and innovative payment solutions to more easily integrate with existing applications, resulting in increased competition without stifling innovation. This ultimately leads to higher quality and cost effective solutions which the market will chose.


#*Practical integer division with Karatsuba complexity
#@Tudor Jebelean
#t1997
#cProceedings of the 1997 international symposium on Symbolic and algebraic computation
#index84033
#%223335
#%596654


#*A VHDL primer (3rd ed.)
#@J. Bhasker
#t1998
#c
#index87372


#*Service: the future of information technology
#@Richard T. Watson,Leyland F. Pitt,Pierre R. Berthon
#t1996
#cACM SIGMIS Database
#index80531


#*Visualizing differences in movies of cortical activity
#@Kay A. Robbins,David M. Senseman
#t1998
#cProceedings of the conference on Visualization '98
#index95227
#%77033
#%601617
#%227266
#%458911


#*Financial Planning with Quicken 99 for Windows, 2nd edition
#@David Milton
#t1999
#c
#index623733
#!:Appropriate as a stand alone or as a supplemental book, Finanical Planning with Quicken&reg; deluxe 99 for Windows covers the basics of personal financial planning using Quicken&reg;, the most popular personal finance software in use today. This book provides the tools necessary to embark upon the lifelong process of determining personal financial goals and objectives. It is uniquely designed to guide the student, step-by-step, through the financial planning process. Three different case scenarios throughout the book create a unique blend of theory and practical application and help the student understand the issues involved in various stages of the financial planning life cycle. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Inducing constraint grammars
#@Christer Samuelsson,Pasi Tapanainen,Atro Voutilainen
#t1996
#cProceedings of the 3rd International Colloquium on Grammatical Inference: Learning Syntax from Sentences
#index363540


#*Wanted: e-business professionals
#@Jane Falla
#t1999
#cE-business Advisor
#index327511


#*An ASIP design methodology for embedded systems
#@Kayhan Küçükçakar
#t1999
#cProceedings of the seventh international workshop on Hardware/software codesign
#index296709
#%76189
#%77656
#%88070
#%621243
#%447995


#*Type inference for objects
#@Jens Palsberg
#t1996
#cACM Computing Surveys (CSUR)
#index586605
#%166833
#%208191
#%593116


#*21st Century: Meeting the Challenges to Business Education
#@Pat A. G. Villee,Michael G. Curran, Jr.
#t1999
#c
#index240824


#*How to manage a successful software project
#@Sanjiv Purba,David Sawh Bharat Shah
#t1995
#c
#index593271


#*The Vancouver Academy of Management Jass Symposium: Jazz As a Metaphor for Organizing In the 21st Century
#@Mary Jo Hatch,Karl E. Weick
#t1998
#cOrganization Science
#index560332


#*Exact Aliasing Computation for RAM BIST
#@O. Kebichi,Michael Nicolaidis,Vyacheslav N. Yarmolik
#t1995
#cProceedings of the IEEE International Test Conference on Driving Down the Cost of Test
#index562372


#*Functor Categories and Two-Level Languages
#@Eugenio Moggi
#t1998
#cProceedings of the First International Conference on Foundations of Software Science and Computation Structure
#index261482


#*Mapping clones with a given ordering or interleaving (abstract)
#@Tao Jiang,Richard M. Karp
#t1997
#cProceedings of the first annual international conference on Computational molecular biology
#index78793


#*Health Information Systems: Design Issues and Analytic Applications, 1st edition
#@Elizabeth A. McGlynn,Robert H. Brook,Eve A. Kerr,Cheryl L. Damberg
#t1998
#c
#index241481
#!:This book introduces the basic concepts of health services researchthe key policy concerns that shape such research and the specific techniques used to conduct it. The book's central purpose is to provide practical guidance about using different types of data effectively to answer questions posed by a variety of stakeholders in the U.S. health care system. The book is structured to meet the needs of multiple audiences. For chief executive officers (CEOs) and corporate decisionmakers, it offers a broad overview of the critical issues in using health care data. The book's technical chapters address analytic topics of concern to researchers and analysts who are working in private and public sector groups and are responsible for purchasing, managing, delivering, and regulating health care services.


#*Extremal solutions of the two-dimensional L-problem of moments, II
#@Mihai Putinar
#t1998
#cJournal of Approximation Theory
#index76482


#*How the Web Was Won: Conquering the Digital Frontier, 1st edition
#@Cerise Vablais
#t1998
#c
#index250990
#!:How The Web Was Won: Conquering The Digital Frontier presents a valuable overview of the trials and tribulations of the developers who blazed the early path to the Web-highlighting the techniques that separated the winners from the also-rans. Leveraging the real-world experiences of Level 3 Site Builder Network members, this practical guide presents a complete and authentic picture of Internet development and comes filled with case studies, lessons learned, and proven tips and tactics. Pack a copy of How The Web Was Won: Conquering The Digital Frontier before you ride off on your own Web development expedition. Experience Level: Beginner/ Intermediate The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*The ascent of content
#@Edward D. Horowitz
#t1999
#cThe future of the electronic marketplace
#index289538


#*Adaptive agents and personality change: complementarity versus similarity as forms of adaptation
#@Youngme Moon,Clifford I. Nass
#t1996
#cConference companion on Human factors in computing systems: common ground
#index87434
#%74436


#*Java in Plain English, 2nd edition
#@Brian Cverland
#t1997
#c
#index619096
#!:Java in Plain English, Second Edition, covers the entire Java 1.1 language and API in a remarkably compact size and easy-to-use format. This powerful reference guide explains each method, field, and parameter, and provides extensive, easy-to-follow examples. Unique features of the book include the language reference, which highlights Java/C++ differences, in each topic, making it the most convenient reference for C and C++ programmers. In addition, the API Reference is one of the few sources available anywhere that summarizes the entire API , both concisely and comprehensively. This second edition is greatly expanded to provide more coverage of Java database capabilities -- including a tutorial and reference to SQL commands -- as well as more examples and definitions of the latest Java concepts. Coverage includes: Updated and expanded to cover the latest Java 1.1 concepts Focus on common programming tasks JDBC tutorial helps you start using Java database features quickly SQL appendix covers most common database commands Expanded API reference with more examples and improved format Language reference summarizes syntax and Java/C++ differences Concise introduction to Java, including special Java features such as packages, objects, and threads Extensive cross referencing, including an alphabetical cross reference of the Java API by task Useful tables for graphical programming Convenient A-Z reference of all Java keywords, functions, and terms Whether you're exploring Java as a newcomer, are migrating from C++ or C, or need a reference guideto exploit its most advanced features, Java in Plain English, Second Edition will answer your questions quickly. From its comprehensive guide to the Java API, to its detailed and practical alphabetical reference to Java syntax, this is a reference to rely on.


#*A epsilon-Relaxation Method for Generalized Separable Convex Cost Network Flow Problems
#@Paul Tseng,Dimitri P. Bertsekas
#t1996
#cProceedings of the 5th International IPCO Conference on Integer Programming and Combinatorial Optimization
#index562016


#*Explaining inheritance: a code reusability perspective
#@Robert Biddle,Ewan Tempero
#t1996
#cACM SIGCSE Bulletin
#index599078
#%206639
#%213025
#%467093
#%475832
#!Programmers new to the object-oriented paradigm often have difficulty learning how to use inheritance properly. In this paper we introduce an approach to explaining inheritance that is based on understanding the nature of reusability. We show how the important aspect of inheritance is interface conformance, and explain the role this plays in supporting reusability. We then outline a method for determining when and how to use both single inheritance and multiple inheritance, and discuss the implications of our approach.


#*The locker metaphor to teach dynamic memory
#@Richardo Jiménez-Peris,Cristóbal Pareja-Flores,Marta Patiño-Martínez,J. Ángel Velázquez-Iturbide
#t1997
#cACM SIGCSE Bulletin
#index89908
#%519814
#!Some students experience difficulties when first introduced to dynamic memory. The goal of this paper is to present an analogy between dynamic memory programming and a real-world example that will help students in understanding the underlying concepts behind dynamic memory: a left-luggage room with lockers.


#*Compositing computer graphics and real world video sequences
#@Przemyslaw Rokita
#t1998
#cComputer Networks and ISDN Systems
#index300817


#*Improvements on the pronunciation prefix tree search organization
#@F. Alleva
#t1996
#cProceedings of the Acoustics, Speech, and Signal Processing, 1996. on Conference Proceedings., 1996 IEEE International Conference - Volume 01
#index414545
#!The need for ever more efficient search organizations persists as the size and complexity of the knowledge sources used in continuous speech recognition (CSR) tasks continues to increase. We address efficiency issues associated with a search organization based on pronunciation prefix trees (PPTs). In particular we present (1) a mechanism that eliminates redundant computations in non-reentrant trees, (2) a comparison of two methods for distributing language model probabilities in PPTs, and (3) report results on two look ahead pruning strategies. Using the 1994 DARPA 20 k NAB word bigram for the male segment of si dev5m 92 (the 5k speaker independent development test set for the WSJ), the error rate was 12.2% with a real-time factor of 1.0 on a 120 MHz Pentium.


#*Microsoft VS. NetScape: The Battle for the Internet Infrastructure
#@Paul Korzeniowski
#t1997
#c
#index625642


#*Implementing the Real-Time Publisher/Subscriber Model on the Controller Area Network (CAN)
#@J. Kaiser,M. Mock
#t1999
#cProceedings of the 2nd IEEE International Symposium on Object-Oriented Real-Time Distributed Computing
#index111772
#!Designing distributed real-time systems as being composed of communicating objects offers many advantages with respect to modularity and extensibility of these systems. However, distributed real-time applications exhibit communication patterns that significantly differ from the traditional object invocation style.The publisher/subscriber model for inter-object communication matches well with these patterns. Any implementation of that model must address the problems of binding subscribers to publishers, of routing and filtering of messages, as well as reliability, efficiency and latency of message delivery. In the context of real-time applications, all these issues must be subject to a rigid inspection with respect to meeting real-time requirements.We argue that for embedded control systems built around smart microcontroller-powered devices these requirements can only be met when exploiting the properties of the underlying network. The CAN-Bus (CAN: Controller Area Network) which is an emerging standard in the field of real-time embedded systems is particularly suited to implement a publisher/subscriber model of communication. In this paper, we present an implementation of the real-time publisher/subscriber model that exploits the underlying facilities of the CAN-Bus.In particular, we introduce a novel addressing scheme for publisher/subscriber communication that makes efficient use of the CAN-Bus addressing method. We provide a detailed design and implementation details along with some preliminary performance estimations.


#*ACSEE Undergraduate Scholarships
#@
#t1997
#cProceedings of the 34th annual Design Automation Conference
#index434853


#*POINTRA - ein intelligentes Lehrsystem f&uuml;r die Programmierung dynamischer Verweisstrukturen
#@Christian Herzog
#t1997
#cInformatik und Lernen in der Informationsgesellschaft, 7. GI-Fachtagung Informatik und Schule
#index259383


#*C database programming with ODBC
#@Alex Ragen
#t1995
#cC/C++ Users Journal
#index588592


#*Distributed knowledge representation in fully connected networks
#@J. R. Gattiker
#t1996
#cProceedings of the 1996 IEEE International Joint Symposia on Intelligence and Systems
#index123083
#!Fully-connected binary networks, in addition to implementing content addressable memories, have been shown to be capable of encoding arbitrary limit cycles using synchronous dynamics. A stochastic knowledge representation paradigm is proposed, and a way to encode this knowledge form into cycles in fully-connected networks is described. This new representation format stores information in a truly distributed manner across the network, as opposed to previous schemes which store one knowledge atom per neuron.


#*Local and Global Approaches to Achieve Quantitative Measurement of Handwritings
#@Thierry Frêche,Nicole Vincent
#t1999
#cProceedings of the Fifth International Conference on Document Analysis and Recognition
#index551912
#!A writing style is defined from the global feeling that is coming when simply looking at a text. The text is not only an image, it has a proper orientation and we think that the inner structure of each text must be taken into account, that is to say the lines of the text are important. The parameters we are presenting here, are relying on the extraction of the text lines and on the definition of their upper and lower profiles. We show that a measurement of the evolution of the behavior of some characteristics of these profiles, when observation scales is modified, allows a quantification of different aspects in the handwritings. These new parameters are then interpreted, the link with some physical properties often present in handwriting are shown, such as the presence of loops or the sloping of the writing.


#*A Multi-Threads Runtime for the Pandore Data-Parallel Compiler
#@Françoise André,Jean-Louis Pazat
#t1996
#cProceedings of the International Conference and Exhibition on High-Performance Computing and Networking
#index361825


#*Wave-splitting and absorbing boundary condition for Maxwell's equations on a curved surface
#@Sailing He,Vaughan H. Weston
#t1999
#cMathematics and Computers in Simulation
#index289489


#*Java security
#@Scott Oaks
#t1998
#c
#index91795
#!This essential Java 2 book covers Java's security mechanisms and teaches you how to work with them. It discusses class loaders, security managers, access lists, digital signatures, and authentication and shows how to use these to create and enforce your own security policy.


#*The ALIVE system: wireless, full-body interaction with autonomous agents
#@Pattie Maes,Trevor Darrell,Bruce Blumberg,Alex Pentland
#t1997
#cMultimedia Systems
#index309523
#%168340
#%228158
#%241279
#%252905
#%594685
#%514330
#%458413
#%531208
#%444858
#%486488
#%515205
#!The cumbersome nature of wired interfaces often limits the range of application of virtual environments. In this paper, we discuss the design and implementation of a novel system, called ALIVE, which allows unencumbered full-body interaction between a human participant and a rich graphical world inhabited by autonomous agents. Based on results obtained with thousands of users, the paper argues that this kind of system can provide more complex and very different experiences than traditional virtual reality systems. The ALIVE system significantly broadens the range of potential applications of virtual reality systems: in particular, the paper discusses novel applications in the area of training and teaching, entertainment, and digital assistants or interface agents. We give an overview of the methods used in the implementation of the existing ALIVE systems.


#*Quality Mesh Generation in Higher Dimensions
#@Scott A. Mitchell,Stephen A. Vavasis
#t1996
#c
#index114371
#!We consider the problem of triangulating a d-dimensional region. Our mesh generation algorithm, called QMG, is a qradtree-based algorithm that can triangulate any polyhedral region including nonconvex regions with holes. Furthermore, our algorithm guarantees a bounded aspect ratio triangulation provided that the input domain itself has no sharp angles. Finally, our algorithm is guaranteed never to overrefine the domain in the sense that the number of simplices produced by QMG is bounded above by a factor times the number produced by any competing algorithm, where the factor depends on the aspect ratio bound satisfied by the competing algorithm. The QMG algorithm has been implemented in C++ and is used as a mesh generator for the finite element method.


#*CBET: Acase Base Exploration Tool
#@Paolo Avesani,Anna Perini,Francesco Ricci
#t1997
#cProceedings of the 5th Congress of the Italian Association for Artificial Intelligence on Advances in Artificial Intelligence
#index564370


#*Describing and Quering Semistructured Data: Some Expressiveness Results
#@Natasha Alechina,Maarten de Rijke
#t1998
#cProceedings of the 16th British National Conferenc on Databases: Advances in Databases
#index360600


#*The millicent protocols for electronic commerce
#@Mark S. Manasse
#t1995
#cProceedings of the 1st conference on USENIX Workshop on Electronic Commerce - Volume 1
#index421623


#*Article
#@
#t1998
#cACM SIGDOC Asterisk Journal of Computer Documentation
#index254337


#*Artistic evolution
#@Dong Pfeifer,Todd Larson,Eddie Lee
#t1999
#cACM SIGGRAPH 99 Electronic art and animation catalog
#index300663


#*SIGACT News complexity theory column 18
#@Lane A. Hemaspaandra
#t1997
#cACM SIGACT News
#index91990


#*A paginated set-associative architecture for databases
#@Pascal Faudemay
#t1995
#cEmerging trends in database and knowledge-base machines: the application of parallel architectures to smart information systems
#index596761


#*Proceedings of the second international symposium on Parallel symbolic computation
#@Hoon Hong,Erich Kaltofen
#t1997
#cInternational Symposium on Parallel Symbolic Computation
#index74503


#*On the linearity of on-line computable functions
#@Hratchia Pélibossian
#t1996
#cTheoretical Computer Science
#index589040


#*OpenVMS system management guide
#@Lawrence L. Baldwin, Jr.
#t1995
#c
#index599306


#*Call admission control or adaptive multimedia in wireless/mobile networks
#@Taekyoung Kwon,Yanghee Choi,Chatschik Bisdikian,Mahmoud Naghsineh
#t1998
#cProceedings of the 1st ACM international workshop on Wireless mobile multimedia
#index85822
#%543595


#*Indexing transaction time databases
#@Tolga Bozkaya,Meral Ozsoyoglu
#t1998
#cInformation Sciences: an International Journal
#index300733


#*On the M(n)/M(n)/s queue with impatient calls
#@Andreas Brandt,Manfred Brandt
#t1999
#cPerformance Evaluation
#index293325


#*Finite Model Search for Equational Theories (FMSET)
#@Belaid Benhamou,Laurent Henocque
#t1998
#cProceedings of the International Conference on Artificial Intelligence and Symbolic Computation
#index559412


#*Post-Scheduling Optimization of Parallel Programs
#@Stephen Shafer,Kanad Ghose
#t1999
#cProceedings of the 5th International Euro-Par Conference on Parallel Processing
#index260626


#*Color Plates
#@
#t1996
#cProceedings of the 1996 IEEE Symposium on Information Visualization (INFOVIS '96)
#index117071


#*What does fuzzy logic bring to AI?
#@Didier Dubois,Henri Prade
#t1995
#cACM Computing Surveys (CSUR)
#index606707
#%219905
#%254870
#%584158


#*Inhabited virtual worlds: a new frontier for interaction design
#@Bruce Damer
#t1996
#cinteractions
#index601900


#*Fifty years of progress in software engineering
#@L. B. S. Raccoon
#t1997
#cACM SIGSOFT Software Engineering Notes
#index95383
#!In this paper, I describe a new outlook on the history of Software Engineering. I portray large-scale structures within Software Engineering to give a better understanding of the flow of history. I use these large-scale structures to reveal the steady, ongoing evolution of concepts, and show how they relate to the myriad whorls and eddies of change. I also have four smaller, more specific purposes in writing this paper.First, I want to point out that old ideas do not die. In The Mythical Man-Month after 20 Years, Brooks claims "the Waterfall Model is Wrong." But if the Waterfall model were wrong, we would stop arguing over it. Though the Waterfall model may not describe the whole truth, it describes an interesting structure that occurs in many well-defined projects and it will continue to describe this truth for a long time to come. I expect the Waterfall model will live on for the next one hundred years and more.Second, I want to show that the Chaos model, Chaos life cycle, Complexity Gap, and Chaos strategy are part of the natural evolution of Software Engineering. The Chaos model and strategy supersede, but do not contradict, the Waterfall and Spiral models, and the Stepwise Refinement strategy. They are more up to date because they express contemporary issues more effectively, and fit our contemporary situations better. The Chaos model, life cycle, and strategy are equally as important, but not better than, other concepts.Third, I compare the Chaos model, life cycle, and strategy to other models, life cycles, and strategies. This paper can be considered a comparison of the ideas presented in my papers about chaos with other ideas in the field. I avoided comparisons in my other papers because I wanted to define those ideas in their own terms and the comparisons did not further the new ideas.Fourth, I make a few predictions about the next ten years of Software Engineering. The large-scale structures described in this history provide a stronger base for understanding how software engineering will evolve in the future.This paper is laid out as follows. In the first section, I use the flow of water as a metaphor to describe the flow of progress in Software Engineering. I use the Water metaphor to show some of the structures within Software Engineering. The current work builds on top of the historical work, and future work will build on top of current work. In the remaining sections, I describe the waves, streams, and tides that portray the evolution of concepts and technologies in Software Engineering.


#*Runge-Kutta-Nystro&uml;m methods for general second order ODEs with application to multi-body systems
#@A. Murua
#t1998
#cApplied Numerical Mathematics
#index292490


#*Metric subgraphs of the Chamfer metrics and the Melter-Tomescu path generated metrics
#@Frank Rhodes
#t1995
#cDiscrete Mathematics
#index595848


#*FALCON: A MATLAB Interactive Restructuring Compiler
#@Luiz De Rose,Kyle Gallivan,Efstratios Gallopoulos,Bret A. Marsolf,David A. Padua
#t1995
#cProceedings of the 8th International Workshop on Languages and Compilers for Parallel Computing
#index359876


#*Symmetrization of Binary Random Variables
#@Kagan Abram,Mallows Colin L.,Shepp Larry A.,Vanderbei Robert J.,Vardi Yehuda
#t1999
#c
#index116668
#!A random variable $Y$ is called an independent symmetrizer of a given random variable $X$ if (a) it is independent of $X$ and (b) the distribution of $X+Y$ is symmetric about $0$. In cases where the distribution of $X$ is symmetric about its mean, it is easy to see that the constant random variable $Y = - \Exp X$ is a minimum-variance independent symmetrizer. Taking $Y$ to have the same distribution as $-X$ clearly produces a symmetric sum but it may not be of minimum variance. We say that a random variable $X$ is symmetry resistant if the variance of any symmetrizer, $Y$, is never smaller than the variance of $X$. Let $X$ be a binary random variable: $\Prob \{ X = a \} = p$ and $\Prob \{ X = b \} = q$ where $a \ne b$, $0 > p > 1$, and $q = 1-p$. We prove that such a binary random variable is symmetry resistant if (and only if) $p \ne 1/2$. Note that the minimum variance as a function of $p$ is discontinuous at $p = 1/2$. Dropping the independence assumption, we show that the minimum-variance reduces to $pq - \min (p,q)/2$, which is a continuous function of $p$.


#*Undergraduate AI and its non-imperative prerequisite
#@Deepak Kumar,Richard Wyatt
#t1995
#cACM SIGART Bulletin
#index583912
#%537583
#!This position paper presents, we believe, a strong case for including in an undergraduate Computer Science (CS) program a required course in non-imperative programming. Such a course is motivated by the need to provide a uniform and adequate background for a course in Artificial Intelligence (AI). We make no claim about graduate AI courses. We survey the recommendations of the ACM-IEEE Joint Curriculum Task Force for an undergraduate course in AI and argue that some of the "dilemmas" of teaching introductory AI courses can be resolved by changes in the core CS curriculum. The argument for such a course is the focus of the paper; we also offer some ancillary remarks on other matters relating to teaching AI at the introductory level.


#*MPI-parallelized Radiance on SGI CoW and SMP
#@Roland Koholka,Heinz Mayer,Alois Goller
#t1999
#cProceedings of the 4th International ACPC Conference Including Special Tracks on Parallel Numerics and Parallel Computing in Image Processing, Video Processing, and Multimedia: Parallel Computation
#index262289


#*A queueing model for optimal control of partial buffer sharing in ATM
#@Ho Woo Lee,Boo Yong Ahn
#t1998
#cComputers and Operations Research
#index78696


#*Is merger-mania harming local competition?
#@Thomas K. Crowe
#t1998
#cComputer Telephony
#index293375


#*The Computer Major's Guide to the Real World, 1st edition
#@Alan Simon
#t1999
#c
#index614112
#!:The good news is that there are plenty of good jobs for trained college students with computer science majors. The bad news is that too many computer science majors leave their comforting academic environment and enter the cold, cruel employment world with inadequate skills for coping on a career level. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Extending and Managing Software Reflexion Models
#@Gail C. Murphy,David Notkin,Kevin Sullivan
#t1997
#c
#index192298
#!The artifacts comprising a software system often "drift" apart over time. Design documents and source code are a good example. The software reflexion model technique was developed to help engineers exploit---rather than remove---this drift to help them perform various software engineering tasks. More specifically, the technique helps an engineer compare artifacts by summarizing where one artifact (such as a design) is consistent with and inconsistent with another artifact (such as source). The use of the technique to support a variety of tasks-including the successful use of the technique to support an experimental reengineering of a system comprising a million lines-of-code-identified a number of shortcomings. In this paper, we present two categories of extensions to the technique. The first category concerns the typing of software reflexion models to allow different kinds of interactions to be distinguished. The second category concerns techniques to ease the investigation of reflexion models. These extensions are aimed at making the engineer more effective in performing various tasks by improving the management and understanding of the inconsistencies---the drift---between artifacts.


#*Identifying DEF/USE Information of Statements that Construct and Traverse Dynamic Recursive Data Structures
#@Yuan-Shin Hwang,Joel H. Saltz
#t1997
#cProceedings of the 10th International Workshop on Languages and Compilers for Parallel Computing
#index355219


#*Production scheduling: an interactive graphical approach
#@J. Steve Davis,J. J. Kanet
#t1997
#cJournal of Systems and Software
#index76269


#*Tom Clancy's Rainbow Six: Prima's Official Strategy Guide
#@Michael Knight,Tom Clancy
#t1998
#c
#index245525
#!:Tom Clancy is the master of military action. In Rainbow Six, you lead his elite multinational task force in a battle against international terrorism. To succeed in this treacherous mission you will need Prima's Official Strategy Guide. Inside you will find everything you need to concoct an effective plan and lead a terrifying assault, including backgrounds on the 20 special operatives from which you can choose your team, expert information for all 16 unique missions, specs for all weapons, details of all locations, and multiplayer tips and tactics.


#*Tangent @ 23 fire
#@Phillip George
#t1997
#cACM SIGGRAPH 97 Visual Proceedings: The art and interdisciplinary programs of SIGGRAPH '97
#index88871


#*Dynamically expanding modular neural network architecture for the control of robot manipulators
#@Young-Joo Moon,Se-Young Oh
#t1995
#cNeural, Parallel Scientific Computations
#index602815


#*Towards a new benchmarking paradigm in EDA: analysis of equivalence class mutant circuit distributions
#@Nevin Kapur,Debabrata Ghosh,Franc Brglez
#t1997
#cProceedings of the 1997 international symposium on Physical design
#index94324
#%96563


#*Hybrid genetic algorithms with hyperplane synthesis: a theoretical and empirical study
#@Byung-Ro Moon
#t1995
#c
#index604008


#*Year 2000: Best Practices for Y2K Millenium Computing
#@Dick Lefkon
#t1998
#c
#index619625
#!From the Book:PREFACE: Preface If you are 35 and reading this book at midnight of 1999, you will suddenly qualify for retirement on some pension systems. And if you're 82 or 83 years old at that time, some college selection computers will be eager to bring you in as a standard age first-year student. In a nutshell, that's the Year 2000/Y2K/Millennium computing crisis: Because most mainframe programs and machines—from Eisenhower through Clinton—stored and used only a two-digit year (97, not 1997), the year after O99 is O00. Take your age, subtract it from 00 and use a sign-free number, and you'll see how the example just described makes sense. If you don't believe me, how do you account for the 104-year-old woman in Minnesota who recently was sent a letter inviting her to join a pre-school there? Your core Y2K mission is to make your computer systems run right and make their external interfaces conform to (probably) the new FIPS and ANSI date standards reproduced in the first chapter of this book. Your non-IS people will learn to replace non-conformant embedded chips, so that, in March of this “surprise” leap year, your security systems won't automatically seal off the entryways every Friday, thinking it is a Saturday. Many goofy and amusing stories, often true, can be told about Year 2000 Computing. But it is very serious business. The cost of making the world's information systems work right will rival the cost of the U.S. Savings and Loan debacle—slightly smaller if you consider just the fixes, but larger if you include the damage and displacement costs to those who don't fix. Asingleparts factory shutdown recently stopped all General Motors manufacturing for months, so don't suppose that you can fix your systems and ignore whether or not your business partners fix theirs. And offsite code conversion has its savings limits, as you'll expend greater effort setting the inventory, baselining it onsite with confidential data, and retesting. Can a company change its systems to be Year 2000 conformant? Mostly, yes! I reported on having done this in 1984, and others may have done it earlier and just not reported it. (Having a non-production “time machine” test computer helped.) That company-wide change was in the securities business, and we treated the Y2K need as though it was an inflexible regulatory requirement with noncompliance penalties in both cash and reputation. So should you. Have organizations known about Y2K for a long time? Most certainly. For instance, attendees at my 1991 Y2K awareness paper presentations at the “Safe Computing” and “National Computer Security” conferences later told me they'd carried the alert back to their own companies, agencies and armed service branches. Is there a lot of time left? Unfortunately not, and two precedents come to mind. After AIDS was recognized as a general-population threat in 1985, it took eleven years of significant funding to bring forth medicines that can reduce its virus concentrations in the human body. But the U.S. metric conversion—of cost to manufacturing similar to Year 2000 for computing—was never completed, even though given a generous 20 years deadline. Year O00 is approaching much faster, and most suggest you finish before O99. Should conducting this Millennium war be left entirely to the “soldiers?” Probably not. Programmer/analysts generally reserve highest professional respect for those of greatest expertise, but several of the Y2K gurus gossiping over the Internet don't just want systems to work right and interfaces to carry a four-digit year: They won't rest —until every man, woman and child around the globe— also says “1998” instead of OO98. Should, then, techies be excluded from the deliberations? Again, no. The CIO sets the strategic course, the Y2K manager devises and executes the plan, but the house expert and soldier programmer/analysts should all also be involved in the planning phases for two reasons: (1) Collectively, they know most skeletons and closets; no outsourcing will as quickly catch dates passed in FILLER fields. And (2) morale must be one of your centerpieces or you'll find skeleton/closet expertise peeling away as each new month adds another dollar or two onto Y2K coder and manager hourly rates. This book truly represents the state of the art, both for do-it-yourself and for choosing a vendor to help if that's your desire. IBM, GUIDE, SIM, IMF, IMC, ACM, IEEE, AITP/DPMA, and nearly every recognized top professional in this field have permitted their best Y2K work to be reprinted here so that your corporation or agency will have available the knowledge to accomplish this organization-survival mission. These pages contain at least half the information you'll need to make decisions and take action. Once you absorb respectively the sections for CEO/CIO-expert-manager, you'll know how to obtain any further information needed. You'll also be able to defend yourself from vendors who truly believe they have another solution. You'll also be better at separating hard data from fluff at www sites such as dod.mil, gsa.gov, y2klinks.com, and year2000.command limiting your (212) 539-3072 Editor's Advice inquiries. If you had the extra millions or billions, you might be tempted to ignore and outsource the whole issue. Unfortunately, this is not a standard oranges-and-tangerines order, and it won't work just to throw three darts at a vendor list and select the best bid. that's because the solution paths (both outsourced and in-house) differ markedly from each other, and you can't choose if you don't know. For each application, you'll need to decide among date expansion, “smart” century, century, window, date shift in code or data, dropping/replacing the app, or not fixing it this century. Most technical and management books present one consistent approach. Even where excellent, that viewpoint will work only accidentally for your Y2K effort because of the diversity of distinct cures. The present volume lays out at least three different well-stated solutions to each Y2K issue. To enable this, we ran a four-month public competition for “Year 2000 Best Practices” papers. To publicize its completion, we are presenting a series of two-day Y2K conference free to user organizations, ever since the first edition was published in autumn of 1996. Even before being revised and expanded, that book was welcomed into the personal libraries of most Year 2000 practitioners; was heavily cited and excerpted in well-known Year 2000-related publications; was the technology resource for expert testimony to joint hearings of the U.S. House of Representatives Subcommittees on Science/Technology and Government Management; and contained material explicitly cited in expert testimony before the U.S. Senate Banking Committee. With this “final report” in hand, you'll see that Y2K isn't Nobel Prize stuff—just a prohibitively large set of familiar tasks. The best way to use this compendium is to get people bearing the titles CEO/CIO-expert-manager into a room for a series of meetings. Except for the start-up, all the planning meetings follow your usual format; but at the first meeting, each job title takes on the commitment to absorb a roughly equal slice of this book and at the next meeting to distribute/discuss a typed summary of aspects of our content which are specific to your organization. For most solutions, running this management-intensive effort under your established successful process will be a good way to proceed: You'll have the ongoing ability to triage nonessential conversions away from critical ones. And, when the inevitable bulge arises, you can divert reliable resources from non-Y2K efforts—not be forced to start inventing the wheel near the scheduled end of your path. Large organizations without an established “funnel” will want to set up a distinct (Y2K) project office. Remember that AITP used to be named DPMA, Data Processing Management Association. Our task as IS management is — literally — to rescue our organizations. All the co-authors and editors, including the initial project sponsors at AITPOs Special Interest Group for Mainframe Computers, want you to succeed! Dick Lefkon


#*Special issue on numerical methods for ordinary differential equations
#@R. Vichnevetsky,J. E. Flaherty
#t1995
#cApplied Numerical Mathematics
#index585115


#*Microsoft PowerPoint 97: Exam Prep, 1st edition
#@David W. Beskeen
#t1998
#c
#index619683
#!:"The demand for highly trained office workers is higher than it's ever been. Companies can't find enough skilled professionals and assessing the skills of applicants is difficult. To help with training and assessing of the skills of computer users, Microsoft has created the Microsoft Office User Specialist program. Certification is achieved by passing one or more exams in applying skills and solving real-world problems. Certification InsiderTM Press' Microsoft PowerPoint 97 Exam Prep is written by expert trainers to help office professionals prepare quickly for the Microsoft PowerPoint 97 exam. Each chapter is organized as a sequence of full-color interactive study projects.The unique hands-on tutorial approach with real-world exercises and projects is ideally suited for "on the job" training situations. Use of the lessons and the "active learning" CD-ROM will fully prepare the reader to pass the Microsoft PowerPoint 97 certification exam." "Proudly carries the Microsoft Approved Study Guide logo for that competitive edge." "Includes performance-based quiz feature to help readers quickly test their skills." "Fully illustrated in 4-color to help visualize tricky concepts." "Explains all of the PowerPoint 97 techniques that readers will need to know to be proficient with Microsoft PowerPoint 97 in a clear step-by-step format." Written by an experienced certification trainer. "Award-winning interactive simulation tutorial allows you to learn MS PowerPoint from within--a complete walk through all the basics." "Practice files for "step" and end-of-chapter skill practice eliminate the need to create the documents allowing the examcandidates to spend the extra study time reaching their goals." "David W. Beskeen (Pleasanton, CA) is a co-owner of Perspection, Inc., a company that produces computer training books. He has also authored or packaged over 20 books for the retail, corporate, and education markets since 1992. David has worked on successful book series such as the Illustratedseries, published by Course Technology and the Step by Step and At a Glance series, published by Microsoft Press."


#*Real-valued LMS Fourier analyzer for sinusoidal signals in additive noise
#@Yegui Xiao,Yoshiaki Tadokoro,Keiya Iwamoto
#t1998
#cSignal Processing
#index296164


#*An empirical study of dynamic graph algorithms
#@David Alberts,Giuseppe Cattaneo,Giuseppe F. Italiano
#t1996
#cProceedings of the seventh annual ACM-SIAM symposium on Discrete algorithms
#index294904
#%283468
#%525691
#%594287
#%600460


#*Image difference threshold strategies and shadow detection
#@Paul L. Rosin,Tim Ellis
#t1995
#cProceedings of the 1995 British conference on Machine vision (Vol. 1)
#index586003


#*A generic concept for reducing complexity in international operations - An asymptotic strive for manufacturing simplicity
#@M. Rudberg,M. West,Jan Olhager
#t1998
#cProceedings of the International Conference of the Manufacturing Value-Chain on Strategic Management of the Manufacturing Value Chain
#index266094


#*The impact of public policy on the diffusion and implementation of EDI: an evaluation of the TEDIS programme
#@Stefan Klein
#t1995
#cInformation Economics and Policy
#index582404


#*High-level synthesis and codesign methods: an application to a videophone codec
#@Pierre Paulin,Jean Fréhel,Michel Harrand,Elisabeth Berrebi,Clifford Liem,François Naçabal,Jean-Claude Herluison
#t1995
#cProceedings of the conference on European design automation
#index606239
#%590054
#%591348
#%605862


#*Analysis of Mouse Movement Time based on Varying Control to Display Ratios using Fitts'' Law
#@Joseph J. LaViola, Jr.
#t1997
#c
#index116892
#!This paper describes an experiment that attempts to determine what impact different control to display ratios will have on movement time of a mouse in a set of static tasks. The experiment shows that an increasing control to display ratio will actually increase the time it takes to perform a given task with a mouse. Linear regression models were built using Fitts'' law to get a correlation between the five different control to display ratios that were used. A discussion of how the experiment was conducted and analysis of the results will be provided.


#*Lexicon-driven word recognition
#@Chien-Huei Chen
#t1995
#cProceedings of the Third International Conference on Document Analysis and Recognition (Volume 2) - Volume 2
#index549049
#!Most conventional document understanding systems use lexicons only in a postprocessing step to verify or correct character recognition results. The authors present a new approach to word recognition that uses a lexicon to "drive" the recognition process. Lexicon words are encoded in trie data structures, and recognition of a word image is done by searching a lexicon trie for a path whose node characters yield the best match to the word image. This approach has two important advantages. First, it is segmentation-free; there is no need to presegment the text image into isolated characters. Second, it performs recognition by verifying character hypotheses, as opposed to the classification method used in most conventional optical character recognition (OCR) systems. Hence, the recognition process is more efficient and the results are more accurate. They demonstrated the feasibility and the advantage of this approach with a lexicon size of more than 50000 words, on severely degraded images.


#*Synchrotron x-ray photoconductor detector arrays made on MBE grown CdTe
#@S. S. Yoo,B. Rodricks,S. Sivananthan,J. P. Faurie,P. A. Montano
#t1996
#cJournal of Electronic Materials
#index596668


#*Multidimensional Outlines - WordgraphsTM
#@Robert B. Garvey
#t1998
#cProceedings of the 6th International Symposium on Graph Drawing
#index270192


#*Integrating communicative action, conversations and decision theory to coordinate agents
#@Mihai Barbuceanu,Mark S. Fox
#t1997
#cProceedings of the first international conference on Autonomous agents
#index77713
#%478606
#%591581
#%542267
#%620417
#%541854
#%620023
#%595044
#%212092


#*Using Tabu Search to Find Optimal Grasps in Scenes Represented by Triangular Meshes
#@Frank Ade,Martin Rutishauser,Markus Stricker
#t1996
#cIntelligent Robots: Sensing, Modeling and Planning [Dagstuhl Workshop, September 1-6, 1996]
#index276251


#*Complex Regions in Topological Queries
#@Viet Hai Nguyen,Christine Parent,Stefano Spaccapietra
#t1997
#cProceedings of the International Conference on Spatial Information Theory: A Theoretical Basis for GIS
#index367993


#*University research on branches of information system technology (Italian)
#@Interventi di I. De Lotto,A. Roveri,B. Ricco,G. Levi
#t1999
#cRivista di Informatica
#index288450


#*Solving the productivity paradox: TQM for computer professionals
#@Jessica Keyes
#t1995
#c
#index599824


#*Processes of contextual nets and their characteristics
#@Józef Winkowski
#t1998
#cFundamenta Informaticae
#index295801


#*An environment for supporting independent, individualized learning and problem solving
#@Susan M. William,Ray Bariess,Brian J. Reiser
#t1996
#cProceedings of the 1996 international conference on Learning sciences
#index21795
#%210871
#!We have been investigating ways of supporting middle-school students who are learning mathematics by constructing unique solutions to complex problems. This work addresses three needs in supporting independent, individualized learning and problem solving: realistic, complex contexts for learning, structured problem-solving activities that make complex problems more manageable for novices, and readily-available guidance for students during problem solving.Learning is problem-based. Students are asked to design and layout a playground in order to learn to measure, draw to scale, and compute perimeter, area, and volume. The curriculum encourages an iterative approach to problem solving in which students create designs, give each other feedback, and revise their work. To support their problem solving, a software environment provides a simple model of the design task that aids students in identifying sub-goals, brainstorming questions that provide general procedural hints, and two structured multimedia databases: A student database is used to record students' designs, annotated with procedures used, new concepts learned, design rationale, and evaluations. A performance support database provides an archive of previously created designs with associated conceptual and procedural information.


#*Conjugacy classes of &Ggr;(2) and spectral rigidity
#@Ralph Phillips
#t1995
#cMathematics of Computation
#index600654


#*Small minimal blocking sets and complete k-arcs in PG(2,p3)
#@Olga Polverino
#t1999
#cDiscrete Mathematics
#index286521


#*Why 32-bit desktops need virus protection
#@Fred Cohen
#t1995
#cDatamation
#index594938


#*An investigation of a cost-effective solution for multimedia medical information management
#@Ken Chee Keung Law,Horace Ho Shing Ip,Siu Lok Chan
#t1995
#cInformation and Management
#index607073


#*Finite algebras of finite complexity
#@Keith A. Kearnes,Emil W. Kiss
#t1999
#cDiscrete Mathematics
#index287392


#*Parallelism in LASSAP, a LArge Scale Sequence compArisons Package
#@Jean-Jacques Codani,Eric Glemet
#t1995
#cProceedings of the International Conference and Exhibition on High-Performance Computing and Networking
#index362379


#*Self-Tuning Systems
#@Dror G. Feitelson,Michael Naaman
#t1999
#cIEEE Software
#index439393
#%163354
#%211746
#%278316
#%377584
#%517247
#%463810
#%446144


#*Discovering HTML 4.0
#@Bryan Pfaffenberger
#t1998
#c
#index92741


#*Essential PowerPoint 97 Book: The Get It Done Tutorial
#@Faithe Wempen
#t1997
#c
#index619483
#!:Written by best-selling author and software guru Faithe Wempen, The Essential PowerPoint 97 Book is simply the most sought after PowerPoint instruction guide in the industry today.


#*Automated system for inspection planning
#@Yu. M. Paramonov,V. I. Abramor,A. A. Glagorsky
#t1999
#cComputers and Industrial Engineering
#index297848


#*JPMQ - An Advanced Persistent Message Queuing Service
#@Hans-Peter Steiert,Jürgen Zimmermann, II
#t1998
#cProceedings of the 16th British National Conferenc on Databases: Advances in Databases
#index380202


#*Source to Source Optimizations of CLP($\Re_{Lin}$)
#@Viswanath Ramachandran,Pascal Van Hentenryck
#t1995
#c
#index120594
#!This paper describes the design and implementation of an optimizing compiler for CLP($\Re_{Lin}$), a constraint logic programming language over linear real constraints. The compiler performs a number of source to source optimizations which aim at replacing constraint solving, the basic operation of the language, by assignments (when, at runtime, all but one variables have a fixed value) and tests (when, at runtime, all variables have a fixed value) These optimizations follow the 3R''s methodology which consists of refining, reordering, and removing constraints. The compiler uses abstract interpretation to decide when and how to perform the optimizations. The resulting system (40,000 lines of C, 10,000 of which concern the optimizations) has been evaluated experimentally. Our preliminary results indicate that substantial (often asymptotic) speedups can be obtained. Most of these speedups can be made arbitrary large, since they depend on the input size. This is, to our knowledge, the first operational compiler for CLP($\Re_{Lin}$) with these functionalities and the first implementation of reordering and constraint removal. It is also a convincing demonstration that abstract interpretation can be used to produce dramatic speedups for CLP($\Re_{Lin}$) programs.


#*Algorithm 745: computation of the complete and incomplete Fermi-Dirac integral
#@Michele Goano
#t1995
#cACM Transactions on Mathematical Software (TOMS)
#index605886
#%175473
#%319074
#%319886
#%451334
#%459872
#%476274
#%533712
#!Portable Fortran subroutines computing the Fermi-Dirac integral Fjx and the incomplete Fermi-Dirac integral Fjx,b are presented. For the first time a set of series expansions is implemented allowing these special functions to be evaluated efficiently within a prescribed accuracy for real jand x.


#*Change analysis in an architectural model: a design rationale based approach
#@Prasanta Bose
#t1998
#cProceedings of the third international workshop on Software architecture
#index89658
#%83967
#%85706
#%86004
#%295339
#%291668


#*Microsoft Visual Basic 6.0 Fundamentals with Cdrom
#@Kamran Iqbal,Tony Jamieson
#t1999
#c
#index235397
#!:The ultimate self-study solution for beginning Visual Basic 6.0 developers, this manual is straight-from-the-source training designed to help users build their expertise in creating custom solutions using Microsoft developer tools and technologies. The CD-ROM contains complete code from the lessons, which students can reuse in their own applications.


#*Inside Microsoft Research
#@Scott Hamilton
#t1998
#cComputer
#index448697
#%586654
#!What are 250 top researchers from academia and industry working on at Microsoft Research? What attracted them to Redmond, Washington, as well as two new facilities in San Francisco and Cambridge, UK? MSR's appeal to its researchers is that their research will likely be "productized" for the mass market. Each of three metagroups have long-term goals but look for ways to incorporate their research into products shipping now. Research is already shipping in some form in nearly every Microsoft product. This article gives an overview of the organization and goals of MSR, established in 1991 to look three to five years out to ensure that Microsoft remains well ahead of the technology curve. As a corporate research lab, MSR is unapologetic about its intentions to identify and fund technologies and new applications that are relevant to Microsoft's corporate strategy. Research is tightly coupled to Microsoft's vision of next-generation systems and software development: PCs that are intuitive to even neophytes, programming paradigms and tools that improve programmer productivity and program maintainability, and next-generation systems for the enterprise. Three metagroups-Advanced Interactivity and Intelligent Systems; Programming Tools and Methodologies; and Systems and Architecture-undertake research in roughly 20 areas, including speech technology, vision, natural language processing, user interface development, and decision theory.


#*A hierarchical layout algorithm for drawing directed graphs
#@Jason Reynolds
#t1998
#c
#index89940


#*Auto-recoverable Auto-certifiable Cryptosystems (A Survey)
#@Adam Young,Moti Yung
#t1999
#cProceedings of the International Exhibition and Congress on Secure Networking - CQRE (Secure) '99
#index561442


#*On flexible support for mobile objects
#@W. Joosen,F. Matthijs,J. Van Oeyen,B. Robben,S. Bijnens,P. Verbaeten
#t1996
#cProceedings of the 5th International Workshop on Object Orientation in Operating Systems (IWOOOS '96)
#index119352
#!CORRELATE is a concurrent object-oriented language with a flexible run time system that enables the instantiation of application specific run time objects. We have exploited this capability in the development of mobile agents for large scale distributed computing systems, such as the Internet. We discuss some key elements of the run time system. We illustrate how the system architecture supports mobile objects, we discuss what it requires from the operating system and how we aim at evolving towards more flexibility.


#*An efficient shape representation scheme using Voronoi skeletons
#@Niranjan Mayya,V. T. Rajan
#t1995
#cPattern Recognition Letters
#index586131


#*Compiling array expressions for efficient execution on distributed-memory machines
#@S. K. S. Gupta,S. D. Kaushik,C.-H. Huang,P. Sadayappan
#t1996
#cJournal of Parallel and Distributed Computing
#index590226


#*Inference Rights for Controlling Search in Generating Theorem Provers
#@Dirk Fuchs
#t1997
#cProceedings of the 8th Portuguese Conference on Artificial Intelligence: Progress in Artificial Intelligence
#index379264


#*Transform predictive coding of wideband speech signals
#@Juin-Hwey Chen,Dongmei Wang
#t1996
#cProceedings of the Acoustics, Speech, and Signal Processing, 1996. on Conference Proceedings., 1996 IEEE International Conference - Volume 01
#index415425
#!This paper presents a novel wideband speech coding algorithm called transform predictive coding (TPC). The main emphasis is on low complexity. TPC uses short-term and long-term prediction to remove the redundancy in speech. The prediction residual is quantized in the frequency domain based on a calculated noise masking threshold. In its simplest form, the TPC coder uses only open-loop quantization and therefore has a low complexity. A 16 kb/s full-duplex, open-loop TPC coder takes only 22% of the CPU load on a 150 MHz SGI Indy workstation and about 34% on a 90 MHz Pentium PC. The speech quality of TPC is almost transparent at 32 kb/s, very good at 24 kb/s, and acceptable at 16 kb/s. In the second half of the paper, we report our recent progress in using closed-loop quantization techniques to improve TPC output speech quality.


#*Illustrator 8 F/X and Design with Cdrom, 1st edition
#@Sherry London,T. Michael Clark
#t1999
#c
#index240965
#!From the Book: Introduction Introduction Im so glad that youre reading this page. Whether youve just purchased this volume or youre thinking about it, I want to tell you why Michael and I have written this book and what you can expect from it. There are many Illustrator books on the market, and each one does something slightly differentor does it in a different way. Almost all are good books, how do you begin to select which one or ones to buy? Illustrator books seem to fall into several categories. There are the "manual replacements." These books are usually of mid-length and repeat the commands in the manual, restating them in case you couldnt understand Adobes directions. These books are for total beginners or for infrequent users of Illustrator who need to be reminded of how to do a specific thing. Then there are exhaustive reference volumes such as Ted Alspachs Illustrator 8 Bible and Deke McClellands Real World Illustrator. These wonderful books belong on everyones book shelf. You can learn something new from either of these books each time you look at them. Finally, there are books that showcase the design tricks of a variety of artists. These books are like wonderful eye candy, and just looking at them can inspire you. They are sometimes a bit short on guidance, but they are fantastic sources of creative ideas. About This Book So what approach does this book take? It takes a bit of them all and a lot of none-of-the-above. In your hands, you hold a book written by two opinionated artists. We picked a wide (but by no means exhaustive) range of techniques and gave you a tutorial to follow. Although this book is really not for the rank beginnerwe assume that you already know the basics of Illustratorwe go to extreme lengths to ensure that you can follow the instructions for the projects. Every step is clearly stated, so even if youre not an expert when you start this book, youll be much closer to that status when you finish it. If you work your way through it at the computer (it isnt a novelyou really need a computer sitting in front of you as you read), youll find that you learn things about Illustrator that you never knew. Weve tried to give you a range of start-to-finish projects that go from basic idea to completed artwork. Weve tried very hard to find a balance in the amount of work needed to complete each project. Sometimes you start from a blank document; at other times, we give you the critical pieces. To make it easier to work through each chapter, weve included a CD-ROM with the book. For each Illustration (really an exercise or a project, but this is a book on Illustrator, so I came up with this catchy title for these elements), youll find two figure areas on the CD-ROM. One area contains all the images that you need to start and build the project. The other folder contains the finished projects so that you can learn by looking at the completed work and see what objects were defined and how. Illustrator is much better than Photoshop in this regard. Many things that you do in Illustrator leave "tracks" so that its easier to reconstruct the way that the project was worked. In Illustrator, for example, if I applied a gradient to an object on this books CD-ROM, you will see by clicking on the object exactly what gradient was applied (and if you like it, you can reuse it in your own images). In Photoshop, there is no reasonable way to figure out the colors in a gradient. The raster format of Photoshop simply applies and moves on. You also get the benefit of multiple authors in this book. Though I wrote 2/3 of the book, Michaels unique perspective adds value and is a good complement. Its always good to get multiple opinions, and in this book, you do. As you read each chapter, our bylines tell you which one of us is speaking. Because Michael and I are quite different, our approach to the program is different as well. You can never have too many teachers. Teacher. Thats what Ive been for many years, and thats what I consider myself to be as I write this book. Teacher. Guide. Friend. The best part of this is seeing the "student" surpass me. Many of you willand that makes this book worth writing (for me) and worth reading (for you). Enjoy! I had a great time writing this book, and I hope that you enjoy it. Keep in touch. My email address is slondon@earthlink.net. Michaels is tmc@grafx-design.com. Sherry London About Third-Party Filter Sets Although this book is in the f/x and design series, weve chosen not to provide extensive coverage of most of the available third-party filter sets. Most third-party filters are Macintosh-only, and we really dont want to receive email flames from the Windows-only readers who may misunderstand our appearing to give preferential treatment to the Mac. The other (major) consideration is that Adobe changed the plug-in interface with Illustrator 8 so that many of the currently available third-party plug-ins are no longer 100-percent compatible (and few of them are even being sold). Here is the status of Illustrator 6 and 7 filter sets that are considered incompatible with Illustrator 8. These sets are Macintosh-only. Table I Illustrator filter set status. Company Filter Set Name Retail Status Alien Skin Stylist Not Being Sold BeInfinite InfinteF/X Not Being Sold Cytopia Software CSI Not Being Sold Extensis Vector Tools 2.0 Available Letraset Envelopes Not Being Sold MetaCreations KPT Vector Effects Not Being Sold This leaves you with little choice. However, you can use some of these filters, after a fashion. The Extensis Vector Tools still work if you remove everything to do with Vector Bars and Vector Tips. VectorTools also tries to install a menubar at the top of the screen to allow you to access the filters. This bar doesnt install properly, but seems to "find" itself after you access the menus a bit. It eventually pushes the Help menu over one spot to the right. The color and the shapes filters that remain all seem to work properly, and it is lovely to be able to randomize colors and adjust them. The KPT Vector Effects filters all seem to work without problems, but this set was withdrawn from the marketplace. So, if you have them, try them on your system. I dont think that some of the previews work as well as they previously did, but the effects seem fully usable. The CSI filters are also no longer for sale. They work if you remove anything that says Start-up or Plug-in from the set. The CSI filters gave you good control over 3D manipulations of vector objects (although you can do the same thing with the KPT Vector Effects filters). The Letraset and BeInfinite filters have not been available for a number of years (although you can try them if you already own them). Alien Skin Stylist will not work at all.


#*Macromedia Director 5 for Dummies, 2nd edition
#@Lauren Steinhauer
#t1996
#c
#index621966
#!:If becoming a Macromedia Director whiz is you sweetest dream, but figuring out how to use it is your worst nightmare, then Macromedia« Director« 5 For Dummies«, 2nd Edition, has your name written all over it! This friendly, easy-to-use reference gives you the jump start you need when working with multimedia and publishing on the web. Inside, find helpful advice on how to: Get the information you need on Director's essential commands and features, including Shockwave, your key to working with multimedia on the Web without programming Reference crucial information without taking intimidating detours into complex technical issues Successfully build cross-platform movies for the MacOS and Microsoft Windows Delve confidently into the World Wide Web with Lingo, Director's easy-to-understand scripting language Add high-powered multimedia to your Web site and all your business communications Create push-button animated bullet charts that zoom and slide with Animation Wizard Plus Lauren's Top Ten Lists: Ten important questions and answers about Macromedia Director Ten ways to add animation to your movies Ten important Lingo commands to discover


#*Tractable constraints in finite semilattices
#@Jakob Rehof,Torben Ægidius Mogensen
#t1999
#cScience of Computer Programming
#index284363


#*Trust-Region Interior-Point SQP Algorithms for a Class of Nonlinear Programming Problems
#@J. E. Dennis,Matthias Heinkenschloss,Luís N. Vicente
#t1998
#cSIAM Journal on Control and Optimization
#index287870
#!In this paper, a family of trust-region interior-point sequential quadratic programming (SQP) algorithms for the solution of a class of minimization problems with nonlinear equality constraints and simple bounds on some of the variables is described and analyzed. Such nonlinear programs arise, e.g., from the discretization of optimal control problems. The algorithms treat states and controls as independent variables. They are designed to take advantage of the structure of the problem. In particular they do not rely on matrix factorizations of the linearized constraints but use solutions of the linearized state equation and the adjoint equation. They are well suited for large scale problems arising from optimal control problems governed by partial differential equations.The algorithms keep strict feasibility with respect to the bound constraints by using an affine scaling method proposed, for a different class of problems, by Coleman and Li [SIAM J. Optim., 6 (1996), pp. 418--445] and they exploit trust-region techniques for equality-constrained optimization. Thus, they allow the computation of the steps using a variety of methods, including many iterative techniques.Global convergence of these algorithms to a first-order Karush--Kuhn--Tucker (KKT) limit point is proved under very mild conditions on the trial steps. Under reasonable, but more stringent, conditions on the quadratic model and on the trial steps, the sequence of iterates generated by the algorithms is shown to have a limit point satisfying the second-order necessary KKT conditions. The local rate of convergence to a nondegenerate strict local minimizer is q-quadratic. The results given here include, as special cases, current results for only equality constraints and for only simple bounds.Numerical results for the solution of an optimal control problem governed by a nonlinear heat equation are reported.


#*Vlsi implementation of cellular neural networks
#@Jose Maria Cruz-Moreno
#t1996
#c
#index194568


#*A Longitudinal Study of Software Process Improvement
#@Brian Fitzgerald,Tom O'Kane
#t1999
#cIEEE Software
#index442514
#%441908
#%515427
#%585800


#*On the worst-case complexity of integer Gaussian elimination
#@Xin Gui Fang,George Havas
#t1997
#cProceedings of the 1997 international symposium on Symbolic and algebraic computation
#index92568
#%84761
#%602810
#%589881


#*Envisioning communication: task-tailorable representations of communication in asynchronous work
#@Christine M. Neuwirth,James H. Morris,Susan Harkness Regli,Ravinder Chandhok,Geoffrey C. Wenger
#t1998
#cProceedings of the 1998 ACM conference on Computer supported cooperative work
#index94430
#%83932
#%583932
#%275597
#%482285
#%600328
#%519425
#%543375
#%459553
#%485077
#%183311


#*STOCKS, BONDS, AND BOTH: an exercise in risk/return tradeoffs
#@Karen M. Hogan,Richard J. Kish
#t1999
#cSimulation and Gaming
#index282370


#*A Review of Experiences with Reliable Multicast
#@Kenneth Birman
#t1999
#c
#index114715
#!By understanding how real users have employed reliable multicast in real distributed systems, we can develop insight concerning the degree to which this technology has matched expectations. This paper reviews a number of applications with that goal in mind. Our findings point to tradeoffs between the form of reliability used by a system and its scalability and performance. We also find that to reach a broad user community (and a commercially interesting market) the technology must be better integrated with component and object-oriented systems architectures. Looking closely at these architectures, however, we identify some assumptions about failure handling which make reliable multicast difficult to exploit. Indeed, the major failures of reliable multicast are associated with attempts to position it within object oriented systems in ways that focus on transparent recovery from server failures. The broader opportunity appears to involve relatively visible embeddings of these tools into object-oriented architectures enabling knowledgeable users to make tradeoffs. Fault-tolerance through transparent server replication may be better viewed as an unachievable holy grail. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Modulated filter banks and wavelets-a general unified theory
#@R. A. Gopinath
#t1996
#cProceedings of the Acoustics, Speech, and Signal Processing, 1996. on Conference Proceedings., 1996 IEEE International Conference - Volume 03
#index419198
#!This paper generalizes and unifies well-known results on modulated filter banks (MFBs) and modulated wavelet tight frames (MWTFs). It classifies MFBs based on the discrete cosine or sine transforms that they are associated with. By proper choice of the form of modulation the perfect reconstruction (PR) conditions are seen to be (surprisingly) identical for all classes of MFBs. This has the interesting consequence that optimal MFB prototype designs can be shared across MFB classes. For some classes of MFBs associated MWTFs do not exist, while for others they do. The results cover both orthogonal and biorthogonal MFBs; and the filters could be arbitrary sequences in l/sup 2/(Z).


#*Detection and Recognition of Periodic, Nonrigid Motion
#@Ramprasad Polana,Randal C. Nelson
#t1997
#cInternational Journal of Computer Vision
#index83139
#%589822
#%471727
#%482994
#%186918
#!The recognition of nonrigid motion, particularly that arising from human movement (and by extension from the locomotory activity of animals) has typically made use of high-level parametric models representing the various body parts (legs, arms, trunk, head etc.) and their connections to each other. Such model-based recognition has been successful in some cases; however, the methods are often difficult to apply to real-world scenes, and are severely limited in their generalizability. The first problem arises from the difficulty of acquiring and tracking the requisite model parts, usually specific joints such as knees, elbows or ankles. This generally requires some prior high-level understanding and segmentation of the scene, or initialization by a human operator. The second problem, with generalization, is due to the fact that the human model is not much good for dogs or birds, and for each new type of motion, a new model must be hand-crafted. In this paper, we show that the recognition of human or animal locomotion, and, in fact, any repetitive activity can be done using low-level, non-parametric representations. Such an approach has the advantage that the same underlying representation is used for all examples, and no individual tailoring of models or prior scene understanding is required. We show in particular, that repetitive motion is such a strong cue, that the moving actor can be segmented, normalized spatially and temporally, and recognized by matching against a spatio-temporal template of motion features. We have implemented a real-time system that can recognize and classify repetitive motion activities in normal gray-scale image sequences. Results on a number of real-world sequences are described.


#*A parallel MPEG-2 video encoder with look-ahead rate control
#@P. Tiwari
#t1996
#cProceedings of the Acoustics, Speech, and Signal Processing, 1996. on Conference Proceedings., 1996 IEEE International Conference - Volume 04
#index425016
#!We describe a parallel implementation of a MPEG-2 compliant, constant bit rate video encoder on a shared memory system. The emphasis is on techniques for obtaining compressed video with picture quality superior to that of commercially available real-time hardware encoders. We propose a novel scheme for bit allocation and rate control. The most remarkable aspect of this scheme is the analysis of future frames in order to determine bit allocation for the current frame. This analysis includes use of preliminary motion estimation, masking factor computation, and coding regions of future frames to model their coding complexity. To the best of our knowledge, this is the first instance of an MPEG encoder which integrates a detailed analysis of future frames in the bit-allocation/rate-control mechanism.


#*An Argumentation-Theoretic Approach to Logic Program Transformation
#@Francesca Toni,Robert A. Kowalski
#t1995
#cProceedings of the 5th International Workshop on Logic Programming Synthesis and Transformation
#index277662


#*An integrated junior-year laboratory based on an autonomous mobile robot platform
#@J. Y. Hung
#t1998
#cProceedings of the 28th Annual Frontiers in Education - Volume 03
#index431517
#!In the Fall 1997 quarter, the Department of Electrical Engineering (EE) at Auburn University implemented a new curriculum model. A significant feature of the new curriculum is a set of 6 core laboratories, occurring over the sophomore and junior years. Unlike prior EE laboratories that are closely aligned with a specific course topic, the new core laboratories are designed to present EE topics in an integrated, multidisciplinary fashion. In this paper, the author describes one of the junior-year laboratory courses, "EE 305-Laboratory V". The EE 305 laboratory course appears in the students' second quarter of the junior year, and is based on a design problem in which teams of 2-3 students attempt to design and fabricate an electronic control system for a small autonomous mobile robot. Topics from several EE subdisciplines are studied as students attack the design project. In addition to reinforcing concepts from earlier and concurrent courses, the course serves as a platform for exposing students to topics that appear in greater depth in later courses, including electives. Also, students mature in areas such as oral and written communication, awareness of professional ethics issues, and working effectively in a team-based setting. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*On bounds for size Ramsey numbers of a complete tripartite graph
#@Izolda Gorgol
#t1997
#cSelected papers from the second Krakow conference on Graph theory
#index93399


#*GW-Ada/Ed: free Ada 83 development environments for IBM PC-compatible and Apple Macintosh computers
#@Michael B. Feldman,Charles W. Kann,Arthur Vargas Lopes,Manuel A. Pérez-Quiñones
#t1995
#cProceedings of the conference on TRI-Ada '95: Ada's role in global markets: solutions for a changing complex world
#index326745
#%214149
#%228573
#%516173
#%481888


#*Java 1.2 Class Libraries Unleashed, 1st edition
#@Krishna Sankar
#t1998
#c
#index254654


#*Integrated multi-media computers in the execution of ISO9000 quality system requirements for document control and training
#@J. Edwards,P. R. Gibson
#t1997
#cComputers and Industrial Engineering
#index78105


#*West's Essential Lotus 1-2-3 for Windows Release 5, 1st edition
#@Pusins
#t1995
#c
#index250164


#*Monitoring Motorway Infrastructures for Detection of Dangerous Events
#@G. L. Foresti,B. Pani
#t1999
#cProceedings of the 10th International Conference on Image Analysis and Processing
#index552451
#!In this paper, a visual-based surveillance system for monitoring motorway infrastructures is presented. The system receives in input a sequence of color images and makes out an interpretation of the observed scene according to a set of possible events previously defined.The considered events are divided into four classes and range from normal situations (any object is present on the surveilled overpass) to very dangerous situations (persons performing harmful behaviors). Experimental results are presented on a long real image sequence containing two persons with suspicious behavior moving into a limited area of a motorway overpass.


#*A Distribution Format for Communication-Free Reshape in Distributed Memory Computers
#@Hyun-Gyoo Yook,Mi-Soon Koo,Myong-Soon Park,Tae-Guen Kim
#t1997
#cProceedings of the 1997 International Conference on Parallel and Distributed Systems
#index269455
#!Data parallel languages designed for distributed memory computing environments provide a single global address space to the programmer. The mapping from this global address space to the distributed local address space is performed by a compiler, which does this mapping based on the array distribution format. Thus, each array in a data parallel language program has its own distribution format. The Reshape function changes the array distribution format as well as the array shape. However, the changed distribution format cannot be represented by any distribution format supported in current languages. Because there is no suitable distribution format, it is necessary to change the reshaped distribution format to an existing distribution format, with heavy overhead due to the redistribution function. To eliminate the redistribution step in Reshape function, we have proposed a new distribution format, HIER-CYCLIC, which can represent the reshaped distribution format. We have also proposed a language syntax to use HIER-CYCLIC and a compiling mechanism. Finally, we performed an experiment on an IBM-SP2 machine using a shift function.**


#*Flow Visualization and Image Processing of Multiphase Systems
#@Wen-Jei Yang,F. Mayinger,F. Yamamoto
#t1995
#c
#index234468


#*Performance of the gallery parallel file system
#@Nils Nieuwejaar,David Kotz
#t1996
#cProceedings of the fourth workshop on I/O in parallel and distributed systems: part of the federated computing research conference
#index594755
#%110128
#%114003
#%117722
#%195269
#%220133
#%370268
#%527909
#%588644
#%606264


#*A formalism for inter-perspective relationships checking
#@Laurent Perrussel,Pierre-Jean Charrel,Bernard Rothenburger
#t1998
#cInformation modelling and knowledge bases VIII
#index285322


#*Computer-aided design-for-reliability of deep sub-micron integrated circuits
#@Aurobindo Dasgupta
#t1996
#c
#index192398


#*What's in a word?
#@Stan Kelly-Bootle
#t1997
#cSoftware Development
#index93283


#*Cellular digital packet data
#@C.-K. Toh
#t1998
#cACM SIGMOBILE Mobile Computing and Communications Review
#index237091


#*Blocking Gibbs sampling in very large probabilistic expert systems
#@Claus S. Jensen,Uffe Kjærulff,Augustine Kong
#t1995
#cInternational Journal of Human-Computer Studies
#index604099


#*Infinite State Model Checking by Abstract Interpretation and Program Specialisation
#@Michael Leuschel,Thierry Massart
#t1999
#cSelected papers from the 9th International Workshop on Logic Programming Synthesis and Transformation
#index261576


#*On rational interpolation to |x| at the adjusted Chebyshev nodes
#@Lev Brutman
#t1998
#cJournal of Approximation Theory
#index295660


#*Context sensitive case comparisons in practical ethics: reasoning about reasons
#@Bruce M. McLaren,Kevin D. Ashley
#t1995
#cProceedings of the 5th international conference on Artificial intelligence and law
#index604040
#%154644
#%363935
#%461394
#%511368
#%517814


#*Labour Movement and the Internet: The New Internationalism
#@Eric H. Lee
#t1997
#c
#index624359
#!:'The Labour Movement and the Internet' is the first guide to the new electronic medium written specifically for trade unionists worldwide.


#*Enterprise Objects Framework: a second generation object-relational enabler
#@Charly Kleissner
#t1995
#cProceedings of the 1995 ACM SIGMOD international conference on Management of data
#index596877
#%169380
#%457425
#%520215
#%521312
#!Today's information system executives desperately need to improve programmer productivity and reduce software maintenance costs. They are demanding flexibility in frameworks and architectures in order to meet unforeseen changes (see [Yankee 94]). Adaptability is a major requirement of most company's information systems efforts. Management of change is one of the key computing concepts of the 1990s.Object-oriented tools and development frameworks are starting to deliver the benefits of increased productivity and flexibility. These next-generation products now need to be combined with relational databases to leverage investments and facilitate access to business data. Object-Relational Enablers automate the process of storing complex objects in a relational database management system (see [Aberdeen 94]).The Enterprise Objects Framework product is a second generation product bringing the benefits of object-oriented programming to relational database application development. Enterprise Objects Framework enables developers to construct reusable business objects that combine business logic with persistent storage in industry-standard relational databases. Enterprise objects are first class citizens in the NEXTSTEP and OpenStep developer and user environments. They can be geographically distributed throughout heterogeneous servers within an enterprise using the Portable Distributed Objects product (see [NeXT-DO 94]).In this extended abstract we first describe the enterprise object distribution model and then give a brief synopsis of how relational data is mapped into objects. We then present an outline of the system architecture, explain how objects are mapped to multiple tables, and summarize the transaction semantics as well as the application development life-cycle. We conclude with an outlook on future development.


#*Convergence of matrix LMS algorithms with applications to LMS/Newton
#@C. Horn,R. H. Kwong
#t1995
#cSignal Processing
#index596083


#*How To Reason About Akratic Action Practically?
#@Valentyn Omelyanchyk
#t1996
#cProceedings of the International Conference on Formal and Applied Practical Reasoning
#index381418


#*Progress in robotics and intelligent systems: volume 3
#@George W. Zobrist,C. Y. Ho
#t1995
#c
#index606147


#*Prefix Computations on Symmetric Multiprocessors
#@David R. Helman,Joseph JáJá
#t1999
#cProceedings of the 13th International Symposium on Parallel Processing and the 10th Symposium on Parallel and Distributed Processing
#index567870
#!We introduce a new optimal prefix computation algorithm on linked lists which builds upon the sparse ruling set approach of Reid-Miller and Blelloch. Besides being somewhat simpler and requiring nearly half the number of memory accesses, we can bound our complexity with high probability instead of merely on average. Moreover, whereas Reid-Miller and Blelloch targeted their algorithm for implementation on a vector multiprocessor architecture, we develop our algorithm for implementation on the symmetric multiprocessor architecture (SMP). These symmetric multiprocessors dominate the high-end server market and are currently the primary candidate for constructing large scale multiprocessor systems. Our prefix computation algorithm was implemented in C using POSIX threads and run on four symmetric multiprocessors - the IBM SP-2 (High Node), the HP-Convex Exemplar (S-Class), the DEC AlphaServer, and the Silicon Graphics Power Challenge.We ran our code using a variety of benchmarks which we identified to examine the dependence of our algorithm on memory access patterns. For some problems, our algorithm actually matched or exceeded the performance of the standard sequential solution using only a single thread. Moreover, in spite of the fact that the processors must compete for access to main memory, our algorithm still achieved scalable performance with up to 16 processors, which was the largest platform available to us.


#*Learning-based hand sign recognition using SHOSLIF-M
#@Yuntao Cui,D. L. Swets,J. J. Weng
#t1995
#cProceedings of the Fifth International Conference on Computer Vision
#index551780
#!We present a self-organizing framework called the SHOSLIF-M for learning and recognizing spatiotemporal events (or patterns) from intensity image sequences. The proposed framework consists of a multiclass, multivariate discriminant analysis to automatically select the most discriminating features (MDF), a space partition tree to achieve a logarithmic retrieval time complexity for a database of n items, and a general interpolation scheme to do view inference and generalization in the MDF space based on a small number of training samples. The system is tested to recognize 28 different hand signs. The experimental results show that the learned system can achieve a 96% recognition rate for test sequences that have not been used in the training phase.


#*A sequential multinomial selection procedure with elimination
#@D. M. Goldsman,A. J. Hayter,T. M. Kastner
#t1997
#cAdvances in statistical decision theory and applications
#index84699


#*Linear-time algorithms for parametric minimum spanning tree problems on planar graphs
#@David Fernández-Baca,Giora Slutzki
#t1997
#cTheoretical Computer Science
#index79276


#*Analysis of timing-based mutual exclusion with random times
#@Eli Gafni,Michael Mitzenmacher
#t1999
#cProceedings of the eighteenth annual ACM symposium on Principles of distributed computing
#index296186
#%77820
#%180095
#%223551
#%287914


#*An Introduction to the Layered Characterisation for High Performance Systems
#@E. Papaefstathiou,D. J. Kerbyson,G. R. Nudd,T. J. Atherton,J. S. Harper
#t1997
#c
#index198254
#!A toolset for performance analysis of parallel systems, PACE, is presented in this report. In this toolset expert knowledge about the performance evaluation techniques is not required as a prerequisite for the user. Instead a declarative approach to the performance study is taken by describing the application in a way that is both intuitive to the user, but can also be used to obtain performance results. The underlying performance related characterisation models and their evaluation processes are hidden from the user. This document describes the special purpose language, and the evaluation system, that form the core of the PACE toolset. Amongst the aims of the toolset is the support of characterisation model reusability, ease of experimentation, provide different levels of prediction accuracy, and support of different levels of characterisation model abstraction.


#*Inside the Linux kernel
#@Ted Ts'o
#t1999
#cProceedings of the 3rd annual conference on Atlanta Linux Showcase - Volume 3
#index422749


#*Multiscalar processors
#@Gurindar S. Sohi,Scott E. Breach,T. N. Vijaykumar
#t1998
#c25 years of the international symposia on Computer architecture (selected papers)
#index82914
#%78745
#%541261
#%169230
#%328811


#*Pseudo-optimal choice of parameter for the regularization method
#@A. S. Leonov
#t1995
#cComputational Mathematics and Mathematical Physics
#index585648


#*Polarization-space-time domain generalized likelihood ratio detection of radar targets
#@Hyung-Rae Park,Jian Li,Hong Wang
#t1995
#cSignal Processing
#index583842


#*Comparing Self-Organizing Maps
#@Samuel Kaski,Krista Lagus
#t1996
#cProceedings of the 1996 International Conference on Artificial Neural Networks
#index370021


#*Perfect reconstructing nonlinear filter banks
#@D. A. F. Florencio
#t1996
#cProceedings of the Acoustics, Speech, and Signal Processing, 1996. on Conference Proceedings., 1996 IEEE International Conference - Volume 03
#index430723
#!Perfect reconstruction (PR) filter banks have found numerous applications, and have received much attention in the literature. For linear filter banks, necessary and sufficient conditions for PR have been established for most practical situations. Recently, nonlinear filter banks have been proposed for image coding applications. These filters are generally simple, and produce better results than linear filters of same complexity. Nevertheless, the lack of general PR conditions limits these filters to cases where one of the filters is the identity. In this paper, we present a framework that allows, for the first time, the design of PR nonlinear filter banks including (non-trivial) filters on all channels. Although the framework does not include all nonlinear PR filter banks, it does include all previously published nonlinear filter banks, as well as all linear ones. This framework suggest new possibilities for the design of nonlinear PR filter banks.


#*Proceedings of the Acoustics, Speech, and Signal Processing, 1996. on Conference Proceedings., 1996 IEEE International Conference - Volume 03
#@
#t1996
#cICASSP
#index428172


#*Safety Related Standards: A Tutorial
#@Victoria Stavridou
#t1999
#cProceedings of the 4th IEEE International Symposium and Forum on Software Engineering Standards
#index112109
#!The objective of this tutorial is to introduce current and emerging standards that address computer system and software safety. We consider relevant available standards and identify their strengths and weaknesses, we explore how to evaluate standards and we consider their application in practice. We address in depth IEC 61508 and Def Stan 00-56, two important standards. In addition, we will discuss current safety standards activity within the IEEE Software Engineering Standards Committee and we will touch upon the thorny issue of introducing standards into an organization. The tutorial will be practical and will address the application - not just the theory of safety standards. The tutorial is aimed at managers, project managers, safety engineers and software engineers with system or safety responsibility during the lifecycle of safety critical systems.


#*Frequency Filtering for Elliptic Interface Problems with Lagrange Multipliers
#@B. N. Khoromskij,G. E. Mazurkevich,G. Wittum
#t1999
#cSIAM Journal on Scientific Computing
#index299881
#!The solution of the saddle point interface problem arising in hybrid formulation with the Lagrange multipliers for elliptic problems with nonmatching grids is considered. The preconditioner is constructed using frequency filtering decompositions of the local Schur complements. The convergence rate of the resulting iterative process does not depend on the size of the interface problem. The approach is applied for the treatment of the local refinement procedures and considered as an alternative to the refinement with slave nodes or full closure of the grid. Numerical experiments on the convergence rate are presented.


#*Should/Could Software Be More Reliable than the "World" in Which it is Used?
#@W. Turski
#t1998
#cProceedings of the The Ninth International Symposium on Software Reliability Engineering
#index114942


#*Necessary and Sufficient Conditions for Consistent Global Snapshots
#@Robert H. B. Netzer,Jian Xu
#t1995
#cIEEE Transactions on Parallel and Distributed Systems
#index595845
#%160921
#%161348
#%216269
#%319217
#%476544
#!Consistent global snapshots are important in many distributed applications. We prove the exact conditions for an arbitrary checkpoint, or a set of checkpoints, to belong to a consistent global snapshot, a previously open problem. To describe the conditions, we introduce a generalization of Lamport's happened-before relation called a zigzag path.Index Terms¿Causality, global checkpoints, distributed systems, consistent global states, Lamport's happened-before relation.


#*A Parallel System for Dynamic 3D Medical Imaging
#@M. F. Santarelli,V. Positano,L. Landini,O. Parodi,T. Serafini
#t1997
#cProceedings of the International Conference and Exhibition on High-Performance Computing and Networking
#index361989


#*Recent advances in evolvable systems-ices 96 (international conference on evolvable systems)
#@Ian Frank,Bernard Manderick,Tetsuya Higuchi
#t1997
#cEvolutionary Computation
#index347490
#!This paper reviews the developments in evolvable hardware systems presented at the First International Conference on Evolvable Systems (ICES 96). The main body of the review gives an overview of the 34 papers presented orally, splitting them into three broad groups according to whether they involve (1) evolving a fit solution to a problem as a member of a population of competing candidates, (2) evolving solutions that can individually learn from and adapt to their environments, or (3) the embryonic growth of solutions. We also review the discussion sessions of the conference and give pointers to related upcoming events.


#*Comments on "A meta model transformation approach towards harmonisation in information system modelling" by J. L. H. Oei
#@Udo W. Lipeck
#t1995
#cProceedings of the IFIP international working conference on Information system concepts: Towards a consolidation of views
#index370813


#*A model-based framework to overlap product development activities
#@Viswanathan Krishnan,Steven D. Eppinger,Daniel E. Whitney
#t1997
#cManagement Science
#index75228


#*Approximating the SVP to within a factor (1+1/dimE) is NP-Hard under randomized reductions
#@Jin-Yi Cai,Ajay Nerurkar
#t1999
#cJournal of Computer and System Sciences
#index288868


#*Large-Scale Parallel Data Clustering
#@Dan Judd,Philip K. McKinley,Anil K. Jain
#t1998
#cIEEE Transactions on Pattern Analysis and Machine Intelligence
#index86962
#%444596
#%544040
#!Algorithmic enhancements are described that enable large computational reduction in mean square-error data clustering. These improvements are incorporated into a parallel data-clustering tool, P-CLUSTER, designed to execute on a network of workstations. Experiments involving the unsupervised segmentation of standard texture images were performed. For some data sets, a 96 percent reduction in computation was achieved.


#*An automated curve fairing algorithm for cubic B-spline curves
#@Janet F. Poliakoff,Yew Kee Wong,Peter D. Thomas
#t1999
#cJournal of Computational and Applied Mathematics
#index280788


#*Intelligent information retrieval: diagnosing information need. part I. the theoretical framework for developing an intelligent IR tool
#@Charles Cole
#t1998
#cInformation Processing and Management: an International Journal
#index295935


#*Scalable Processors in the Billion-Transistor Era: IRAM
#@Christoforos E. Kozyrakis,Stylianos Perissakis,David Patterson,Thomas Anderson,Krste Asanovic,Neal Cardwell,Richard Fromm,Jason Golbus,Benjamin Gribstad,Kimberly Keeton,Randi Thomas,Noah Treuhaft,Katherine Yelick
#t1997
#cComputer
#index448034
#%444128
#%601747
#!T his article proposes a new architecture called "trace processors," which consist of multiple, distributed on-chip processor cores, each of which simultaneously executes a different trace. All but one core executes the traces speculatively, having used branch prediction to select traces that follow the one executing. (Although this architectural concept is similar to multiscalar processors, described in a sidebar, it does not require explicit compiler support). The authors argue that future processors will rely heavily on replication and hierarchy, and they show how their architecture exploits these concepts.


#*Improving Performance of Adaptive Media Access Control Protocols for High-Density Wireless Networks
#@Alvin Lim,Kui Mok
#t1999
#cProceedings of the 1999 International Symposium on Parallel Architectures, Algorithms and Networks
#index125003
#!The problems of intermittent disconnection, high error rate and collision in high-density wireless networks cause degradation in the performance of wireless media access control protocols, such as slotted ALOHA Time Division Multiple Access (slotted ALOHA/TDMA) and Direct Sequence Code Division Multiple Access (DS/CDMA). We propose adaptive techniques for improving performance of media access protocols through awareness of the mobile communication environment. These techniques involve detection of intermittent disconnection, high error rates, and collisions. Upon detection and notification of these conditions by snooping devices, the media access control layer adapts its operation and synchronization accordingly to reduce delay and loss of bandwidth. Results from our simulation studies show that adaptive TDMA improves performance by as much as 12 times over basic TDMA and adaptive CDMA improves by as much as 4 times over basic CDMA in wireless network with high population cells. Overall, adaptive CDMA still performs better than adaptive TDMA by about 4 times.


#*Building a Genetic Programming Framework: The Added-Value of Design Patterns
#@Tom Lenaerts,Bernard Manderick
#t1998
#cProceedings of the First European Workshop on Genetic Programming
#index264408


#*Routing with end-to-end QoS guarantees in broadband networks
#@Ariel Orda
#t1999
#cIEEE/ACM Transactions on Networking (TON)
#index300195
#%94123
#%115336
#%116638
#%211164
#%227925
#%280723
#%591286
#%589405
#%300633


#*NDC++: an approach to concurrent extension of C++
#@Jiajun Chen,Guoliang Zheng
#t1997
#cACM SIGPLAN Notices
#index81299
#!In this paper, we present an approach to extending C++ with the capability of describing concurrent computation. The concurrent object-oriented model we adopt consists of a group of concurrent objects which may have bodies. When a concurrent object is created, its body begins to run. Inter-object communication uses the synchronous message passing and the internal concurrency of object is permitted. Concurrency control is distributed among each method's activation condition in an object. We also provide a policy to transform the classes defined in the extended C++ into C++ classes. The implementation is based on the multithreading and synchronization facilities supported in some multitasking operating systems such as Windows 95.


#*A two-machine flowshop sequencing problem with limited waiting time constraints
#@Dar-Li Yang,Maw-Sheng Chern
#t1995
#cComputers and Industrial Engineering
#index586410


#*High aspect ratio resist structures by e-beam overexposure
#@Henk de Koning,Peter Zandbergen,Martin J. Verheijen,Udo K. P. Biermann
#t1995
#cMicroelectronic Engineering
#index587541


#*A parallel algorithm for static program slicing
#@Sebastian Danicic,Mark Harman,Yoga Sivagurunathan
#t1995
#cInformation Processing Letters
#index588420


#*The body electric
#@Gordon Bell
#t1997
#cCommunications of the ACM
#index87845
#%610298


#*Testing the monster chip
#@Yervant Zorian
#t1999
#cIEEE Spectrum
#index297251


#*Creating information graphics in PageMaker
#@D. Dofy
#t1998
#cAldus Magazine
#index484356


#*ACM fellow profile: Meir M(Manny) Lehman
#@Greg Cooper,Arnulf Mester
#t1998
#cACM SIGSOFT Software Engineering Notes
#index80463


#*A morphological point thinning algorithm
#@Joshua Brown,Anne Hoger
#t1996
#cPattern Recognition Letters
#index585677


#*Stable pushing: mechanics, controllability, and planning
#@Kevin M. Lynch,Matthew T. Mason
#t1995
#cProceedings of the workshop on Algorithmic foundations of robotics
#index585910


#*Mathematical Morphology and Weighted Least Squares to Correct Handwriting Baseline Skew
#@Marisa E. Morita,Silvio J. A. Garnés,Jacques Facon,Flávio Bortolozzi,Robert Sabourin
#t1999
#cProceedings of the Fifth International Conference on Document Analysis and Recognition
#index552850
#!An approach to correct the baseline handwritten word skew in the image of bank check dates is presented in this article. The main goal of such approach is to reduce the use of empirical thresholds. The weighted least squares approach is used on the pseudo-convex hull obtained from the mathematical morphology.


#*A Fuzzy Petri Nets Based Mechanism for Fuzzy Rules Reasoning
#@Stephen J. H. Yang,William C. Chu,Jonathan Lee,Wei T. Huang
#t1997
#cProceedings of the 21st International Computer Software and Applications Conference
#index366288
#!This paper presents a mechanism for normalizing fuzzy rules of a rule-based system, transforming the rules into a fuzzy Petri net, and answering queries based on the net with imprecise information. In addition, we are presenting an algorithm utilizing the formalism of Petri nets to compute the degree of truth of the resulting answers to the queries. The degree of truth is computed in algebraic form based on the state equation which can be implemented in matrix computation in Petri nets.


#*AI System Support for Conceptual Design: Proceedings of the 1995 Lancaster International Workshop on Engineering Design, Held March 27-29, 1995
#@John E. Sharpe
#t1995
#c
#index609420


#*Distributed Computer-Aided Engineering: For Analysis, Design, and Visualization, 1st edition
#@Hojjat Adeli,Sanjay Kumar
#t1998
#c
#index247408
#!:Distributed Computer-Aided Engineering presents distributed algorithms for three fundamental areas of engineering: finite element analysis, design optimization, and visualization - providing a new direction in high performance structural engineering computing.


#*A Shape Metric for Blum Ribbons
#@M. Kerckhove
#t1999
#cJournal of Mathematical Imaging and Vision
#index284338
#%86446
#%150480
#%173505
#%465007
#%589905
#!A Blum ribbon is a figure whose boundary is the envelope of a family of circles the centers of which lie along a single unbranched curve called its medial axis. Define a Blum ribbon to be simple if its medial axis is the line segment joining points (0,0) and (1,0). Any Blum ribbon can be made simple by flexing the medial axis, rotating, then dilating, all of which are basic transformations in Blum&lsquo;s geometry of shape. The Lie group SL(2, R) acts on circles centered on the x-axis by linear fractional transformations. By means of this action it is possible to associate to any simple Blum ribbon a curve in SL(2, R). A distance between corresponding points lying on such curves is defined using the bi-invariant metric on SL(2, R). Resulting scale-invariant metrics on the set of figures defined as Blum ribbons are described and it is shown that these metrics can provide effective measures of shape difference.


#*Memory systems
#@Doug Burger
#t1996
#cACM Computing Surveys (CSUR)
#index600284


#*Optimal operating policies in the presence of exchange rate variability
#@Sriram Dasu,Lode Li
#t1997
#cManagement Science
#index83061


#*An adaptive-gain alpha-beta tracker combined with three-dimentional circular prediction using estimation of the plane state
#@T. Kawase
#t1999
#cProceedings of the Acoustics, Speech, and Signal Processing, 1999. on 1999 IEEE International Conference - Volume 05
#index420341
#!In tracking systems using a phased array antenna, the adaptive-gain /spl alpha/-/spl beta/ tracker combined with circular prediction has been proposed for manoeuvring targets. However, the tracking quality of the circular prediction filter degrades for highly manoeuvring targets that continue to change the turning plane, since the circular prediction is calculated on the assumption that a target flies on the same plane of the previous three measured positions. In this paper, we extend the circular prediction to three-dimensional space and propose an adaptive-gain /spl alpha/-/spl beta/ tracker combined with three-dimensional circular prediction using estimation of the plane state to improve tracking quality.


#*Weyl quantization and Fourier integral operators
#@Jean-Michel Bony
#t1996
#cPartial differential equations and mathematical physics
#index585420


#*Underspecification in Type-Logical Grammars
#@Dirk Heylen
#t1997
#cSelected papers from the Second International Conference on Logical Aspects of Computational Linguistics
#index373612


#*Implementing design patterns as language constructs
#@Yan-David Erlich
#t1998
#cProceedings of the third ACM SIGPLAN international conference on Functional programming
#index86315
#%229228
#%165714


#*Automatic speaker clustering from multi-speaker utterances
#@J. McLaughlin
#t1999
#cProceedings of the Acoustics, Speech, and Signal Processing, 1999. on 1999 IEEE International Conference - Volume 02
#index420825
#!Blind clustering of multi-person utterances by speaker is complicated by the fact that each utterance has at least two talkers. In the case of a two-person conversation, one can simply split each conversation into its respective speaker halves, but this introduces error which ultimately hurts clustering. We propose a clustering algorithm which is capable of associating each conversation with two clusters (and therefore two-speakers) obviating the need for splitting. Results are given for two speaker conversations culled from the Switchboard corpus, and comparisons are made to results obtained on single-speaker utterances. We conclude that although the approach is promising, our technique for computing inter-conversation similarities prior to clustering needs improvement.


#*Learning and Adoption Versus Optimization
#@Yuri M. Ermoliev
#t1997
#cProceedings of the 8th European Workshop on Modelling Autonomous Agents in a Multi-Agent World: Multi-Agent Rationality
#index256239


#*A Data Driven Model for Designing Applications with Smart Cards
#@William J. Caelli,Vincent Cordonnier,Anthony Watson
#t1998
#cProceedings of the The International Conference on Smart Card Research and Applications
#index562878


#*Security issues in a networked UNIX and MVS/VM environment
#@James J. Mavrikidis
#t1996
#cACM SIGSAC Review
#index598275
#%475699
#%519121
#!This paper examines some security issues that arise from the interaction of different operating environments. The paper will focus on a particular network configuration involving two of IBM's Mainframe operating systems and an AT amp;T UNIX system. Each system along with the networking scheme used to connect these environments will be examined. The examined interaction will consist mostly of remote process execution. Each system will be described insofar as it relates to the security issues. A more detailed description of each operating environment can be found in the books in the reference section of this paper.


#*Teacher as Aladdin
#@John Swartzberg
#t1999
#c
#index613530


#*An interval branch and bound algorithm for global optimization of a multiperiod pricing model
#@M. A. Venkataramanan,A. V. Cabot,W. L. Winston
#t1995
#cComputers and Operations Research
#index588802


#*COBRA: a 100-MOPS single-chip programmable and expandable FFT
#@Tom Chen,Glen Sunada,Jian Jin
#t1999
#cIEEE Transactions on Very Large Scale Integration (VLSI) Systems
#index286508


#*Creating Great Web Graphics, 2nd edition
#@Laurie McCanna
#t1997
#c
#index615779
#!:Creating cool graphics for your web site is no longer a daunting task with Laurie McCanna's expert advice and easy-to-Follow Photoshop and CorelDRAW recipes. Everyone from novices to webmasters needs help fashioning a well-designed web site that includes fabulous and quick downloading images. Creating Great Web Graphics focuses solely on how to create quality PC graphics for World Wide Web sites. Through step-by-step instructions, you learn how to create icons, type, background tiles, and images that work well within Web protocols. McCanna uses the popular PC applications Photoshop and Corel's PhotoPaint to address the major challenges of creating graphics for the Web - creating low-resolution, small files that load quickly but look professional on all major computer platforms (Mac, UNIX, PC). In her straightforward, humorous style, McCanna teaches essential web graphics tricks such as anti-aliasing files so they display smoothly on low-resolution computer monitors, using transparency to create non-rectangular buttons and images, or using beveled edges to give depth to icons. Expert color advice includes color indexing instructions to create the smallest possible files, and a hex code color chart for quick reference when creating your pages. This high-powered but friendly reference belongs on every webmaster's desk. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Evaluation in built-in self-test
#@Shujian Zhang
#t1998
#c
#index284396


#*Proceedings of the 1997 International Conference on Microelectronics Systems Education (MSE '97)
#@
#t1997
#cMSE
#index612535


#*Mutual exclusion scheduling
#@Brenda S. Baker,Edward G. Coffman, Jr.
#t1996
#cTheoretical Computer Science
#index589883


#*Efficient algorithms for line and curve segment intersection using restricted predicates
#@Jean-Daniel Boissonnat,Jack Snoeyink
#t1999
#cProceedings of the fifteenth annual symposium on Computational geometry
#index284604
#%76518
#%80789
#%144427
#%211718
#%213777
#%583188
#%593389
#%599681
#%462858


#*Logical not Polynomial Forms to represent Multiple-Valued Functions
#@Elena N. Zaitseva,Tatyana G. Kalganova,Evgeny G. Kochergov
#t1996
#cProceedings of the 26th International Symposium on Multiple-Valued Logic
#index114159
#!The synthesis of logical not polynomial forms to represent completely and incompletely defined multiple-valued logic functions is proposed. To compute these forms, discrete orthogonal transforms are used. The matrix and vector procedures are the founda


#*A Min-Max Theorem for a Constrained Matching Problem
#@Andreas Hefner
#t1997
#cSIAM Journal on Discrete Mathematics
#index82417
#!The following constrained matching problem arises in the area of manpower scheduling. Consider an undirected graph $G=(V,E)$ and a digraph $D=(V,A)$. A master/slave-matching (MS-matching) in $G$ with respect to $D$ is a matching in $G$ such that for each arc $(u,v)\in A$ for which the node $u$ is matched, the node $v$ is matched too. The problem is to find an MS-matching of maximum cardinality. This paper addresses the special case where $G$ is bipartite with bipartition $V=W\cup U$ and every (weakly) connected component of $D$ is either an isolated node or two nodes in $U$ which are joined by a single arc. The polyhedral structure of this special case is investigated and a min-max theorem which characterizes the cardinality of a maximum MS-matching in terms of the weight of a special node cover is derived. This min-max theorem includes as a special case the theorem of König.


#*The split delivery vehicle scheduling problem with time windows and grid network distances
#@P. W. Frizzell,J. W. Giffin
#t1995
#cComputers and Operations Research
#index595287


#*Energy
#@Ian Barbour
#t1999
#cTechnology and society: a bridge to the 21st century
#index293666


#*Multi-pitch and periodicity analysis model for sound separation and auditory scene analysis
#@M. Karjalainen
#t1999
#cProceedings of the Acoustics, Speech, and Signal Processing, 1999. on 1999 IEEE International Conference - Volume 02
#index427344
#!A model for multi-pitch and periodicity analysis of complex audio signals is presented that is more efficient and practical than the Meddis and O'Mard (see J. Acoust. Soc. Am., vol.102, p.1811-20, 1997) unitary pitch perception model, yet exhibits very similar behavior. We also demonstrate how to apply this model to source separation of complex audio signals such as polyphonic and multi-instrumental music and mixtures of simultaneous speakers. Such analysis techniques are important for automatic transcription of music and structural representation of audio signals.


#*Activeeducation's Access 97 (Mous) Expert Test Preparation
#@Jodie Jones
#t1997
#c
#index241838
#!:Find more curricular activities! Explore ActiveEducation's other titles and training options. Want a piece of the action? Learn more about ActiveEducation. MOUS Expert Test Preparation: Access 97 provides intensive review and hands-on practice in preparation for the Microsoft Office User Specialist Expert-level test for Access 97. At the end of the book, a practice test is provided to simulate the actual testing environment.


#*Nonlinear time series analysis
#@Holger Kantz,Thomas Schreiber
#t1997
#cCambridge Nonlinear Science Series; Vol. 7
#index90339


#*Spline approximations of real algebraic surfaces
#@Chandrajit L. Bajaj,Guoliang Xu
#t1997
#cJournal of Symbolic Computation
#index93387


#*Design and Analyses of Two Basic Protocols for Use in TTP-Based Key Escrow
#@Feng Bao,Robert H. Deng,Yongfei Han,Albert B. Jeng
#t1997
#cProceedings of the Second Australasian Conference on Information Security and Privacy
#index364615


#*More chemistry on CD-ROM
#@Wendy A. Warr
#t1995
#cDatabase
#index591122


#*VTRACE and Communication Performance Analysis
#@Peng Dai,Thomas W. Doeppner, Jr.
#t1995
#c
#index123995
#!As the requirements for communication performance grow and the vast variation and improvement in hardware components increase, the various functionally different software layers have been increasingly responsible for performance degradation. In this paper, we explore the use of VTRACE, a tracing facility provided in Solaris, as a general methodology in communication per formance analysis and also present performance data for an experimental version of Sun''s Solaris Operating System.


#*Reducing the Time to Market Through Rapid Prototyping
#@Apostolos Dollas,Nick Kanopoulos
#t1995
#cComputer
#index440385


#*CSCW '94
#@Aaron Tay
#t1995
#cACM SIGCHI Bulletin
#index604830


#*Laguerre-Freud equations for the recurrence coefficients of D semi-classical orthogonal polynomials of class one
#@M. Foupouagnigni,M. N. Hounkonnou,A. Ronveaux
#t1998
#cJournal of Computational and Applied Mathematics
#index296643


#*Finding Government Information on the Internet: A How-To-Do-It Manual
#@John Maxymuk
#t1996
#c
#index617865


#*Complexity metrics for object-oriented software
#@Dongzi Huang
#t1997
#c
#index75376


#*Cycle factors in dense graphs
#@Eldar Fischer
#t1999
#cDiscrete Mathematics
#index297535


#*Integrating Subtyping, Matching and Type Quantification: A Practical Perspective
#@Andreas Gawecki,Florian Matthes
#t1996
#cProceedings of the 10th European Conference on Object-Oriented Programming
#index366683


#*Practical Methods for Your Year 2000 Problem: The Lowest Cost Solution with Cdrom
#@Robert B. Chapman
#t1997
#c
#index612835
#!:Using the VisualAge 2000 toolset by IBM for examples, this book teaches in-house personnel how to solve the Year 2000 problem without spending large amounts of money on professional consulting firms. The CD-ROM contains all the software needed for a successful Year 2000 project.


#*Computer Graphics Technical Committee
#@William Ribarsky
#t1996
#cComputer
#index442722


#*Advanced Data Repository Support for JAVA Scientific Programming
#@Peter Brezany,Marianne Winslett
#t1999
#cProceedings of the 7th International Conference on High-Performance Computing and Networking
#index572237


#*Does electronic monitoring contribute to community based penalties for offenders?
#@Dick Whitfield,Ruud Boelens
#t1996
#cNew Technology in the Human Services
#index606222


#*Fat-tree for local area multiprocessors
#@Qiang Li,David B. Gustavson
#t1995
#cProceedings of the 9th International Symposium on Parallel Processing
#index371721
#!The local area multiprocessor (LAMP) is a newly-feasible approach for achieving high-performance low-cost parallel computing. LAMP allows a large number of machines distributed over a LAN-size area to operate as a distributed-shared-memory multiprocessor. Latency is kept low by using the scalable coherent interface and by caching remote data. SCI keeps the caches consistent and provides a high performance multiprocessor "bus" using only point-to-point physical connections (links), which can operate at far higher speeds than any bus. Large numbers of links may be used concurrently for extremely high system throughput, interconnected by a packet switch using any of a wide range of topologies and technologies. This paper examines the use of a fat-tree topology for this (possibly distributed) switch. Simulation results are presented to show the latency, throughput, buffer requirements, and the effect of cable length. Link clock speeds assumed are 250 MHz (GaAs or biCMOS chips) and 32 MHz (CMOS).


#*An On-line Problem Database
#@Nachum Dershowitz,Ralf Treinen
#t1998
#cProceedings of the 9th International Conference on Rewriting Techniques and Applications
#index269069


#*Coding For Content-Based Retrieval
#@M. D. Swanson
#t1996
#cProceedings of the Acoustics, Speech, and Signal Processing, 1996. on Conference Proceedings., 1996 IEEE International Conference - Volume 04
#index417915
#!We define a data structure called a "web" together with an algorithm to choose scale-space atoms for representing an image. The corresponding wavelet coefficients (of the atoms chosen using this method) have useful properties which lead to (i) the definition of a stochastic process for representing images and (ii) an efficient image compression algorithm. The advantage of our image compression algorithm is that the computational requirement is very low. The stochastic process is useful in a theoretical sense because it gives us a framework in which to understand images and certain image compression algorithms.


#*Query Expansion for Intelligent Information Retrieval on Internet
#@Jae Hyun Lim,Young-Chan Kim,Hyonwoo Seung,Jun Hwang,Heung-Nam Kim
#t1997
#cProceedings of the 1997 International Conference on Parallel and Distributed Systems
#index269711
#!Most systems that manage distributed information on Internet have difficulties in retrieving relevant information for they are not able to include the exact semantics of retrieval queries that users request. In this paper, we propose an automatic query expansion method based on term distribution which naturally reflects semantics of retrieval terms in order to enhance the performance of information retrieval. The SVD technique in the LSI is utilized in the proposed method to measure the term distribution which appears similar to a query. Terms appearing most similar to the query in consideration of the distribution are appended to the query. Thereby, the query can hit documents without having common terms but with common concepts. An automatic term reduction technique is also proposed which does not choose to append all the terms in the same distribution area. The experimental results show our method maintains comparable retrieval effectiveness as the other LSI methods without having to append many unnecessary terms.


#*Efficient Identity-Based Conference Key Distribution Protocols
#@Shahrokh Saeednia,Reihaneh Safavi-Naini
#t1998
#cProceedings of the Third Australasian Conference on Information Security and Privacy
#index369243


#*The Illustrated AutoCAD LT for Windows Quick Reference: Release 1 and 2, 1st edition
#@Ralph Grabowski
#t1995
#c
#index610987
#!:All the power of AutoCAD LT for Windows Release 1 and 2 is right at your fingertips! This easy-to-use quick reference features an accessible one-command-per-page layout that gives you immediate access to complete descriptions of all AutoCAD LT for Windows commands and functions. Clear, informative illustrations, plus even more invaluable tips and tricks provide the expert help you need to tap into the full power of AutoCAD LT for Windows!


#*Jump number maximization for proper interval graphs and series-parallel graphs
#@Ruay-Shiung Chang
#t1999
#cInformation Sciences&mdash;Informatics and Computer Science: An International Journal
#index283234


#*Geometry-Aided Rectilinear Partitioning of Unstructured Meshes
#@Rainer Koppler
#t1999
#cProceedings of the 4th International ACPC Conference Including Special Tracks on Parallel Numerics and Parallel Computing in Image Processing, Video Processing, and Multimedia: Parallel Computation
#index274018


#*Good numbers&mdash;and bad
#@Robert L. Glass
#t1998
#cJournal of Systems and Software
#index287506


#*Weather forecasting on parallel architectures
#@J. G. Sela
#t1995
#cParallel Computing
#index582406


#*Convergence of a Stochastic Rootfinding Procedure
#@Burton Simon
#t1998
#c
#index124108
#!We consider an exponential queueing system with multiple stations, each of which has an infinite number of servers. Each station has a dedicated arrival stream of jobs. In addition, there is an arrival stream of jobs that choose a station based on the state of the system. In this paper we describe two heavy traffic approximations for the stationary joint probability mass function of the number of busy servers at each station. One of the approximations involves state-space collapse and is accurate for large traffic loads. The state-space in the second approximation does not collapse. It provides an accurate estimate of the stationary behavior of the system over a wide range of traffic loads. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*On the local distinguishing numbers of cycles
#@C. T. Cheng,L. J. Cowen
#t1999
#cDiscrete Mathematics
#index279984


#*Reuse-Driven Tiling for Data Locality
#@Jingling Xue,Chua-Huang Huang
#t1997
#cProceedings of the 10th International Workshop on Languages and Compilers for Parallel Computing
#index370309


#*Personal digital assistants: Part 2
#@Noah Davids
#t1996
#cComputer
#index446170


#*A Hierarchical Neural Object Classifier for Subsymbolic-Symbolic Coupling
#@Hans A. Kestler,Steffen Simon,Axel Baune,Markus Hagenbuchner,Friedhelm Schwenker,Günther Palm
#t1999
#cMustererkennung 1999, 21. DAGM-Symposium
#index565930


#*On Formation of Exception Hierarchy
#@Kouzou Ohara,Noboru Babaguchi,Tadahiro Kitahashi
#t1996
#cProceedings of the 4th Pacific Rim International Conference on Artificial Intelligence: Topics in Artificial Intelligence
#index258204


#*Using Composition to Design Secure, Fault-Tolerant Systems
#@Duane E. Olawsky,Charles Payne,Thomas Sundquist,David Apostal,Todd Fine
#t1998
#cThe 3rd IEEE International Symposium on High-Assurance Systems Engineering
#index362411


#*Trading packet headers for packet processing
#@Girish P. Chandranmenon,George Varghese
#t1995
#cACM SIGCOMM Computer Communication Review
#index596886
#%210564
#%226381
#%315648
#%328436
#%453387
#%459796
#%518945
#%524577
#%601227
#!In high speed networks, packet processing is relatively expensive while bandwidth is cheap. Thus it pays to add information to packet headers to make packet processing easier. While this is an old idea, we describe several specific new mechanisms based on this principle. We describe a new technique, source hashing, which can provide O(1) lookup costs at the Data Link, Routing, and Transport layers. Source hashing is especially powerful when combined with the old idea of a flow ID; the flow identifier allows packet processing information to be cached, and source hashing allows efficient cache lookups. Unlike Virtual Circuit Identifiers (VCIs), source hashing does not require a round trip delay for set up. In an experiment with the BSD Packet Filter implementation, we found that adding a flow ID and a source hash improved packet processing costs by a factor of 7. We also found a 45% improvement when we conducted a similar experiment with IP packet forwarding. We also describe two other new techniques: threaded indices, which allows fast VCI-like lookups for datagram protocols like IP; and a Data Manipulation Layer, which compiles out all the information needed for Integrated Layer Processing into an easily accessible portion of each packet.


#*Understanding Neural Networks and Fuzzy Logic: Basic Concepts and Applications, 1st edition
#@Stamatios V. Kartalopoulos,Stamatios V. Kartakapoulos
#t1997
#c
#index255360
#!:Understand the fundamentals of the emerging field of fuzzy neural networks, their applications and the most used paradigms with this carefully organized state-of-the-art textbook. Previously tested at a number of noteworthy conference tutorials, the simple numerical examples presented in this book provide excellent tools for progressive learning. UNDERSTANDING NEURAL NETWORKS AND FUZZY LOGIC offers a simple presentation and bottom-up approach that is ideal for working professional engineers, undergraduates, medical/biology majors, and anyone with a nonspecialist background.Sponsored by:IEEE Neural Networks Council


#*Low-cost, high-performance barrier synchronization on networks of workstations
#@Donald Johnson,David Lilja,John Riedl,James Anderson
#t1997
#cJournal of Parallel and Distributed Computing
#index85835


#*Knowledge acquisition using rough sets when membership values are fuzzy sets
#@A. de Korvin,C. McKeegan,R. Kleyle
#t1998
#cJournal of Intelligent Fuzzy Systems: Applications in Engineering and Technology
#index344934
#!In this paper we model uncertainty using the so-called rough set approach in which upper and lower approximations of a set of objects are based on equivalence classes determined by attribute values. However, due to imprecision in the information, both the attributes and the resulting decisions are modeled as fuzzy sets. Furthermore, the membership of these fuzzy sets is also fuzzy, creating fuzzy sets of type II. From information of this type, we construct inference rules of unequal strength. The strength of any rule is determined by both its degree of truth and its degree of belief, each of which are obtained from the fuzzy memberships.


#*An Empirical Text Categorizing Computational Model Based on Stylistic Aspects
#@S. E. Michos,E. Stamatatos,N. Fakotakis,G. Kokkinakis
#t1996
#cProceedings of the 8th International Conference on Tools with Artificial Intelligence
#index119039
#!The presented work is strongly motivated by the need of categorizing unrestricted texts in terms of functional style (FS) in order to attain a satisfying outcome in style processing. Towards this aim, it is given a three-level description of FS that comprises: (a) the basic categories of FS, (b) the main features that characterize each one of the above categories, and (c) the linguistic identifiers that act as style markers in texts for the identification of the above features. Special emphasis is put on the problems that faced the computational implementation of the aforementioned findings as well as the selection of the most appropriate stylometrics (i.e., stylistic scores) to achieve better results on text categorization. This approach is language independent, empirically-driven, and can be used in various applications including grammar and style checking, natural language generation, style verification in real-world texts, and recognition of style shift between adjacent portions of text.


#*Microsoft Wks 4.0 MAC: Tutorial and Apps, 1st edition
#@William Robert Pasewark
#t1996
#c
#index612840
#!:Integrated records management/filing program that provides information on both manual and electronic filing procedures. Alphabetic, alphanumeric, numeric, geographic, and subject filing are all covered in this brief text and simulation.


#*Reasonong about Classess in Object-Oriented Languages: Logical Models and Tools
#@Ulrich Hensel,Marieke Huisman,Bart Jacobs,Hendrik Tews
#t1998
#cProceedings of the 7th European Symposium on Programming: Programming Languages and Systems
#index357191


#*Adding the Everywhere Operator to Propositional Logic
#@David Gries,Fred B. Schneider
#t1996
#c
#index120020
#!Sound and complete modal propositional logic C is presented, in which "P" has the interpretation "P is true in all states". The interpretation is already known as the Carnapian extension of S5. A new axiomatization for C provides two insights. First, introducing an inference rule "textual substitution" allows seamless integration of the propositional and modal parts of the logic, giving a more practical system for writing formal proofs. Second, the two following approaches to axiomatizing a logic are shown to be not equivalent: (i) give axiom schemes that denote an infinite number of axioms and (ii) write a finite number of axioms in terms of propositional variables and introduce a substitution inference rule.


#*The landing party
#@David Haxton
#t1997
#cACM SIGGRAPH 97 Visual Proceedings: The art and interdisciplinary programs of SIGGRAPH '97
#index81362


#*Approximation Schemes for Covering and Scheduling on Related Machines
#@Yossi Azar,Leah Epstein
#t1998
#cProceedings of the International Workshop on Approximation Algorithms for Combinatorial Optimization
#index270479


#*Ordered sharing: a new lock primitive for database systems
#@Divyakant Agrawal,Amr El Abbadi
#t1995
#cInformation Systems
#index590530


#*Immune to serious issues
#@Langdon Winner
#t1996
#cTechnology Review
#index606373


#*Constructing multivariate distributions with specific marginal distributions
#@Kenneth J. Koehler,James T. Symanowski
#t1995
#cJournal of Multivariate Analysis
#index583872


#*A faster algorithm for minimum cost submodular flows
#@Satoru Iwata,S. Thomas McCormick,Maiko Shigeno
#t1998
#cProceedings of the ninth annual ACM-SIAM symposium on Discrete algorithms
#index285680
#%89286
#%149759
#%153444
#%161193
#%166850
#%470732
#%472818
#%467077
#%481010
#%517660


#*Scenario-Based Reliability Analysis of Component-Based Software
#@Sherif M. Yacoub,Bojan Cukic,Hany H. Ammar
#t1999
#cProceedings of the 10th International Symposium on Software Reliability Engineering
#index115893
#!Software designers are motivated to utilize off-the-shelf software components for rapid application development. Such applications are expected to have high reliability as a result of deploying trusted components. The claims of high reliability need further investigation based on reliability analysis techniques that are applicable to component-based applications.This paper introduces a probabilistic model and a reliability analysis technique applicable to high-level designs. The technique is named "Scenario-Based Reliability Analysis" (SBRA). SBRA is specific for component-based software whose analysis is strictly based on execution scenarios. Using scenarios, we construct a probabilistic model named "Component-Dependency Graph" (CDG). CDGs are directed graphs that represent components, component reliabilities, link and interface reliabilities, transitions, and transition probabilities. In CDGs, component interfaces and link reliabilities are treated as first class elements of the model. Based on CDGs, an algorithm is presented to analyze the reliability of the application as the function of reliabilities of its components and interfaces. A case study illustrates the applicability of the algorithm. The SBRA is used to identify critical components and critical component interfaces, and to investigate the sensitivity of the application reliability to changes in the reliabilities of components and their interfaces.


#*Analysis of Backoff Protocols for Mulitiple AccessChannels
#@Johan H&aringstad,Tom Leighton,Brian Rogoff
#t1996
#cSIAM Journal on Computing
#index594492
#!In this paper, we analyze the stochastic behavior of backoff protocols for multiple access channels such as the Ethernet. In particular, we prove that binary exponential backoff is unstable if the arrival rate of new messages at each station is $\lam/N$ for any $\lam >{1\over 2}$ and the number of stations N, is sufficiently large. For small $N$ we prove that $\lam \geq \lam_0+{1\over 4N-2}$ implies instability where $\lam_0\approx .567$. More importantly, we also prove that any superlinear polynomial backoff protocol (e.g., quadratic backoff) is stable for any set of arrival rates that sum to less than one, and any number of stations. The results significantly extend the previous work in the area, and provide the first examples of acknowledgment based protocols known to be stable for a nonnegligible overall arrival rate distributed over an arbitrarily large number of stations. The results also disprove a popular assumption that exponential backoff is the best choice among acknowledgment based protocols for systems with large overall arrival rates. Finally, we prove that any linear or sublinear backoff protocol is unstable if the arrival rate at each station is $\lambda \over N$ for any fixed $\lambda$ and sufficiently large $N$.}


#*Quantitative Data Analysis with SPSS Release 8 for Windows: A Guide for Social Scientists, 1st edition
#@Alan Bryman,Duncan Cramer
#t1999
#c
#index243767
#!:The latest edition of this best-selling introduction to Quantitative Data Analysis through the use of a computer package has been completely updated to accommodate the needs of users of SPSS Release 8 for Windows. Like its predecessor, it provides a non-technicalapproach to quantitative data analysis and a user-friendly introduction to the widely used SPSS for Windows. It assumes no previous familiarity with either statistics or computing but takes the reader step-by-step through the techniques, reinforced by exercises for further practice. Techniques explained include: correlation, simple and multiple regression, multivariate analysis of variance and covariance, and factor analysis. The book also covers issues such as sampling, statistical significance, conceptualization and measurement and the selection of appropriate tests.


#*Modelling Competitive Co-operation of Agents in a Compositional Multi-Agent Framework
#@Frances M. T. Brazier,Pascal van Eck,Jan Treur
#t1997
#cProceedings of the 10th European Workshop on Knowledge Acquisition, Modeling and Management
#index371788


#*Distributed Route Planning Using Partial Map Building
#@Christine J. Alvarado
#t1998
#c
#index123041
#!Our goal is to manipulate and guide an object across an unknown environment toward a goal in a known location in space. Our tools include a system of manipulation robots, which are "blind" and one mobile scout robot who relies on a series of sonar sensors for information about the environment. Previous solutions to this problem have taken a simultaneous guiding and manipulating approach, moving the whole system under the scout''s guidance. My approach, however, presents a separate scouting algorithm that can return a series of coordinates through which the manipulation system can safely pass to reach the goal in a static environment. This new approach produces more optimal paths to the goal, as well as evading the concern of what actions to take should the entire system reach a dead end. In this paper I will present both the algorithm and the experimental results I obtained when I built the scouting system.


#*A Comparison of Multi-modal Combination Modes for The Map System
#@Gao Zhang,Xiangshi Ren,Guozhong Dai
#t1999
#cProceedings of HCI International (the 8th International Conference on Human-Computer Interaction) on Human-Computer Interaction: Ergonomics and User Interfaces-Volume I - Volume I
#index557717


#*Highlights of the June 1995 ASISWG/ASISRG meeting
#@Currie Colket
#t1995
#cACM SIGAda Ada Letters
#index592778


#*Spatial Information and Actions
#@Silvia Mecklenbräuker,Werner Wippich,Monika Wagener,Jörg E. Saathoff
#t1998
#cSpatial Cognition, An Interdisciplinary Approach to Representing and Processing Spatial Knowledge
#index365326


#*Buying Travel Services on the Internet
#@Durant Imboden
#t1999
#c
#index448442
#!:The world's leading e-commerce association shows how to find the best travel deals online. Looking for rock-bottom prices on airline tickets and car rentals? In search of the perfect hotel or resort? Checking out cruises? Doing research on business desitnations,family vacations,orromantic getaways? Travel already draws more people to the Internet than any other topic - and online travel revenues will reach an astounding $12 billion by 2002,according to The Industry Standard,which tracks Net economy. It all adds up to a huge built-in audience for this taime-saving guide. Like a well-connected travel agent,it takes netsurfing travelers straight to the best deals. Special features include: Guided tours of key sites like Travelocity and City. net; Tips on using Priceline and similar "name your price" services; Advice on comparison-shopping and bargaining; Questions to ask and scams to avoid. Where do you want to go today? Fly direct to the best travel information on the Web! Did you know that travel is the most sought-for topic on the world wide web? With good reason. Wherever you want to go,whatever you want to know,it's there somewhere on the Internet: the cheap fares,the hard-to-find information,the time-saving services. But how do you find what you need without wandering all across cyberspace? Start your trip here: Buying Travel Services on the Internet. Travel writer Durant Imboden and CommerceNet,the foremost nonprofit organization for e-commerce,have done the legwork for you. They sifted thousands of sitesthey even researched the search enginesto collect only the best into one definitive,unibiased guidebook that puts your destination justa click away! Whether you're heading for Machu Pichu or Missoula,on the road for business or pleasure,this URL-packed,globe-trotting,web-navigating guidebook is your best ticket to the most useful,money-saving,and interesting travel-related sites on the Internet. Get right to the sites that help you: comparison shop for airline and cruise bargains virtual-visit almost every spot on earthfrom Algarve to Zimbabwe; check into lodging,from 5-star hotels to eco-campgrounds; rent a car,track a rail route,book a berth on a freighter; map door-to-door travel directions; apply for a passport and visas; plan family vacations,gay/lesbian travel,adventures,and other special-interest trips; prepare with health and safety into,and weather forecasts; calculate currency conversions. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Hypertext wrapped up (abstract)
#@Simon Knight,Hugh Davis
#t1996
#cACM SIGWEB Newsletter
#index585801


#*v-Promela: A Visual, Object-Oriented Language for SPIN
#@Stefan Leue,Gerard Holzmann
#t1999
#cProceedings of the 2nd IEEE International Symposium on Object-Oriented Real-Time Distributed Computing
#index117789
#!We describe the design of VIP, a graphical front-end to the model checker SPIN. VIP supports a visual formalism, called v-Promela that connects the model checker to modern hierarchical notations for the specification of object-oriented, reactive systems. The formalism is comparable to formalisms such as UML-RT, ROOM, and Statecharts, but is presented here in a framework that allows us to combine the benefits of a visual, hierarchical specification method with the power of LTL model checking provided by SPIN. Like comparable formalisms, VIP can describe hierarchies of behaviour and of system structure. The formalism is designed to be transparent to the SPIN model checker itself, by allowing all central constructs to be translated mechanically into basic PROMELA, as already supported by the existing model checker.


#*Infinite Probabilistic and Nonprobabilistic Testing
#@K. Narayan Kumar,Rance Cleaveland,Scott A. Smolka
#t1998
#cProceedings of the 18th Conference on Foundations of Software Technology and Theoretical Computer Science
#index277718


#*A semidefinite bound for mixing rates of Markov chains
#@Nabil Kahale
#t1995
#c
#index115773
#!We study the method of bounding the spectral gap of a reversible Markov chain by establishing canonical paths between the states. We provide examples where improved bounds can be obtained by allowing variable length functions on the edges. We give a simple heuristic for computing good length functions. Further generalization using multicommodity flow yields a bound which is an invariant of the Markov chain, and which can be computed at an arbitrary precision in polynomial time via semidefinite programming. We show that, for any reversible Markov chain on n states, this bound is off by a factor of at most O(log^2), and that this is tight.


#*Operating system resource reservation for real-time and multimedia applications
#@Clifford Wayne Mercer
#t1997
#c
#index188879


#*Separating Exponentially Ambiguous Finite Automata from Polynomially Ambiguous Finite Automata
#@Hing Leung
#t1998
#cSIAM Journal on Computing
#index79361
#!We resolve an open problem raised by Ravikumar and Ibarra [SIAM J. Comput., 18 (1989), pp. 1263--1282] on the succinctness of representations relating to the types of ambiguity of finite automata. We show that there exists a family of nondeterministic finite automata {An} over a two-letter alphabet such that, for any positive integer n, An is exponentially ambiguous and has n states, whereas the smallest equivalent deterministic finite automaton has 2n states, and any smallest equivalent polynomially ambiguous finite automaton has 2n -1 states.


#*Expert systems diffusion in British banking: diffusion models and media factor
#@Yuan Pu Shao
#t1999
#cInformation and Management
#index299724


#*Remarks on a generalized beta function
#@Allen R. Miller
#t1998
#cJournal of Computational and Applied Mathematics
#index282622


#*Multiresolution rendering of complex botanical scenes
#@Dana Marshall,Donald S. Fussell,A. T. Campbell, III
#t1997
#cProceedings of the conference on Graphics interface '97
#index83559


#*Election Vs. Consensus in Asynchronous Systems
#@Laura S. Sabel,Keith Marzullo
#t1995
#c
#index113782
#!It was shown in 1985 that the {\em Consensus problem} cannot be solved in an asynchronous system if even a single crash failure can occur. In this paper, we show that there are other problems that cannot be solved in an asynchronous system, and for the same intuitive reason: it is impossible to distinguish a very slow processor from a crashed processor. However, these problems are harder than Consensus, in that there are contexts in which Consensus can be solved but these other problems cannot. More precisely, the weakest failure detector that is needed to solve these problems is a Perfect Failure Detector, which is strictly stronger than the weakest failure detector that is needed to solve Consensus. We use a formulation of the Election problem as the prototype for these problems that are harder than Consensus.


#*A note on coverings of plane graphs
#@Eduardo Rivera-Campo
#t1995
#cJournal of Graph Theory
#index597343


#*Work processes: scenarios as a preliminary vocabulary
#@Kari Kuutti
#t1995
#cScenario-based design: envisioning work and technology in system development
#index583552


#*An Approach to Outlier Detection Based on Bayesian Probabilistic Model
#@V. L. Brailovsky
#t1996
#cProceedings of the 13th International Conference on Pattern Recognition - Volume 2
#index17743


#*Optical switch configuration and lightpath assignment in wavelength routing multihop lightwave networks
#@Chien Chen,S. Banerjee
#t1995
#cProceedings of the Fourteenth Annual Joint Conference of the IEEE Computer and Communication Societies (Vol. 3)-Volume - Volume 3
#index123085
#!A wide-area transparent optical network can be constructed by using wavelength routers and switches, each dealing with only a small number of wavelengths. In this work we consider the problem of configuring the wavelength routers based on the observed traffic. Various policies for wavelength routing, and the corresponding assignment of wavelengths along the routes have been studied before, which are based on minimizing congestion, average hop-distance, and call blocking probability or on maximizing carried traffic, and the number of clear channels. However these approaches often lead to scenarios where a significant number of available wavelengths at the input/output ports of the routers cannot be used due to potential wavelength conflict. The wavelength routing and assignment algorithms presented in this paper focus on maximizing the wavelength-utilization at the switching devices which also improve the overall network performance.


#*I remember IANA
#@Vinton G. Cerf
#t1998
#cCommunications of the ACM
#index91665


#*The Unicode standard version 3.0
#@Joan Aliprand,Julie Allen,Joe Becker,Mark Davis,Michael Everson,Asmus Freytag,John H. Jenkins,Mike Ksar,Rick McGowan,Lisa Moore,Michel Suignard,Ken Whistler
#t1999
#c
#index281764


#*Developing Social Virtual Worlds using NetEffect
#@Tapas K. Das,Gurminder Singh,Alex Mitchell,P. Senthil Kumar,Kevin McGee
#t1997
#cProceedings of the 6th Workshop on Enabling Technologies on Infrastructure for Collaborative Enterprises
#index273797
#!Abstract: This paper describes NetEffect, an infrastructure for developing, supporting, and managing large, media-rich, 3-D social virtual worlds for use by several thousand geographically-dispersed users using low-end computers (PCs) and modems. It has been modularized into six components, in the form of a toolkit, which simplifies the development of network-based virtual worlds. NetEffect partitions a whole virtual world into communities, allocates these communities among a set of servers, and migrates clients from one server to another as clients move through the communities. It devotes special attention to minimizing the network traffic, particularly the traffic that must go through servers. HistoryCity, a virtual world for children, has been developed on NetEffect, which is being beta-tested for deployment in Singapore.


#*Rooted routing in the plane
#@Bruce Reed
#t1995
#cDiscrete Applied Mathematics
#index582435


#*Evaluations of HPF for Practical Scientific Algorithms on T3E
#@Chris H. Q. Ding
#t1998
#cProceedings of the International Conference and Exhibition on High-Performance Computing and Networking
#index382671


#*Adobe PhotoDeluxe "X" for Dummies, 1st edition
#@Julie Adair King
#t1998
#c
#index619760
#!:Graphics pro Julie Adair King shows you some simple techniques and fun tricks for enhancing photos from digital cameras, touching up scanned images, and creating exciting collages.


#*Source and environmental parameter estimation using electromagnetic matched field processing
#@P. Gerstoft
#t1999
#cProceedings of the Acoustics, Speech, and Signal Processing, 1999. on 1999 IEEE International Conference - Volume 04
#index428463
#!Modern signal and array processing methods now incorporate the physics of wave propagation as an integral part of the processing. Matched field processing (MFP) refers to signal and array processing techniques in which, rather than a plane wave arrival model, complex-valued (amplitude and phase) field predictions for propagating signals are used. Matched field processing has been successfully applied in ocean acoustics and electromagnetics. In this paper, source localization performance via MFP is examined in the electromagnetics domain. Specifically, the impact of uncertainty in the a priori knowledge of the underlying physical parameters, atmospheric refractivity vs. height, on source localization performance is examined.


#*Measuring Resemblance of Complex Patterns
#@Michiel Hagedoorn,Remco C. Veltkamp
#t1999
#cProceedings of the 8th International Conference on Discrete Geometry for Computer Imagery
#index569822


#*Developing activity theory: the zone of proximal development and beyond
#@Vladimir P. Zinchenko
#t1995
#cContext and consciousness: activity theory and human-computer interaction
#index596306


#*Multiwavelength optical networks with limited wavelength conversion
#@Rajiv Ramaswami,Galen Sasaki
#t1998
#cIEEE/ACM Transactions on Networking (TON)
#index294578
#%120137
#%225520
#%606797


#*TULIP at Cornell University
#@Steven L. Worona,John M. Saylor
#t1995
#cLibrary Hi Tech
#index586961


#*Using dynamic cache management techniques to reduce energy in a high-performance processor
#@Nikolaos Bellas,Ibrahim Hajj,Constantine Polychronopoulos
#t1999
#cProceedings of the 1999 international symposium on Low power electronics and design
#index294058
#%89972
#%93869
#%515562


#*GA-Based Parallel Image Registration on Parallel Clusters
#@Prachya Chalermwat,Tarek A. El-Ghazawi,Jacquline LeMoigne
#t1999
#cProceedings of the 11 IPPS/SPDP'99 Workshops Held in Conjunction with the 13th International Parallel Processing Symposium and 10th Symposium on Parallel and Distributed Processing
#index365033


#*Freedom vs. performance
#@Martin J. Garvey
#t1999
#cMachine-Mediated Learning
#index292610


#*A Timed Semantics for the STATEMATE Implementation of Statecharts
#@Carsta Petersohn,Luis Urbina
#t1997
#cProceedings of the 4th International Symposium of Formal Methods Europe on Industrial Applications and Strengthened Foundations of Formal Methods
#index276109


#*Hybrid Space: Generative Form and Digital Architecture, 1st edition
#@Peter Zellner
#t1999
#c
#index620080


#*Microsoft Project 2000 for Dummies, 1st edition
#@Martin Doucette,Margin Douchette
#t1999
#c
#index239693
#!:Includes sample project files and more on CD-ROM Packed with savvy tips on project management Make the most of Microsoft Project  and make every project a success Microsoft Project is a powerful tool for planning and managing projects  including really complicated projects. But where do you begin? Filled with plain-English explanations and tips on the latest program features, this friendly guide shows you how to put Project to work right away  and deliver results on time and under budget. all this on the bonus CD-ROM Author-created sample project files Trial versions of Visual Staff Scheduler Pro 4.0 and Project KickStart 2.05 Evaluation version of Paint Shop Pro PC running Windows 98, Windows NT 4 or later; CD-ROM drive; Microsoft Project 2000. See the CD Appendix for details and complete system requirements. Plus leading Internet tools Discover how to: Build a powerful project plan Report your project status using e-mail Map complex projects with confidence Create a budget and monitor costs Manage people and time efficiently Get smart!


#*The size of a revised knowledge base
#@Marco Cadoli,Francesco M. Donini,Paolo Liberatore,Marco Schaerf
#t1995
#cProceedings of the fourteenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems
#index584747
#%162057
#%180846
#%234334
#%532160
#%543242
#%544949


#*Microsoft BackOffice Administrator's Survival Guide
#@Arthur E. Knowles
#t1996
#c
#index624167
#!:This hands-on, step-by-step guide provides you with the detailed information necessary to run any combination of Microsoft BackOffice products smoothly and efficiently. Practical guides and step-by-step examples teach you the entire BackOffice environment - from installation to daily administration and maintenance. Additional chapters give you practical guides and tips of tuning, optimizing, and hassle-free on-the-fly problem solving.


#*A family of sparse graphs of large sum number
#@Nora Hartsfield,W. F. Smyth
#t1995
#cDiscrete Mathematics
#index605138


#*Some p-Ranks Related to Orthogonal Spaces
#@Aart Blokhuis,G. Eric Moorhouse
#t1995
#cJournal of Algebraic Combinatorics: An International Journal
#index603665
#!We determine the p-rank of the incidence matrix of hyperplanes of PG(n, pe) and points of a nondegenerate quadric. This yields new bounds for ovoids and the size of caps in finite orthogonal spaces. In particular, we show the nonexistence of ovoids in O^+_{10}(2^e), O_{10}^+(3^e), O_9(5^e), O^+_{12}(5^e) and O^+_{12}(7^e). We also give slightly weaker bounds for more general finite classical polar spaces. Another application is the determination of certain explicit bases for the code of PG(2, p) using secants, or tangents and passants, of a nondegenerate conic.


#*Factorisation of regular graphs into forests of short paths
#@Terri Lindquester,Nicholas C. Wormald
#t1998
#cDiscrete Mathematics
#index91503


#*Evolutionary Systems Applied to the Synthesis of a CPU Controller
#@Ricardo S. Zebulum,Marco Aurélio Pacheco,Marley Vellasco
#t1998
#cSelected papers from the Second Asia-Pacific Conference on Simulated Evolution and Learning on Simulated Evolution and Learning
#index360076


#*CyberSource
#@Frederic E. Davis
#t1995
#c
#index621571
#!:Longtime computer journalist Frederic E. Davis presents the people who make up the computer industry as they talk about the products and services that have had an impact on their lives. Witty, insightful commentary and a free-wheeling layout make CyberSource perfect pleasure reading for people who like computers.


#*Special issue on restructuring the electric power business&mdash;a new paradigm for reducing regulation
#@Andrew B. Whinston
#t1999
#cDecision Support Systems
#index284864


#*Quality of service and asynchronous transfer mode in ip internetworks
#@Bruce Albert Mah
#t1996
#c
#index189930


#*Auto-adaptative multimedia composition (abstract)
#@Michel Crampen
#t1996
#cACM SIGWEB Newsletter
#index597412


#*Solid modeling and design
#@Lawrence L. Barinka
#t1995
#cHandbook of solid modeling
#index589112


#*The Impact of Memory Hierarchies on Cluster Computing
#@Xing Du,Xiaodong Zhang
#t1999
#cProceedings of the 13th International Symposium on Parallel Processing and the 10th Symposium on Parallel and Distributed Processing
#index362002
#!Using off-the-shelf commodity workstations and PCs to build a cluster for parallel computing has become a common practice. A choice of a cost-effective cluster computing platform for a given budget and for certain types of application workloads is mainly determined by its memory hierarchy and interconnection network of the cluster.Finding such a solution from exhaustive simulations would be highly time-consuming and expensive; and predictions from measurements on existing clusters would be impractical. We present an analytical model for evaluating performance impact of memory hierarchies and networks on cluster computing. The model covers the memory hierarchy of a single SMP, a cluster of workstations/PCs, or a cluster of SMPs by changing various modeling and architectural parameters. Network variations covering bus and switch networks are also included in the analysis. Applications of different types are characterized by parameterized workloads with different computation and communication requirements. The model has been validated by simulations.Our study shows that the length of memory hierarchy is the most sensitive factor to affect the execution time for many types of workloads. However, the interconnection network cost of a tightly coupled system with a short length of memory hierarchy, such as an SMP is significantly more expensive than a normal cluster network connecting independent computer nodes. Thus, the essential issue to be considered is the trade-off between the length of memory hierarchy and system cost. Based on analytical and case studies, we present our quantitative recommendations for building cost-effective clusters for different application workloads.


#*Topological Errors and Optimal Chamfer Distance Coefficients
#@Stéphane Marchand-Maillet,Yazid M. Sharaiha
#t1997
#cProceedings of the 7th International Workshop on Discrete Geometry for Computer Imagery
#index566369


#*Multipurpose DRAM architecture for optimal power, performance, and product flexibility
#@W. F. Ellis,J. E. Barth, Jr.,J. H. Dreibelbis,A. Furman,E. L. Hedberg,H. S. Lee,T. M. Maffitt,C. P. Miller,C. H. Stapper,H. L. Kalter,S. Divakaruni
#t1995
#cIBM Journal of Research and Development
#index584421


#*Concurrency Admission Control Management in ACCORD
#@Sue Nagy,Azer Bestavros
#t1997
#c
#index124855
#!Abstract We propose and evaluate admission control mechanisms for ACCORD, an Admission Control and Capacity Overload management Real-time Database framework---an architecture and a transaction model---for hard deadline RTDB systems. The system architecture consists of admission control and scheduling components which provide early notification of failure to submitted transactions that are deemed not valuable or incapable of completing on time. In this paper, we focus on our Concurrency Admission Control Manager (CACM), which ensures that admitted transactions do not overburden the system by requiring a level of concurrency that is not sustainable. The transaction model consists of two components: a primary taskand a compensating task. The execution requirements of the primary task are notknown a priori, whereas those of the compensating task are known a priori. Upon the submission of a transaction, the Admission Control Mechanismsare employed to decide whether to admitor rejectthat transaction. Once admitted, a transaction is guaranteed to finishexecuting before its deadline. A transaction is considered to have finished executing if exactly one of two things occur: Either its primary task is completed (successful commitment), or its compensating task is completed (safe termination). Committed transactions bring a profit to the system, whereas a terminated transaction brings no profit. The goal of the admission control and scheduling protocols (e.g., concurrency control, I/O scheduling, memory management) employed in the system is to maximize system profit. In that respect, we describe a number of concurrency admission control strategies and contrast (through simulations) their relative performance.


#*Interactive storytelling systems for children: using technology to explore language and identity
#@Marina Umaschi Bers,Justine Cassell
#t1999
#cJournal of Interactive Learning Research
#index280395


#*Ontology-based Web agents
#@Sean Luke,Lee Spector,David Rager,James Hendler
#t1997
#cProceedings of the first international conference on Autonomous agents
#index93325
#%591915


#*Communication scheduling in a distributed memory parallel interactive continuous media server system
#@Reinhard Lüling,Francisco Cortés Gómez
#t1998
#cProceedings of the 1998 International Conference on Parallel Processing Workshops
#index120157
#!This paper describes the design of a scaleable interactivecontinuous media server that is realized using a distributedmemory parallel computer architectures. We presenta scheme for data layout, admission control and communicationscheduling that provides inherent Quality of Servicesupport for the delivery of continuous media streamsfrom the storage devices to the external communication interfaceswithin the internal communication network of themedia server.The methods presented here are used for the developmentof a parallel continuous media server that is integrated withdifferent applications and supports the RTP/RTCP protocolfor data delivery as well as the RTSP protocol to control thedelivery of media streams.


#*Distortion viewing techniques for 3-dimensional data
#@M. Sheelagh T. Carpendale,T. Carpendale,D. J. Cowperthwaite,F. D. Fracchia
#t1996
#cProceedings of the 1996 IEEE Symposium on Information Visualization (INFOVIS '96)
#index119332
#%222532
#%586765
#%163826
#%601276
#%229620
#%307342
#!As the use of 3D information presentation becomes more prevalent, the need for effective viewing tools grows accordingly. Much work has been done in developing tools for 2D spaces which allow for detail in context views. We examine the extension of such 2D methods to 3D and explore the limitations encountered in accessing internal regions of the data with these methods. We then describe a novel solution to this problem of internal access with the introduction of a distortion function which creates a clear line of sight to the focus revealing sections previously obscured. The distortion is symmetric about the line of sight and is smoothly integrated back into the original 3D layout.


#*Quantum cellular automata: computing with quantum dot molecules
#@Paul Douglas Tougaw
#t1996
#c
#index188603


#*Point pattern matching algorithm invariant to geometrical transformation and distortion
#@Fang-Hsuan Cheng
#t1996
#cPattern Recognition Letters
#index75905


#*Rationalizing Medical Work: Decision-Support Techniques and Medical Practices, 1st edition
#@Marc Berg
#t1997
#c
#index621814
#!: "Is medicine a science or an art? Marc Berg's contribution to this long-standing debate moves away from normative arguments replacing them with an ethnographic inquiry that goes to the heart of medical work. Berg's analysis leads to a provocative new understanding of the practice of medicine and of medical judgment, grounded in a detailed empirical account rather than simplistic generalizations." -- Alberto Cambrosio, Department of Social Studies of Medicine, McGill University "This book is an outstanding contribution to STS scholarship and the study of sociotechnical practices. Berg's key conceptual theme, and the sharp, subtle, and sophisticated inferences he draws from his data, will stimulate other scholars to explore the generality of his insights beyond the field of medical practice. Berg's eclectic ability to interrelate different perspectives enhances the theoretical payoff of his case study. This book will be a tour de force that technology-studies scholars and others will refer to over and over again in thinking about how to conceptualize and linguistify human-machine interfaces." -- Mark A. Shields, Division of Technology, Culture, and Communication, University of Virginia One response to the current crisis in medicine--indicated by large variations in practice and skyrocketing costs--has been a call for the rationalizing of medical practice through decision-support techniques. These tools, which include protocols, decision analysis, and expert systems, have generated much debate. Advocates argue that the tools will make medical practice more rational, uniform, and efficient: that they will transform the "art" of medical work into a "science." Critics within medicine, as well as those in philosophy and science studies, question the feasibility and desirability of the tools. They argue that formal tools cannot and should not supplant humans in most real-life tasks. Marc Berg takes the issues raised by advocates and critics as points of departure for investigation, rather than as positions to choose from. Drawing on insights and methodologies from science and technology studies, he attempts to understand what "rationalizing medical practices" means: what these tools do and how they work in concrete medical practices. Rather than take a stand for or against decision-support techniques, he shows how medical practices are transformed through these tools; this helps the reader to see what is gained and what is lost. The book investigates how new discourses on medical work and its problems are linked to the development of these tools, and it studies the construction of several individual technologies. It looks at what medical work consists of and how these new technologies figure in and transform the work. Although the book focuses on decision-support techniques in the field of medicine, the issues raised are relevant wherever rationalizing techniques are being debated or constructed. Touching upon broader issues of standardization, universality, localization, and the politics of technology, the book addresses core problems in medical sociology, technology studies, and tool design. Inside Technology series


#*Collusion-Secure Fingerprinting for Digital Data (Extended Abstract)
#@Dan Boneh,James Shaw
#t1995
#cProceedings of the 15th Annual International Cryptology Conference on Advances in Cryptology
#index269670


#*Orientation dependence of HgCdTe epitaxial layers grown by MOCVD on Si substrates
#@K. Shigenaka,K. Matsushita,L. Sugiura,F. Nakata,K. Hirahara,M. Uchikoshi,M. Nagashima,H. Wada
#t1996
#cJournal of Electronic Materials
#index600228


#*Subpixel Stereo Matching by Robust Estimation of Local Distortion Using Gabor Filters
#@Peter Werth,Stefan Scherer,Axel Pinz
#t1999
#cProceedings of the 8th International Conference on Computer Analysis of Images and Patterns
#index562804


#*Clustering bipartite and chordal graphs: complexity, sequential and parallel algorithm
#@Nesrine Abbas,Lorna Stewart
#t1999
#cDiscrete Applied Mathematics
#index300597


#*A set of new separation axioms in L-fuzzy topological spaces
#@J. Fang,B. Ren
#t1998
#cFuzzy Sets and Systems
#index85684


#*AutoBrief: a multimedia presentation system for assisting data analysis
#@Stephan Kerpedjiev,Giuseppe Carenini,Steven F. Roth,Johanna D. Moore
#t1997
#cComputer Standards Interfaces
#index83295


#*Developing Custom Delphi Components, 11th edition
#@Ray Konopka
#t1995
#c
#index620062
#!:Includes the Delphi Object Pascal object model. Covers VCL component architecture, multi-control components, and component DLLs. Explains component creation and debugging, and field protection and access rights. Clarifies Object Pascal exceptions and exception handling. Shows you how to use many of the best Delphi controls available to build Windows applications. Tells about implementing properties, property editors, and events and event handlers.


#*Design Considerations in Boeing 777 Fly-By-Wire Computers
#@Y. C. (Bob) Yeh
#t1998
#cThe 3rd IEEE International Symposium on High-Assurance Systems Engineering
#index378294
#!The new technologies in flight control avionics systems selected for the Boeing 777 airplane program consist of the following: Fly-By-Wire (FBW), ARINC 629 Data Bus, and Deferred Maintenance.The FBW must meet extremely high levels of functional integrity and availability. The heart of the FBW concept is the use of triple redundancy for all hardware resources: computing system, airplane electrical power, hydraulic power and communication paths.The multiple redundant hardware are required to meet the numerical safety requirements. Hardware redundancy can be relied upon only if hardware faults can be contained; fail-passive electronics are necessary building blocks for the FBW systems. In addition, FBW computer architecture must consider other fault tolerance issues: generic errors, common mode faults, near-coincidence faults and dissimilarity.


#*Using Multi-chromosomes to Solve a Simple Mixed Integer Problem
#@Hans J. Pierrot,Robert Hinterding
#t1997
#cProceedings of the 10th Australian Joint Conference on Artificial Intelligence: Advanced Topics in Artificial Intelligence
#index358427


#*Personal Information Management: Tools and Techniques for Achieving Professional Effectiveness
#@Barbara Etzel,Peter J. Thomas
#t1999
#c
#index242439
#!:In this handbook, written for the office of the twenty-first century, Barbara Etzel and Peter J. Thomas provide guidance for those struggling to manage the growing volume of mail, memos, e-mail messages, and electronic documents that arrive daily. Personal Information Management details the skills professionals need to process this information, save time, and work more effectively. Etzel and Thomas present common organizational difficulties and concrete techniques for overcoming them. They guide the reader through a variety of computer software and hardware products, paper-based information products, and personal time-management techniques, helping the reader to develop an individually tailored "Personal Information Management Strategy." Technologies covered include accounting and business software, word processors, databases, personal organizers, e-mail programs, tracking and storing packages, personal digital assistants, CD-ROMs, computer backup devices, scanning devices, voice mail, cellular phones, pagers, and fax machines, to name only a few.


#*An Upper Bound on the Number of Edges of a 2-Connected Graph
#@Pou-Lin Wu
#t1997
#cCombinatorics, Probability and Computing
#index309873
#!Let G be a loopless 2-connected graph whose largest cycle has c edges, and whose largest bond has c&#x002A; edges. We show that &#x007C;E(G)&#x007C; &le; &half;cc&#x002A;.


#*MODSIM III&mdash;a tutorial
#@Alasdar Mullarney
#t1996
#cProceedings of the 28th conference on Winter simulation
#index88702
#!This tutorial introduces the MODSIM III language, showing how its simulation "world view" together with its object-oriented architecture and built in graphics contribute to successful simulation model building. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Side Effect Analysis on User-Defined Reduction Functions with Dynamic Pointer-Linked Data Structures
#@Yuan-Shin Hwang,Joel H. Saltz
#t1996
#cProceedings of the 9th International Workshop on Languages and Compilers for Parallel Computing
#index382284


#*CdZnTe substrate impurities and their effects on liquid phase epitaxy HgCdTe
#@J. P. Tower,S. P. Tobin,M. Kestigian,P. W. Norton,A. B. Bollong,H. F. Schaake,C. K. Ard
#t1995
#cJournal of Electronic Materials
#index598704


#*Computing local parameters of biquartic interpolatory splines
#@Jiří Kobza
#t1995
#cJournal of Computational and Applied Mathematics
#index598747


#*Two-sided patches suitable for inclusion in a B-spline surface
#@Malcolm Sabin
#t1998
#cProceedings of the international conference on Mathematical methods for curves and surfaces II Lillehammer, 1997
#index84171


#*Lossy Compression Effects on Digital Image Matching
#@
#t1998
#cProceedings of the 14th International Conference on Pattern Recognition-Volume 2 - Volume 2
#index434731


#*Modeling Concepts for Workflow Specification
#@Markus Kradolfer,Andreas Geppert
#t1997
#c
#index199351
#!This paper describes modeling concepts for the specification of processing entities and workflows and a workflow execution model for the TRAMs project.


#*A Mixed Approach to Negation in General Datalog Programs
#@Viet Phan Luong
#t1995
#cProceedings of the Fourth International Conference on Deductive and Object-Oriented Databases
#index365456


#*A Fuzzy Structural Approach to Handwritten Word Recognition
#@Richard Buse,Zhi-Qiang Liu
#t1995
#cProceedings of the Third International Computer Science Conference on Image Analysis Applications and Computer Graphics
#index361159


#*Design Elements of EHW Using GA with Local Improvement of Chromosomes
#@Mircea Gh. Negoita,Adrian Horia Dediu,Dan Mihaila
#t1997
#cProceedings of the International Conference on Computational Intelligence, Theory and Applications
#index364392


#*Computational Aspects of Multi-Species Lattice-Gas Automata
#@David Dubbeldam,Alfons G. Hoekstra,Peter M. A. Sloot
#t1999
#cProceedings of the 7th International Conference on High-Performance Computing and Networking
#index384082


#*Question/answer dialogues for interfacing a database with Supreme Court decisions
#@José Gabriel Lopes,Paulo Quaresma,Irene Rodrigues
#t1997
#cProceedings of the 6th international conference on Artificial intelligence and law
#index89008


#*An industrial SR-TXRF facility at ESRF
#@F. Comin,P. Mangiagalli,M. Navizet,G. Apostolo
#t1999
#cMicroelectronic Engineering
#index296960


#*On the learnability of rich function classes
#@Joel Ratsaby,Vitaly Maiorov
#t1999
#cJournal of Computer and System Sciences
#index298261


#*Overlapping Communication with Computation in Distributed Object Systems
#@Françoise Baude,Denis Caromel,Nathalie Furmento,David Sagnol
#t1999
#cProceedings of the 7th International Conference on High-Performance Computing and Networking
#index356882


#*AutoMod tutorial
#@Matthew W. Rohrer
#t1996
#cProceedings of the 28th conference on Winter simulation
#index93694
#!The AutoMod/sup TM/ simulation system differs significantly from other systems because of its ability to deal with the physical elements of a system in physical (graphical) terms and the logical elements of a system in logical terms. AutoMod also offers advanced features to allow users to simulate complex movement (kinematics and velocity) of equipment such as robots, machine tools, transfer lines, and special machinery. All graphics are represented in 3-D space with unlimited viewing control including: translation, rotation, scale, light-sourced solids, perspective, and continuous motion viewing. The AutoMod CAD features are used to define the physical layout of manufacturing, material handling, and distribution systems. Unlike most other simulation software, the powerful AutoMod graphical interface accurately captures the physical constraints of distance, size, and space in 3-b. AutoMod is really two programs. The build portion is for the physical and logical model definition. After the user has defined the physical and logical components of the model, it is then compiled into an executable model, where the simulation and animation run concurrently. The executable model is fully interactive, it can be stopped at any instant in simulated time to view statistics and model status.


#*Regulated Grammars with Leftmost Derivation
#@Henning Fernau
#t1998
#cProceedings of the 25th Conference on Current Trends in Theory and Practice of Informatics: Theory and Practice of Informatics
#index266927


#*Abstract Games for Infinite State Processes
#@Perdita Stevens
#t1998
#cProceedings of the 9th International Conference on Concurrency Theory
#index265057


#*A design of high-performance multiplier for digital video transmission
#@Keisuke Okada,Shun Morikawa,Isao Shirakawa,Sumitaka Takeuchi
#t1995
#cProceedings of the 1995 Asia and South Pacific Design Automation Conference
#index604523


#*The Intranet Resource Kit, 1st edition
#@Prakash Ambegaonkar
#t1996
#c
#index613399
#!:No other Intranet book comes even close to this gem of a handbook from the Intranet experts at Frontier Technologies. Not only is it loaded with tips, techniques, and shortcuts, it also features a ready-to-use version of Frontier Technologies' Intranet Genie software on CD - giving you everything you need to go from concept to blueprint to fully working Intranet in one complete package! With this powerful book/CD combination, you'll learn step-by-step how to create a versatile, scalable, and affordable Intranet. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A computer-based learning environment for teaching high-school students feedback control through design
#@J. Ma
#t1998
#cProceedings of the 28th Annual Frontiers in Education - Volume 03
#index421026
#!Summary form only given as follows. Feedback control is a pervasive and powerful concept that engineers have applied to design and analyze devices and processes, such as satellite attitude control and that scientists have used to study natural phenomena, such as thermoregulation in the human body. Yet, traditionally, students first encounter feedback control theory in college engineering courses where it is taught using mathematics that is more advanced than what most high school students study (i.e., calculus, Laplace transforms, and complex analysis). This paper describes current efforts to introduce the concept of feedback control to high school students with a computer-based learning environment we have developed called the Feedback Articulate Virtual Laboratory, or FAVL. The environment consists of a virtual design space and associated activities in which students can analyze, construct, and run simulations of feedback control systems without resorting to college-level mathematics. In addition, FAVL provides scaffolding, or learning supports, for students to help them understand feedback concepts and develop design and analysis skills. In this paper, we describe FAVL and present preliminary findings from a pilot study we conducted in a high school engineering class with two groups of 9th grade students. Specifically, we share initial results on students' changing conceptions of feedback phenomena and difficulties and successes students had while working with FAVL. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A Cellular-Programming Approach to Pattern Classification
#@Giovanni Adorni,Federico Bergenti,Stefano Cagnoni
#t1998
#cProceedings of the First European Workshop on Genetic Programming
#index260127


#*Evolution and generalization of a single neurone: II. complexity of statistical classifiers and sample size considerations
#@Šarūnas Raudys
#t1998
#cNeural Networks
#index89415


#*Schottky barriers on n-GaN grown on SiC
#@E. V. Kalinina,N. I. Kuznetsov,V. A. Dimitriev,K. G. Irvine,C. H. Carter, Jr.
#t1996
#cJournal of Electronic Materials
#index588979


#*Landmark Documents in American History Macintosh
#@
#t1998
#c
#index12236


#*The area bisectors of a polygon and force equilibria in programmable vector fields
#@Karl-Friedrich Böhringer,Bruce Randall Donald,Dan Halperin
#t1997
#cProceedings of the thirteenth annual symposium on Computational geometry
#index85362
#%147906


#*Volume Leases for Consistency in Large-Scale Systems
#@Jian Yin,Lorenzo Alvisi,Michael Dahlin,Calvin Lin
#t1999
#cIEEE Transactions on Knowledge and Data Engineering
#index446101
#%113047
#%117731
#%122917
#%151906
#%167164
#%359389
#%382653
#%486373
#%596406
#%484199
#%599128
#!This article introduces volume leases as a mechanism for providing server-driven cache consistency for large-scale, geographically distributed networks. Volume leases retain the good performance, fault tolerance, and server scalability of the semantically weaker client-driven protocols that are now used on the web. Volume leases are a variation of object leases, which were originally designed for distributed file systems. However, whereas traditional object leases amortize overheads over long lease periods, volume leases exploit spatial locality to amortize overheads across multiple objects in a volume. This approach allows systems to maintain good write performance even in the presence of failures. Using trace-driven simulation, we compare three volume lease algorithms against four existing cache consistency algorithms and show that our new algorithms provide strong consistency while maintaining scalability and fault-tolerance. For a trace-based workload of web accesses, we find that volumes can reduce message traffic at servers by 40 percent compared to a standard lease algorithm, and that volumes can considerably reduce the peak load at servers when popular objects are modified.


#*Static scheduling for synthesis of DSP algorithms on various models
#@Liang-Fang Chao,Edwin Hsing-Mean Sha
#t1995
#cJournal of VLSI Signal Processing Systems
#index589776


#*DIRICHLET MIXTURES: A METHOD FOR IMPROVING DETECTION OF WEAK BUT SIGNIFICANT PROTEIN SEQUENCE HOMOLOGY
#@Kimmen Sjolander,Kevin Karplus,Michael Brown,Richard Hughey,Anders Krogh,I. S Mian,David Haussler
#t1996
#c
#index193411
#!This paper presents the mathematical foundations of Dirichlet mixtures, which have been used to improve database search results for homologous sequences, when a variable number of sequences from a protein family or domain are known. We present a method for condensing the information in a protein database into a mixture of Dirichlet densities. These mixtures are designed to be combined with observed amino acid frequencies, to form estimates of expected amino acid probabilities at each position in a profile, hidden Markov model, or other statistical model. These estimates give a statistical model greater generalization capacity, such that remotely related family members can be more reliably recognized by the model. Dirichlet mixtures have been shown to outperform substitution matrices and other methods for computing these expected amino acid distributions in database search, resulting in fewer false positives and false negatives for the families tested. This paper corrects a previously published formula for estimating these expected probabilities, and contains complete derivations of the Dirichlet mixture formulas, methods for optimizing the mixtures to match particular databases, and suggestions for efficient implementation.


#*Applying Distributed Shared Memory Techniques for Implementing Distributed Objects
#@Antonio J. Nebro,Ernesto Pimentel,José M. Troya
#t1997
#cProceedings of the Workshops on Object-Oriented Technology
#index259172


#*Recovering map static nonlinearities from chaotic data using dynamical models
#@Luis Antonio Aguirre
#t1997
#cPhysica D
#index84386


#*Multigrid Solution of an Elliptic Boundary-Value Problem with Integral Constraints
#@Achi Brandt,Moshe Israeli,Irad Yavneh,Andrew Siegel
#t1999
#cSIAM Journal on Scientific Computing
#index287625
#!An efficient multigrid approach for solving a discretized elliptic equation whose boundary values are determined in part by integral relations is developed, analyzed, and tested. The algorithm is motivated by a problem that is solved during integration of the 3D quasigeostrophic (QG) equations, which model large-scale rotating stratified flows, where the integral constraints represent mass conservation.


#*Existence and multiplicity results for semilinear elliptic Dirichlet problems in exterior domains
#@Giovanna Cerami,Donato Passaseo
#t1995
#cNonlinear Analysis: Theory, Methods Applications
#index583085


#*Special Edition Using Corel WordPerfect 9
#@Laura Acklen,Read Gilgen
#t1999
#c
#index234615
#!:Discover the power of WordPerfect 9 and see what makes it one of the world's most popular word processing applications; learn the ins and outs of using the Writing Tools; master page layout formatting, styles, and templates; use lists and outlines to organize information; collaborate on WordPerfect 9 documents with others in your workgroup; master dozens of time-saving tricks; fax your documents from WordPerfect 9 or send as email attachments; add drawings, graphics, shapes, and images to your documents; customize graphic shapes and images; import data and work with other programs and applications; create and publish Web pages; and build interactive and multimedia documents.


#*The impact of gender, occupation, and presence of children on telecommuting motivations and constraints
#@Patricia L. Mokhtarian,Michael N. Bagley,Ilan Salomon
#t1998
#cJournal of the American Society for Information Science
#index80849


#*Robust stabilization of nonlinear systems via stable kernel representations with L2-gain bounded uncertainty
#@A. J. van der Schaft
#t1995
#cSystems Control Letters
#index590960


#*A fast CString replacement
#@Dan Shappir
#t1997
#cWindows Developer's Journal
#index88081


#*NetScape Navigator 4.0: Fast and Easy
#@Rob Tidrow
#t1997
#c
#index620577
#!:Navigator 4 Fast & Easy is a practical tutorial that shows how to use Netscape's newest Web browser to connect to, search, and navigate resources on the Internet and Web. This inexpensive book includes lots of figures that help users learn the most popular Web browser in the world. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*An Exact Branch and Bound Algorithm for the Steiner Problem in Graphs
#@B. N. Khoury,Panos M. Pardalos
#t1995
#cProceedings of the First Annual International Conference on Computing and Combinatorics
#index270422


#*Modeling ATM systems with GSPNs and SWNs
#@Marco Ajmone Marsan,Rossano Gaeta
#t1998
#cACM SIGMETRICS Performance Evaluation Review
#index91087
#!This paper overviews the work of the authors in the field of modeling and analysis of Asynchronous Transfer Mode (ATM) networks using Generalized Stochastic Petri Nets (GSPN) and a special class of high-level stochastic Petri nets known as Stochastic Well-formed Nets (SWN). These formalisms are first shown to be adequate tools for the development of models of ATM systems, provided that only one timed transition is used, together with many immediate transitions. The only timed transition in the GSPN and SWN models represents the ATM systems cell time, while immediate transitions implement the ATM systems behavior. The firing time distribution of the only timed transition is irrelevant for the computation of several interesting performance indices. The results, as well as the problems, derived from the analysis of ATM switches and Local Area Networks (LAN) that adopt the Available Bit Rate (ABR) service category are summarized and discussed, providing references to the works containing the technical details.


#*Using behavioural rules in animation
#@Colin Beardon,Victor Ye
#t1995
#cComputer graphics: developments in virtual environments
#index585907


#*Entropy of fuzzy partitions: a general model
#@Radko Mesiar,Ján Rybárik
#t1998
#cFuzzy Sets and Systems
#index282613


#*Interacting with statistics &mdash; report from a workshop at CHI 99
#@Michael Levi,Frederick Conrad
#t1999
#cACM SIGCHI Bulletin
#index295344


#*Automatic language identification using large vocabulary continuous speech recognition
#@S. Mendoza
#t1996
#cProceedings of the Acoustics, Speech, and Signal Processing, 1996. on Conference Proceedings., 1996 IEEE International Conference - Volume 02
#index417434
#!We have developed a highly accurate automatic language identification system based on large vocabulary continuous speech recognition (LVCSR). Each test utterance is recognized in a number of languages, and the language ID decision is based on the probability of the output word sequence reported by each recognizer. Recognizers were implemented for this test in English, Japanese, and Spanish, using the Ricardo corpus of telephone monologues. When tested on the OGI corpus of digitally recorded telephone speech, we obtained error rates of 3% or lower on 2-way and 3-way closed-set classification of ten-second and one-minute speech segments.


#*Compression of computer animation frames
#@Hee Cheol Yun
#t1996
#c
#index197586


#*ROMM routing on mesh and torus networks
#@Ted Nesson,S. Lennart Johnsson
#t1995
#cProceedings of the seventh annual ACM symposium on Parallel algorithms and architectures
#index583337
#%112826
#%167945
#%177286
#%217162
#%220887
#%365447
#%439869
#%440046
#%441438
#%443028
#%444574
#%447211
#%459796
#%469898
#%471348
#%474505
#%478401
#%521177
#%523472
#%524692
#%528544
#%546368
#%554880
#%594100


#*Anisotropic Diffusion as a Preprocessing Step for Efficient Image Compression
#@
#t1998
#cProceedings of the 14th International Conference on Pattern Recognition-Volume 2 - Volume 2
#index436450


#*Invertible Orientation Bundles on 2D Scalar Images
#@Stiliyan Kalitzin,Bart M. ter Haar Romeny,Max A. Viergever
#t1997
#cProceedings of the First International Conference on Scale-Space Theory in Computer Vision
#index275923


#*Code of Practice for the Design and Operation of on-Board Truck Computer Systems for Road Tankers
#@Institute Of Petroleum
#t1995
#c
#index617303
#!:On-board truck computer (OTC) systems interface with equipment at loading terminals and service stations, provide tractor-trailer monitoring and control as well as transmit data to a central point for routing, dispatch control, invoicing, etc. This outstanding reference contains guidelines essential to ensure the maximum degree of compatibility and safe operation of OTC equipment installed by various users. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A Compiler Optimization Algorithm for Shared-Memory Multiprocessors
#@Kathryn S. McKinley
#t1998
#cIEEE Transactions on Parallel and Distributed Systems
#index85680
#%457923
#%163816
#%625612
#%160970
#%596545
#%362120
#%465675
#%146000
#%529946
#%583509
#%512271
#%445659
#%591376
#%361601
#%210863
#%246590
#%480940
#%208002
#%589354
#%606723
#%516399
#%508541
#%168818
#%604130
#%207885
#%445680
#%538343
#%510910
#!This paper presents a new compiler optimization algorithm that parallelizes applications for symmetric, shared-memory multiprocessors. The algorithm considers data locality, parallelism, and the granularity of parallelism. It uses dependence analysis and a simple cache model to drive its optimizations. It also optimizes across procedures by using interprocedural analysis and transformations. We validate the algorithm by hand-applying it to sequential versions of parallel, Fortran programs operating over dense matrices. The programs initially were hand-coded to target a variety of parallel machines using loop parallelism. We ignore the user's parallel loop directives, and use known and implemented dependence and interprocedural analysis to find parallelism. We then apply our new optimization algorithm to the resulting program. We compare the original parallel program to the hand-optimized program, and show that our algorithm improves three programs, matches four programs, and degrades one program in our test suite on a shared-memory, bus-based parallel machine with local caches. This experiment suggests existing dependence and interprocedural array analysis can automatically detect user parallelism, and demonstrates that user parallelized codes often benefit from our compiler optimizations, providing evidence that we need both parallel algorithms and compiler optimizations to effectively utilize parallel machines.


#*Access 97 Unleashed with CD-ROM, 2nd edition
#@Dwayne Gifford
#t1996
#c
#index616905
#!:Access, one of Microsoft's database managers for Windows, has become one of the most accepted standards of database management for personal computers. The Unleashed format for this book allows current and new users to quickly find and easily find the information they need on the new features. It also serves as a complete reference for database programmers new to Access.Readers learn advanced techniques for working with tables, queries, forms, and dataShows how to program Access and how to integrate the database with the InternetCD-ROM includes Access utilities and applications and an electronic Access reference library


#*The optimisation of financial decision in a contracting firm
#@Ka Chi Lam
#t1997
#c
#index196368


#*G-Rep: geometry and feature representation for an integration with knowledge based design systems
#@Rüdiger Klein
#t1997
#cProceedings of the fifth IFIP TC5/WG5.2 international workshop on geometric modeling in computer aided design on Product modeling for computer integrated design and manufacture
#index79080


#*EyeSi - A Simulator for Intra-ocular Surgery
#@Markus A. Schill,Clemens Wagner,Marc Hennen,Hans-Joachim Bender,Reinhard Männer
#t1999
#cProceedings of the Second International Conference on Medical Image Computing and Computer-Assisted Intervention
#index278434


#*Automatic VLAN creation based on on-line measurement
#@Sean Rooney,Christian Hörtnagl,Jens Krause
#t1999
#cACM SIGCOMM Computer Communication Review
#index615039
#!Virtual LANs (VLANs) permit hosts connected to a LAN switch to be grouped together into logical groups as a function of some management policy rather than simply of their physical location. Commercial LAN switches support a variety of policies based on either physical or logical addresses, protocol types, tagged frames, or user defined rules. The objective of these policies is the same: to reduce the amount of traffic that needs to be routed by grouping together hosts which are likely to communicate with each other into the same virtual LAN. This paper proposes a novel and more direct approach, it shows how VLANs can be created and removed dynamically as a function of the measured traffic patterns across the network. This is both simpler than configuring many static rules and permits the VLAN configuration to adapt to the evolution in the traffic patterns. The latter point is especially important in future LANs supporting peer-to-peer continuous media services, such as IP telephony or video-conferencing, in which clusters of hosts come together to communicate with each other intensively for relatively short periods of time and then form into new clusters.


#*Official Advanced PowerBuilder 6.0: The Definitive Guide, 1st edition
#@Kouros Gorgani
#t1997
#c
#index613251
#!From the Book: Official Advanced PowerBuilder 6: The Definitive Guide is a new and different approach to this powerful program Official Advanced PowerBuilder 6: The Definitive Guide is a new and different approach to this powerful program. I have tried to construct this book in a fashion that provides a comprehensive look into the features of PowerBuilder 6. It was not my intention to offer a replacement for the PowerBuilder documentation, but rather to provide an additional resource to help you extend your knowledge base, become more proficient, and even exceed your goals. PowerBuilder has so many features and so much potential for enhancing your applications that it can be quite overwhelming to try to master them all at once. Therefore, in this book I have tried to cover PowerBuilders features in a way that allows you to focus specifically on information most appropriate and timely for your particular needs. I am assuming that you are somewhat familiar with PowerBuilder. However, if you are a newcomer to the program, this book will introduce you to the concepts behind client/server development and to the most efficient ways of using PowerBuilder to develop and deploy GUI applications. On the other hand, if you are an advanced developer, youll probably be particularly interested in finding solutions to problems and scenarios youve frequently encountered in your applications. I have divided this book into seven parts. Part I basically provides an overview on PowerBuilder and defines some of the industry buzzwords. Part II gets into the development phase; Ive covered some of the most common objects and classes used during development, including windows, controls, DataWindows, User objects, printing, SQL, and debugging. Part III discusses more advanced topics such as external interfaces, dynamic DataWindows, OLE, MAPI, and version control. In Part IV, I have described database connectivity in detail. Youll learn about ODBC, PowerBuilders database interfaces, Sybase SQL Anywhere, and the Adaptive Server Enterprise. Part V covers creating executables, as well as deploying and executing your applications. Part VI is all about administration: youll learn performance and fine-tuning tips, how to use Data Pipeline objects, and how to create Help files. Part VII, the final part, is a comprehensive section, focusing on distributed computing, building Web servers, PFCs, internationalization, other class libraries, and various third-party and Sybase tools. In a nutshell, most PowerBuilder features are explored in great detail. I wanted this book to be a technical session between you and me, so I have tried to get straight to the point and have skipped some of the basics. I have also had the benefit of input from four of Sybases Senior Technical Consultants, who assisted with various chapters of the book. All in all, I think youll find this book friendly, readable, filled with juicy tidbits, and packed with information that can be used in a real enterprise application. I hope you enjoy reading it as much as I have enjoyed writing it. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*The resolution of ambiguity in english language episodes through the achievement of a minimum global energy state in a boltzmann machine neural network architecture
#@Teresa Stephanie Zigh
#t1997
#c
#index198274


#*On the Cahn-Hilliard equation with degenerate mobility
#@Charles M. Elliott,Harald Garcke
#t1996
#cSIAM Journal on Mathematical Analysis
#index589483


#*L-functions of algebraic varieties over finite fields: rationality, meromorphy and entireness
#@Daqing Wan
#t1996
#cProceedings of the third international conference on Finite fields and applications
#index79576


#*User centered design: quality or quackery?
#@John Karat
#t1996
#cinteractions
#index598659
#%597464


#*Explicit Substitutions for Objects and Functions
#@Delia Kesner,Pablo E. Martínez López
#t1998
#cProceedings of the 10th International Symposium on Principles of Declarative Programming
#index568934


#*Implementing associative containers
#@P. J. Plauger
#t1997
#cC/C++ Users Journal
#index94402


#*Fuzzy implications of fuzzy cognitive map with emphasis on fuzzy causal relationship and fuzzy partially causal relationship
#@Hyun Soo Kim,Kun Chang Lee
#t1998
#cFuzzy Sets and Systems
#index78102


#*Matching of 3-D curves using semi-differential invariants
#@T. Pajdla,L. Van Gool
#t1995
#cProceedings of the Fifth International Conference on Computer Vision
#index552166
#!A method for matching 3-D curves under Euclidean motions is presented. Our approach uses a semi-differential invariant description requiring only first derivatives and one reference point, thus avoiding the computation of high order derivatives. A novel curve similarity measure building on the notion of /spl epsiv/-reciprocal correspondence is proposed. It is shown that by combining /spl epsiv/-reciprocal correspondence with the robust least median of squares motion estimation, the registration of partially occluded curves can be accomplished. An experiment with real curves extracted from 3-D surfaces demonstrates that curve matching can be successfully performed even on data from a simple and cheap 3-D sensor.


#*Computationally private information retrieval (extended abstract)
#@Benny Chor,Niv Gilboa
#t1997
#cProceedings of the twenty-ninth annual ACM symposium on Theory of computing
#index88793
#%144784
#%184597
#%523768
#%460810
#%222044
#%92900


#*View-less value based security
#@Prasad Venkataramana Rallapalli
#t1998
#c
#index74363


#*NetScape and the WWW for Dummies
#@Paul E. Hoffman
#t1995
#c
#index610710


#*Probabilistic Linear-Time Model Checking: An Overview of the Automata-Theoretic Approach
#@Moshe Y. Vardi
#t1999
#cProceedings of the 5th International AMAST Workshop on Formal Methods for Real-Time and Probabilistic Systems
#index556126


#*Parallel Image Analysis: Tools and Models
#@Serge Miguet,Patrick S. Wang,Annick Montanvert
#t1998
#c
#index233334
#!:This book contains a selection of papers presented at the Fourth International Workshop on Parallel Image Analysis, held at the Laboratoire de l'Informatique du Parallelisme of the Ecole Normale Superieure de Lyon, France. It is representative of the traditional topics of the workshop, from theoretical models for parallel image analysis to real life applications implemented on parallel multicomputers.


#*The multipole method for Poisson's equation in regions with rounded corners
#@V. I. Vlasov,D. B. Volkov
#t1995
#cComputational Mathematics and Mathematical Physics
#index606166


#*Distributed OLE stumbling blocks
#@Kevin Strehlo
#t1995
#cDatamation
#index597278


#*Wavelets in polar coordinates
#@O. Andric
#t1996
#cProceedings of the Acoustics, Speech, and Signal Processing, 1996. on Conference Proceedings., 1996 IEEE International Conference - Volume 03
#index414100
#!The problems encountered in the development and implementation of two-dimensional orthonormal wavelet bases and their filter banks in polar coordinates are addressed. These wavelets and filter banks have possible applications in processing signals that are collected by sensors working in the polar coordinate system, such as biomedical and radar generated signals. Wavelet bases are developed in the convenient and familiar surrounding of the rectangular plane, and the theory is transported to the polar plane. Corresponding filter banks are developed and the implementation of wavelet analysis in the polar plane is discussed. Examples are provided.


#*When parallel lines meet
#@Ken Rudin
#t1998
#cBYTE
#index95077


#*Teach Yourself PalmPilot and Palm III in 10 Minutes, 1st edition
#@Michael Steinberg,Preston Gralla
#t1998
#c
#index241894
#!:10 minutes is all you need to learn how to customize your Palm organizer with preferences and options, use all the basic applications like To-Do List and Address Book, add applications to your Palm organizer, manage your data and organize your life, access and manage your email and calendar, synchronize your schedule and addresses to your main computer.


#*Clone Detection Using Abstract Syntax Trees
#@Ira D. Baxter,Andrew Yahin,Leonardo Moura,Marcelo Sant'Anna,Lorraine Bier
#t1998
#cProceedings of the International Conference on Software Maintenance
#index113536
#!Existing research suggests that a considerable fraction (5-10%) of the source code of large-scale computer programs is duplicate code ("clones"). Detection and removal of such clones promises decreased software maintenance costs of possibly the same magnitude. Previous work was limited to detection of either near-misses differing only in single lexems, or near misses only between complete functions. This paper presents simple and practical methods for detecting exact and near miss clones over arbitrary program fragments in program source code by using abstract syntax trees. Previous work also did not suggest practical means for removing detected clones. Since our methods operate in terms of the program structure, clones could be removed by mechanical methods producing in-lined procedures or standard preprocessor macros.A tool using these techniques is applied to a C production software system of some 400K source lines, and the results confirm detected levels of duplication found by previous work. The tool produces macro bodies needed for clone removal, and macro invocations to replace the clones. The tool uses a variation of the well-known compiler method for detecting common sub-expressions. This method determines exact tree matches; a number of adjustments are needed to detect equivalent statement sequences, commutative operands, and nearly exact matches. We additionally suggest that clone detection could also be useful in producing more structured code, and in reverse engineering to discover domain concepts and their implementations.


#*Actions as Prolog Programs
#@Marcus V. Tolentino,Paulo E. Santos,Flavio S. C. da Silva,Marcio Rillo
#t1996
#cProceedings of the 1996 IEEE International Joint Symposia on Intelligence and Systems
#index112577
#!As an extention of the TRASYS approach to reasoning about actions, this work presents a new step in the direction to the transposition of the gap between action formalisms and their real execution inside planning environments. We try to clarify some points of the former paper by presenting a re-structured overview of the Transaction Logic formalism and proposing some modifications to the action model which will allow the use of non-atomic formulae in the world model. Aiming an efficient method for executing action specifications, we present how could these specifications be rendered into a PROLOG program.


#*Every Unsolvable lambda Term has a Decoration
#@René David
#t1999
#cProceedings of the 4th International Conference on Typed Lambda Calculi and Applications
#index377820


#*Analysis and design consideration of a unity power factor quasi-resonant rectifier
#@M. Tou,R. Chaffaï,K. Al-Haddad,V. Rajagopalan
#t1995
#cMathematics and Computers in Simulation
#index604731


#*Analyzing the M/M/1 queue in frequency domain experiments
#@Sheldon H. Jacobson
#t1995
#cApplied Mathematics and Computation
#index586146


#*A neural network based dedicated thinning method
#@P. Ahmed
#t1995
#cPattern Recognition Letters
#index587749


#*The self-sufficient library collection: a test of assumptions
#@F. C. A. Exon,Keith F. Punch
#t1997
#cJournal of the American Society for Information Science
#index93125


#*Projection and contraction methods for semidefinite programming
#@Qiaoming Han
#t1998
#cApplied Mathematics and Computation
#index281103


#*Curvature Estimation with a DCA Neural Network
#@Enno Littmann,Helge Ritter
#t1995
#cMustererkennung 1995, 17. DAGM-Symposium
#index556028


#*Windows 3.11 for Dummies, 4th edition
#@Andy Rathbone
#t1998
#c
#index234672
#!:Best-selling author Andy Rathbone has helped more than a million novice Windows users get around the Windows interface like it's their own backyard. Now, Andy has updated Windows 3.11 For Dummies&reg; to bring you the latest information about how Windows can make your PC more efficient and a lot easier to use. Inside, find helpful advice on how to Use all the handy features of Windows 3.1 and 3.11 Run DOS programs under Windows with no sweat Install Windows programs when they come without an installation program Customize Windows for optimal use Navigate the File Manager easily Use and move icons on your desktop Run Windows for Workgroups 3.11 -- including networking and special features of WFW


#*Handbook of mathematics (3rd ed.)
#@I. N. Bronshtein,K. A. Semendyayev
#t1997
#c
#index80170


#*Developing an image viewer for content-based retrieval and navigation (abstract)
#@Stephen Perry,Mark Dobie,Paul Lewis
#t1996
#cACM SIGWEB Newsletter
#index589594


#*Delay jitter correlation analysis for traffic transmission on high speed networks
#@C. Fulton,San-Qi Li
#t1995
#cProceedings of the Fourteenth Annual Joint Conference of the IEEE Computer and Communication Societies (Vol. 2)-Volume - Volume 2
#index119285
#!Studies the time-dynamic behavior of delay jitter as captured by the autocorrelation function; the second-order statistics provide information relating to consecutive cell loss in real-time services. The authors derive an expression for delay jitter correlation of a stationary traffic stream in an MMPP/M/1/K system with FIFO service discipline; use of a type of deterministic rate server yields the same correlation function but with reduced variance. The jitter second-order statistics are shown to depend strongly on those of the queue, and the queue second-order statistics depend strongly on those of the input traffic. The authors show that the shape of the jitter correlation is determined by the weighted difference in queue correlations, and they derive a method for obtaining the weights for an MMPP traffic stream. In the numerical study emphasis is placed on a periodic traffic stream (such as CBR video) multiplexed on a major communication node; the authors investigate the impact of input traffic correlations and queueing system parameters on the queue length and delay jitter second-order statistics. They also briefly consider the delay jitter correlation from a binary Markov source (voice model).


#*Microsoft Excel 97 Quick Source Guide
#@Quick Source Staff
#t1998
#c
#index231860
#!:With this guide users learn to master the powerful Excel 97. Using graphics and step-by-step instructions, it covers: worksheet basics; working with rows and columns; formatting cells; using formulas; creating charts and graphs; using data maps; printing worksheets; shortcuts; and getting help.Author Biography: Quick Source is a national supplier of training materials to corporations throughout the United States. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A Control Method for Assimilation of Surface Data in a Linearized Navier--Stokes-Type Problem Related to Oceanography
#@Aziz Belmiloudi,Françoise Brossier
#t1997
#cSIAM Journal on Control and Optimization
#index93597
#!A method of control is developed in order to compute the variability of the velocity and pressure $(u, p)$ in an oceanic doman $\Omega$ during a time $T$. The observation is the variability of $p$ of $\Gamma_0 \times ]0, T[$, where $\Gamma_0$ is the upper surface of $\Omega$ and corresponds to the undisturbed sea surface. The observation is deduced from satellite data. The control is the variability of the wind-stress $f$, which acts as the forcing of the perturbation. The mean circulation in $\Omega$ is supposed to be known. The equations verified by $(u, p)$ are linearized around this mean circulation. The continuity of the application: $f \rightarrow (u(f), p(f))$ in convenient functional spaces is proved. We deduce from this result the existence and uniqueness of an optimal control, which is characterized by a set of equations including the direct problem of linearized Navier--Stokes type verified by $(u, p)$ and the adjoint problem. The cost function and consequently the optimal control depend on a real parameter $\alpha$. We prove the convergence of the sequence $(f_{\alpha})$, when $\alpha$ tends to 0, toward a wind-stress $f$ which minimizes the distance between the observed and computed pressures. This result is obtained by means of minimizing sequences.


#*Adaptive Non-uniform Mutation for Genetic Algorithms
#@André Neubauer
#t1997
#cProceedings of the International Conference on Computational Intelligence, Theory and Applications
#index357057


#*A personal job-seeking odyssey
#@Nancy Collier
#t1997
#cACM SIGGRAPH Computer Graphics
#index253466
#%620206
#!Imagine a world in which the oranges that looked so beautiful an hour ago in the market have a completely different color when you get them out of the bag at home. Imagine, when you approach a traffic light, you cannot tell what color the light is. Imagine the colors of traffic lights changing from one block to the next one. Could you?If you can't, just go to your computer and launch your World Wide Web browser. Viewing a color document on the Web, you cannot be sure what the colors will be. Some of it has been deliberate; so that people with different viewing capabilities can still view documents. That is why, under most circumstances, the color of the background, text and hyperlinks are all left to the choice of the client (browser) side.However, the World Wide Web has become a major source of information. Not only does it provide a wealth of information for you to consume, but it also gives you the opportunity to be an information producer --- a publisher.This, in turn, gives you the opportunity to violate every known recommendation for effective color usage! Indeed, a large majority of information producers on the Web either have not bothered to study such recommendations, or have decided to deliberately ignore them.Color on the Web has experienced the same neglect as in other applications of visual computing such as computer graphics, imaging and visualization. In all these cases, color was ignored or neglected for a long period of time before interest mounted.A case in point is the default color most Web browsers assign to hyperlinks: blue. As is well known, our visual system has the lowest sensitivity to blue, making it the worst color for small samples, such as text and line graphics.There are many other examples of sites on the Web that burden the viewer with text in colors that are barely readable, with insufficient contrast between foreground and background, with annoying color and texture combinations and more.As the Web is becoming more and more a preferred choice of publishing --- either exclusively, or in conjunction with traditional publishing channels --- the demand for higher-quality graphics, imaging, and thus color, will increase. It will not be long before publishers --- and, remember, on the Web anybody can be a publisher --- seek to publish high-quality graphics, just like the glossy stuff you see in magazines. To date, there isn't enough color capability in standard Web technology to support this goal.This article briefly explores color issues on the World Wide Web. We summarize the main color capabilities that are available to us on the Web today; the summary is as short as the capabilities to date.We anticipate that, as with other visual computing applications, interest will eventually arise in using and supporting color in a more complete and effective way. We thus attempt to outline what we consider to be the needs that lie ahead to obtain the improved color support needed.


#*A core library for robust numeric and geometric computation
#@V. Karamcheti,C. Li,I. Pechtchanski,C. Yap
#t1999
#cProceedings of the fifteenth annual symposium on Computational geometry
#index288472
#%75647
#%76518
#%80789
#%90065
#%116081
#%154908
#%210855
#%220319
#%224543
#%284150
#%593389
#%457431
#%606713
#%599681
#%376357
#%600460
#%377959
#%475349
#%603295


#*The Computers and Society agora
#@
#t1999
#cACM SIGCAS Computers and Society
#index231369


#*Curved asymptotic solitons of Kadomtsev-Petviashvili-I and modified Kadomtsev-Petviashvili-I equations
#@I. A. Anders
#t1995
#cProceedings of the conference on The nonlinear Schrodinger equation
#index592350


#*MCSE Windows NT Workstation 4 for Dummies Training Kit with CD-ROM
#@Dummies Technology Press
#t1999
#c
#index447044
#!:MCSE For Dummies Training Kits are Jam-Packed with Test Prep Tools! Introducing the ultimate.For Dummies MCSE test prep tool. The centerpiece of each MCSE Training Kit is the original Certification For Dummies study guide - The Fun and Easy Way to prepare for each MCSE exam. Plus each training kit contains the original software - the versatile Dummies test engine and QuickLearn sci-fi game. Inside every MCSE Training Kit, you will get even more, including: A CD-ROM with an evaluation edition of the software covered in the test or other valuable software relevant to the topic A 64 -page scenario book with step-by-step exercises listed by objective An audio CD with up to 70 minutes of verbal questions and answers - perfect for practice in the car or at the gym Sento mentoring coupon for two free online Q&A's with Sento staff Each MCSE For Dummies Training Kit includes MCSE Certification For Dummies book, scenario book, and 3 CD-ROMs. Reader level: Intermediate-Advanced


#*Fixture design in a computer integrated manufacturing (CIM) environment
#@Joe Amal Cecil
#t1995
#c
#index596239


#*Subjectivity and GenVoca Generators
#@Don Batory
#t1996
#cProceedings of the 4th International Conference on Software Reuse
#index110318
#!The tenet of subjectivity is that no single interface can adequately describe any object; interfaces to the same object will vary among different applications. Thus, objects with standardized interfaces seem too brittle a concept to meet the demands of a wide variety of applications. Yet, objects with standardized interfaces is a central idea in domain modeling and software generation. Standard interfaces make objects plug-compatible and interchangeable, and it is this feature that is exploited by generators to synthesize high-performance, domain-specific software systems. Interestingly, generated systems have customized interfaces that can be quite different from the interfaces of their constituent objects. In this paper, we reconcile this apparent contradiction by showing that the objects (components) in the GenVoca model of software generation are not typical software modules; their interfaces and bodies mutate upon instantiation to a "standard" that is application-dependent.


#*Linux to Go, 1st edition
#@Rich Grace,Tim Parker
#t1999
#c
#index241949
#!From the Book:PREFACE: PrefaceLinux has seen a spectacular growth curve over the last two or three years. When mail-order companies start to preload the operating system, you know it's made it to the big leagues. According to reasonable market estimates, there are over eight million Linux users in the world. Compare that to Windows's sixty-six million, and you can see that Linux has found a considerable niche in the market. Linux's popularity has grown as the operating system has evolved from a hacker's paradise a mere six years ago to a robust, dependable, stable operating system with a friendly GUI, commercial applications, and dedicated support on the Internet. Users are no longer faced with convoluted installation and configuration processes. They don't even have to learn much about UNIX. Since Linux can work superbly on old hardware, like the 386 and 486 you replaced with your Pentium, there's no reason not to use it. Along with the rise in popularity there has been an outpouring of books about the subject. One author has written eight books on the subject in the last five years. Yet most of the books on the shelves deal with introductory-level material for the non-UNIX user, or special configuration and programming subjects. There are no books on tricks and tips for the user who isn't a guru, but isn't a neophyte, either. You already know Linux commands, and you have the operating system running smoothly. This book addresses where to go from the basics you already understand. The target audience for all the To Go books are users moving beyond basic knowledge levels. The series tries to cover many aspects of the subject that may be of interest,withoutconcentrating too much on any one subject or theme. You'll find a varied assortment in these pages. Some of the subjects in this book are likely to be familiar to you; others may not be. Many veteran Linux users know the basic UNIX commands, but don't understand subjects like file permissions, using find, or configuring X properly. Thus, we've taken the subjects that most Linux users want to know about, answered many of the most commonly-asked questions, and tried to extend the typical Linux user's knowledge about the use of the operating system. Many of the subjects in this book, such as DNS, Apache, Samba, and Usenet news, have been included because of repeated requests for information from students in advanced UNIX courses. If they are curious, you may be, too.We cover a lot of material here, from the simple to the complex. We don't try to cover every obscure aspect of Linux. We don't try to be comprehensive. We can't possibly do that in the few hundred pages you hold. Instead, we include enough detail to whet your appetite, to start you experimenting with your system, and to expand your knowledge level considerably. We hope you enjoy reading Linux To Go. If you have suggestions for changes or additions, we'd like to hear from you. Above all else, we hope you learn something and are able to get even more from this great operating system.


#*Prediction-driven computational auditory scene analysis
#@Daniel P. W. Ellis
#t1996
#c
#index191776


#*Dynamic object identification and verification using video
#@B. Li
#t1999
#cProceedings of the Acoustics, Speech, and Signal Processing, 1999. on 1999 IEEE International Conference - Volume 06
#index430702
#!We introduce the concepts of dynamic object identification and verification using video. A generalized Hausdorff metric, which is more robust to noise and allows a confidence interpretation, is suggested for the identification and verification problem. Parameters from sensor motion compensation procedure are incorporated into the search step such that the Hausdorff metric based matching can be achieved efficiently under more complex transformation groups. An algorithm is proposed for identification/verification based on edge map matching using the generalized Hausdorff metric. Experiments on infrared video sequences are provided.


#*Electro-optic properties of sol-gel derived PZT and PLZT thin films
#@G. Teowee,J. T. Simpson,Tianji Zhao,M. Mansuripur,J. M. Boulton,D. R. Uhlmann
#t1995
#cProceedings of the 1st European meeting on Integrated ferroelectrics
#index593666


#*Saga Dreamcast Official Preview Guide
#@Brady Games,Sega Ent Apuraizesu
#t1999
#c
#index237774
#!:Dreamcast is the only console to have a 56k modem with network capability to handle online multi-player gaming in high-resolution. Fifteen games are expected to be available for the Dreamcast system around the September launch date and over 30 games will be available by December. The Dreamcast system runs on a 200Mhz processor, performs faster than a 266 Pentium II processor, and brings arcade-style graphics into the home. Reports show that the Dreamcast console is 15 times more powerful than the Sony PlayStation and 10 times more powerful than Nintendo 64.


#*Factors contributing to successful implementation of computer technology in schools
#@Brevard Springs Williams, III
#t1995
#c
#index198913


#*Creating Telecommunication Services based on Object-Oriented Frameworks and SDL
#@Richard Sinnott,Mario Kolberg
#t1999
#cProceedings of the 2nd IEEE International Symposium on Object-Oriented Real-Time Distributed Computing
#index125221
#!This paper describes the tools and techniques being applied in the TINA Open Service Creation Architecture (TOSCA) project to develop object-oriented models of distributed telecommunication services in SDL. The paper also describes the way in which Tree and Tabular Combined Notation (TTCN) test cases are derived from these models and subsequently executed against the CORBA-based implementations of these services through a TTCN/CORBA gateway.


#*The Matrix Template Library: A Generic Programming Approach to High Performance Numerical Linear Algebra
#@Jeremy G. Siek,Andrew Lumsdaine
#t1998
#cProceedings of the Second International Symposium on Computing in Object-Oriented Parallel Environments
#index268566


#*Multimedia applications and their communications needs
#@Stewart D. Personick
#t1995
#cProceedings of an IEEE symposium on Worldwide advances in communication networks
#index597579


#*Towards a computer-aided economic planning support system
#@Motaz Khorshid
#t1995
#cDecision Support Systems
#index592057


#*Generalized gradient adaptive step sizes for stochastic gradient adaptive filters
#@S. C. Douglas
#t1995
#cProceedings of the Acoustics, Speech, and Signal Processing, 1995. on International Conference - Volume 02
#index26856
#!We derive new adaptive step size algorithms for two general classes of modified stochastic gradient adaptive filters that include the sign-error, sign-data, sign-sign, and normalized gradient adaptive filters as specific cases. These computationally-simple parameter adjustment algorithms are based on stochastic gradient approximations of steepest descent procedures for the unknown parameters. Analyses of the algorithms show that the stationary points of the steepest descent procedures yield the optimum step size values at each time instant as obtained from statistical analyses of the adaptive filter updates. Simulations verify the theoretical results and indicate that near-optimal tracking performance can be obtained from each of the adaptive step size algorithms without any knowledge of the rate of change of the unknown system.


#*For Unknown Secrecies Refusal is Better than Lying
#@Joachim Biskup
#t1999
#cProceedings of the IFIP WG 11.3 Thirteenth International Conference on Database Security: Research Advances in Database and Information Systems Security
#index365224


#*Quest for Java
#@Sonya Freeman Cohen
#t1998
#cCommunications of the ACM
#index86976


#*Why the CIO's job is so difficult
#@James C. Emery
#t1997
#cJournal of Global Information Management
#index90109


#*A Notation Based on Process Product Unification
#@Elif Demirörs,Onur Demirörs
#t1998
#cProceedings of the 6th European Workshop on Software Process Technology
#index368875


#*Retrospective: decoupled access/execute architectures
#@James E. Smith
#t1998
#c25 years of the international symposia on Computer architecture (selected papers)
#index82336
#%149669
#%144697


#*Home health care support
#@Linda Tetzlaff,Michelle Kim,Robert J. Schloss
#t1995
#cConference companion on Human factors in computing systems
#index602389


#*Spreadsheets as an interface to parallel computation
#@Alan G. Yoder
#t1997
#c
#index202956


#*A conceptual basis for feature engineering
#@C. Reid Turner,Alfonso Fuggetta,Luigi Lavazza,Alexander L. Wolf
#t1999
#cJournal of Systems and Software
#index329924


#*Micro Review
#@Richard Mateosian
#t1995
#cIEEE Micro
#index440986


#*On Use of ANNs to Model and to Control Robot Manipulators
#@Ignacy Culeba,Robert Muszynski
#t1997
#cProceedings of the 7th International Conference on Artificial Neural Networks
#index370274


#*Teaching transient behavior of electrical machines with personal computers
#@Mehmet Akbaba
#t1997
#cComputers Education
#index93121


#*Real-time control of HgCdTe growth by organometallic vapor phase epitaxy using spectroscopic ellipsometry
#@Srikanteswara Dakshina Murthy,Ishwara Bhat,Blaine Johs,Shakil Pittal,Ping He
#t1995
#cJournal of Electronic Materials
#index606122


#*Graphs with given odd sets and the least number of vertices
#@S. Louis Hakimi
#t1997
#cJournal of Graph Theory
#index89043


#*A high-level intermediate language and the algorithms for compiling finite-domain constraints
#@Neng-Fa Zhou
#t1998
#cProceedings of the 1998 joint international conference and symposium on Logic programming
#index287992


#*Windows 98 Programming from the Ground Up, 1st edition
#@Herbert Schildt
#t1997
#c
#index610531
#!:Master Windows 98 Programming with Herb Schildt's Proven Method forSuccess! Keep your skills current and marketable with Windows 98 Programming from the Ground Upthe comprehensive,self-paced programming guide by Herb Schildt,the world's leading programming author. Windows 98 is filled with new options,new features,and new performance standards. Herb Schildt helps you take advantage of them all. You'll program your way from beginner to expert using Schildt's hands-on examples,easy-to-follow explanations,and exclusive "Portability" tips for migratting from Windows 3. x,Windows 95,and Windows NT. As an extra bonus,you'll find "In Depth" boxes packed with critical insight throughout the book. Learn from the top-notch programmer,best-selling author,and expert teacher whose books have led millions of programmers to success. Whether you're a seasoned professional looking for a quick migration path,or a programming novice,you'll find everything you need in Windows 98 Programming from the Ground Up The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*ECCAI announces new publication medium&colon; Electronic Transactions on Artificial Intelligence
#@Staff
#t1997
#cAI Communications
#index12479


#*Investigating feedforward neural networks with respect to the rejection of spurious patterns
#@G. C. Vasconcelos,M. C. Fairhurst,D. L. Bisset
#t1995
#cPattern Recognition Letters
#index595391


#*Symbolic performance prediction of scalable parallel programs
#@Mark J. Clement,Michael J. Quinn
#t1995
#cProceedings of the 9th International Symposium on Parallel Processing
#index374443
#!Recent advances in the power of parallel computers have made them attractive for solving large computational problems. Scalable parallel programs are particularly well suited to Massively Parallel Processing (MPP) machines since the number of computations can be increased to match the available number of processors. Performance tuning can be particularly difficult for these applications since it must often be performed with a smaller problem size than that targeted for eventual execution. This research develops a performance prediction methodology that addresses this problem through symbolic analysis of program source code. Algebraic manipulations can then be performed on the resulting analytical model to determine performance for scaled up applications on different hardware architectures.


#*Strawson on Intended Meaning and Context
#@Varol Akman,Ferda Nur Alpaslan
#t1999
#cProceedings of the Second International and Interdisciplinary Conference on Modeling and Using Context
#index379451


#*Pixel masks for screen-door transparency
#@Jurriaan D. Mulder,Frans C. A. Groen,Jarke J. van Wijk
#t1998
#cProceedings of the conference on Visualization '98
#index95476
#%220730
#%479695
#%249160
#%234204
#%551285
#%522005
#%155023


#*On a singular nonlinear elliptic equation
#@Hongwei Chen
#t1997
#cNonlinear Analysis: Theory, Methods Applications
#index93306


#*Application of neural networks and fuzzy logic in nondestructive evaluation of materials
#@C. H. Chen
#t1996
#cFuzzy logic and neural network handbook
#index600904


#*Efficient algorithms for maximum regression depth
#@Marc van Kreveld,Joseph S. B. Mitchell,Peter Rousseeuw,Micha Sharir,Jack Snoeyink,Bettina Speckmann
#t1999
#cProceedings of the fifteenth annual symposium on Computational geometry
#index286461
#%86671
#%147906
#%161759
#%177153
#%223925
#%224325
#%225611
#%465074
#%591339
#%582538
#%527689
#%517539


#*The Legend of Zelda: Ocarina of Time Official Strategy Guide
#@Brady Games
#t1998
#c
#index233377
#!:BradyGAMES The Legend of Zelda:Ocarina of Time Official Strategy Guide Features: Killer strategy for every Boss and all the creatures in Hyrule. Maps to help navigate you through all the key locations. Uncover all the Secrets, including the hidden Heart Pieces. Every Mini-Game covered!


#*Global stacking for analog circuits
#@B. Arsintescu,S. Spânoche
#t1996
#cProceedings of the conference on European design automation
#index80511
#%609739


#*H/sup /spl infin// adaptive filtering
#@B. Hassibi,T. Kailath
#t1995
#cProceedings of the Acoustics, Speech, and Signal Processing, 1995. on International Conference - Volume 02
#index34046
#!H/sup /spl infin// optimal estimators guarantee the smallest possible estimation error energy over all possible disturbances of fixed energy, and are therefore robust with respect to model uncertainties and lack of statistical information on the exogenous signals. We have shown that if the prediction error is considered, then the celebrated LMS adaptive filtering algorithm is H/sup /spl infin// optimal. We consider prediction of the filter weight vector itself, and for the purpose of coping with time-variations, exponentially weighted, finite-memory and time-varying adaptive filtering. This results in some new adaptive filtering algorithms that may be useful in uncertain and non-stationary environments. Simulation results are given to demonstrate the feasibility of the algorithms and to compare them with well-known H/sup 2/ (or least-squares based) adaptive filters.


#*Security Management Against Cloned Cellular Telephones
#@Mirela Sechi Moretti Annoni Notare,Fernando Augusto da Silva Cruz,Bernardo Gonçalves Riso,Carlos Becker Westphall
#t1999
#cProceedings of the 7th IEEE International Conference on Networks
#index114501
#!The present work describes a security management system against the frauds related with the cloning of cellular phones. The system intends to make this fraud a nonlucrative business, and then, to finish with it. The system uses of three main techniques: (1) The ISO 8807 Technique (FDT LOTOS) is used to specify and validate the system through the Eucalyptus software employment; (2) A Pattern Recognition Technique is used to classify the telephone users into classes in order to identify if a call does not correspond to the patterns of a specific user -through MatLab software employment; and (3) CORBA Technique is used for the implementation of this distributed system (i.e., manager and agents), by VisiBroker software employment.


#*Adaptive control of hot-dip galvanizing
#@Desong Chen
#t1995
#cAutomatica (Journal of IFAC)
#index585200


#*Distributed partial evaluation
#@Michael Sperber,Peter Thiemann,Hervert Klaeren
#t1997
#cProceedings of the second international symposium on Parallel symbolic computation
#index81953
#%328436
#%466243
#%594506
#%218396
#%218926
#%162605
#%588072
#%223822
#%174606
#%600122
#%616766
#%222582
#%594556
#%528164


#*Dynamic Runtime Optimization
#@Thomas Kistler
#t1997
#cProceedings of the Joint Modular Languages Conference on Modular Programming Languages
#index363631


#*Journalism in the Information Age: A Guide to Computers for Reporters and Editors, 1st edition
#@Brian S. Brooks
#t1996
#c
#index622755
#!:The arrival of computer-delivered information is the beginning of a new era for journalism and journalists. This book introduces readers to commercial databases, the Internet, and the many other potential uses of computers in journalism. By acquainting them with the emerging new electronic services, readers come to understand the power these technologies hold for the changing realities of the Information Age. Coverage of the Internet and on-line services such as CompuServe, America Online, Prodigy, and Delphi shows the potential benefits of this rich source of public information. In addition, readers are exposed to the many ways in which computers can help them perform better on the job. For professionals working in the field of journalism. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Closure properties of the classes of sets recognized by space-bounded two-dimensional probalistic turing machines
#@Tokio Okazaki,Katsushi Inoue,Akira Ito,Yue Wang
#t1999
#cInformation Sciences&mdash;Informatics and Computer Science: An International Journal
#index280012


#*Social interaction on the net: virtual community or participatory genre?
#@Thomas Erickson
#t1997
#cACM SIGGROUP Bulletin
#index89075


#*Search Space Reduction in QoS Routing
#@Liang Guo,Ibrahim Matta
#t1999
#c
#index110914
#!Abstract To provide real-time service or engineer constrained-based paths, networks require the underlying routing algorithm to be able to find low-cost paths that satisfy given Quality-of-Service (QoS) constraints. However, the problem of constrained shortest (least-cost) path routing is known to be NP-hard, and some heuristics have been proposed to find a near-optimal solution. However, these heuristics either impose relationships among the link metrics to reduce the complexity of the problem which may limit the general applicability of the heuristic, or are too costly in terms of execution time to be applicable to large networks. In this paper, we focus on solving the delay-constrained minimum-cost path problem, and present a fast algorithm to find a near-optimal solution. This algorithm, called DCCR (for Delay-Cost-Constrained Routing), is a variant of the k-shortest path algorithm. DCCR uses a new adaptive path weight function together with an additional constraint imposed on the path cost, to restrict the search space. Thus, DCCR can return a near-optimal solution in a very short time. Furthermore, we use the method proposed by Blokh and Gutin to further reduce the search space by using a tighter bound on path cost. This makes our algorithm more accurate and even faster. We call this improved algorithm SSR+DCCR (for Search Space Reduction+DCCR). Through extensive simulations, we confirm that SSR+DCCR performs very well compared to the optimal but very expensive solution. (This technical report revises TR NU-CCS-98-09.)


#*The political role of ethics debate in agricultural biotechnology
#@Les Levidow
#t1995
#cProceedings of the conference on Ethical aspects of modern biotechnology
#index605014


#*Generalized Linear Complementary Problems and the Analysis of Continuously Variable Systems and Discrete Event Systems
#@Bart De Schutter,Bart De Moor
#t1997
#cProceedings of the International Workshop on Hybrid and Real-Time Systems
#index257308


#*Knowledge Societies ...in a Nutshell: Information Technology for Sustainable Development
#@Andreas Crede,Robin Mansell
#t1998
#c
#index231207
#!:The Information Revolution and the accelerating spread of information and communication technologies (ICTs) are at the heart of recent societal transformations around the world. Developing countries in particular are now being encouraged to invest in national ICT infrastructure so that they might experience the expected future social and economic benefits. But at what cost? What are the true risks and benefits of the "new technologies" to the countries of the developing world?From 1995 to 1997, the Working Group on Information Technology and Development of the UN Commission on Science and Technology for Development investigated the claims and counter claims about the risks and benefits of ICTs. This book encapsulates the findings of the Working Group. It argues that although the costs of building ICT infrastructure in the developing world are high, the costs of not doingso are likely to be much higher.This book focuses particularly on the dangers that will accompany a failure to develop ICT strategies tailored to the specific and changing needs of countries in the developing regions of the world.


#*"Formality and Informality in Requirements Engineering"
#@
#t1996
#cProceedings of the 2nd International Conference on Requirements Engineering (ICRE '96)
#index124877


#*Using Reinforcement Learning to Spider the Web Efficiently
#@Jason Rennie,Andrew McCallum
#t1999
#cProceedings of the Sixteenth International Conference on Machine Learning
#index357629


#*Computer-Aided Diagnostic System for Pulmonary Nodules Using Helical CT Images
#@Keizo Kanazawa,Yoshiki Kawata,Noboru Niki,Hitoshi Satoh,Hironobu Ohmatsu,Ryutaro Kakinuma,Masahiro Kaneko,Kenji Eguchi,Noriyuki Moriyama
#t1998
#cProceedings of the First International Conference on Medical Image Computing and Computer-Assisted Intervention
#index255574


#*Invariant Standrad Positions of Ordered Sets of Points
#@Herbert Suesse,Klaus Voss,Irene Rothe
#t1995
#cProceedings of the 6th International Conference on Computer Analysis of Images and Patterns
#index560696


#*New Fast Algorithms for Structured Linear Least Squares Problems
#@Ming Gu
#t1999
#cSIAM Journal on Matrix Analysis and Applications
#index292816
#!We present new fast algorithms for solving the Toeplitz and the Toeplitz-plus-Hankel least squares problems. These algorithms are based on a new fast algorithm for solving the Cauchy-like least squares problem. We perform an error analysis and provide conditions under which these algorithms are numerically stable. We also develop implementation techniques that significantly reduce the execution time. While no previous fast algorithm is known to be numerically stable for very ill conditioned problems, our numerical results indicate that these new algorithms are efficient and numerically stable for problems ranging from well conditioned to very ill conditioned to numerically singular.


#*Shape feature determination usiang the curvature region representation
#@Ratnaker Sonthi,Girish Kunjur,Rajit Gadh
#t1997
#cProceedings of the fourth ACM symposium on Solid modeling and applications
#index85381
#%626097
#%467385
#%181788
#%207402
#%249182


#*Extreme k-families
#@Emanuel Knill
#t1995
#cEuropean Journal of Combinatorics
#index600119


#*Design techniques to reduce substrate noise
#@Tallis Blalack
#t1999
#cAnalog circuit design: volt electronics; mixed-mode systems; low-noise and RF power amplifiers for telecommunication
#index297114


#*Experience in using Electronics Workbench
#@M. H. Rashid
#t1997
#cProceedings of the Frontiers in Education Conference,1997. on 27th Annual Conference. Teaching and Learning in an Era of Change. - Volume 01
#index425098
#!This paper summarizes the usefulness of the circuit simulator Electronics Workbench in analysis and design verifications of electronic circuits. It simulates a real laboratory environment with meters, function generator, oscilloscope, and Bode plotter. It is illustrated through examples. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Planning focus of attention for multifingered hand with consideration of time-varying aspects
#@Shigeyuki Sakane,Toshiji Kuruma,Toru Omata,Tomomasa Sato
#t1995
#cComputer Vision and Image Understanding
#index606379


#*The economic efficiency of Internet public goods
#@Martyne M. Hallgren,Alan K. McAdams
#t1997
#cInternet economics
#index92750


#*Designing communication and learning environments
#@Diane M. Gayeski
#t1995
#c
#index596595


#*Information Systems Modeling with CGs Logic
#@Ryszard Raban
#t1997
#cProceedings of the Fifth International Conference on Conceptual Structures: Fulfilling Peirce's Dream
#index366129


#*Polar lust
#@Joe Fournier
#t1999
#cACM SIGGRAPH 99 Electronic art and animation catalog
#index285839


#*Set constraints in some equational theories
#@Witold Charatonik
#t1998
#cInformation and Computation
#index76323


#*The Virtual Campus: Trends for Higher Education and Training; IFIP Tc3/Wg3.3 and Wg3.6 Joint Working Conference on the Virtual Campus: Trend
#@M. F. Verdejo,G. Davies
#t1999
#c
#index242880


#*Using dynamical systems methods to solve minimization problems
#@Johannes Schropp
#t1995
#cSelected papers of the seventh conference on Numerical treatment of differential equations
#index588555


#*Forward and backward simulations II.: timing-based systems
#@Nancy Lynch,Frits Vaandrager
#t1996
#cInformation and Computation
#index601020


#*Constraint Resolution within Object Hierarchies
#@Hongxue Wang
#t1998
#cSelected papers from the 11th Australian Joint Conference on Artificial Intelligence on Advanced Topics in Artificial Intelligence
#index380866


#*From SIBS to Distributed Objects: A Transformation Approach for Service Creation
#@Elie Najm,Frank Olsen,Sylvie Vignes
#t1999
#cProceedings of the IFIP TC6 WG6.7 Fifth International Conference on Intelligence in Networks
#index272409


#*Yenta: a multi-agent, referral-based matchmaking system
#@Leonard N. Foner
#t1997
#cProceedings of the first international conference on Autonomous agents
#index95572
#%476127
#%209072
#%586599
#%122669


#*Writing Effective E-Mail
#@Nancy Flynn,Tom Flynn
#t1998
#c
#index241678
#!:Finally a book on e-mail that works from page one to simplify and demystify this essential subject. You'll examine whether e-mail is the appropriate communication tool for every message. Then you'll work through the critical steps of creating e-mail that has the right tone, avoiding e-mail pitfalls, and polishing up cybergrammar skills. There are key sections on formatting, as well as managing your e-mail from messages to viruses.


#*Ethical imperatives in decision support systems design
#@Andrew McCosh
#t1996
#cImplementing systems for supporting management decisions: concepts, methods and experiences
#index83700


#*Using Emil Post's machine for an introduction to formal programming (poster)
#@V. Dagdilelis,M. Satratzemi
#t1997
#cThe supplemental proceedings of the conference on Integrating technology into computer science education: working group reports and supplemental proceedings
#index91202


#*Oracles That Compute Values
#@Stephen Fenner,Steven Homer,Mitsunori Ogihara,Alan Selman
#t1997
#cSIAM Journal on Computing
#index91789
#!This paper focuses on complexity classes of partial functions that are computed in polynomial time with oracles in NPMV, the class of all multivalued partial functions that are computable nondeterministically in polynomial time. Concerning deterministic polynomial-time reducibilities, it is shown that a multivalued partial function is polynomial-time computable with k adaptive queries to NPMV if and only if it is polynomial-time computable via 2k-1 nonadaptive queries to NPMV; a characteristic function is polynomial-time computable with k adaptive queries to NPMV if and only if it is polynomial-time computable with k adaptive queries to NP; unless the Boolean hierarchy collapses, for every k, k adaptive (nonadaptive) queries to NPMV are different than k+1 adaptive (nonadaptive) queries to NPMV. Nondeterministic reducibilities, lowness, and the difference hierarchy over NPMV are also studied. The difference hierarchy for partial functions does not collapse unless the Boolean hierarchy collapses, but, surprisingly, the levels of the difference and bounded query hierarchies do not interleave (as is the case for sets) unless the polynomial hierarchy collapses.


#*Non-linear Registration with the Variable Viscosity Fluid Algorithm
#@Hava Lester,Simon R. Arridge,Kalvis M. Jansons,Louis Lemieux,Joseph V. Hajnal,Anjela Oatridge
#t1999
#cProceedings of the 16th International Conference on Information Processing in Medical Imaging
#index367303


#*Two methods for solving linear equations using neural networks
#@M. A. Styblinski,Jill R. Minick
#t1995
#cProceeding of an international workshop on VLSI for neural networks and artificial intelligence
#index588823


#*Museums without walls (panel session): new media for new museums
#@Alonzo C. Addison,Douglas MacLeod,Gerald Margolis,Beit Hashoah,Michael Naimark,Hans-Peter Schwarz
#t1995
#cProceedings of the 22nd annual conference on Computer graphics and interactive techniques
#index604407


#*On the feedback vertex set problem for a planar graph
#@W. Hackbusch
#t1997
#cComputing
#index93873


#*Interstate '82: Official Strategy Guide
#@Steven M. Schafer
#t1998
#c
#index614778
#!:In the sequel to Interstate '76, get multi-vehicle action, indoor and outdoor environments a 3D hardware engine as you learn to drive, car-jack and fight through battlefields riddled with enemies and obstacles. You can learn the strategy to each mission with a complete walk-through and detailed listing of all car types and upgrades with tips on building the best vehicle.


#*Parametricity and local variables
#@P. W. O'Hearn,R. D. Tennent
#t1995
#cJournal of the ACM (JACM)
#index589547
#%165252
#%165361
#%171991
#%200022
#%223935
#%329080
#%368434
#%450876
#%460056
#%472780
#%486260
#%529001
#%533738
#%544115
#%555858
#%585538
#!We propose that the phenomenon of local state may be understood in terms of Strachey's concept of parametric (i.e., uniform) polymorphism. The intuitive basis for our proposal is the following analogy: a non-local procedure is independent of locally-declared variables in the same way that a parametrically polymorphic function is independent of types to which it is instantiated.A connection between parametricity and representational abstraction was first suggested by J.C. Reynolds. Reynolds used logical relations to formalize this connection in languages with type variables and user-defined types. We use relational parametricity to construct a model for an Algol-like language in which interactions between local and non-local entities satisfy certain relational criteria. Reasoning about local variables essentially involved proving properties of polymorphic functions. The new model supports straightforward validations of all the test equivalences that have been proposed in the literature for local-variable semantics, and encompasses standard methods of reasoning about data representations. It is not known whether our techniques yield fully abstract semantics. A model based on partial equivalence relations on the natural numbers is also briefly examined.


#*Smartcards - From Security Tokens to Intelligent Adjuncts
#@Boris Balacheff,Bruno Van Wilder,David Chan
#t1998
#cProceedings of the The International Conference on Smart Card Research and Applications
#index258014


#*Invading wave fronts and their oscillatory wakes are linked by a modulated travelling phase resetting wave
#@Jonathan A. Sherratt
#t1998
#cPhysica D
#index82283


#*MCSD Fast Track: 4-in-1 Bundle
#@Lyle A. Bryant,Thomas Moore,Kent Sharkey,Brian Matsik
#t1999
#c
#index244654
#!:Microsoft has recently revamped its MCSD program. In order to obtain their MCSD, candidates are required to pass four exams-three core exams and one elective exam. All of the core exams are new tests as are many of the electives. Microsoft is putting a huge push behind increasing the number of MCSDs worldwide, and will be putting a significant marketing effort behind the MCSD program. Given the increased importance of the MCSD program to Microsoft's certification strategy, the popularity of the new VB 6 exams, and the increasing interest in the MCSD program, the MCSD arena will be attracting new exam candidates over the next year. In addition to attracting new exam candidates, existing MCSDs will also be updating their certifications to cover the newly released exams. Candidates are in need of complete, concise, inexpensive study guides to fully prepare them to pass the MCSD exams. This book is the answer.


#*Next century challenges: RadioActive networks
#@Vanu Bose,David Wetherall,John Guttag
#t1999
#cProceedings of the 5th annual ACM/IEEE international conference on Mobile computing and networking
#index284379
#%82354
#%86604
#%93978
#%599821


#*A phase transition for the minimum free energy of secondary structures of a random RNA
#@Momiao Xiong,Michael S. Waterman
#t1997
#cAdvances in Applied Mathematics
#index82903


#*WebOQL: restructuring documents, databases, and webs
#@Gustavo O. Arocena,Alberto O. Mendelzon
#t1999
#cTheory and Practice of Object Systems
#index284596


#*Java language reference (2nd ed.)
#@Mark Grand
#t1997
#c
#index87391


#*Learning Microsoft Excel 2000
#@Jennifer Fulton,Nancy Kaczmarczyk
#t1999
#c
#index254103
#!:Discover Excel's better AutoFormatting capabilities, its improved "Sum" function and new interactive charting on the Web. Now use Excel's "drag and drop data" ability usable with any Internet browser.


#*Letter to Peter Cassidy on NSA role in digital telephony proposal
#@Louis A. Baer
#t1997
#cThe electronic privacy papers: documents on the battle for privacy in the age of surveillance
#index89986


#*Trust region algorithm for nonsmooth optimization
#@R. J. B. de Sampaio,Jin-Yun Yuan,Wen-Yu Sun
#t1997
#cApplied Mathematics and Computation
#index75279


#*Octtrees Meet Splines
#@Alvar Vinacua,Isabel Navazo,Pere Brunet
#t1998
#cGeometric Modelling, Dagstuhl, Germany, 1996
#index257500


#*Big Basic Web Site Directory, 1st edition
#@Mark Cierzniak
#t1997
#c
#index245191
#!:The book is a highly visual directory of Web sites. Instead of one-line descriptions of more sites than anyone would ever use, this has readable descriptions and at least one screen shot of every site listed. The sites listed are intended to be the best of the best. Why bother listing dozens of sites in a category like live news for example when there are five sites that cover every live news event that a reader could ever need to see? This visual format of the book gives this book more mass market appeal to new users than does the "telephone book" style directory with 10 s of thousands of tiny listings. The selection of topics and sites is geared toward the mass consumer, not the Internet elite.Includes readable descriptions and at least one screen shot of every site listedServes as a value-packed Web site directory with a highly visual layout and presentationHighlights Web sites that are geared to appeal to the masses of consumers getting on or considering getting on the Internet


#*Characteristic Galerkin Schemes for Scalar Conservation Laws in Two and Three Space Dimensions
#@Peixiong Lin,K. W. Morton,E. Süli
#t1997
#cSIAM Journal on Numerical Analysis
#index79924
#!In this paper we are concerned with a finite element method for multidimensional scalar conservation laws: we describe a general formulation of the Euler characteristic Galerkin (ECG) scheme, motivated by key features of the one-dimensional ECG scheme. The method is defined by projecting the transport collapse operator onto a finite element space spanned by piecewise constant basis functions. The ECG scheme is {\em TVD, monotone, maximum norm nonincreasing and unconditionally stable in the $L^{1}$-norm}. To the best of our knowledge, there is no other method which has all these properties. However, with piecewise constant basis functions, the ECG scheme is at most first-order accurate; greater accuracy can be obtained through a recovery procedure. Unlike conventional dimension-by-dimension methods, multidimensional ECG schemes contain important terms which describe corner effects. Nonuniform meshes and large time steps can be used with this class of schemes.


#*Multimedia virtual circuit model for MPEG on ATM networks
#@Anna Hać,Johnny On
#t1998
#cInternational Journal of Network Management
#index280571
#%116972
#%209355
#%276583
#%599491
#%518619
#%517055
#%542771
#%518607
#%526806
#!A Multimedia Virtual Circuit &lpar;MVC&rpar; model for MPEG &lpar;Motion Picture Experts Group&rpar; transmission demonstrates an efficient method to accommodate the bandwidth requirements of multiple sources. In our simulation we compare the leaky bucket system that requires client to reserve the maximum rate and the proposed MVC system. &copy; 1998 John Wiley Sons, Ltd.


#*Longing
#@Amy Moran
#t1999
#cACM SIGGRAPH 99 Electronic art and animation catalog
#index286608


#*Quicken 6 for Windows 95, NT, and 3.1 (Mastering)
#@Stephen L. Nelson
#t1996
#c
#index625355
#!:Finally: a Quicken book that's organized by financial management task--not software feature. This incredibly user-friendly book offers extensive coverage of the topics that interest you most: setting up a budget, retirement planning, saving for college, and mutual fund and stock investment strategies. It also offers expanded coverage of Quicken's small business management features, ways to get more from Quicken, online banking, and plenty of money-smart tips. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Supporting Parallel Processing on the RHODOS Cluster of Workstations
#@M. Hobbs,A. Goscinski
#t1997
#cProceedings of the 1997 International Symposium on Parallel Architectures, Algorithms and Networks
#index114027
#!With the move towards parallel processing on Clusters of Workstations (COWs) the ability to fully utilize the computational resources of all workstations through the initial placement and movement of workload is desirable by the user of the system, to improve the overall performance. This is a critical task when many users run their parallel pro grams simultaneously. The ability to have an even spread of load over an entire COW can be achieved through the employment of Global Scheduling. This paper introduces the concept of global scheduling exploiting static allocation and dynamic load balancing along with the implementation of such a facility and support services, remote process creation and process migration, respectively, on the RHODOS distributed operating system. The suitability of the RHO DOS implementation is demonstrated by results obtained from initial test runs of a SPMD parallel application.


#*The enabling impact of information technology: the case of the Ohio University MBA
#@John E. Stinson,Richard G. Milter
#t1995
#cThe first international conference on Computer support for collaborative learning
#index582636


#*Windows 95: Exam 70-064, 2nd edition
#@Que Corporation,Dale Holmes,Cory Woodrow
#t1998
#c
#index232718
#!:The MCSE TestPrep series is a unique way of preparing for MCSE exams. Each chapter covers a different exam objective. Each objective is further broken down into manageable sections. The information will be presented in a brief, outline format and will include an abundance of tables, figures, screen shots, and lists. Following each section will be a series of review questions, exercises, and answer explanations. Two complete practice exams and a glossary will be located at the end of the book.Includes only the ESSENTIAL information needed to pass the Windows 95 exam - #70-64 (one of four core exams)PRACTICE, PRACTICE, PRACTICE rather than read pages of text everything written in concise chunksStudy HUNDREDS of sample test questions as well as practice taking the exam with two complete exams at the back of the book


#*Interactive two-handed gesture interface in 3D virtual environments
#@Hiroaki Nishino,Kouichi Utsumiya,Daisuke Kuraoka,Kenji Yoshioka,Kazuyoshi Korida
#t1997
#cProceedings of the ACM symposium on Virtual reality software and technology
#index79731
#%216374
#%522316
#%533830
#%224441
#%306665


#*The TSQL2 Temporal Query Language
#@Richard Thomas Snodgrass
#t1995
#c
#index621412


#*On Uniformization of Affine Dependence Algorithms
#@Weijia Shang,Edin Hodzic,Zhigang Chen
#t1996
#cIEEE Transactions on Computers
#index439748
#%184117
#%212814
#%222089
#%230142
#%519772
#%529972
#!This paper deals with the problem of transforming irregular data dependence structures of algorithms with nested loops into more regular ones. Algorithms under consideration are n-dimensional algorithms (algorithms with n nested loops) with affine dependences where dependences are affine functions of index variables of the loop. Methods are proposed to uniformize affine dependence algorithms, i.e., to transform affine dependence algorithms into uniform dependence algorithms where dependences are independent of the index variables (constant). Objectives are considered to guide the selection of feasible uniformizations. The first one is to reduce the number of dependences after uniformization. The second one is to maximize parallelism preserved by the uniformization. Some parallelism might be lost due to the uniformization. The parallelism preserved by the uniformization is measured by 1) the total execution time by the optimal linear schedule which assigns each computation in the algorithm an execution time according to a linear function of the index of the computation, and 2) the size of the cone spanned by the dependence vectors after uniformization.


#*A Current-Mode Logic for Low-Voltage, High-Speed Mixed-Mode VLSI Circuits
#@İ. ENS Ungan,Murat Aşkar
#t1999
#cAnalog Integrated Circuits and Signal Processing
#index290275
#%596639
#!A wired-AND current-mode logic (WCML) circuit is designed for high performance mixed analog and digital system designs on a common silicon substrate, using standard CMOS process. Current is used for digital information carrier in order to be able to reduce supply voltage, power consumption, digital switching noise and to increase operating frequency. The WCML circuit uses current-steering technique. It is composed of a simple current mirror with a current injector. Wired-AND connections cause the logic circuit to operate as a NAND logic gate which provides to implement any boolean function. High-speed is achieved by varying the injection current level even at low-voltage supply (<1.5 V) with low-power consumption.


#*Promoter 2 Process Modeling Techniques
#@Jean-Claude Derniame
#t1998
#cProceedings of the 6th European Workshop on Software Process Technology
#index370338


#*The object as a paradigm for licensing models of multi-lingual software
#@Gerhard Auinger,Viktor Mayer-Schönberger
#t1995
#cProceedings of the conference on Intellectual property rights and new technologies
#index585202


#*Client Access Token-Ring Connectivity
#@Chris Patterson
#t1996
#c
#index612015
#!:Attaching PCs to AS/400s via a Token-Ring can become complicated. When things go wrong, an understanding of PCs, the Token-Ring, and OS/400 is required. This book brings these three areas together, with all the details you need for successful troubleshooting. The author concentrates only on the information needed for successful communications, so beginners as well as more advanced specialists can understand and support the environment.Beginning with a description of the Token-Ring, the book goes on to describe the important PC files involved with Client Access for OS/400, as well as the main AS/400 screens and messages needed for error recovery. A special chapter is included for resolving Client Access error messages. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*AIgorithms: an integrated algorithm analysis, writing and artificial intelligence course
#@James H. Martin,Karl Winklmann
#t1995
#cACM SIGART Bulletin
#index587907
#%453387
#!This article describes an undergraduate course that combines the teaching of algorithms, artificial intelligence and technical writing. The primary goal of this course is to achieve a better integration of AI concepts and techniques into our undergraduate CS program. This integration is achieved through an alignment of material from existing AI and Algorithms classes.


#*Solution of the Multisource Weber and Conditional Weberproblems by D.-C. Programming
#@Pey-Chun Chen,Pierre Hansen,Brigitte Jaumard,Hoang Tuy
#t1998
#cOperations Research
#index572355
#!D.-c. programming is a recent technique of global optimization that allows the solution of problems whose objective function and constraints can be expressed as differences of convex (i.e., d.-c.) functions. Many such problems arise in continuous location theory. The problem first considered is to locate a known number of source facilities to minimize the sum of weighted Euclidean distances between a user's fixed location and the source facility closest to the location of each user. We also apply d.-c. programming to the solution of the conditional Weber problem, an extension of the multisource Weber Problem, in which some facilities are assumed to be already established. In addition, we consider a generalization of Weber's problem, the facility location problem with limited distances, where the effective service distance becomes a constant when the actual distance attains a given value. Computational results are reported for problems with up to 10,000 users and two new facilities, 50 users and three new facilities, 1,000 users, 20 existing facilities and one new facility or 200 users, 10 existing and two new facilities.


#*Value of search results as a whole as the best single measure of information retrieval performance
#@Louise T. Su
#t1998
#cInformation Processing and Management: an International Journal
#index288956


#*Military keynote address and panel discussion: military simulation and modeling&mdash;today&mdash;tomorrow
#@Joseph J. Redden
#t1995
#cProceedings of the 27th conference on Winter simulation
#index585751


#*Using multicast communications to distribute code and data in wide area networks
#@Jon Knight,Steve Guest
#t1995
#cSoftware&mdash;Practice Experience
#index598437


#*Nonlinear equation in (2+1) dimensions for a plasma with negative ions
#@K. Roy Chowdhury,A. Roy Chowdhury
#t1996
#cAustralian Journal of Physics
#index94721


#*Fatal error number 27
#@Robert W. Lucky
#t1997
#cIEEE Spectrum
#index75749


#*On the Performance of the DVB-T System in Mobile Environments
#@R. Burow,K. Fazel,P. Hoeher,O. Klank,H. Kussmann,Peter Pogrzeba,P. Robertson,M. J. Ruf
#t1998
#cProceedings of the Third European Conference on Multimedia Applications, Services and Techniques
#index260645


#*Creating Cool Web Sites with Microsoft FrontPage
#@Paul Summitt
#t1996
#c
#index619237
#!:A


#*PlayStation Game Secrets Volume 7: Prima's Unauthorized Strategy Guide
#@Steve Faragher,Dean Evans,Neil Worley
#t1999
#c
#index235706


#*Multiple-Valued Logic Minimization by Genetic Algorithms
#@Yutaka Hata,Kiyoshi Hayase,Takahiro Hozumi,Naotake Kamiura,Kazuharu Yamato
#t1997
#cProceedings of the 27th International Symposium on Multiple-Valued Logic
#index119043
#!This paper describes an approach to minimize multiple-valued logic expressions by genetic algorithms. We encode a multiple-valued logic expression as a "chromosome" whose length allows to change and corresponds to the number of implicants of the expression. Our fitness function evaluates the following three items:1.How may outputs does the logic expression represent correctly?2. How many implicants the logic expression requires?3. How many connections does the logic expression requires?Our method employ the fitness function and minimize sum-of-products expressions, where sum refers TSUM or MAX and product refers to MIN of set literals or window literals. The simulation results show that our method derive good results for some arithmetic functions and intend to avoid the local minimal solution, compared to neural-computing-based method.Keywords, multiple-Valued logic, Genetic Algorithms, minimization


#*Proposals of MIDI Coding and its Application for Audio Authoring
#@T. Modegi,S.-I. Iisaku
#t1998
#cProceedings of the IEEE International Conference on Multimedia Computing and Systems
#index117480


#*Integrated performance measurement systems: Implementation case studies
#@U. S. Bititci,A. S. Carrie,T. Turner,S. Lutz
#t1998
#cProceedings of the International Conference of the Manufacturing Value-Chain on Strategic Management of the Manufacturing Value Chain
#index258787


#*A comprehensive mathematical model for a multispecies flow through ground coffee
#@A. Fasano,F. Talamucci
#t1999
#cSIAM Journal on Mathematical Analysis
#index289918


#*Using Typography in Document Image Analysis
#@Frédéric Bapst,Rolf Ingold
#t1998
#cProceedings of the 7th International Conference on Electronic Publishing, Held Jointly with the 4th International Conference on Raster Imaging and Digital Typography: Electronic Publishing, Artistic Imaging, and Digital Typography
#index273242


#*Authentication schema defying known crackers' techniques
#@Pascal Jean Abadie
#t1997
#c
#index92742


#*Program transformation in calculational form
#@Akihiko Takano,Zhenjiang Hu,Masato Takeichi
#t1998
#cACM Computing Surveys (CSUR)
#index82729
#%525769
#%171752
#%208652
#%594057
#%95123
#%451071
#%583364
#%467380
#%96737
#%361160
#%583221


#*Selective error protection of ITU-T G.729 codec for digital cellular channels
#@K. Swaminathan,M. Austin
#t1996
#cProceedings of the Acoustics, Speech, and Signal Processing, 1996. on Conference Proceedings., 1996 IEEE International Conference - Volume 01
#index432774
#!The recently adopted ITU-T G.729 8 kbps codec standard's performance is evaluated for digital cellular channels that are characterized by Rayleigh fading. Two forward error correction schemes (FEC) are studied. They are the convolutional code based FEC and the Nordstrom Robinson based FEC. The effects of interleaving depth are investigated for both FEC schemes. Both flat fading as well as co-channel interference limited models are used in our study.


#*Aspects of Functional Programming
#@Gary Meehan
#t1999
#c
#index199602
#!This thesis explores the application of functional programming in new areas and its implementation using new technologies. We show how functional languages can be used to implement solutions to problems in fuzzy logic using a number of languages: Haskell, Ginger and Aladin. A compiler for the weakly-typed, lazy language Ginger is developed using Java byte-code as its target code. This is used as the inspiration for an implementation of Aladin, a simple functional language which has two novel features: its primitives are designed to be written in any language, and evaluation is controlled by declaring the strictness of all functions. Efficient denotational and operational semantics are given for this machine and an implementation is developed using these semantics. We then show that by using the advantages of Aladin (simplicity and strictness control) we can employ partial evaluation to achieve considerable speed-ups in the running times of Aladin programs.


#*A Method for Analyzing Combinatorial Properties of Static Connecting Topologies
#@Guennadi Vesselovski,Marina Kupriyanova
#t1995
#cProceedings of the 3rd International Conference on Parallel Computing Technologies
#index384351


#*A cooperative packet recovery protocol for multicast video
#@N. F. Maxemchuk,K. Padmanabhan,S. Lo
#t1997
#cProceedings of the 1997 International Conference on Network Protocols (ICNP '97)
#index117851
#!In this paper we describe a protocol that improves the quality of multicast video or audio transmissions by recovering lost packets. The protocol is applied to a corporate intranet, and measurements indicate that significant improvements in audio/video quality are achieved. A unique characteristic of this protocol is that it can be used on current MBone sessions without changing the operation of the source or receivers. The improvement in quality can be restricted to a subset of the receivers, so that a service provider, that does not necessarily generate content, can use the protocol to improve reception for its own customers. A second unique characteristic is that only a small fraction of the receivers that obtain the benefits of the protocol are active participants. As a result the problems associated with large multicast groups, such as the number of control messages, is reduced. Finally, because of the differences between data and voice or video communications, many of the network parameters that vary between or during connections are changed rather than predicted. This is a much simpler operation.


#*Importance sampling for Markov chains: computing variance and determining optimal measures
#@Indira Kuruganti,Stephen G. Strickland
#t1996
#cProceedings of the 28th conference on Winter simulation
#index88347
#%86763
#%165131
#%158345
#%468306
#%586235
#!In this paper we describe several computational algorithms useful in studying importance sampling (IS) for Markov chains. Our algorithms compute optimal IS measures and evaluate the estimate variance for a given measure. As knowledge of the optimal IS measure implies knowledge of the quantity to be estimated, our algorithms produce this quantity as a by-product. Since effective IS measures must often closely approximate the optimal measure, the use of these algorithms for small problems may produce in sights that lead to effective measures for larger problems of actual interest. We consider two classes of problems: hitting times and fixed-horizon costs.


#*On the influence matrix used in the spectral solution of the 2D Stokes problem (vorticity-stream function formulation)
#@R. Bwemba,R. Pasquetti
#t1995
#cApplied Numerical Mathematics
#index593444


#*Using the heartbeat failure detector for quiescent reliable communication and consensus in partitionable networks
#@Marcos Kawazoe Aguilera,Wei Chen,Sam Toueg
#t1999
#cTheoretical Computer Science
#index290001


#*International Symposium on Computational Intelligence in Robotics and Automation Proceedings
#@IEEE Computer Society
#t1999
#c
#index231379


#*Evaluating animations as student aids in learning computer algorithms
#@Michael D. Byrne,Richard Catrambone,John T. Stasko
#t1999
#cComputers Education
#index285072


#*Hierarchical multifeature integration for automatic object recognition in forward looking infrared images
#@Shishir Shah,J. K. Aggarwal
#t1999
#cProceedings of the 12th international conference on Industrial and engineering applications of artificial intelligence and expert systems: multiple approaches to intelligent systems
#index297147


#*Generalized factors of words
#@Lucian Ilie
#t1998
#cFundamenta Informaticae
#index81742


#*Pattern systems
#@Victor Mitrana,Gheorghe Păun,Grzegorz Rozenberg,Arto Salomaa
#t1996
#cTheoretical Computer Science
#index594355


#*SAS ODBC Driver Technical Report: User's Guide and Programmer's Reference, Release 6. 11
#@CORPORATE SAS Institute Staff
#t1999
#c
#index612285


#*Comparing Arguments Using Preference Orderings for Argument-Based Reasoning
#@Leila Amgoud,Claudette Cayrol,Daniel Le Berre,I. R. I. T. UniversitePaul Sabatier
#t1996
#cProceedings of the 8th International Conference on Tools with Artificial Intelligence
#index111850
#!Argument-based reasoning is a promising approach to handle inconsistent belief bases. The basic idea is to justify each plausible conclusion by acceptable arguments. The purpose of this paper is to enforce the concept of acceptability by the integration of preference orderings. Pursuing previous work on preference-based argumentation, we focus here on the definition of preference relations for comparing conflicting arguments. We present a comparative study of several proposals. Then, we propose techniques for computing and comparing arguments, taking advantage of an Assumption-Based Truth Maintenance System.


#*Telekommunikation
#@Gerhard Krüger
#t1995
#cInnovative Konzepte f&uuml;r die Ausbildung, 7. GI-Fachtagung Informatik und Schule
#index262570


#*A new content-based access method for video databases
#@P. J. Cheng,W. P. Yang
#t1999
#cInformation Sciences: an International Journal
#index299745


#*Chat circles
#@Fernanda B. Viégas,Judith S. Donath
#t1999
#cProceedings of the SIGCHI conference on Human factors in computing systems: the CHI is the limit
#index288393
#%612146
#!Although current online chat environments provide new opportunities for communication, they are quite constrained in their ability to convey many important pieces of social information, ranging from the number of participants in a conversation to the subtle nuances of expression that enrich face to face speech. In this paper we present Chat Circles, an abstract graphical interface for synchronous conversa-tion. Here, presence and activity are made manifest by changes in color and form, proximity-based filtering intuitively breaks large groups into conversational clusters, and the archives of a conversation are made visible through an integrated history interface. Our goal in this work is to create a richer environment for online discussions.


#*Guidance for Requirements Engineering Processes
#@Samira Si-Said,Colette Rolland
#t1997
#cProceedings of the 8th International Conference on Database and Expert Systems Applications
#index565755


#*On GMW Designs and Cyclic Hadamard Designs
#@Wen--Ai Jackson,Peter R. Wild
#t1997
#cDesigns, Codes and Cryptography
#index89354
#!We generalise results of Jackson concerning cyclic Hadamard designs admitting SL(2,2)^n as a point transitive automorphism group. The generalisation concerns the designs of Gordon, Mills and Welch and we characterise these as designs admitting GM(m,q)^n acting in a certain way. We also generalise a construction given by Maschietti, using hyperovals, of cyclic Hadamard designs, and characterise these amongst the designs of Gordon, Mills and Welch.


#*Protocols for achieving consistency and reliability in replicated database systems that utilize asynchronous updates
#@Parvathi Chundi
#t1996
#c
#index189382


#*New principles for engineering ethics
#@Edwards Wenk, Jr.
#t1995
#cComputerization and controversy (2nd ed.): value conflicts and social choices
#index592460


#*A robust adaptive strategy for the nonlinear Poisson equation
#@W. Dörfler
#t1995
#cComputing
#index588929


#*The application of fuzzy logic in automatic modelling of electromechanical systems
#@P. J. Costa Branco,J. A. Dente
#t1998
#cFuzzy Sets and Systems
#index78957


#*A Demonstration IC for the P1149.4 Mixed-Signal Test Standard
#@Keith Lofstrom
#t1996
#cProceedings of the IEEE International Test Conference on Test and Design Validity
#index557850


#*Cat-a-Cone: an interactive interface for specifying searches and viewing retrieval results using a large category hierarchy
#@Marti A. Hearst,Chandu Karadi
#t1997
#cProceedings of the 20th annual international ACM SIGIR conference on Research and development in information retrieval
#index76366
#%211740
#%77442
#%227313
#%81430
#%543420
#%290652
#%464297
#%529239
#%455526
#%543593
#%615647
#%587207
#%530946
#%96590
#%542611
#%511694
#%220943
#%219981
#%451075
#%566972
#%206618
#%467273


#*An intelligent decision support system for new product development
#@Ronald Eugene Thomas
#t1995
#c
#index199044


#*Microsoft Excel 97: Visual Basic Step by Step, 1st edition
#@Reed Jacobson
#t1997
#c
#index627047
#!:With this book and Microsoft Excel 97, you'll learn to use Visual Basic for Applications to build a Microsoft Excel application with Visual Basic for Applications, create custom worksheet functions, extend the power of ranges and formulas, use Visual Basic tools, customize menus and toolbars, automate routine tasks, create presentation tools, and customize recorded macros.


#*A new multicasting-based architecture for Internet host mobility
#@Jayanth Mysore,Vaduvur Bharghavan
#t1997
#cProceedings of the 3rd annual ACM/IEEE international conference on Mobile computing and networking
#index80623
#%598229
#%331101
#%485827
#%512926
#%606235
#%586852
#%534204


#*Usability at Eastman Kodak Company: a study in group collaboration
#@Elizabeth Rosenzweig,Cay Lodine
#t1995
#cConference companion on Human factors in computing systems
#index584523


#*Complex Aggregation at Multiple Granularities
#@Kenneth A. Ross,Divesh Srivastava,Damianos Chatziantoniou
#t1998
#cProceedings of the 6th International Conference on Extending Database Technology: Advances in Database Technology
#index363381


#*Wafer level systems: theory and applications
#@David Clifford Blight
#t1996
#c
#index78039


#*SIMPROCESS III: object-oriented business process simulation
#@Jeffry Jones
#t1995
#cProceedings of the 27th conference on Winter simulation
#index598372
#!SIMPROCESS III combines the principles of business process re-engineering, the power of simulation, and the clarity of animated graphics to help understand and predict the consequences of proposed changes to business systems. SIMPROCESS III is designed to answer questions quickly-with no programming. You pose a question, graphically configure a model, run the simulation, and reach conclusions. You then run the model with proposed changes to close in on the system configuration that best suits your needs. This paper describes who should use SIMPROCESS III, the types of systems SIMPROCESS III can model, and how a model is constructed.


#*A Parallel Algorithm for the Optimal Power Flows Problem
#@Domenico Conforti,Lucio Grandinetti,C. Triki
#t1996
#cProceedings of the International Conference and Exhibition on High-Performance Computing and Networking
#index355573


#*Dawn of the Internet Appliance
#@George Lawton
#t1997
#cComputer
#index439265


#*Unrestricted and finite model reasoning in class-based representation formalisms
#@Diego Calvanese
#t1996
#cAI Communications
#index95628


#*Directed safe zones and the dual extent algorithms for efficient grid traversal during ray tracing
#@Sudhanshu K. Semwal,Hakan Kvanstrom
#t1997
#cProceedings of the conference on Graphics interface '97
#index95960


#*Effective utilization of hypercubes in the presence of faults
#@Guanghua Lin,Nian-Feng Tzeng
#t1996
#cJournal of Parallel and Distributed Computing
#index596611


#*Critics for Knowledge-Based Design Systems
#@Huan Liu,Chris D. Rowles,Wilson X. Wen
#t1995
#cIEEE Transactions on Knowledge and Data Engineering
#index445704
#%163738
#%439988
#%520403
#%480014
#%454539
#%530173
#%527357
#!Expert critics have been built to critique human performance in various areas such as engineering design, decision making, etc. We suggest that critics can also be useful in the building and use of knowledge-based design systems (KBDSs).Knowledge engineers elicit knowledge from domain experts and build a knowledge-based design system. The system generates designs. The amount of knowledge the system possesses and the way it applies the knowledge directly influence the performance of its designs. Therefore, critics are proposed to assist 1) acquiring sufficient knowledge for constructing a desirable system, and 2) applying proper knowledge to generating designs. Methodologies of equipping a KBDS with critics are developed. Our practice in building and using a KBDS shows the applicability and capability of these critics.


#*A Temporal Agent Communication Language for Dynamic Multi-agent Systems
#@Thibault Carron,Hubert Proton,Olivier Boissier
#t1999
#cProceedings of the 9th European Workshop on Modelling Autonomous Agents in a Multi-Agent World: MultiAgent System Engineering
#index269789


#*A probabilistic performance metric for real-time system design
#@Tao Zhou,Xiaobo (Sharon) Hu,Edwin H.-M. Sha
#t1999
#cProceedings of the seventh international workshop on Hardware/software codesign
#index281770
#%75789
#%181929
#%473918


#*WIN32 API Programming with Visual Basic with CD-ROM, 1st edition
#@Steven Roman
#t1999
#c
#index251244
#!:The Win32 API, or Application Programming Interface, is of immense use in extending the power of Visual Basic. The Win32 API is the collection of functions and subroutines that provides programmatic access to the features of the operating system. It allows Visual Basic programmers far greater access to the inner workings of the Windows operating system without having to suffer through the steep learning curve associated with Visual C++ style Windows programming. The book is designed for users with an intermediate-level (or higher) knowledge of Visual Basic version 4 or later and a desire to stretch VB into the realm of Windows system programming. Users do not need any background in Visual C++, nor do they need any previous experience programming the Win32 API. This book teaches users how to do relatively simple tasks, such as adding tab stops to a list box and gathering system information (i.e., which version of Windows is running on a system and the number of buttons on the user's mouse). It also teaches users about several advanced programming techniques such as synchronizing two VB applications so they can work in cooperation with each other and how to extract data from controls that belong to another application. Win32 API Programming with Visual Basic also spends a good deal of time describing the basic operations of the Windows NT and Windows 95/98 operating systems. Microsoft's documentation seldom takes into account what the reader knows or does not know. Hence, a solid grounding in the basics of the Windows operating systems will help VB programmers to better understand Microsoft's documentation. This book helps VB programmers eliminate the trial and error process that is usually associated with calling the Win32 API from Visual Basic and does so in a practical, straightforward fashion that is the hallmark of author Steve Roman's style.


#*Increasing the Computational Potential of the World Wide Web
#@S. D. Reilly,J. L. Pfaltz,J. C. French
#t1996
#c
#index187598
#!For many World Wide Web applications there is a need to provide session semantics so that users have the impression of a continuous interaction. This is true, for example, when one searches a database interactively. Because WWW servers are stateless some extra mechanism is necessary to give the impression of session semantics. This report discusses a strategy for implementing session semantics over a WWW application. Apart from the need to maintain state during interactive sessions, there is also the need to control the application. Under any circumstances this is a tedious activity. This report also discusses a mechanism for modeling a WWW application as a finite state automaton and describes a tool, the Stateful Server Application Tool (SSAT), built to assist in the development of these applications.


#*A novel analog fuzzy controller for intelligent sensors
#@Liliane Peters,Shuwei Guo,Raul Camposano
#t1995
#cFuzzy Sets and Systems
#index593971


#*On the Power of Aggregation in Relational Query Languages
#@Leonid Libkin,Limsoon Wong
#t1997
#cProceedings of the 6th International Workshop on Database Programming Languages
#index569253


#*Variable dimension quantization in the transform domain
#@D. L. Tull,R. J. Safranek
#t1995
#cProceedings of the 1995 International Conference on Image Processing (Vol. 1)-Volume 1 - Volume 1
#index548618
#!Quantization is a critical procedure in lossy image compression. Linear (uniform) quantizers are used in most of the present image (sequence) compression standards for their simplicity and flexibility. Unfortunately, the resulting representation is often inefficient, preventing potentially significant gains in image compression. We introduce a new class of linear, low complexity, variable dimension quantizers (VDQ) that efficiently reduces the redundancy of the data stream while retaining the design flexibility and signal-to-noise performance of a linear quantizer. When applied to frequency domain representations in the JPEG image compression standard, this approach resulted in SNR improvements of almost 9 dB over the baseline quantizer at comparable bit rates. The algorithm presented is near optimal and runs in O(N) time, making it suitable for real time applications. Its low complexity and effectiveness make VDQ a promising alternative to conventional quantization for image codecs.


#*Commitments Among Autonomous Agents in Information-Rich Environments
#@Munindar P. Singh
#t1997
#cProceedings of the 8th European Workshop on Modelling Autonomous Agents in a Multi-Agent World: Multi-Agent Rationality
#index255940


#*Borden Inc. downsizes with PowerHouse
#@Linda L. Briggs
#t1995
#cData Based Advisor
#index588010


#*Cisco Router Ospf: Design and Implementaton Guide
#@William Parkhurst
#t1998
#c
#index610560
#!:Be prepared for the CCIE exam - or hone your Cisco expertise - with this best-of-class guide to network design and implementation for the OSPF (Open Shortest Path First) protocol. Both comprehensive and practical, Cisco Router OSPF doesn't leave you guessing. It picks up where Cisco documentation leaves off and explains everything from the underlying mechanisms of network data transmission to configuration issues and OSPF troubleshooting.


#*A system for multithreaded parallel simulation and computation with migrant threads and objects
#@Edward Mascarenhas
#t1996
#c
#index203848


#*An Adaptive Transport Protocol for Multimedia Communication
#@Dane Dwyer,Sungwon Ha,Jia-Ru Li,Vaduvur Bharghavan
#t1998
#cProceedings of the IEEE International Conference on Multimedia Computing and Systems
#index123709
#!In this paper, we propose a novel approach for effectively supporting multimedia packet flows in an Internet environment. The following are the key contributions of this paper: (a) we propose a new transport protocol called HPF that supports multiple interleaved reliable and unreliable data sub-streams, (b) we decouple the congestion control and reliability mechanisms that are integrated in TCP -- this allows us to provide congestion control for unreliable streams as well as reliable streams, and (c) we use priorities within sub-streams of a packet flow as application-defined hints for the link level scheduler to drop packets during congestion.We show through performance measurements in our experimental testbed that our approach can provide effective support for heterogeneous packet flows in the presence of dynamic networking resources.


#*Scheduling interval ordered tasks in parallel
#@Sivaprakasam Sunder,Xin He
#t1998
#cJournal of Algorithms
#index96342


#*Optimal sequencing of inspection of dependent characteristics
#@S. O. Duffuua,S. M. Pollock
#t1999
#cJournal of Optimization Theory and Applications
#index290112


#*WaveTool: an integrated software for wavelet and multirate signal processing
#@H. Singh,P. N. Heller
#t1995
#cProceedings of the 1995 International Conference on Image Processing (Vol. 1)-Volume 1 - Volume 1
#index549760
#!Wavelets and multi-rate filter banks are increasingly important tools for various digital image processing (DIP) and image analysis tasks in addition to their traditional applications in one dimensional signal processing. WaveTool, is an integrated software environment for rapid prototyping of wavelet-based algorithms. It is particularly attractive for signal processing because of its rich collection of filter bank choices, online multi-rate filter design, and interactive tree building. This paper presents a general overview of WaveTool with emphasis on its image processing capabilities. Example applications to texture classification, seismic data compression, and image restoration are presented, and the future direction of WaveTool is discussed.


#*Necessary and sufficient conditions for the existence of a G-type Lyapunov function
#@Kaiqi Xiong
#t1995
#cAutomatica (Journal of IFAC)
#index582722


#*A New Degeneracy Method and Steepest-Edge--Based Conditioning for LP
#@Roger Fletcher
#t1998
#cSIAM Journal on Optimization
#index251418
#!A new recursive method for resolving degeneracy in simplex-like methods for linear programming (LP) is described. The method provides a guarantee of termination, even in the presence of round-off errors, and is readily implemented. In contrast to a previous method of the author, this method works throughout in the primal space. One consequence is that the steepest-edge criterion can be used on all iterations and at all levels of recursion.It is also shown that the associated steepest-edge coefficients provide information from which the expected condition of the current LP basis can be calculated cheaply. This provides a more accurate indication of the actual condition of a system than is obtained from norm-based condition numbers. This idea also enables the condition of null space matrices to be estimated.


#*An Online Algorithm for Dimension-Bound Analysis
#@Paul A. S. Ward
#t1999
#cProceedings of the 5th International Euro-Par Conference on Parallel Processing
#index266964


#*Inexact SQP Interior Point Methods and Large Scale Optimal Control Problems
#@F. Leibfritz,E. W. Sachs
#t1999
#cSIAM Journal on Control and Optimization
#index291501
#!Optimal control problems with partial differential equations lead to large scale nonlinear optimization problems with constraints. An efficient solver which takes into account the structure and also the size of the problem is an inexact sequential quadratic programming method where the quadratic problems are solved iteratively. Based on a reformulation as a mixed nonlinear complementarity problem we give a measure of when to terminate the iterative quadratic program solver. For the latter we use an interior point algorithm. Under standard assumptions, local linear, superlinear, and quadratic convergence can be proved. The numerical application is an optimal control problem from nonlinear heat conduction.


#*On orderings of higher level
#@E. Becker,R. Berr
#t1997
#cSelected surveys presented at two conferences on Advances in algebra and model theory
#index292721


#*Computational algorithm for an M-stage open tandem queue with blocking and feedback operation
#@Yong Deok Noh
#t1997
#cComputers and Industrial Engineering
#index91023


#*Filling gaps in the boundary of a polyhedron
#@Gill Barequet,Micha Sharir
#t1995
#cComputer Aided Geometric Design
#index591318


#*Optimal solution approximation for infinite positive-definite quadratic programming
#@P. Benson,R. L. Smith,I. E. Schochetman,J. C. Bean
#t1995
#cJournal of Optimization Theory and Applications
#index599948


#*Identification of highly accurate low order state space models in the frequency domain
#@Robert N. Jacques,Ketao Liu,David W. Miller
#t1996
#cSignal Processing
#index593262


#*Logical interpretation of discrete Choquet integral defined by general measure
#@Dragan Radojević
#t1999
#cInternational Journal of Uncertainty, Fuzziness and Knowledge-Based Systems
#index313682


#*Analysis of (iso)surface reconstructions: quantitative metrics and methods
#@Tracey Allen Beauchat
#t1996
#c
#index205847


#*Pattern generation for a deterministic BIST scheme
#@Sybille Hellebrand,Birgit Reeb,Steffen Tarnick,Hans-Joachim Wunderlich
#t1995
#cProceedings of the 1995 IEEE/ACM international conference on Computer-aided design
#index596551
#%173711
#%553252
#%595385
#!Recently a deterministic built-in self-test scheme has been presented based on reseeding of multiple-polynomial linear feedback shift registers. This scheme encodes deterministic test sets at distinctly lower costs than previously known approaches. In this paper it is shown how this scheme can be supported during test pattern generation. The presented ATPG algorithm generates test sets which can be encoded very efficiently. Experiments show that the area required for synthesizing a BIST scheme that encodes these patterns is significantly less than the area needed for storing a compact test set. Furthermore, it is demonstrated that the proposed approach of combining ATPG and BIST synthesis leads to a considerably reduced hardware overhead compared to encoding a conventionally generated test set.


#*Environmental information systems based on physical flows
#@A. J. D. Lambert,M. H. Jansen,R. V. Schuwer,M. A. M. Splinter
#t1997
#c
#index88423


#*An Engine for Cursive Handwriting Interpretation
#@Gaofeng Qian
#t1999
#cProceedings of the 11th IEEE International Conference on Tools with Artificial Intelligence
#index111645
#!This paper describes an interpretation system for on-line cursive handwriting that requires very little initial training and that rapidly learns, and thus adapts to, the handwriting style of a user. Key features are a shape analysis algorithm that efficiently determines shapes in the handwritten word, a linear segmentation algorithm that optimally matches characters identified in the handwritten word to characters of candidate words, and a learning algorithm that adds, adjusts, or replaces character templates to adapt to the user writing style. In tests, the system was trained on four samples of each character of the alphabet. These samples were written in isolation by one writer. Using a lexicon with 10,000 words, the system achieved for four additional writers an average recognition rate of 81.3% for top choice and 91.7% for the top three choices. The average response time of the system was 1.2 seconds per handwritten word on a SUN SPARC 10 (42 mips).


#*COATIS, an NLP System to Locate Expressions of Actions Connected by Causality Links
#@Daniela Garcia
#t1997
#cProceedings of the 10th European Workshop on Knowledge Acquisition, Modeling and Management
#index372039


#*Three examples of S-integral points of elliptic curves over Q
#@Horst G. Zimmer
#t1997
#cACM SIGSAM Bulletin
#index85120


#*Book Review: The Object Primer
#@Suzette Person
#t1996
#cACM SIGSOFT Software Engineering Notes
#index247596


#*On the number of cyclic projective planes
#@John Konvalina
#t1998
#cAdvances in Applied Mathematics
#index96377


#*Guest Editor's Introduction: Reengineering Digital Systems
#@Vijay K. Madisetti
#t1999
#cIEEE Design Test
#index439761


#*Reconfigurable Computing in Remote and Harsh Environments
#@Gordon J. Brebner,Neil W. Bergmann
#t1999
#cProceedings of the 9th International Workshop on Field-Programmable Logic and Applications
#index560452


#*Functional conversion of signals in the study of relaxation phenomena
#@Vairis Shtrauss
#t1995
#cSignal Processing
#index604667


#*Mastering Mri: Central Nervous System and Musculoskeletal System/Cd-Rom for MacIntosh (Mastering MRI)
#@John V. Crues,William G. Bradley, Jr.
#t1996
#c
#index2150


#*Software Tools for High-Performance Computiing: Survey and Recommendations
#@Bill Appelbe,Donna Bergmark
#t1996
#cScientific Programming
#index395896
#%222795
#%539796
#!Applications programming for high-performance computing is notoriously difficult. Al-though parallel programming is intrinsically complex, the principal reason why high-performance computing is difficult is the lack of effective software tools. We believe that the lack of tools in turn is largely due to market forces rather than our inability to design and build such tools. Unfortunately, the poor availability and utilization of parallel tools hurt the entire supercomputing industry and the U.S. high performance computing initiative which is focused on applications. A disproportionate amount of resources is being spent on faster hardware and architectures, while tools are being neglected. This article introduces a taxonomy of tools, analyzes the major factors that contribute to this situation, and suggests ways that the imbalance could be redressed and the likely evolution of tools.


#*Efficient algorithms and data structures for geometric intersection problems
#@Ravi Janardan
#t1995
#c
#index198725


#*General Loss Bounds for Universal Sequence Prediction
#@Marcus Hutter
#t2001
#cProceedings of the Eighteenth International Conference on Machine Learning
#index374438


#*Benchmarking Least Squares Support Vector Machine Classifiers
#@Tony Van Gestel,Johan A. K. Suykens,Bart Baesens,Stijn Viaene,Jan Vanthienen,Guido Dedene,Bart De Moor,Joos Vandewalle
#t2004
#cMachine Learning
#index308123
#%214951
#%286105
#%294425
#%531284
#%620759
#%510766
#%357509
#%590645
#%311413
#%378021
#%514342
#%317917
#%382482
#%321018
#%586607
#!In Support Vector Machines (SVMs), the solution of the classification problem is characterized by a (convex) quadratic programming (QP) problem. In a modified version of SVMs, called Least Squares SVM classifiers (LS-SVMs), a least squares cost function is proposed so as to obtain a linear set of equations in the dual space. While the SVM classifier has a large margin interpretation, the LS-SVM formulation is related in this paper to a ridge regression approach for classification with binary targets and to Fisher's linear discriminant analysis in the feature space. Multiclass categorization problems are represented by a set of binary classifiers using different output coding schemes. While regularization is used to control the effective number of parameters of the LS-SVM classifier, the sparseness property of SVMs is lost due to the choice of the 2-norm. Sparseness can be imposed in a second stage by gradually pruning the support value spectrum and optimizing the hyperparameters during the sparse approximation procedure. In this paper, twenty public domain benchmark datasets are used to evaluate the test set performance of LS-SVM classifiers with linear, polynomial and radial basis function (RBF) kernels. Both the SVM and LS-SVM classifier with RBF kernel in combination with standard cross-validation procedures for hyperparameter selection achieve comparable test set performances. These SVM and LS-SVM performances are consistently very good when compared to a variety of methods described in the literature including decision tree based algorithms, statistical algorithms and instance based learning methods. We show on ten UCI datasets that the LS-SVM sparse approximation procedure can be successfully applied.


#*Armada: a parallel I/O framework for computational grids
#@Ron Oldfield,David Kotz
#t2002
#cFuture Generation Computer Systems
#index246342


#*Applying JAVA-triggers for X-link management in the industrial framework
#@Abraham Alvarez,Y. Amghar
#t2003
#cEffective databases for text & document management
#index309745
#%78302
#%181837
#%209776
#%210125
#%215941
#%257564
#%283756
#%599634
#%326444
#%533036
#%586277
#%356192
#%460969
#%594341
#%324628
#%625236
#%516429
#%587791
#!This chapter focuses on referential link integrity problems. In the industrial context, the life cycle of a document plays a central role in describing the "steps out" of a product. Users realize some manipulations like creation, edition, suppression and querying under a multi-user environment, risking possible destruction or the alteration of the document's integrity. A classical impact is the infamous "Error 404: file not found." However, the user needs a notification alert mechanism to prevent and warrant the coherence of manipulations over all the life cycle processes of a product. The main objective of this chapter is to provide a generic relationship validation mechanism to remedy this shortcoming. We believe in the combination of some standard features of XML, specifically XLL specification as a support for integrity management and Java-Triggers approach as an alert method. This study, compared with actual approaches, proposes a solution based on active functionalities.


#*Design of computer workstations
#@Michael J. Smith,Pascale Carayon,William J. Cohen
#t2002
#cThe human-computer interaction handbook: fundamentals, evolving technologies and emerging applications
#index568250
#%521625


#*Professional PhotoShop 6.0: The Classic Guide to Color Correction with Cdrom
#@Dan Margulis
#t2000
#c
#index610546
#!:An electronic prepress master reveals how to get the most out of PhotoshopRenowned among graphic design professionals for his technical grounding and ability to clearly explain difficult principles and techniques, Dan Margulis has updated his bestselling book, Professional Photoshop 5, to help readers quickly master Photoshop 6 and learn how to take full advantage of its latest tools and capabilities. Rather than focusing on program features, Dan Margulis builds on a solid foundation of classic design concepts and skills. This new edition has been substantially expanded to include coverage of issues surrounding image handling for devices other than offset printers, such as final output on desktop color printers, high-volume copiers, and large-format printers for outdoor displays.


#*Cyclic Projective Reed-Muller Codes
#@Thierry P. Berger,Louis de Maximy
#t2001
#cProceedings of the 14th International Symposium on Applied Algebra, Algebraic Algorithms and Error-Correcting Codes
#index357516


#*Sectored Snakes: Evaluating Learned-Energy Segmentations
#@Samuel D. Fenster,John R. Kender
#t2001
#cIEEE Transactions on Pattern Analysis and Machine Intelligence
#index617482
#%87645
#%256848
#%442408
#%479235
#!We describe how to teach deformable models to maximize image segmentation correctness based on user-specified criteria, and we present a method for evaluating which criteria work best. A traditional deformable model (&ldquo;snake&rdquo; in 2D) fails to find an object's boundary when the strongest nearby image edges are not the ones sought. But models can be trained to respond to other image features instead, by learning their probability distributions. The implementor must then decide on which of many image qualities to teach the model. To this end, we show how to evaluate the efficacy of any resulting deformable model, given a sampling of ground truth, a model of the range of shapes tried during optimization, and a measure of shape closeness. In the domain of abdominal CT images, we demonstrate such evaluation on a simple &ldquo;sectoring&rdquo; of a snake in which intensity and perpendicular gradient are observed over equal-length segments. This specific set of qualities shows a measured improvement over an objective function that is uniform around the shape, and it follows naturally from examination of the latter's failures due to image variations around the organ boundary.


#*TTTC Newsletter
#@
#t2003
#cIEEE Design Test
#index567767


#*Secure Electronic Commerce: Building the Infrastructure for Digital Signatures and Encryption, 2nd edition
#@Warwick Ford,Michael S. Baum
#t2000
#c
#index252944
#!: "More now than ever, business has a responsibility to understand the trade-offs, costs, benefits and risks involved in choosing any particular type of information security technology. That necessary due diligence begins in Chapter 1 of this book." Spence Abraham, United States Senate Your e-commerce site is only as successful as it is secure Customer confidence is a prerequisite for successful e-commerce, and security is the underpinning of that confidence. To make your e-commerce deployment safe and functional, you need to know not merely the latest security technologies, but also the most current legal strategies. This revised best seller combines the advice of seasoned experts from both the technical and legal fields to help you create a winning business strategy. Traditional business users will learn how e-commerce transactions differ from paper-based commerce, and how to minimize the risks while maximizing the benefits. Technical users will appreciate the extensive coverage of the latest security technologies and how they are applied in the business environment. Internet and security topics: Digital signatures for secure transactions Public-key infrastructure and certification policies Firewalls, virtual private networks, Web and e-mail security Legal and business topics: Legal principles and practices to achieve enforceability Regulations and guidelines in the U.S. and internationally Non-repudiation and the role of trusted third-parties Newcomers will appreciate the clear explanations of theorigins and development of secure e-commerce. More experienced developers can move straight to the detailed technical material. Anyone who is involved in e-commerce design, management, or operation needs Secure Electronic Commerce.


#*Fast computation in adaptive tree approximation
#@Peter Binev,Ronald DeVore
#t2004
#cNumerische Mathematik
#index433496
#!Adaptive methods of approximation arise in many settings including numerical methods for PDEs and image processing. They can usually be described by a tree which records the adaptive decisions. This paper is concerned with the fast computation of near optimal trees based on n adaptive decisions. The best tree based on n adaptive decisions could be found by examining all such possibilities. However, this is exponential in n and could be numerically prohibitive. The main result of this paper is to show that it is possible to find near optimal trees using computations linear in n.


#*On reachability, relevance, and resolution in the planning as satisfiability approach
#@Ronen I. Brafman
#t2001
#cJournal of Artificial Intelligence Research
#index501627
#%155311
#%590460
#!In recent years, there is a growing awareness of the importance of reachability and relevance-based pruning techniques for planning, but little work specifically targets these techniques. In this paper, we compare the ability of two classes of algorithms to propagate and discover reachability and relevance constraints in classical planning problems. The first class of algorithms operates on SAT encoded planning problems obtained using the linear and GRAPHPLAN encoding schemes. It applies unit-propagation and more general resolution steps (involving larger clauses) to these plan encodings. The second class operates at the plan level and contains two families of pruning algorithms: Reachable-k and Relevant-k . Reachable-k provides a coherent description of a number of existing forward pruning techniques used in numerous algorithms, while Relevant-k captures different grades of backward pruning. Our results shed light on the ability of different plan-encoding schemes to propagate information forward and backward and on the relative merit of plan-level and SAT-level pruning methods.


#*An evolutionary algorithm with advanced goal and priority specification for multi-objective optimization
#@Kay Chen Tan,Eik Fun Khor,Tong Heng Lee,Ramasubramanian Sathikannan
#t2003
#cJournal of Artificial Intelligence Research
#index494005
#%151640
#%194484
#%254047
#%355375
#%356426
#%517247
#!This paper presents an evolutionary algorithm with a new goal-sequence domination scheme for better decision support in multi-objective optimization. The approach allows the inclusion of advanced hard/soft priority and constraint information on each objective component, and is capable of incorporating multiple specifications with overlapping or non-overlapping objective functions via logical "OR" and "AND" connectives to drive the search towards multiple regions of trade-off. In addition, we propose a dynamic sharing scheme that is simple and adaptively estimated according to the on-line population distribution without needing any a priori parameter setting. Each feature in the proposed algorithm is examined to show its respective contribution, and the performance of the algorithm is compared with other evolutionary optimization methods. It is shown that the proposed algorithm has performed well in the diversity of evolutionary search and uniform distribution of non-dominated individuals along the final trade-offs, without significant computational effort. The algorithm is also applied to the design optimization of a practical servo control system for hard disk drives with a single voice-coil-motor actuator. Results of the evolutionary designed servo control system show a superior closed-loop performance compared to classical PID or RPT approaches.


#*Neural Networks in Finance: Gaining Predictive Edge in the Market (Academic Press Advanced Finance Series)
#@Paul D. McNelis
#t2004
#c
#index8317


#*Mobility
#@
#t2002
#cProceedings of the 10th ACM SIGSOFT symposium on Foundations of software engineering
#index252669


#*The Utility of Global Representations in a Cognitive Map
#@Margaret E. Jefferies,Wai K. Yeap
#t2001
#cProceedings of the International Conference on Spatial Information Theory: Foundations of Geographic Information Science
#index573185


#*Mac OS X Security
#@Bruce Potter,Preston Norvell,Brian Wotring
#t2003
#c
#index113070
#!:Mac OS X now operates on a UNIX engine. As such it is much more powerful than previous operating systems. It is now a multitasking, multithreaded, multi-user, and multiprocessor system with enhanced interoperability with other systems. Along with that increased power comes increased security vulnerability. Part I introduces readers to the basics of OS X security. Part II addresses system security beginning at the client workstation level. This section addresses UNIX-specific information such as permissions, executables, and network protocols and the related security concerns. Part III covers network security. The chapters in this section will cover security for internet services, file sharing, and network protection systems. Part IV addresses enterprise security using a variety of tools (Kerberos, NetInfo, and Rendezvous) as well as workstation configurations to illustrate how OS X Server and OS X inter-operate. The final section addresses auditing and forensics and what to do when an OS X network is compromised. This section teaches readers to audit systems painlessly and effectively and how to investigate and handle incidents.


#*Coordinating work in hospitals through a global tool: implications for the implementation of electronic patient records in hospitals
#@Gunnar Ellingsen
#t2003
#cScandinavian Journal of Information Systems
#index304039
#%83863
#%244252
#%299029
#%299278
#!Modem organisations increasingly have to face the challenge of increased complexity and specialisation. The specialisation of work requires professionals, people possessing specialised skills and often having a high level of education. Organisations that face this kind of problem are large hospitals. The implementation of Electronic Patient Records (EPRs) in these hospitals is accordingly expected to reduce complexity and curb specialisation by coordinating work among contexts and different types of users. The paper is based on a hospital department with several different professionals working together. The professionals successfully organise their work and the production of their reports according to a global classification system. This makes the case an illustrative example on how hospitals might take a starting point in EPRs through such a mechanism and may provide some strategies for the implementation of EPRs.


#*A new approach to fuzzy bitopological spaces
#@S. A. El-Sheikh
#t2001
#cInformation Sciences: an International Journal
#index233236


#*ADO.NET
#@Craig Utley,Mark Scott
#t2002
#c
#index241102
#!:A high-end comprehensive developer's guide that provides information to effectively use and create scalable, enterprise-wide applications with ADO.NET. This book covers ADO.NET, the new database technology underlying Microsoft's .NET strategy, perhaps their largest technology strategy ever. ADO.NET looks at the ADO.NET objects and how they compare to ADO, which is currently used by several million developers, according to Microsoft. Craig focuses on how to effectively use the new objects, but just as important, he focuses on the new design paradigm required to use a disconnected data access technology. This will require changes in how applications are designed and constructed. This book teaches the reader more than new objects; it will also ensure that then readers' applications are designed to be scalable and robust.


#*Guaranteed Software Quality
#@H. Dieter Rombach
#t2001
#cProceedings of the Third International Conference on Product Focused Software Process Improvement
#index555824


#*Nintendo 64 Secret Codes, Volume 5
#@
#t2001
#c
#index13683


#*A high performance RNS multiply-accumulate unit
#@A. P. Preethy,Damu Radhakrishnan,Amos Omondi
#t2001
#cProceedings of the 11th Great Lakes symposium on VLSI
#index326188
#%170424
#%335044


#*First-Order and Second-Order Conditions for Error Bounds
#@Zili Wu,Jane J. Ye
#t2003
#cSIAM Journal on Optimization
#index303624
#!For a lower semicontinuous function f on a Banach space X, we study the existence of a positive scalar $\mu$ such that the distance function dS associated with the solution set S of $f(x)\leq 0$ satisfies \[ d_S(x)\leq \mu \max\{ f(x),0\} \] for each point x in a neighborhood of some point x0 in X with $f(x)<\epsilon$ for some $0<\epsilon \leq +\infty.$ We give several sufficient conditions for this in terms of an abstract subdifferential and the Dini derivatives of f. In a Hilbert space we further present some second-order conditions. We also establish the corresponding results for a system of inequalities, equalities, and an abstract constraint set.


#*Cisco Networking Academy Program: Fundamentals of Voice and Data Cabling: Lab Companion
#@
#t2003
#c
#index115953
#!:The official Lab Companion of the Cisco Networking Academy Program's Fundamentals of Voice and Data Cabling course.Maps to the current Web-based course offered by the Cisco Networking Academy ProgramPrepares students for the BICSI Registered Installer, Level I ExamIncludes hands-on lab exercisesThe Fundamentals of Voice and Data Cabling Lab Companion will be the companion lab manual for a one-semester course on cabling technologies. The course and companion materials provide an introduction to the physical aspects of voice and data network cabling and installation. The review questions and thought exercises included in the lab companion focus on cabling issues related to data and voice connections and provide an understanding of the industry and its worldwide standards, types of media and cabling, physical and logical networks, as well as signal transmission. This book will help students learn how to do the following: read network design documentation, set up part lists and purchase components, pull and mount cable, choose wiring closets, install jacks, and perform cable testing. It will also help develop skills in documentation, design, cable management, and troubleshooting installation issues, as well as laboratory safety, on-the-job safety, and how to work effectively in group environments. The hands-on approach and comprehensive coverage of topics in the Fundamentals of Voice and Data Cabling Lab Companion will be part of a unique learning package to help students prepare for the BICSI Registered Installer, Level 1 exam. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*A Clustering Based Approach to Efficient Image Retrieval
#@Ruofei Zhang,Zhongfei (Mark) Zhang
#t2002
#cProceedings of the 14th IEEE International Conference on Tools with Artificial Intelligence
#index120778
#!This paper addresses the issue of effective and efficient content based image retrieval by presenting a novel indexing and retrieval methodology that integrates color, texture, and shape information for the indexing and retrieval, and applies these features in regions obtainedthrough unsupervised segmentation, as opposed to applying them to the whole image domain. In order to address the typical color feature "inaccuracy" problem in the literature, fuzzy logic is applied to the traditional color histogram to solve for the problem to a certain degree. Thesimilarity is defined through a balanced combination between global and regional similarity measures incorporating all the features. In order to further improve the retrieval efficiency, a secondary clustering technique is developed and employed to significantly save queryprocessing time without compromising the retrieval precision. An implemented prototype system has demonstrated a promising retrieval performance for a test database containing 2000 general-purpose color images, as compared with its peer systems in the literature.


#*An algorithm to judge the integrability of second order linear differential equation with rational coefficients
#@Lej Jinzhi,Guan Keying
#t2000
#cNeural, Parallel Scientific Computations
#index322683


#*Virtual Trackballs Revisited
#@Knud Henriksen,Jon Sporring,Kasper Hornbæk
#t2004
#cIEEE Transactions on Visualization and Computer Graphics
#index309943
#%75584
#%151925
#%208871
#%282346
#%290253
#%293499
#%295239
#%296003
#%597069
#%443373
#%465070
#!Abstract--Rotation of three-dimensional objects by a two-dimensional mouse is a typical task in computer-aided design, operation simulations, and desktop virtual reality. The most commonly used rotation technique is a virtual trackball surrounding the object and operated by the mouse pointer. This article reviews and provides a mathematical foundation for virtual trackballs. The first, but still popular, virtual trackball was described by Chen et al. [CHECK END OF SENTENCE]. We show that the virtual trackball by Chen et al. does not rotate the object along the intended great circular arc on the virtual trackball and we give a correction. Another popular virtual trackball is Shoemake's quaternion implementation [CHECK END OF SENTENCE], which we show to be a special case of the virtual trackball by Chen et al.. Shoemake extends the scope of the virtual trackball to the full screen. Unfortunately, Shoemake's virtual trackball is inhomogeneous and discontinuous with consequences for usability. Finally, we review Bell's virtual trackball [CHECK END OF SENTENCE] and discuss studies of the usability of virtual trackballs.


#*Managing XML data storage
#@Jerry Emerick
#t2002
#cCrossroads
#index252288
#%244862


#*Challenging students with creative assignments
#@Michael Mitzenmacher
#t2001
#cACM SIGACT News
#index251064


#*How Did Computing Go Global? The Need for an Answer and a Research Agenda
#@James W. Cortada
#t2004
#cIEEE Annals of the History of Computing
#index388398
#!The answers to how computing went global have ramifications for historians and society far beyond mere documentation. By understanding the complexities of how IT computing technology spread around the globe, we may gain insight into future technologies and be able to help shape their deployment to a larger extent, which may ultimately better benefit humankind, while learning more about how technologies have spread in the past.


#*Using unlabeled data for learning classification problems
#@A. Verikas,A. Gelzinis,K. Malmqvist
#t2002
#cNew learning paradigms in soft computing
#index607371
#%84760
#%90074
#%280461
#%287552
#%459332
#%462990
#%518004
#%596422
#!This chapter presents an approach of using unlabeled data for learning classification problems. The chapter consists of two parts. In the first part of the chapter, an approach of using both labeled and unlabeled data to train a multilayer percetron is presented. The approach banks on the assumption that regions of low pattern density usually separate data classes. The unlabeled data are iteratively preprocessed by a perceptron being trained to obtain the soft class label estimates. It is demonstrated that substantial gains in classification performance may be achieved by using the approach when the labeled data do not adequately represent the entire class distributions. In the second part of the chapter, we propose a quality function for learning decision boundary between data clusters from unlabeled data. The function is based on third order polynomials. The objective of the quality function is to find a place in the input sparse in data points. By maximizing the quality function, we find a decision boundary between data clusters. A superiority of the proposed quality function over the other similar functions as well as the conventional clustering algorithms tested has been observed in the experiments.


#*Introducing granularity-dependent quantitative distance and diameter measures in common-sense reasoning contexts
#@Maureen Donnelly
#t2001
#cProceedings of the international conference on Formal Ontology in Information Systems - Volume 2001
#index615346
#!In this paper, I will present a method for constructing correlated series of granularity-dependent distance and diameter measures on the basis of a theory of qualitative spatial concepts. Each granularity-dependent measure function has as its range a discrete subset of R. As we proceed through a series of such functions, the distance between the values in the range will become smaller and the measurements returned by the functions will become correspondingly more precise. My method for constructing the series of functions is partially based on work in Kranz, Luce, Suppes, and Tversky, The Foundations of Measurement, Vol. 1. I use a result from that volume to prove that my series of distance and diameter measures converge to continuous, extensive distance and diameter measures. But it is the discrete measures in the series, not the continuous limit measures, that should be used in analyses of common-sense concepts. Unlike the continuous measure functions, arbitrary values for the discrete measure functions can, in most contexts, be determined through practical procedures. Moreover, the ability to move from one granularity-level to the next is appropriate for common-sense contexts in which the level of precision is typically kept at the minimum necessary to accomplish the task at hand.


#*On computing the distribution function of the sum of independent random variables
#@Mani K. Agrawal,Salah E. Elmaghraby
#t2001
#cComputers and Operations Research
#index318980


#*A Hierarchy of Reactive Behaviors Handles Complexity
#@Sven Behnke,Raúl Rojas
#t2001
#cBalancing Reactivity and Social Deliberation in Multi-Agent Systems, From RoboCup to Real-World Applications (selected papers from the ECAI 2000 Workshop and additional contributions)
#index372150


#*Agents' advanced features for negotiation and coordination
#@Eugenio Oliveria
#t2001
#cMutli-agents systems and applications
#index234172
#%75256
#%121402
#%231782
#%558363
#%371841
#%361717
#%289732
#%441248
#%294354
#%282516
#%292666
#%294666
#!Agent-based systems suitable for dealing with applications where the environment is both dynamic and populated with competitors demand for sophisticated characteristics including adaptation, negotiation and coordination. We here briefly summarize some proposals on agents' negotiation capabilities including adaptation through reinforcement learning as well as qualitative multi-criteria negotiation and coalition formation protocols. Also, and inspired by robosoccer domain, some basic hints on knowledge representation for agents' team work are here described. All those proposals on automatic negotiation have been implemented through agent-based systems for different application domains (MACIV, SMACE, ForEV).


#*On the convergence of certain Gauss-type quadrature formulas for unbounded intervals
#@A. Bultheel,C. Díaz-Mendoza,P. González-Vera,R. Orive
#t2000
#cMathematics of Computation
#index284255


#*Attribute based compiler implemented using visitor pattern
#@Norman Neff
#t2004
#cProceedings of the 35th SIGCSE technical symposium on Computer science education
#index302995
#%162585
#!In our compiler course for undergraduate students, we use a class of attribute grammars to specify type information, target code, and other properties calculated for the source program. In the design of the compiler, a modification of the visitor design pattern allows us to transparently compute the attributes. Within our framework, implementation is straightforward; the emphasis of the course shifts to theory and specification. In several offerings of the course, students have implemented parts of a highly modular compiler for a small, statically typed object oriented language.


#*Models For Interconnect Capacitance Extraction
#@Asim Husain
#t2001
#cProceedings of the 2nd International Symposium on Quality Electronic Design
#index115740
#!Commonly used numerical methods in capacitance extraction both for small and large circuit blocks are reviewed for a VLSI design. Boundary element based field solvers can effectively be used for small structures but can not be used for large structures because of large grid requirement. Field solvers based on random walk method are more appropriate for large structures but still they are quite slow in comparison to analytic capacitance models, which are generally applied for chip level extractions. Accounting for 3D fringing fields has become essential in analytic models for accurate extraction of current VLSI technologies. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Volume Graphics
#@Min Chen,Arie Kaufman,Roni Yagel
#t2001
#c
#index231881


#*Study of some algebraical properties of adaptive combination rules
#@Mourad Oussalah
#t2000
#cFuzzy Sets and Systems
#index326701


#*Adaptive meshing for two-dimensional thermoelastic problems using Hermite boundary elements
#@J. C. Miranda-Valenzuela,K. H. Muci-Küchler,S. Soriano-Soriano
#t2001
#cAdvances in Engineering Software
#index333268


#*Applications of sampling and fractional factorial designs to model-free data squashing
#@William DuMouchel,Deepak K. Agarwal
#t2003
#cProceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining
#index312080
#%286029
#!The concept of "data squashing" was introduced by DuMouchel et al [4] as a method of summarizing massive data sets that preserves statistical relationships among variables. The idea is to create a smaller data set that allows statistical modeling to take place using in-memory algorithms, and to preserve the modeling results more accurately than would a same-size random sample from the massive data set. This research attempts to avoid several limitations of previous approaches to data squashing. Our method avoids the curse of dimensionality by a double use of principal components transformations that makes computing time linear in the number of cases and quadratic in the number of variables. Categorical and continuous variables are smoothly integrated. Because the binning is based on principal components, which are uncorrelated, we can use fractional factorial designs that sample less than one point per bin. We also investigate various weighting schemes for the squashed sample to see whether matching moments or matching subregion data counts is more effective. Finally, previous work required the specification of a statistical model, either to perform the squashing algorithm or to compare the worth of different squashing methods. Our approach to evaluation is model free and does not even require the specification of variables as responses or predictors. Instead, we develop a chi-squared like measure of accuracy to compare the closeness of various discrete densities (the squashed data sets) to the discrete massive data set.


#*Makespan minimization subject to flowtime optimality on identical parallel machines
#@Chien-Hung Lin,Ching-Jong Liao
#t2004
#cComputers and Operations Research
#index438221
#%228474
#!We consider the identical parallel machine problem with makespan minimization subject to minimum total flowtime. First, we develop an optimal algorithm to the identical parallel machine problem with the objective of minimizing makespan. To improve the computational efficiency, two implementation techniques, the lower bound calculation and the job replacement rule, are applied. Based on the algorithm, an optimal algorithm, using new lower bounds, to the considered problem is developed. The result of this study can also be used to solve the bicriteria problem of minimizing the weighted sum of makespan and mean flowtime. Computational experiments are conducted up to six machines and 1000 jobs. Although the proposed algorithm has an exponential time complexity, the computational results show that it is efficient to find the optimal solution.


#*Evaluation of sine wave tests of ADCs from windowed data
#@István Kollár
#t2000
#cComputer Standards Interfaces
#index334559


#*Model-based Hierarchical Average-reward Reinforcement Learning
#@Sandeep Seri,Prasad Tadepalli
#t2002
#cProceedings of the Nineteenth International Conference on Machine Learning
#index373511


#*Parallel PIC plasma simulation through particle decomposition techniques
#@B. Di Martino,S. Briguglio,G. Vlad,P. Sguazzero
#t2001
#cParallel Computing
#index334250


#*Applications of Jensen's inequality
#@Mihály Bencze
#t2001
#cOctogon Mathematical Magazine
#index438673


#*Software Metrics and Human Factors for WIBIS (WWW Internet Based Information Systems
#@Motoei Azuma
#t2002
#cProceedings of the 1st IEEE International Conference on Cognitive Informatics
#index371023
#!World wide web and Internet Based Information Systems (WIBIS) have been widely used, because of popularization of high performance personal computers, Internet and related communication services supported by such information technologies as Hyper-media andGraphical User Interface.WIBIS should be able to adapt itself to (1) changes in environment and (2) changes in information needs. In order to satisfy these requirements, the WIBIS should integrate software development systems and supporting systems, including both human parts and computer parts.In this paper, a three-layer system architecture for WIBIS, which integrates development support system, development system and operation system, is proposed. Then software metrics and human factors issues are discussed for each layer. Human factors issues are alsoexplained using the human cognitive information process model.


#*Bastards & Bloodlines: A Guidebook to Halfbreeds (Races of Renown)
#@Owen K. C. Stephens
#t2002
#c
#index17902


#*A human-centric tool for component design and reuse in the UML
#@E. E. Roubtsova
#t2003
#cProceedings of the 2003 IEEE Symposium on Human Centric Computing Languages and Environments
#index24186


#*Emergence of automated assignment conceptions in a functional programming course
#@Tamar Paz,Tami Lapidot
#t2004
#cACM SIGCSE Bulletin
#index436755
#%146985
#%170300
#%327095
#%449241
#!This paper reports a research into the performance of high school students while they were first exposed to the paradigm of functional programming. The findings have been organized using three categories. In this paper we will concentrate on the "Automated assignment to parameters" conception which was the most widespread conception found in the research. We will describe the conception and will discuss some possible factors that could influence its development.


#*Information Visualization in Locating Obnoxious Facility: Some Examples with Mono and Bicriteria Models
#@Carlos Ferreira
#t2000
#cProceedings of the International Conference on Information Visualisation
#index110264
#!The problem of locating obnoxious facilities has become a major social concern. Operation Research models and methods have been used in this context, however their use can be jeopardized by the huge demanded effort. In consequence, the use of visualization and interaction methods becomes of great importance. This paper addresses specific issues and shows examples of developed solutions for the visualization and interaction problems related to the use of mono and multi-criteria Obnoxious Facility Location in Decision Support scenarios.


#*Components, Interfaces and Information Models within a Platform Architecture
#@Jan Gerben Wijnstra
#t2001
#cProceedings of the Third International Conference on Generative and Component-Based Software Engineering
#index382505


#*Threshold counters with increments and decrements
#@Costas Busch,Neophytos Demetriou,Maurice Herlihy,Marios Mavronicolas
#t2002
#cTheoretical Computer Science
#index239969
#%91717
#%101269
#%214293
#%371727
#%480627
#%370193
#!A threshold counter is a shared data structure that assumes integer values. It provides two operations: Increment changes the current counter value from v to v+1, while Read returns the value [v/w], where v is the current counter value and w is a fixed constant. Thus, the Read operation returns the "approximate" value of the counter to within the constant w. Threshold counters have many potential uses, including software barrier synchronization. Threshold networks are a class of distributed data structures that can be used to construct highly-concurrent, low-contention implementations of shared threshold counters. In this paper, we give the first proof that any threshold network construction of a threshold counter can be extended to support a Decrement operation that changes the counter value from v to v ---1.


#*The Andon System: Designing a CSCW Environment in a Lean Organization
#@André M. da Silva,Maria Cecília Calani Baranauskas
#t2000
#cProceedings of the 6th International Workshop on Groupware
#index383392
#!Andon is a system to support collaborative work in a lean manufacturing organization. The design of Andon is part of a study aimed at exploring the multiple disciplines involved in CSCW (computer-supported cooperative work). Its development is an attempt to use participatory practices and a proposed lifecycle model to overcome the difficulties that arise during the development of CSCW applications. This paper presents and discusses the design process of Andon.


#*Multiple Neuronal Networks Mediate Sustained Attention
#@Natalia S. Lawrence,Thomas J. Ross,Ray Hoffmann,Hugh Garavan,Elliot A. Stein
#t2003
#cJournal of Cognitive Neuroscience
#index30590
#%619100
#%31011
#!Sustained attention deficits occur in several neuropsychiatric disorders. However, the underlying neurobiological mechanisms are still incompletely understood. To that end, functional MRI was used to investigate the neural substrates of sustained attention (vigilance) using the rapid visual information processing (RVIP) task in 25 healthy volunteers. In order to better understand the neural networks underlying attentional abilities, brain regions where task-induced activation correlated with task performance were identified. Performance of the RVIP task activated a network of frontal, parietal, occipital, thalamic, and cerebellar regions. Deactivation during task performance was seen in the anterior and posterior cingulate, insula, and the left temporal and parahippocampal gyrus. Good task performance, as defined by better detection of target stimuli, was correlated with enhanced activation in predominantly right fronto-parietal regions and with decreased activation in predominantly left temporo-limbic and cingulate areas. Factor analysis revealed that these performance-correlated regions were grouped into two separate networks comprised of positively activated and negatively activated intercorrelated regions. Poor performers failed to significantly activate or deactivate these networks, whereas good performers either activated the positive or deactivated the negative network, or did both. The fact that both increased activation of task-specific areas and increased deactivation of task-irrelevant areas mediate cognitive functions underlying good RVIP task performance suggests two independent circuits, presumably reflecting different cognitive strategies, can be recruited to perform this vigilance task.


#*Suitability of Evolutionary Algorithms for Evolutionary Testing
#@Joachim Wegener,André Baresel,Harmen Sthamer
#t2002
#cProceedings of the 26th International Computer Software and Applications Conference on Prolonging Software Life: Development and Redevelopment
#index380397
#!A great number of today's products is based on the deployment of embedded systems. There are examples of this in nearly all industrial areas, for example in aerospace technology, railway and motor vehicle technology, process and automation technology, communicationtechnology, process and power engineering, as well as in defense electronics. Nearly 90% of all electronic components produced today are used in embedded systems [I]. Embedded systems are also frequently used in applications relevant to safety. Therefore, the occurrence of errors may endanger human lives or result in costly recalls for products produced in high quantities, for example in the automotive industry. Accordingly, the development of embedded systems must comply with the highest quality standards.In order to achieve high quality in the development of embedded systems central importance is attributed to analytical quality assurance. In practice, the most important analytical quality assurance measure is dynamic testing. The thorough testing of systems developed is essential to product quality. The aim of the test is to detect errors in the system to be tested, and to convey confidence in the correct functioning of the system if no errors arefound during comprehensive testing. Testing often takes up more than 50% of the total development costs for embedded systems [4, 5].The most significant weakness of testing is that the postulated functioning of the tested system can, in principle, only be verified for those input situations selected as test data. According to Dijkstra [6], testing can only show the existence but not the non-existence oferrors. The correctness proof can only be produced by a complete test, i.e. a test with all possible input values, input value sequences, and input value combinations under all practically possible constraints. A complete test is usually practically impossible because of the vast amount of possible input situations. Testing is therefore a sampling procedure. Accordingly, an essential testing task is the selection of an appropriate sample containing themost error-sensitive test data. If test data relevant to the practical deployment of the system are omitted, the defined for the test aim and evolutionary computation is applied as a search technique, then the evolutionary test probability of detecting errors within the software declines.


#*Terraforming Cyberspace
#@Jeffrey M. Bradshaw,Niranjan Suri,Alberto J. Cañas,Robert Davis,Kenneth Ford,Robert Hoffman,Renia Jeffers,Thomas Reichherzer
#t2001
#cComputer
#index443709
#%83518
#%95553
#!Cyberspace currently offers a lonely, dangerous, and relatively impoverished environment for software agents, which do not easily sustain rich, long-term, peer-to- peer relationships. No social safety net helps agents when they get stuck or prevents them from setting the network on fire when they go awry. Agents remain cut off from most of the world in which humans operate, and severe practical restrictions limit when and where they can go. The first passerby who finds the power switch can unceremoniously terminate an agent's existence. The authors advocate not only making agents smarter and stronger but also making the environment in which they operate more capable of sustaining various forms of agent life and civilization. As a new kind of environment for human beings, cyberspace is now woefully primitive. Most of our electronically built space is a rat's nest of bewildering pathways of indeterminate destination, much like medieval Rome. Those who are designing and building cyberspace might benefit from the example of the humanist Popes of the Renaissance, who used the cittá ideale concepts to produce connectivity and impart legibility to their city's layout.


#*Op-Glyph: a tool for exploring op art representation of height and vector field data
#@Francis T. Marchese
#t2002
#cProceedings of the working conference on Advanced visual interfaces
#index138758
#%326930
#%237523
#%334631
#!We report our experiences with application of the optical art techniques of Victor Vasarely and Bridget Riley to visualization of height field and vector field data. The bold use of color and simple form in Op Art engages the preattentive processing ability of the human visual system, facilitating a nearly instantaneous perception of image properties without the need for extended scrutiny of component parts. A software system called Op-Glyph was constructed to illustrate the Op Art method for data visualization, providing a user with extensive control over a visual representation's primitives, including shape, size, and color. Initial results suggest that this glyph-based approach to data visualization may be a viable alternative or complement to more complex representation schemes, particularly in situations where there are limited processing or graphical capabilities, such as with PDAs.


#*Distributed Development: Lessons Learned
#@Michael Turnlund
#t2003
#cQueue
#index305472
#!Delivery of a technology-based project is challenging, even under well-contained, familiar circumstances. And a tight-knit team can be a major factor in success. It is no mystery, therefore, why most small, new technology teams opt to work in a garage (at times literally). Keeping the focus of everyone’s energy on the development task at hand means a minimum of non-engineering overhead.


#*Providing elegant peripheral awareness
#@JJ Cadiz,Mary Czerwinski,Scott McCrickard,John Stasko
#t2003
#cCHI '03 extended abstracts on Human factors in computing systems
#index560085
#%254784
#%287341
#%324656
#!In a one-day workshop, we strive to build community in this emerging research area, specifically targeting interfaces that are designed to provide awareness in a peripheral and elegant manner. We focus on improving consensus of basic and fundamental issues and developing a structural framework--critical parameters, design themes, and evaluation procedures--for research on these types of user interfaces.


#*An Ontology for Linkups between Norms
#@Raffaella Brighi
#t2004
#cProceedings of the Database and Expert Systems Applications, 15th International Workshop
#index436360
#!This paper is aimed at investigating the forms of expression specific to the linkups between norms and showing structures with which to formalize the essential properties of such linkups, working from the linguistic formulations the provisions are set in. A formal expression of these concepts, defining a set of ontological categories specific to the legal domain, will enable us to supplement legal texts with information that software agents can process and exchange. In this process, important aspects of application are brought to light that help us find improved ways of using and understanding legal texts.


#*Intelligent Web Topics Search Using Early Detection and Data Analysis
#@Ching-Cheng Lee,Yixin Yang
#t2003
#cProceedings of the 27th Annual International Conference on Computer Software and Applications
#index305781
#!Topic-specific search engines that offered users relevanttopics as search results have recently been developed.However, these topic-specific search engines requireintensive human efforts to build and maintain. In addition,they visit many irrelevant pages. In our project, wepropose a new approach for Web topics search. First, wedo early detection for "candidate topics" while extractingwords from the HTML text. Secondly, we perform dataanalysis on the appearance information such asappearance times and places for candidate topics. Bythese two techniques, we can reduce candidate topics'crawling times and computing cost. Analysis of the resultsand the comparisons with related research will be madeto demonstrate the effectiveness of our approach.


#*An Efficient Implementation of Braid Groups
#@Jae Choon Cha,Ki Hyoung Ko,Sang-Jin Lee,Jae Woo Han,Jung Hee Cheon
#t2001
#cProceedings of the 7th International Conference on the Theory and Application of Cryptology and Information Security: Advances in Cryptology
#index257889


#*Some challenges and grand challenges for computational intelligence
#@Edward A. Feigenbaum
#t2003
#cJournal of the ACM (JACM)
#index448605
#%439582


#*Breaking the Access Barrier: Delivering Internet Connections over Cable
#@Mark E. Laubach,David Farber,Stephen Dukes
#t2002
#c
#index245878
#!:An inside look at high-speed access written for the cable industryCable modems have emerged as a leading consumer choice for high-speed Internet access, outpacing alternatives such as digital subscriber lines, but not without raising issues about quality of service and controversy about open access. Providing an objective review of residential broadband and cable television networking, this book will be of great use for professionals who are integrating cable into their networks or service offerings. The authors compare cable access systems to competing technologies and discuss the increasingly difficult issues confronting each. Readers will also find coverage of the hottest areas in the field including high-speed data and packet voice standards, managing the "always-on" connection, and security and privacy risks.


#*A dataflow specification for system level synthesis of 3D graphics applications
#@Chanik Park,Sungchan Kim,Soonhoi Ha
#t2001
#cProceedings of the 2001 Asia and South Pacific Design Automation Conference
#index331521
#%90914
#%94508
#%587498
#%441565
#!3D graphics is becoming an important application area together with multimedia applications. The dynamic behavior of 3D graphics application brings new challenges for system level specification and synthesis methodologies. Although existing dataflow models are successfully used for DSP system design, they are not sufficient to deal with 3D graphics algorithms since they lack in global state management and dynamic behavior handling. In this paper, we propose an extended synchronous piggybacked dataflow model with dynamic constructs for representing 3D graphics algorithm. We also present implementation techniques for software and hardware synthesis from the specification. With a simple 3D graphics pipeline, we show the novelty and usefulness of the proposed specification model.


#*Coloring locally bipartite graphs on surfaces
#@Bojan Mohar,Paul D. Seymour
#t2002
#cJournal of Combinatorial Theory Series B
#index237842
#%229148
#%600530
#%598640
#%483925
#!It is proved that there is a function f: N → N such that the following holds. Let G be a graph embedded in a surface of Euler genus g with all faces of even size and with edge-width ≥ f(g). Then (i) If every contractible 4-cycle of G is facial and there is a face of size > 4, then G is 3-colorable. (ii) If G is a quadrangulation, then G is not 3-colorable if and only if there exist disjoint surface separating cycles C1, ..., Cg such that, after cutting along C1, ..., Cg, we obtain a sphere with g holes and g Möbius strips, an odd number of which is nonbipartite.If embeddings of graphs are represented combinatorially by rotation systems and signatures [5], then the condition in (ii) is satisfied if and only if the geometric dual of G has an odd number of edges with negative signature.


#*Scalability and failure recovery in a linux cluster file system
#@Kenneth W. Preslan,Andrew Barry,Jonathan Brassow,Michael Declerck,A. J. Lewis,Adam Manthei,Ben Marzinski,Erling Nygaard,Seth Van Oort,David Teigland,Mike Tilstra,Steven Whitehouse,Matthew O'Keefe
#t2000
#cProceedings of the 4th annual Linux Showcase & Conference - Volume 4
#index415699
#%77820
#%601227
#!In this paper we describe how we implemented journaling and recovery in the Global File System (GFS), a shared-disk, cluster file system for Linux. We also present our latest performance results for a 16-way Linux cluster.


#*An efficient method for mining associated service patterns in mobile web environments
#@Shin-Mu Tseng,Cing-Fu Tsui
#t2003
#cProceedings of the 2003 ACM symposium on Applied computing
#index302259
#%121469
#%207703
#%362949
#%440187
#%444112
#%357760
#!This research presents a new data mining method that can efficiently discover associated service patterns requested by users in mobile web environments. Although there exist some studies on data mining in mobile systems in recent years, they were mostly focused on topics like moving path mining or service request log mining and the issue of discovering user's associated service patterns with the locations has not been explored. In particular, this problem becomes more complex when the hierarchical concepts of locations and services are considered. In this work, we propose a new data mining method named two-dimensional multi-level association rules mining, which can efficiently discover the associated service request patterns by taking into account the hierarchical characteristics of the location and service concept. To our best knowledge, this is the first work resolving this research issue. Through detailed experimental evaluations under various system conditions, our method was shown to deliver excellent performance in terms of accuracy, completeness, execution efficiency and scalability.


#*Introduction to Charles Babbage Eulogy
#@Martin Campbell-Kelly
#t2000
#cIEEE Annals of the History of Computing
#index321160


#*Prolog (3rd ed.): programming for artificial intelligence
#@Ivan Bratko
#t2000
#c
#index315083


#*Preparing for Mous Certification Microsoft PowerPoint 2000
#@Faithe Wempen,Patty Winter,Rick Winter
#t2000
#c
#index243810


#*The Top Risks of Requirements Engineering
#@Brian Lawrence,Karl Wiegers,Christof Ebert
#t2001
#cIEEE Software
#index438583


#*Designing an ultra highly available DBMS (tutorial session)
#@Svein Erik Bratsberg,Øystein Torbjørnsen
#t2000
#cACM SIGMOD Record
#index282539


#*Pre-layout prediction of interconnect manufacturability
#@Phillip Christie,José Pineda de Gyvez
#t2001
#cProceedings of the 2001 international workshop on System-level interconnect prediction
#index315045
#%280388
#%284086
#%292667
#%297476
#%321060
#!Functional yield is a term used to describe the percentage of dies on a wafer that fail due to catastrophic defects. Within the interconnect these defects are usually caused by particle contamination and are divided into bridging defects, which join adjacent wires, and cuts, which result in broken wires. The probability of failure is therefore determined by the geometry of the routing channels and the distribution of defect sizes. Since the wire spacing and width are usually fixed, and the distribution of defects within a mature production facility is well known, the problem reduces to estimating individual wire lengths for cuts, and to estimating the overlapping distance that two wires share in neighboring sections of the routing grid for bridges. Since the probability of failure is determined by the behavior of the wires averaged over the entire interconnect, the application of System Level Interconnect Prediction (SLIP) techniques is particularly appropriate. This paper presents a method for utilizing previously developed techniques for wire length estimation and layer assignment and applies them to the problem of cut and bridge functional yield estimation.


#*Fix-mundis for fuzzy IF-THEN rule bases with standard compositional rule of inference interpretation
#@Karl-Heinz Temme,Madjid Fathi
#t2000
#cProceedings of the 2000 ACM symposium on Applied computing - Volume 1
#index291941


#*A visual approach for generating server page type weh applications based on template method
#@M. Taguchi
#t2003
#cProceedings of the 2003 IEEE Symposium on Human Centric Computing Languages and Environments
#index33239


#*A Formal Definition of Bottom-Up Embedded Push-Down Automata and Their Tabulation Technique
#@Miguel A. Alonso,Eric Villemonte de la Clergerie,Manuel Vilares Ferro
#t2001
#cProceedings of the 4th International Conference on Logical Aspects of Computational Linguistics
#index383271


#*JAVA IDE's: why and how we use what we do
#@
#t2002
#cACM SIGCSE Bulletin
#index231703


#*Accurate exploration of timing and area trade-offs in arithmetic optimization using carry-save-adders
#@Youngtae Kim
#t2001
#cProceedings of the 2001 Asia and South Pacific Design Automation Conference
#index319422
#%280570
#%293377
#%602182
#!Timing and area of circuits are two of the most important design criteria to be optimized in data path synthesis. In addition, carry-save-adder (CSA) has been proven to be one of the most efficient implementation units in optimizing timing and/or area of arithmetic circuits. However, the existing approaches are restricted in using CSAs, i.e., optimizing operation trees separately without any interaction between them, resulting in a locally optimized CSA circuit. To overcome this limitation, we propose a practically efficient solution to the problem of an accurate exploration of timing and area trade-offs in optimizing arithmetic circuits in the presence of multiple operation trees using CSAs. The application of our approach is able to find a best CSA implementation of circuit in terms of timing and area.


#*A new heuristic and dominance relations for no-wait flowshops with setups
#@Tariq Aldowaisan
#t2001
#cComputers and Operations Research
#index328908


#*Breaking the rules: success and failure in groupware-supported business process reengineering
#@Alan R. Dennis,Traci A. Carte,Gigi G. Kelly
#t2003
#cDecision Support Systems
#index301473
#%561801
#%533779
#%614640
#!In the information economy, businesses are changing more often and more rapidly than ever before. The lessons learned from a decade of business process reengineering (BPR) research may provide insights to researchers and managers trying to understand and successfully navigate these changes. This paper examines the successes and failures of groupware-supported BPR processes in four organizations. Two were successful and two were failures. Groupware allowed certain tasks to be performed faster, added structure to the BPR process and facilitated participation by more people. The key difference between the successful and the unsuccessful cases was when and how senior management was involved.


#*Group Rekeying with a Customer Perspective
#@Melek Onen,Refik Molva
#t2004
#cProceedings of the Parallel and Distributed Systems, Tenth International Conference
#index436778
#!In secure multi-party communications, several solutionshave been proposed to deal with group rekeying. However,most of existing solutions including the most efficient onesstill are severely lacking with respect to reliability and realcustomer expectations. Since in these solutions, each rekeyingoperation requires the update of the keying materialof all members alike, frequent rekeying caused by volatilemembers would strongly affect long-lived members. We thuspropose to restructure the Logical Key Hierarchy (LKH)scheme, by separately regrouping members based on theirmembership duration aiming at preserving members withlong duration membership from the impact of rekeying operationscaused by arrivals or departures of short-lived members.We designed a hybrid reliability scheme based on acombination of ARQ and FEC that assures a quasi certaindelivery of keying material to long-lived members. We thencome up with an extensive method to determine the systemparameters applicable to each member set based on the targetcustomer satisfaction criteria.


#*Chinese keyword extraction based on max-duplicated strings of the documents
#@Wenfeng Yang
#t2002
#cProceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval
#index246622
#%92706
#!The corpus analysis methods in Chinese keyword extraction look on the corpus as a single sample of language stochastic process. But the distributions of keywords in the whole corpus and in each document are very different from each other. The extraction based on global statistical information only can get significant keywords in the whole corpus. Max-duplicated strings contain the local significant keywords in each document. In this paper, we designed an efficient algorithm to extract the max-duplicated strings by building PAT-tree for the document, so that the keywords can be picked out from the max-duplicated strings by their SIG values in the corpus.


#*A guide to software configuration management
#@Alexis Leon
#t2000
#c
#index295444


#*Rapid dynamic simulation
#@David Baraff,Andrew Witkin
#t2000
#cCloth modeling and animation
#index324491


#*Fusion of Concurrent Invocations of Exclusive Methods
#@Yoshihiro Oyama,Kenjiro Taura,Akinori Yonezawa
#t2001
#cProceedings of the 6th International Conference on Parallel Computing Technologies
#index368848


#*Computationally Efficient and Numerically Stable Reliability Bounds for Repairable Fault-Tolerant Systems
#@Juan A. Carrasco
#t2002
#cIEEE Transactions on Computers
#index626974
#%150307
#%151448
#%156320
#%183039
#%480507
#!The transient analysis of large continuous time Markov reliability models of repairable fault-tolerant systems is computationally expensive due to model stiffness. In this paper, we develop and analyze a method to compute bounds for a measure defined on a particular, but quite wide, class of continuous time Markov models, encompassing both exact and bounding continuous time Markov reliability models of fault-tolerant systems. The method is numerically stable and computes the bounds with well-controlled and specifiable-in-advance error. Computational effort can be traded off with bounds accuracy. For a class of continuous time Markov models, class $\rm C^{\prime\prime}$, including typical failure/repair reliability models with exponential failure and repair time distributions and repair in every state with failed components, the method can yield reasonably tight bounds at a very small computational cost. The method builds upon a recently proposed numerical method for the transient analysis of continuous time Markov models called regenerative randomization.


#*On the Importance of Having an Identity or is Consensus Really Universal?
#@Harry Buhrman,Alessandro Panconesi,Riccardo Silvestri,Paul M. B. Vitányi
#t2000
#cProceedings of the 14th International Conference on Distributed Computing
#index571061


#*Easy Microsoft Windows XP Home Edition, 2 edition
#@Shelley O'Hara,Kate Welsh
#t2003
#c
#index120389
#!: Easy Windows XP Home is the perfect book for beginners who want to learn Windows XP and who prefer a visual, four-color approach. This book covers more than 150 of the most important tasks, ranging from simple features such as opening a folder, to more advanced topics such as installing new hardware or restoring a system.


#*Dhtml and CSS for the World Wide Web: Visual QuickStart Guide, 2nd edition
#@Jason Cranford Teague
#t2001
#c
#index232425
#!:Add dynamic interactivity to your Web site with DHTML and Cascading Style Sheets!Targeted to designers and content creators, not just programmers.Visual, task-based format the ideal way to get up and running with DHTML.This revised and expanded second edition is up-to-date on the current Web standards and browsers, and includes all new coverage of using DHTML to get information about the browser environment and adding multimedia to a site, as well as new basic and advanced dynamic techniques, such as making objects appear and disappear, moving objects in 3D, and adding dynamic content. This edition offers full cross-platform and cross-browser coverage. This book does not focus on the more complex aspects of DHTML, but focuses on practical examples of what really works with DHTML and CSS, making it useful for beginners just starting out with DHTML, as well as professional developers looking for a quick reference.


#*Preparing students for the workforce
#@Gordon S. Lowe
#t2000
#cProceedings of the Australasian conference on Computing education
#index333042
#%180784
#%462586
#%477612
#%538667
#%551102
#!Transition from academic studies to life as a professional is one of the most challenging and important roles in educating students. Students spend most of their academic life learning through completion of assignment work, yet will be expected to work as a member of a team in industry. The skills they will require are more diverse than technical skills, particularly communication, how to manage a project, and team work. This paper discusses the significance of an industry related project to student learning and commitment. Discussion of the difficulties experienced by students is also covered. One of the main outcomes of the project was the positive response from students and their increased awareness of critical non technical issues that make a project successful. One final goal of this paper is to draw attention to autonomous robots as a source of project work for programmers, hardware designers, artificial intelligence developers, and researchers.


#*Computing Optimal Trajectories for Medical Treatment Planning and Optimization
#@Ovidiu Daescu,Ashish Bhatia
#t2002
#cProceedings of the International Conference on Computational Science-Part III
#index373303


#*A Log-Domain CMOS Transcapacitor: Design, Analysis and Applications
#@Eric Fragnière Eric Vittoz,André van Schaik
#t2000
#cAnalog Integrated Circuits and Signal Processing
#index298052
#!We present in this paper the CMOS implementation of a transcapacitor working in the log-domain. This circuit integrates a differential input current into an output pseudo-voltage, which is similar to the compressed voltage used as the internal variable in companding filters. This log-domain transcapacitor is compatible with pseudo-conductances implemented with a single transistor. The pseudo-transcapacitor circuit is analyzed and a collection of log-domain reactive components and small circuits using it is proposed.


#*Motion Correction of MRI from Orthogonal k-Space Phase Difference
#@E. Brian Welch,Armando Manduca
#t2001
#cProceedings of the 4th International Conference on Medical Image Computing and Computer-Assisted Intervention
#index262531


#*Usable Access Control for the World Wide Web
#@Dirk Balfanz
#t2003
#cProceedings of the 19th Annual Computer Security Applications Conference
#index306592
#!While publishing content on the World Wide Web hasmoved within reach of the non-technical mainstream, controllingaccess to published content still requires expertisein Web server configuration, public-key certification, and avariety of access control mechanisms. Lack of such expertisecan result in unnecessary exposure of content publishedby non-experts, or can force cautious non-experts to leavetheir content off-line. Recent research has focused on makingaccess control systems more flexible and powerful, butnot on making them easier to use. In this paper, we proposea usable access control systems for the World Wide Web, i.e.,a system that is easy to use both for content providers (whowant to protect their content from unauthorized access) and(authorized) content consumers (who want hassle-free accessto such protected content). Our system can be constructedwith judicious use of conventional building blocks,such as access control lists and public-key certificates. Wepoint out peculiarities in existing software that make it unnecessarilyhard to achieve our goal of usable access control,and assess the security provided by our usable system.


#*Knowledge dynamics in organisations
#@Youngjin Yoo,Christian Ifvarsson
#t2002
#cKnowledge management in the sociotechnical world: the graffiti continues
#index569479


#*Massively Parallel Solutions for Molecular Sequence Analysis
#@Bertil Schmidt,Heiko Schröder,Manfred Schimmler
#t2002
#cProceedings of the 16th International Parallel and Distributed Processing Symposium
#index364549


#*Collaboration or Catastrophe: cna Libraries and Computer Centres work together?
#@Andrew Rothery,Anne Hannaford
#t2001
#cProceedings of the The 7th International Conference of European University Information Systems on The Changing Universities - The Role of Technology
#index383363


#*Demand-driven logic simulation using a network of loosely coupled processors
#@Paul E. Dunne,Paul H. Leng,Gerald F. Nwana
#t2002
#cJournal of Systems Architecture: the EUROMICRO Journal
#index571516
#%175167
#%210483
#%212237
#%215031
#%222587
#%288247
#%296983
#%329716
#%550539
#!Logic simulation is used extensively in the design of digital systems for the purpose of studying the behaviour of circuits under various conditions and for verifying the required performance of circuits. There is considerable interest in methods which reduce the simulation time during the design process. In this paper, we investigate how this can be achieved by simulating the action of logic circuits using a network of loosely coupled processors. Circuits modelled as directed graphs comprising clocked sequential components and (unclocked) arbitrary combinational logic gates can be partitioned into separate tasks each consisting of a sequential component with an associated network of combinational components. We present cost functions for evaluating a task subject to probabilistic assumptions about the functioning of the circuits. The circuit evaluation method used in the simulation process is significant. We apply lazy evaluation, a demand-driven evaluation strategy in which signals in the circuit are evaluated on a 'need to do' basis, resulting in a considerable saving in circuit simulation time. We achieve distributed logic simulation using a network of workstations and show from experimental results that by using such a configuration, we essentially obtain a single computation engine which can be used to obtain speedups in circuit simulation when compared with uniprocessor simulation systems. Interprocess communications between tasks on different workstations proceed via remote procedure calls while local communications between tasks take place via shared memory. The method of partitioning used in the circuit model ensures that communications between tasks take place only at defined times in the simulation sequence.


#*Nature's way of optimizing
#@Stefan Boettcher,Allon Percus
#t2000
#cArtificial Intelligence
#index295016


#*Corporate Governance, Takeovers, and Top-Management Compensation: Theory and Evidence
#@Richard M. Cyert,Sok-Hyon Kang,Praveen Kumar
#t2002
#cManagement Science
#index301165
#!We examine, both theoretically and empirically, top-management compensation in the presence of agency conflicts when shareholders have delegated governance responsibilities to a self-interested Board of Directors (BOD). We develop a theoretical framework that explicitly incorporates the BOD as a strategic player, models the negotiation process between the CEO and the BOD in designing CEO compensation, and considers the impact of potential takeovers by large shareholders monitoring the CEO-BOD negotiations. In equilibrium, internal governance by the BOD and external takeover threats by a large shareholder act as substitutes in imposing managerial control, especially in constraining management's profligacy in awarding equity-based compensation to itself. The model emphasizes factors in the design of compensation contracts that are rarely considered in the literature, such as equity ownership of the largest outside shareholder and the firm's bankruptcy risk. It also provides new perspectives on factors that are often considered in the literature, such as firm size, firm performance, equity ownership of the BOD, and BOD structure. Our empirical tests lend considerable support for our theoretical predictions. Equity ownership of the largest external shareholder, that of the BOD, and the default risk, are strongly negatively related to the size of CEO equity compensation. Consistent with the theoretical model, these factors do not significantly influence the growth of fixed (or non-performance-related) compensation. We also find that the equity ownership of the BOD is more important in managerial compensation control than other BOD related variables, such as BOD size or the proportion of outside directors.


#*Tighter constant-factor time hierarchies
#@Amir M. Ben-Amram
#t2003
#cInformation Processing Letters
#index113756
#%325481
#%222640
#%376619
#!For certain computational models, a constant-factor time hierarchy theorem is known, showing that a constant-factor difference in time bounds makes a difference in problem-solving power (unlike the situation with Turing machines). In this paper we apply the classic "translational technique" (padding) to these hierarchies and show that they are tighter than indicated by the previous proofs.


#*Primal-dual Newton-type interior-point method for topology optimization
#@R. H. W. Hoppe,S. I. Petrova,V. Schulz
#t2002
#cJournal of Optimization Theory and Applications
#index442465
#%241165
#%333886
#%480265
#%485097
#%582662
#%508649
#!We consider the problem of minimization of energy dissipation in a conductive electromagnetic medium with a fixed geometry and a priori given lower and upper bounds for the conductivity. The nonlinear optimization problem is analyzed by using the primal-dual Newton interior-point method. The elliptic differential equation for the electric potential is considered as an equality constraint. Transforming iterations for the null space decomposition of the condensed primal-dual system are applied to find the search direction. The numerical experiments treat two-dimensional isotropic systems.


#*Incremental construction properties in dimension two: shellability, extendable shellability and vertex decomposability
#@Sonoko Moriyama,Fumihiko Takeuchi
#t2003
#cDiscrete Mathematics
#index556194
#%582834
#!We give new examples of shellable, but not extendably shellable two-dimensional simplicial complexes. They include minimal examples that are smaller than those previously known. We also give new examples of shellable, but not vertex decomposable two-dimensional simplicial complexes, including extendably shellable ones. This shows that neither extendable shellability nor vertex decomposability implies the other. We found these examples by enumerating shellable two-dimensional simplicial complexes that are not pseudomanifolds.


#*Beginning Red Hat Linux 8.1
#@
#t2003
#c
#index5064


#*On-the-fly layout generation for PTL macrocells
#@L. Macchiarulo,L. Benini,E. Macii
#t2001
#cProceedings of the conference on Design, automation and test in Europe
#index332677
#%75054
#%79403
#%283579
#%596474


#*Support for teaching formal methods
#@Vicki L. Almstrum,C. Neville Dean,Don Goelman,Thomas B. Hilburn,Jan Smith
#t2001
#cACM SIGCSE Bulletin
#index241195
#%279510
#%261717
#%441984
#%279693
#%439409
#%440420
#%253659
#%537583
#%371882
#!This report describes a growth path for the area referred to as formal methods within the computing education community. We define the term formal methods and situate it within our field by highlighting its role in Computing Curricula 1991, Computing Curricula 2001, and the SoftWare Engineering Body Of Knowledge (SWEBOK). The working group proposes an enhancement to an existing web resource, which is a rich collection of materials and links related to formal methods. The new resource is designed to provide a bridge between the general computing education community and the formal methods community. The goal is to allow the latter to provide useful support for the former for the ultimate benefit of all of our students. Eventually, the working group aspires to see the concepts of formal methods integrated seamlessly into the computing curriculum so that it is not necessary to separate them in our discussions.


#*A Case Study of Emergent and Intentional Organizational Change: Some Implications for Customer Relationship Management Success
#@Carl-Erik Wikström
#t2004
#cProceedings of the Proceedings of the 37th Annual Hawaii International Conference on System Sciences (HICSS'04) - Track 7 - Volume 7
#index312314
#!The shift from a product-oriented business strategy to a customer-focused one has been a major change agent in companies recently. Many companies have invested heavily in technologies enabling a customer-focused relationship marketing strategy. However, there are mixed results as to how successful firms have been in implementing customer relationshipmanagement systems. The challenge of managing organizational change has been raised as a potential factor affecting the successful outcome of CRM efforts. Our argument is that the proposed relationship between CRM success and organizational change should be made more explicit in order to thoroughly investigate this challenge. Our paper contributes to this by presenting the results of an exploratory single case study. We identified several change events on different observational levels. Our findings suggest that to succeed, one should first identify both emergent and planned change processes. Then one could evaluate, whether change events - triggered by these processes - might effect one another in a way which could endanger the successful CRM implementation outcome.


#*A proposed new high level abstraction for computer technology
#@S. P. Maj,D. Veal,R. Duley
#t2001
#cACM SIGCSE Bulletin
#index313600
#%92695
#%209972
#%213706
#%219059
#%281794
#%526976
#%440924
#%484276
#%611234
#%602759
#%583739
#%509470
#%541987
#!Computer technology can be described using a range of models based on different levels of detail e.g. semiconductors, transistors, digital circuits. Such models are designed to progressively hid irrelevant detail and yet provide sufficient information to be useful for communication, design and documentation. However, developments in computer technology have resulted in a low cost, heterogeneous modular architecture that is difficult to model using current methods. This paper proposes a new generic method of modeling computer technology at a higher level of abstraction than those currently used. Investigations to date indicate that this model is independent of architectural detail and can therefore accommodate changes in technology. This new model is more directly relevant to the cheap, low-cost modular architectures in use today. Furthermore, all work to date has strongly indicated it may be useful as the basis of a new pedagogical framework for teaching not only introductory but also more advanced computer technology.


#*Factoring Polynominals over Finite Fields and Stable Colorings of Tournaments
#@Qi Cheng,Ming-Deh A. Huang
#t2000
#cProceedings of the 4th International Symposium on Algorithmic Number Theory
#index573339


#*Modelling for Added Value, 1st edition
#@R. Paul,S. Warwick,Devarajan Anketell,B. Lehaney
#t2001
#c
#index230805


#*Windows 2000 Programming from the Ground Up, 1st edition
#@Herbert Schildt
#t2000
#c
#index231766
#!:Build robust, peak-performance Windows 2000 programs - component by component. In Windows 2000 Programming from the Ground Up, expert programmer Herb Schildt explains how to take advantage of all the enhanced features of Microsoft's new operating system. By following the hands-on example, you'll learn to create menus and dialog boxes, use controls, handle multithreaded multitasking, develop DLLs, create screen savers, and much, much more. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Repetition Complexity of Words
#@Lucian Ilie,Sheng Yu,Kaizhong Zhang
#t2002
#cProceedings of the 8th Annual International Conference on Computing and Combinatorics
#index267897


#*Scheduling and Load Balancing
#@Maciej Drozdowski,Ioannis Milis,Larry Rudolph,Denis Trystram
#t2002
#cProceedings of the 8th International Euro-Par Conference on Parallel Processing
#index275628


#*TAIT Exploring GO 2003 Training CD
#@
#t2004
#c
#index14665


#*Phase equilibria in transition metal Al-Ga-N systems and thermal stability of cantacts to AlGaN
#@K. O. Schweitz,S. E. Mohney
#t2001
#cJournal of Electronic Materials
#index320011


#*Performance Analysis of a GI-G-1 Preemptive Resume Priority Buffer
#@Joris Walraevens,Bart Steyaert,Herwig Bruneel
#t2002
#cProceedings of the Second International IFIP-TC6 Networking Conference on Networking Technologies, Services, and Protocols; Performance of Computer and Communication Networks; and Mobile and Wireless Communications
#index271450


#*Consequence and Complexity in Infinite-Valued Logic: A Survey
#@Vincenzo Marra,Daniele Mundici
#t2002
#cProceedings of the 32nd International Symposium on Multiple-Valued Logic
#index121616
#!In general, every logic L comes equipped with a syntax, consisting of a finite set A of symbols, calledthe alphabet, and an inductive definition of whichstrings over A are to be called formula of L;a semantics, telling the meaning of each formula,whence in particular, telling when two formula areequivalent;an algorithmic procedure whereby, given a finite setF of formula, one can in principle obtain all conse-quencesof F.In certain fortunate cases-e.g., in classical logic-formulaup to equivalence form an interesting class of algebraicstructures. The infinite-valued calculus of £ukasiewicz issuch a fortunate case. Our aim in this paper is to reviewsemantic-algorithmic issues for this logic, with particularreference to recent research.


#*Response to Adler, "Market, Hierarchy, and Trust"
#@Charles Heckscher
#t2001
#cOrganization Science
#index556916


#*Spatial relationship between Chelungpu Fault and damaged building areas
#@Feng-Tyan Lin
#t2000
#cJournal of the Chinese Institute of Engineers
#index331980


#*Hewlett-Packard Official Pocket PC Handbook
#@Dan Hanttula
#t2000
#c
#index625401
#!:No matter what brand or model Pocket PC you own, this official HP guide delivers all the information you need to make the most of it, from guidance on basic applications to advice on advanced customization. Get up to speed fast on interface and stylus basicsMaximize Pocket Outlook and Pocket OfficeGet more out of music files and e-booksSync your Pocket PC with your desktop PCGet the scoop on wireless and Internet optionsZero in on the best third-party softwareFind solutions to memory and power challenges Complete with Internet resource listings, technical specifications, a glossary and more, this authoritative guide is just what you need to turbocharge your Pocket PC. The handbook also includes a unique twenty page "FAQ and Troubleshooting" appendix that provides solutions to typical Pocket PC problems. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*C++ Tutorial and Programmer's Guide, 2nd edition
#@Paul Verger
#t2000
#c
#index613958


#*The parallel video server SESAME-KB
#@Klaus Breidler,Harald Kosch,László Bözörményi
#t2000
#cDistributed and parallel systems: from instruction parallelism to cluster computing
#index330941


#*Manipulation of Java agent bytecode to add roles
#@Giacomo Cabri,Luca Ferrari,Letizia Leonardi
#t2003
#cProceedings of the 2nd international conference on Principles and practice of programming in Java
#index304372
#%266898
#%315937
#%363947
#!Roles are a powerful paradigm to develop distributed applications based on agents, especially when they are in need of interacting with other entities. An agent-oriented approach requires that roles are conceived as first-class entities, and at the same time that roles are dynamically embedded into agents at runtime. In this paper we propose an approach that addresses such requirements, enabling Java agents to dynamically assume roles. We present a mechanism that modifies the agent bytecode to add the role features.


#*The Two Faces of Lattices in Cryptology
#@Phong Q. Nguyen,Jacques Stern
#t2001
#cRevised Papers from the International Conference on Cryptography and Lattices
#index562182


#*Cyberbride: The Complete Online Guide to Planning Your Wedding
#@Denise Fields,Alan Fields
#t2000
#c
#index239537
#!:The Internet offers brides and grooms great wedding deals, the ease of online gift registry, and expert wedding advice for free. Denise and Alan Fields, dubbed the "wedding watchdogs" after the phenomenal success of their Bridal Bargains, show even technical neophytes where to find it all. They've discovered how to surf the Net for discounts on wedding invitations, how to order wedding flowers online directly from growers, how to download free wedding planning software, and much more, rating and ranking the best sites along the way.


#*Immanants and finite point processes
#@Persi Diaconis,Steven N. Evans
#t2000
#cJournal of Combinatorial Theory Series A
#index321423


#*PeerSpaces: data-driven coordination in peer-to-peer networks
#@Nadia Busi,Cristian Manfredini,Alberto Montresor,Gianluigi Zavattaro
#t2003
#cProceedings of the 2003 ACM symposium on Applied computing
#index313073
#%164088
#%299709
#%621355
#!Shared dataspaces &agrave; la Linda, and the underlying data-driven coordination model, have been successfully exploited in the development of a huge variety of applications, going from parallel computing to web-based collaborative work. In this paper we consider a novel class of applications, namely those developed for peer-to-peer networks &agrave; la Gnutella or FreeNet. We discuss the problems which arise when trying to exploit the original Linda coordination model in this new scenario. In order to address these problems, we introduce PeerSpaces, a new coordination model particularly suited for the realm of peer-to-peer network applications, and we present a prototypical implementation of this coordination model based on the JXTA peer-to-peer technology.


#*DSpace: An Institutional Repository from the MIT Libraries and Hewlett Packard Laboratories
#@MacKenzie Smith
#t2002
#cProceedings of the 6th European Conference on Research and Advanced Technology for Digital Libraries
#index276513


#*Note on nonsymmetric finite differences for Maxwell's equations
#@Tobin A. Driscoll,Bengt Fornberg
#t2000
#cJournal of Computational Physics
#index333326


#*Using support vector machines in data mining
#@Richard A. Wasniowski
#t2004
#cProceedings of the 4th WSEAS International Conference on Systems Theory and Scientific Computation
#index36474
#%510766
#%530377
#%586607
#!Multivariate data analysis techniques have the potential to improve data analysis. Support Vector Machines (SVS) are a recent addition to the family of multivariate data analysis. A brief introduction to the SVM Vector Machines technique is followed by an outline of the practical application.


#*Alternative representations and abstractions for moving sensors databases
#@J. Eisenstein,S. Ghandeharizadeh,C. Shahabi,G. Shanbhag,R. Zimmermann
#t2001
#cProceedings of the tenth international conference on Information and knowledge management
#index620638
#%89365
#%124221
#%282802
#%284934
#%325370
#%356468
#%585504
#!Moving sensors refers to an emerging class of data intensive applications that inpacts disciplines such as communication, health-care, scientific applications, etc. These applications consist of a fixed number of sensors that move and produce streams of data as a function of time. They may require the system to match these streams against stored streams to retrieve relevant data (patterns). With communication, for example, a speaking impaired individual might utilize a haptic glove that translates hand signs into written (spoken) words. The glove consists of sensors for different finger joints. These sensors report their location and values as a function of time, producing streams of data. These streams are matched against a repository of spatio-temporal streams to retrieve the corresponding English character or word.The contributions of this study are two fold. First, it introduces a framework to store and retrieve "moving sensors" data. The framework advocates physical data independence and software-reuse. Second, we investigate alternative representations for storage and retrieve of data in support of query processing. We quantify the tradeoff associated with these alternatives using empirical data RoboCup soccer matches.


#*How Does the Brain Discriminate Familiar and Unfamiliar Faces?: A PET Study of Face Categorical Perception
#@Bruno Rossion,Christine Schiltz,Laurence Robaye,David Pirenne,Marc Crommelinck
#t2001
#cJournal of Cognitive Neuroscience
#index32914
#!Where and how does the brain discriminate familiar and unfamiliar faces? This question has not been answered yet by neuroimaging studies partly because different tasks were performed on familiar and unfamiliar faces, or because familiar faces were associated with semantic and lexical information. Here eight subjects were trained during 3 days with a set of 30 faces. The familiarized faces were morphed with unfamiliar faces. Presented with continua of unfamiliar and familiar faces in a pilot experiment, a group of eight subjects presented a categorical perception of face familiarity: there was a sharp boundary in percentage of familiarity decisions between 40% and 60% faces. In the main experiment, subjects were scanned (PET) on the fourth day (after 3 days of training) in six conditions, all requiring a sex classification task. Completely novel faces (0%) were presented in Condition 1 and familiar faces (100%) in Condition 6, while faces of steps of 20% in the continuum of familiarity were presented in Conditions 2 to 5 (20% to 80%). A principal component analysis (PCA) indicated that most variations in neural responses were related to the dissociation between faces perceived as familiar (60% to 100%) and faces perceived as unfamiliar (0 to 40%). Subtraction analyses did not disclose any increase of activation for faces perceived as familiar while there were large relative increases for faces perceived as unfamiliar in several regions of the right occipito-temporal visual pathway. These changes were all categorical and were observed mainly in the right middle occipital gyrus, the right posterior fusiform gyrus, and the right inferotemporal cortex. These results show that (1) the discrimination between familiar and unfamiliar faces is related to relative increases in the right ventral pathway to unfamiliar/novel faces; (2) familiar and unfamiliar faces are discriminated in an all-or-none fashion rather than proportionally to their resemblance to stored representations; and (3) categorical perception of faces is associated with abrupt changes of brain activity in the regions that discriminate the two extremes of the multidimensional continuum.


#*Integration of the FreeBSD TCP/IP-stack into the discrete event simulator OMNet++
#@Roland Bless,Mark Doll
#t2004
#cProceedings of the 36th conference on Winter simulation
#index28264
#!The discrete event simulator OMNeT++, that is programmed in C++, shows a steady growing popularity. Due to its well-structured nature, it is easy to understand and easy to use. A shortcoming of it, however, is the limited number of available simulation models. Especially, for network simulations a validated TCP implementation was missing. In order to avoid a re-implementation of a full-featured TCP, including all potential implementation errors and costly validation tests, we integrated a TCP/IP stack of a real operating system into OMNeT++. In this paper we show that such a port is feasible with reasonable effort and we describe difficulties of the integration process as well as the applied solutions. We also present some evaluation results that outline memory and CPU usage.


#*Addressing the IT skills crisis (panel session): gender and the IT profession
#@Sue Nielsen,Eileen M. Trauth,Viswanath Venkatesh
#t2000
#cProceedings of the twenty first international conference on Information systems
#index317715
#%217004
#%263972
#%279734


#*A Direct Interpretation of Dynamic Images with Camera and Object Motions for Vision Guided Robot Control
#@Koichiro Deguchi
#t2000
#cInternational Journal of Computer Vision
#index322453
#%514588
#!A general scheme to represent the relation between dynamic images and camera and/or object motions is proposed for applications to visual control of robots. We consider the case where a moving camera observes moving objects in a static scene. The camera obtains images of the objects moving within the scene. Then, the possible combinations of the camera and the objects' poses and the obtained images are not arbitrary but constrained to each other. Here we represent this constraint as a lower dimensional hypersurface in the product space of the whole combination of their motion control parameters and image data. The visual control is interpreted as to find a path on this surface leading to their poses where a given goal image will be obtained. In this paper, we propose a visual control method to utilize tangential properties of this surface. First, we represent images with a composition of a small number of &ldquo;eigen images&rdquo; by using K-L (Karhunen-Lo&egrave;ve) expansion. Then, we consider to reconstruct the eigen space (the eigen image space) to achieve efficient and straightforward controls. Such reconstruction of the space results in the constraint surface being mostly flat within the eigen space. By this method, visual control of robots in a complex configuration is achieved without image processing to extract and correspond image features in dynamic images. The method also does not need camera or hand-eye calibrations. Experimental results of visual servoing with the proposed method show the feasibility and applicability of our newly proposed approach to a simultaneous control of camera self-motion and object motions.


#*The importance of learning styles in group design work
#@K. Carrizosa
#t2000
#cProceedings of the 30th Annual Frontiers in Education - Volume 01
#index418455
#!Effective communication between engineering design team members is essential. It depends on the successful transfer (sending, receiving and processing) of information. This information may range from data and facts to creative ideas. Recent work by R. Felder and L. Silverman (1988) has shown that individuals differ from one another in how they prefer to receive and process information. In this paper, we look at the relationship between individuals' preference for receiving information and their methods of sending information. It was initially anticipated that each individual's mode of presenting information would match his or her preferred mode of receiving information, and that this match would result in improved communication. To study the congruency (or incongruency) of how individuals prefer to receive information and how they go about sending information, an experiment was designed and conducted. The experiment consisted of four teams of engineering educators engaged in a design exercise. Their design activities were videotaped. Results based on analysis of the tapes and individual learning styles inventories showed that most participants preferred to receive information visually and engaged in drawing very little during the design exercise. If the definition was expanded to include using drawings, communicative gesturing (i.e. using hand gestures to describe a physical object or action), using hardware and referencing hardware, then visual communication went from comprising an average of 3.8% of the design time to an average of 21.1% of the design time.


#*Cooperative Navigation in Multimedia Systems
#@Maxime Wack,Nathanael Cottin,Rachid Bouyekhf
#t2002
#cProceedings of the Worshops XMLDM, MDDE, and YRWS on XML-Based Data Management and Multimedia Engineering-Revised Papers
#index355256


#*Applicability of ABR Service to Internet Applications
#@Mika Ishizuka
#t2000
#cProceedings of the 5th IFIP TC6 International Symposium on Next Generation Networks, Networks and Services for the Information Society
#index264055


#*Intersubband absorption characteristics in OMVPE grown delta-doped GaAs/AIGAs multiple quantum well structures
#@Charles R. Lutz,Jason Kanaley,Kei May Lau
#t2000
#cJournal of Electronic Materials
#index285896


#*DyRecT: Software Support for Adaptive Parallelism on NOWs
#@Etienne Godard,Sanjeev Setia,Elizabeth L. White
#t2000
#cProceedings of the 15 IPDPS 2000 Workshops on Parallel and Distributed Processing
#index373564


#*Object Request Brokers in Mobile Computing
#@Attila Ulbert
#t2003
#cWireless Personal Communications: An International Journal
#index555929
#!The widespread use of wireless and mobile networks and devices requires special programming techniques and solutions. The object request brokers of mobile environments have to adopt these techniques and offer services dealing with the problems of mobility. Most of the existing object request brokers however were developed for fixed networks assuming reliable transport protocols (mostly TCP), while the mobile networks cannot offer high quality transport. In this paper we give an overview of the challenges and solutions in mobile computing and present our ORB(M) framework implementing services based on the solutions. Extending the framework doesn't require the assistance of its developers, the user can implement application-specific semantic elements and deploy various new methods bound to the process of remote invocation. The user can form arbitrary new invocation semantics based on these elements and customise the invocation semantics used by a given method. Our new mobility-related semantic elements offer solutions to the challenges of mobility allowing the user to concentrate on the essential problems of the application and handling.


#*The Linux Softsynth roundup
#@Dave Phillips
#t2003
#cLinux Journal
#index566326
#!Whether you want to emulate a vintage synthesizer or create a totally new sound, there's software to help make it happen.


#*Segment Match Refinement and Applications
#@Aaron L. Halpern,Daniel H. Huson,Knut Reinert
#t2002
#cProceedings of the Second International Workshop on Algorithms in Bioinformatics
#index357442


#*Existence of limit cycles of impulsive differential equations with impulses at variable times
#@Jiangang Qi,Xilin Fu
#t2001
#cNonlinear Analysis: Theory, Methods Applications
#index314085


#*Evolution not Revolution: The Data Warehousing Strategy at Credit Suisse Financial Services
#@Markus Tresch,Dirk Jonscher
#t2001
#cProceedings of the 13th International Conference on Advanced Information Systems Engineering
#index381195


#*A hypertext metric based on huffman coding
#@Chris Coulston,Theresa M. Vitolo
#t2001
#cProceedings of the 12th ACM conference on Hypertext and Hypermedia
#index608906
#!Current research has established a relationship between user navigation behavior and outcome measures. This paper presents a metric designed to compare the depth of user navigation against a theoretically optimum behavior; measured using Huffman codes. The application of the metric to an example problem is presented.


#*Longitudinal elasticity modulus of sintered powder test pieces
#@Mariana Arghir
#t2000
#cSystems Analysis Modelling Simulation
#index332686


#*Automatically editing book reviews on the web
#@Koji Eguchi,Shigeki Sugita
#t2001
#cProceedings of the 3rd international workshop on Web information and data management
#index607641
#%250081
#%296500
#%329493
#!A large amount of book information lies scattered on the Web. It is written in non-standard forms, as is other Web information, and this imposes a heavy load on a user browsing search results. We propose an automatic editing method that assists users to retrieve book information, especially book reviews scattered on the Web. Our proposed system retrieves the bibliographic information of a user-specified book using a library catalog database. Using this, it retrieves book reviews on the Web, which are then automatically edited using some heuristic rules for segment extraction, filtering and sorting according to a semantic likelihood of their being book reviews, and are finally presented in tables to the users. We implemented a prototype system and performed a preliminary evaluation of its effectiveness by experiment.


#*Biochemical reactions on helical structures
#@D. A. Edwards
#t2000
#cSIAM Journal on Applied Mathematics
#index327491


#*Solving the binding problem of the brain with bi-directional functional connectivity
#@Masataka Watanabe,Kousaku Nakanishi,Kazuyuki Aihara
#t2001
#cNeural Networks
#index238070


#*On the Linear Complexity of the Naor&ndash;Reingold Pseudo-random Function from Elliptic Curves
#@Igor E. Shparlinski,Joseph H. Silverman
#t2001
#cDesigns, Codes and Cryptography
#index245970
#%95534
#%121409
#!We show that the elliptic curve analogue of the pseudo-random number function, introduced recently by M. Naor and O. Reingold, produces a sequence with large linear complexity. This result generalizes a similar result of F. Griffin and I. E. Shparlinski for the linear complexity of the original function of M. Naor and O. Reingold. The proof is based on some results about the distribution of subset-products in finite fields and some properties of division polynomials of elliptic curves.


#*Adaptive techniques for unstructured nested meshes
#@Miguel A. Padrón,José P. Suárez,Ángel Plaza
#t2004
#cApplied Numerical Mathematics
#index3916
#%255101
#%331456
#%298111
#%88296
#%593482
#%292077
#%520650
#!The purpose of this paper is twofold. First we introduce improved versions of our algorithms for refining and coarsening 2D and 3D nested triangular and tetrahedral grids, and secondly the application of these algorithms in the simulation of 2D and 3D problems, is demonstrated. A key idea of the algorithms is the use of the topological concept of the skeleton of a triangulation in two or three dimensions in order to reduce the dimension of the refinement problem in a natural hierarchic manner.Improved skeleton based refinement (SBR) algorithms and their counterpart, the skeleton based derefinement (SBD) algorithms are described in this study. The algorithms are fully automatic and are applied here to a 2D boundary value problem, a 3D approximation problem with a large gradient, a geometric shape modeling problem and a simulation evolution problem in 3D.


#*Using Hard Classifiers to Estimate Conditional Class Probabilities
#@Ole Martin Halck
#t2002
#cProceedings of the 13th European Conference on Machine Learning
#index380654


#*BER performance of DS-CDMA/EGC system in Nakagami fading channel
#@Y. W. Cao,C. C. Ko,T. T. Tjhung
#t2002
#cProceedings of the The 8th International Conference on Communication Systems - Volume 02
#index429110
#!In this paper, performance of DS-CDMA/EGC system over Nakagami fading channel is investigated. By making using of the infinite series proposed by Beaulieu, a closed form of bit error rate (BER) performance for DS-CDMA/EGC system is derived. Numerical results show that the BER performance of DS-CDMA/EGC is inferior to that of DS-CDMA/MRC, generally with a difference of 1-3 dB. However, DS-CDMA/EGC is still attractive due to its advantage of lower complexity of receiver compared to DS-CDMA/MRC.


#*A Semantic Model for Hypertext Data Caching
#@Kai Cheng,Yahiko Kambayashi
#t2002
#cProceedings of the 21st International Conference on Conceptual Modeling
#index257023


#*Transcript Mapping for Historic Handwritten Document Images
#@Catalin I. Tomai,Bin Zhang,Venu Govindaraju
#t2002
#cProceedings of the Eighth International Workshop on Frontiers in Handwriting Recognition (IWFHR'02)
#index122837
#!There is a large number of scanned historical documents that need to be indexed for archival and retrieval purposes. A visual word spotting scheme that would serve these purposes is a challenging task even when the transcription of the document image is available. We propose a framework for mapping each word in the transcript to the associated word image in the document. Coarse word mapping based on document constraints is used for lexicon reduction. Then, word mappings are refined using word recognition results by a dynamic programming algorithm that finds the best match while satisfying the constraints.


#*Executable Uml: How to Build Class Models
#@Leon Starr
#t2001
#c
#index236808
#!From the Book:Author's prefaceThis book is a collection of models, modeling tips and analysis techniques that have worked for me (and my colleagues) on real projects.It conveys the experience that I have gained in 15 years of buildingexecutable object-oriented models. I have written this book for especially for those of you who have already had an introduction to anexecutable, translation-driven modeling method such as ExecutableUML or the Shlaer-Mellor method. I presume that you are eitherabout to start applying Executable UML on your project or that youhave been building executable models for a year or two. This text isgeared toward those of you who do the hard work of boiling downapplication requirements, formalizing these requirements into fullydetailed models, and getting those models translated into workingsoftware.This book is not a complete statement or grammar of the Executable UML language. For that please see Steve Mellor's text listed inthe "Where to learn more" section at the back of thebook. Instead, I show you some of the ways that I use important features of the object modeling language. I also provide some guidancein how to deal with a few thorny issues.Experience on multiple projects has taught me many things. One ofthe most important lessons is that you can't skimp on the class models and get away with it. You must ensure that your applicationrequirements are thoroughly captured, in great detail, in your classmodels. This takes time and hard work. Whenever my colleaguesand I have cut corners we have run afoul of the following consequences: (1) the state charts become ridiculously complex; (2) oneor two critical requirements lie hidden untillate in the modelingprocess, leading to time-consuming rework; and (3) new requirements that should have been anticipated arise late in the modelingprocess and wreak havoc. On the other hand, a good class modelleads to stable state models and simple threads of control. This bookfocuses on the key to success: building quality class models.Like most of us, coming originally from a function-oriented programming background, learning to build class models has been challenging to say the least. I've noticed that engineers new to object-oriented analysis grapple with many of the same questions that Idid: What model structures are legal? (Can I do that with a generalization relationship?) How much detail should go into the classmodel? How do I build a model that won't fall apart when therequirements change? What's the difference between a good classmodel and a bad class model? Why do I need to write modeldescriptions? What's the best way to express an association involvinga specific number of instances (not 0, 1 or *). What's the best way tomodel a hierarchy of things? This book contains answers to thesequestions and many others.Another big key to success is to use your time effectively. A commonmistake is to spend too much time modeling and not enough timedoing analysis. Few software engineers appreciate the value of distinguishing the activities of analysis and modeling. I don't know howmany times I've seen a novice analyst spend hours building the perfect model to suit a set of perceived requirements. Later on therequirements change, or they turn out to be the wrong requirements, or they turn out to be based on some aspect of the systemthat is so volatile that no attempt to nail down the requirements canbe successful. As a consequence the whole model unravels. I wrotePart 2 of this book to show how this kind of disaster can be avoided.To become a good programmer, not only do you need to write a lotof code, but you also need to look at code written by other people.The same is true when it comes to analysis and modeling. Themodels in this book will give you something helpful to look at fromtime to time as you build lots of models. Have fun.Leon StarrSan Francisco, California


#*A new method for extracting EOT for leaky insulators
#@F. Chen,N. P. Hoilien,S. A. Campbell
#t2004
#cMicroelectronic Engineering
#index437764
#!A three-parameter model is developed and demonstrated for extracting the capacitance and parallel resistance for leaky capacitors. The technique combines dc and ac measurements tn extract these values. The range over which the measurement is valid varies with the device, but is readily determined with a simple measurement. For devices with the highest dc leakage, minority carrier injection into the substrate can substantially increase the measured capacitance. This is not an artifact of the measurement procedure, but a real parasitic effect that increases the gate capacitance.


#*Techniques to Tackle State Explosion in Global Predicate Detection
#@Sridhar Alagar,Subbarayan Venkatesan
#t2001
#cIEEE Transactions on Software Engineering
#index617470
#%189520
#%270682
#%319217
#%359495
#%511328
#%544263
#%583297
#%602539
#!Global predicate detection, which is an important problem in testing and debugging distributed programs, is very hard due to the combinatorial explosion of the global state space. This paper presents several techniques to tackle the state explosion problem in detecting whether an arbitrary predicate $\Phi$ is true at some consistent global state of a distributed system. We present space efficient on-line algorithms for detecting $\Phi$. We then improve the performance of our algorithms, both in space and time, by increasing the granularity of the execution step from an event to a sequence of events in each process.


#*Canonical abstraction for outerjoin optimization
#@Jun Rao,Hamid Pirahesh,Calisto Zuzarte
#t2004
#cProceedings of the 2004 ACM SIGMOD international conference on Management of data
#index437305
#%124226
#%209295
#%238776
#%331712
#%361364
#%366547
#%562162
#!Outerjoins are an important class of joins and are widely used in various kinds of applications. It is challenging to optimize queries that contain outerjoins because outerjoins do not always commute with inner joins. Previous work has studied this problem and provided techniques that allow certain reordering of the join sequences. However, the optimization of outerjoin queries is still not as powerful as that of inner joins.An inner join query can always be canonically represented as a sequence of Cartesian products of all relations, followed by a sequence of selection operations, each applying a conjunct in the join predicates. This canonical abstraction is very powerful because it enables the optimizer to use any join sequence for plan generation. Unfortunately, such a canonical abstraction for outerjoin queries has not been developed. As a result, existing techniques always exclude certain join sequences from planning, which can lead to a severe performance penalty.Given a query consisting of a sequence of inner and outer joins, we, for the first time, present a canonical abstraction based on three operations: outer Cartesian products, nullification, and best match. Like the inner join abstraction, our outerjoin abstraction permits all join sequences, and preserves the property of both commutativity and transitivity among predicates. This allows us to generate plans that are very desirable for performance reasons but that couldn't be done before. We present an algorithm that produces such a canonical abstraction, and a method that extends an inner-join optimizer to generate plans in an expanded search space. We also describe an efficient implementation of the best match operation using the OLAP functionalities in SQL:1999. Our experimental results show that our technique can significantly improve the performance of outerjoin queries.


#*Extending electronic catalogs for supply chain management
#@Aryya Gangopadhyay
#t2000
#cProceedings of the 2000 information resources management association international conference on Challenges of information technology management in the 21st century
#index317152


#*Extrapolation methods and derivatives of limits of sequences
#@Avram Sidi
#t2000
#cMathematics of Computation
#index285914


#*An automatic configuration system for handwriting recognition problems
#@Cara O'Boyle,Barry Smyth,Franz Geiselbrechtinger
#t2000
#cProceedings of the 13th international conference on Industrial and engineering applications of artificial intelligence and expert systems: Intelligent problem solving: methodologies and approaches
#index324230


#*Polynomial Interpolation of the Elliptic Curve and XTR Discrete Logarithm
#@Tanja Lange,Arne Winterhof
#t2002
#cProceedings of the 8th Annual International Conference on Computing and Combinatorics
#index276947


#*Finding Double Euler Trails of Planar Graphs in Linear Time
#@Zhi-Zhong Chen,Xin He,Chun-Hsi Huang
#t2002
#cSIAM Journal on Computing
#index253235
#!This paper answers an open question in the design of complimentary metal-oxide semiconductor VLSI circuits. The question asks whether a polynomial-time algorithm can decide if a given planar graph has a plane embedding ${\cal E}$ such that ${\cal E}$ has an Euler trail P = e1 e2 ... em and its dual graph has an Euler trail $P^*=e^*_1 e^*_2 \ldots e^*_m$, where $e^*_i$ is the dual edge of ei for i=1,2,...,m. This paper answers this question in the affirmative by presenting a linear-time algorithm.


#*Pokémon Ruby & Sapphire Official Trainer's Guide
#@Phillip Marcus
#t2003
#c
#index7961


#*Expertise recommender: a flexible recommendation system and architecture
#@David W. McDonald,Mark S. Ackerman
#t2000
#cProceedings of the 2000 ACM conference on Computer supported cooperative work
#index329949
#%83725
#%88615
#%95572
#%522573
#%469423
#%511327
#%594020
#%601015
#%586599
#!Locating the expertise necessary to solve difficult problems is a nuanced social and collaborative problem. In organizations, some people assist others in locating expertise by making referrals. People who make referrals fill key organizational roles that have been identified by CSCW and affiliated research. Expertise locating systems are not designed to replace people who fill these key organizational roles. Instead, expertise locating systems attempt to decrease workload and support people who have no other options. Recommendation systems are collaborative software that can be applied to expertise locating. This work describes a general recommendation architecture that is grounded in a field study of expertise locating. Our expertise recommendation system details the work necessary to fit expertise recommendation to a work setting. The architecture and implementation begin to tease apart the technical aspects of providing good recommendations from social and collaborative concerns.


#*Access Control Method with Variable Retransmission Probability in Ad-Hoc networks and Its consideration of the Changing Point
#@Yosuke Nakamura,Xuejun Tian,Tetsuo Ideguchi,Takashi Okuda
#t2004
#cProceedings of the Database and Expert Systems Applications, 15th International Workshop
#index437413
#!Ad-Hoc networks do not need infrastructures such as a base station and it is an interested technology. One of the important subjects of Ad-Hoc networks is an access control method in radio media. A control channel is usually used with a method of TDMA base. A big influence is given to a performance of Ad-Hoc networks when a frequency channel zone is used as a method of TDMA base. We have already proposed the access control method that is called the Two Division Back off Algorithm (TDBA). This algorithm can solve collisions with a few overheads. But, this method has the problem that the success probability which a node acquires a channel decreases, when the number of the collision-nodes increases. This paper introduces a variable retransmission probability instead of a fixed retransmission probability. And the characteristic of performances is compared and evaluated. Then, as for the point as well that value is made to change, it is examined.


#*Highly Reliable Component-Based Software Development by Using Algebraic Behavioral Specification
#@Michihiro Matsumoto,Kokichi Futatsugi
#t2000
#cProceedings of the 3rd IEEE International Conference on Formal Engineering Methods
#index122480
#!Component-based software development in which software is developed by combining components and connectors has gained in popularity, because it can increase software productivity. To increase software productivity, components must be reused. However, to do so, we must select software architecture. We propose (1) new software architecture tree architecture. A special class of algebraic behavioral specification projection-style behavioral specification represents it. Recently, even component-based enterprise systems have developed. So, the importance of the technologies how to develop highly reliable component-based software has increased. We propose these technologies by using projection-style behavioral specification. One is (2) the technology that assures high reliability of connectors. Another is (3) the technology that assures consistency of software family evolution. The advantages of these technologies are that these can be automated.


#*Distributed and Concurrent Processing of Business Object Documents in Support of e-Enterprise Integration
#@Stanley Y. W. Su,Youzhong Liu,Jie Meng,Minsoo Lee,Herman Lam
#t2000
#cProceedings of the 4th International conference on Enterprise Distributed Object Computing
#index384271
#!The Internet and distributed object technologies have made it possible for different business enterprises to draw upon the best of their resources for conducting joint business as a virtual e-enterprise (VEE). To enable virtual e-enterprises, the integration of legacy applications and the modeling and enactment of concurrent business processes are necessary. The authors combine the features of the messaging approach and the distributed object approach to system integration. Business Object Documents (BOD) are used for transmitting business operations and data among application systems. Message transmission is supported by two underlying communication infrastructures: CORBA and Java RMI. The separation of messaging from communication infrastructure allows the underlying infrastructure to be changed without impacting application systems. Also, business processes are modeled as sequences or network structures of BOD transmissions. The process models are replicated at all sites and used by an extended information infrastructure to enable distributed, concurrent enactment of processes.


#*Message from the Program Chairs
#@
#t2004
#cProceedings of the 17th International Conference on VLSI Design
#index305700


#*A Foolish Consistency: Technical Challenges in Consistency Management
#@Anthony Finkelstein
#t2000
#cProceedings of the 11th International Conference on Database and Expert Systems Applications
#index567777


#*Switched-capacitor filters
#@Andrea Baschriotto
#t2000
#cThe VLSI handbook
#index297938


#*MCSE Windows 2000 Network Security Design: Training Guide: Exam 70-220 with Cdrom
#@Roberta Bragg
#t2000
#c
#index610848
#!:Exam 70-220, Designing Security for a Windows 2000 Network tests the skills required to analyze the business requirements for security and design a security solution that meets business requirements. Security includes controlling access to resources, auditing access to resources, authentication, and encryption. Ideal for you, professionals looking for comprehensive self-study materials to get you through the exam successfully. Years of publishing in theis category has shown us that the most asked-for type of study information comes in the comprehensive, study-at-your-own-pace package. New Riders Training Guides, with their objective coverage, emphasis on hands-on knowledge, and practice exams, are an ideal tool for this audience.


#*Digital System Clocking: High-Performance and Low-Power Aspects
#@Vojin G. Oklobdzija,Vladimir M. Stojanovic,Dejan M. Markovic,Nikola M. Nedovic
#t2003
#c
#index561412
#!:Provides the only up-to-date source on the most recent advances in this often complex and fascinating topic. The only book to be entirely devoted to clocking Clocking has become one of the most important topics in the field of digital system design. A "must have" book for advanced circuit engineers


#*Virtual shared memory for distributed architectures
#@Eva Kühn
#t2001
#c
#index562069


#*Asymptotic formulas for Melnikov integrals with application to a sliding Toggle block
#@Joseph Gruendler
#t2001
#cNonlinear Analysis: Theory, Methods Applications
#index324875


#*Video techniques
#@
#t2003
#cACM SIGGRAPH 2003 Sketches Applications
#index312436


#*Beyond Discrete E-Services: Composing Session-Oriented Services in Telecommunications
#@Vassilis Christophides,Richard Hull,Gregory Karvounarakis,Akhil Kumar,Geliang Tong,Ming Xiong
#t2001
#cProceedings of the Second International Workshop on Technologies for E-Services
#index260937


#*Some Specific e-Government Management Problems in a Transforming Country
#@Nicolae Costake
#t2002
#cProceedings of the First International Conference on Electronic Government
#index360986


#*Multilevel selection and the evolution of predatory restraint
#@Joshua Mitteldorf,David H. Croll,S. Chandu Ravela
#t2002
#cProceedings of the eighth international conference on Artificial life
#index117622
#!Individual selection favors that predator which can most efficiently turn its prey into increased reproductive capacity. But any species that becomes too successful in this game sows the seed of its own demise; for its progeny may be delivered into an environment where prey populations are depleted, and starvation a danger. From this danger derives a compensatory evolutionary pull toward moderation. The latter effect derives from a cost that is shared generally by the community that claims a common prey population. A widely accepted argument from classical evolutionary theory holds that the selective force of such group effects is likely to be weak and slow-acting compared to the efficiency of individual selection. We offer a numerical simulation in defiance of this wisdom, demonstrating how under general assumptions and a wide range of parameter values, predatory restraint may evolve as a group adaptation.


#*Cell-based multicast grouping in large-scale virtual environments (poster session) (extended abstract)
#@Emmanuel Léty,Thierry Turletti,François Baccelli
#t2000
#cProceedings of the 2000 ACM SIGMETRICS international conference on Measurement and modeling of computer systems
#index297305


#*Like water for data flow
#@Dineh M. Davis
#t2003
#cinteractions
#index445769
#!This issue's Whiteboard takes a bit of a different tack from past columns. Rather than exhorting us to follow process A or stop making mistake B, Dineh Davis immerses herself in the almost mystical idea of water as a metaphor for information. She envisions water as helping us understand and appreciate the diversity in humanity's relationships with information and its technology, enabling us to increase user participation in its development. Now, you may see some problems with this idea. But I'd say that they're, er, soluble.<br>---Elizabeth Buie


#*Proc SQL: Beyond the Basics Using SAS
#@Kirk Paul Lafler
#t2004
#c
#index12021


#*The Omni OpenMP Compiler on the Distributed Shared Memory of Cenju-4
#@Kazuhiro Kusano,Mitsuhisa Sato,Takeo Hosomi,Yoshiki Seo
#t2001
#cProceedings of the International Workshop on OpenMP Applications and Tools: OpenMP Shared Memory Parallel Programming
#index274137


#*Optimum beamformers for uniform circular arrays in a correlated signal environment
#@B. K. Lau
#t2000
#cProceedings of the Acoustics, Speech, and Signal Processing, 2000. on IEEE International Conference - Volume 05
#index415062
#!By virtue of their geometry, uniform circular arrays (UCAs) are ideally suited to provide 360 degrees of coverage in the azimuthal plane. However, in a correlated signal environment, the well-known technique of spatial smoothing to mitigate the signal cancellation effect as seen in an optimum beamformer will not work since this technique is applicable only to uniform linear arrays. We show how the transformation of Davies (1965) can be adopted to design optimum beamformers for UCAs in a correlated signal environment. We also introduce derivative constraints to improve the robustness of the optimum beamformers to mismatches between the beamformers' look direction and the actual direction-of-arrival of the desired signal. The effectiveness of our design method is illustrated by a numerical example.


#*Demonstrations session 1
#@
#t2004
#cProceedings of the 9th annual SIGCSE conference on Innovation and technology in computer science education
#index434728


#*Fully scalable fault-tolerant simulations for BSP and CGM
#@Sung-Ryul Kim,Kunsoo Park
#t2000
#cJournal of Parallel and Distributed Computing
#index321749


#*Efficient mechanisms for the supply of services in multi-agent environments
#@Nir Vulkan,Nicholas R. Jennings
#t2000
#cDecision Support Systems
#index283274


#*Prototyping Digital Library Technologies in zetoc
#@Ann Apps,Ross MacIntyre
#t2002
#cProceedings of the 6th European Conference on Research and Advanced Technology for Digital Libraries
#index275377


#*DVD transcoding via Linux metacomputing
#@F. J. Gonzalez-Castaño,R. Asorey-Cacheda,R. P. Martinez-Alvarez,F. Comesaña-Seijo,J. Vales-Alonso
#t2003
#cLinux Journal
#index306989
#!Strategies for converting MPEG-2 video from DVDs to MPEG-4 for next-generation home media applications.


#*Performance Analysis of R*-Trees with Arbitrary Node Extents
#@Yufei Tao,Dimitris Papadias
#t2004
#cIEEE Transactions on Knowledge and Data Engineering
#index403110
#!Existing analysis for R-trees is inadequate for several traditional and emerging applications including, for example, temporal, spatio-temporal, and multimedia databases because it is based on the assumption that the extents of a node are identical on all dimensions, which is not satisfied in these domains. In this paper, we propose analytical models that can accurately predict R*-tree performance without this assumption. Our derivation is based on the novel concept of extent regression function, which computes the node extents as a function of the number of node splits. Detailed experimental evaluation reveals that the proposed models are accurate, even in cases where previous methods fail completely.


#*Operations Research Trajectories: The Anglo-American Experience from the 1940s to the 1990s
#@Maurice W. Kirby
#t2000
#cOperations Research
#index559714
#!This paper is derived from the author's sponsored history of Operations Research in Britain from its formal inception in the later 1930s. It is inspired by the knowledge that any history of OR in Britain that ignores the interrelationship with OR in the United States would be grossly incomplete. This relates not only to the period of military collaboration in World War II but also to the profound influence on British operations researchers of American-derived techniques and methods. The Anglo-American perspective serves also to highlight major contrasts, as well as striking similarities in the development of OR in both countries. The paper advocates the need for ongoing research into the history of OR as an essential complement to the advancing frontier of knowledge, both in theory and in practice. Virtually all disciplines worthy of university-level study have their chroniclers, and this should apply with no less force to OR in the light of its impressive trajectory of development and early acknowledgment of its utilitarian value in a wide variety of settings in the public and private sectors.


#*On Augmenting Trace Cache for High-Bandwidth Value Prediction
#@Sang-Jeong Lee,Pen-Chung Yew
#t2002
#cIEEE Transactions on Computers
#index447451
#%76632
#%77269
#%77562
#%83477
#%85142
#%90104
#%121905
#%279057
#%282962
#%297195
#%524520
#!Value prediction is a technique that breaks true data dependences by predicting the outcome of an instruction and speculatively executes its data-dependent instructions based on the predicted outcome. As the instruction fetch rate and issue rate of processors increase, the potential data dependences among instructions issued in the same cycle also increase. Value prediction and speculative execution become critical to keep the issue rate high. Unfortunately, most of the proposed value prediction schemes focused only on the accuracy of the prediction. They have yet to consider the bandwidth required to access the value prediction tables. In this paper, we focus on the bandwidth issues of the value prediction. We propose augmenting the trace cache [19], [26] (which was proposed to provide the required fetch bandwidth for wide-issue ILP processors) with a copy of the predicted values and moving the generation of those predicted values (which require accessing the value prediction tables) from the instruction fetch stage to a later stage, e.g., the writeback stage. Such a change will allow ¿selective value prediction,¿ i.e., only those instructions which require value prediction will access the value prediction tables. It can significantly reduce the bandwidth requirement of value prediction tables. We also use a dynamic classification scheme to steer predictor updates to behavior-specific tables (such as last-value, stride, two-level, etc.). A relatively even split among such table accesses further moderates the bandwidth requirement of those tables.


#*Ecological disturbance maintains and promotes biodiversity in an artificial plant ecology
#@Ben Clark,Seth Bullock
#t2002
#cProceedings of the seventh international conference on simulation of adaptive behavior on From animals to animats
#index564552
#!A model of plant growth, competition and reproduction in three dimensions was constructed using L-systems to simulate plant growth, ray tracing to simulate sunlight and shading, and a steady-state genetic algorithm to simulate evolution by natural selection. Simulated plant growth conformed to expected trade-offs between, for instance, growing up and growing out. Simulated cohorts exhibited conventional population-level phenomena such as obeying the self-thinning law. Competition between species was simulated under various disturbance regimes. Undisturbed, a K-selected type of plant species dominated at equilibrium. However, under certain disturbance regimes, diverse life-history strategies were able to coexist at equilibrium, and even speciate.


#*Agent-Based Simulation for Economic and Environmental Studies
#@Hideyuki Mizuta,Yoshiki Yamagata
#t2001
#cProceedings of the Joint JSAI 2001 Workshop on New Frontiers in Artificial Intelligence
#index376725


#*E-Cell: Towards integrative modeling of cellular processes
#@Masaru Tomit
#t2002
#cInformatik bewegt: Informatik 2002 - 32. Jahrestagung der Gesellschaft f&uuml;r Informatik e.v. (GI)
#index271925


#*Sutter's mill: the string formatters of Manor farm
#@Herb Sutter
#t2001
#cC/C++ Users Journal
#index239051
#%610260
#%281989


#*Protocol synthesis and re-synthesis with optimal allocation of resources based on extended petri nets
#@Hirozumi Yamaguchi,Khaled El-Fakih,Gregor von Bochmann,Teruo Higashino
#t2003
#cDistributed Computing
#index109421
#%75398
#%470398
#%617211
#%227950
#%538915
#%509344
#%363795
#%113812
#%111497
#%258968
#%110510
#%114428
#%539701
#!Protocol synthesis is used to derive a protocol specification, that is, the specification of a set of application components running in a distributed system of networked computers, from a specification of services (called the service specification) to be provided by the distributed application to its users. Protocol synthesis reduces design costs and errors by specifying the message exchanges between the application components, as defined by the protocol specification. In general, maintaining such a distributed application involves applying frequent minor modifications to the service specification due to changes in the user requirements. Deriving the protocol specification after each modification using the existing synthesis methods is considered expensive and time consuming. Moreover, we cannot identify what changes we should make to the protocol specification in correspondence to the changes in the service specification, in this paper, we present a new synthesis method to re-synthesize only those parts of the protocol specification that must be modified in order to satisfy the changes in the service specification. The method consists of a set of simple rules that are applied to the protocol specification written in an extended Petri net model. An application example is given along with some experimental results.


#*An Experimental Study of Increasing Diversity for Case-Based Diagnosis
#@Lu Zhang,Frans Coenen,Paul Leng
#t2002
#cProceedings of the 6th European Conference on Advances in Case-Based Reasoning
#index356851


#*Radio Spectrum Conservation: Radio Engineering Fundamentals, 1st edition
#@William Gosling
#t2000
#c
#index236830
#!:This concise, readable text keeps mathematics to a working minimum, with focus on the practical, it is a companion volume to Gosling's Radio Antennas and Propagation. Professor Gosling distils his experience in industry and teaching to show engineers how to deal with these challenges by describing the process of effective spectrum utilisation, including examination of separation of transmissions by space, time, frequency and sequency. Throughout the book reference is made to real-life examples to illustrate the theory. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Thread management mechanisms of CEFOS
#@Makoto Shimosaki,Hideo Taniguchi,Makoto Amamiya
#t2000
#cDistributed and parallel systems: from instruction parallelism to cluster computing
#index321226


#*Improving Cache Performance of Network Intensive Workloads
#@Udaykiran Vallamsetty,Prasant Mohapatra,Ravishankar K. Iyer,Krishna Kant
#t2001
#cProceedings of the 2001 International Conference on Parallel Processing
#index374230


#*Faculty perceptions and participation in distance education: pick fruit from the low-hanging branches
#@Kim E. Dooley,Jane Magill
#t2002
#cThe design and management of effective distance learning programs
#index249669


#*Structure-preserving binary relations for program abstraction
#@David A. Schmidt
#t2002
#cThe essence of computation: complexity, analysis, transformation
#index118122
#%162585
#%293288
#%559345
#%215199
#%249536
#%611103
#%515698
#%153138
#%624959
#%593370
#%149254
#%266329
#%145379
#%483423
#%510676
#%254400
#%271463
#%559153
#%222761
#%256386
#!An abstraction is a property-preserving contraction of a program's model into a smaller one that is suitable for automated analysis. An abstraction must be sound, and ideally, complete. Soundness and completeness arguments are intimately connected to the abstraction process, and approaches based on homomorphisms and Galois connections are commonly employed to define abstractions and prove their soundness and completeness.This paper develops Mycroft and Jones's proposal that an abstraction should be stated as a form of structure-preserving binary relation. Mycroft-Jones-style relations are defined, developed, and employed in characterizations of the homomorphism and Galois-connection approaches to abstraction.


#*Electrical resistivity of thin electroless Ag-W films for metallization
#@E. E. Glickman,V. Bogush,A. Inberg,Y. Shacham-Diamand,N. Croitoru
#t2003
#cMicroelectronic Engineering
#index312733
#%440411
#!It is shown that optimization of the electroless deposition and the use of vacuum annealing yield dramatic decrease in the resistivity and its scatter in 100- and 50-nm silver-tungsten (Ag-W) films. Physical processes, which control the resistivity drop during low-temperature annealing and the residue resistivity in the annealed films are discussed.


#*CAD System for the Assistance of Comparative Reading for Lung Cancer Using Serial Helical CT Images
#@Mitsuru Kubo,T. Yamamoto,Yoshiki Kawata,Noboru Niki,Kenji Eguchi,Hironobu Ohmatsu,Ryutaro Kakinuma,Masahiro Kaneko,M. Kusumoto,Noriyuki Moriyama,Kensaku Mori,H. Nishiyama
#t2001
#cProceedings of the 4th International Conference on Medical Image Computing and Computer-Assisted Intervention
#index255822


#*Sams Teach Yourself WordPerfect Office 2000 for Linux in 24 Hours
#@Alan S. Golub,Judith Samson
#t2000
#c
#index252356
#!:Readers will come away with a greater understanding of, and appreciation for, Linux, and a working knowledge of each application in the office suite. Newcomers will learn how to quickly maximize their use and enjoyment of Corel's full-featured office suite for Linux. Corel's new Linux distribution currently ships with the WordPerfect word processor for Linux - future versions will be sold at retail with the complete WordPerfect Office suite. Book will be day-and-date with the retail release of the WordPerfect Office suite. WordPerfect for Linux is widely considered to be the best word processor in the Linux environment; WordPerfect Office will provide an entire suite of reliable applications that's familiar to users and corporate customers.


#*Consistent policy enforcement in distributed systems using mobile policies
#@Susan Chapin,Don Faatz,Sushil Jajodia,Amgad Fayad
#t2002
#cData Knowledge Engineering
#index447361
#%183462
#%320102
#%439922
#%512138
#!This paper briefly traces the evolution of information system architectures from mainframe-connected terminals to distributed multi-tier architectures. It presents the challenges facing developers of multitier information systems in providing effective consistent data policy enforcement, such as access control in these architectures. Finally, it introduces "Mobile Policy" (MoP) as a potential solution and presents a framework for using mobile policy in the business logic tier of multi-tier information systems.


#*Extraction of Recurrent Patterns from Stratified Ordered Trees
#@Jean-Gabriel Ganascia
#t2001
#cProceedings of the 12th European Conference on Machine Learning
#index375577


#*Analysis Problems for Sequential Dynamical Systems and Communicating State Machines
#@Chris Barrett,Harry B. Hunt, III,Madhav V. Marathe,S. S. Ravi,Daniel J. Rosenkrantz,Richard Edwin Stearns
#t2001
#cProceedings of the 26th International Symposium on Mathematical Foundations of Computer Science
#index383296


#*Capability packages for avionics software (CPAS)
#@Garry Brannum
#t2000
#cACM SIGSOFT Software Engineering Notes
#index291511


#*PRISMA: Towards Quality, Aspect Oriented and Dynamic Software Architectures
#@Jennifer Pérez,Isidro Ramos,Javier Jaén,Patricio Letelier,Elena Navarro
#t2003
#cProceedings of the Third International Conference on Quality Software
#index309392
#!The development of software systems must be doneusing platforms that allow the description of quality,complex, distributed, dynamic and reusable architecturalmodels. We present in this paper PRISMA, anarchitectural modelling approach based on aspects andcomponents, that uses a component definition language(components, connectors and systems) to definearchitectural types at a high abstraction level and aconfiguration language to design the architecture ofsoftware systems. The component definition languageincreases reuse allowing importation of COTS andreduces complexity by integrating two modern softwaredevelopment approaches: Component-Based SoftwareDevelopment and Aspect-Oriented SoftwareDevelopment. The configuration language designs thearchitecture of software systems by creating andinterconnecting instances of the defined types includingpossible imported COTS. PRISMA has a metalevel withreflexive properties for these two languages. For thisreason, the types of PRISMA may evolve and thetopologies of PRISMA may be reconfigureddynamically.


#*Circular Coinduction
#@Grigore Rosu,Joseph Goguen
#t2000
#c
#index206404
#!Circular coinduction is a new technique for behavioral reasoning that extends coinduction to specifications with circularities. We show that a congruence criterion due to Bidoit and Hennicker follows easily from circular coinduction, and we give some natural examples of circular coinductive proofs. A notation, called BOBJ, appropriate for our style of behavioral specification is also sketched. Finally, everything is conducted in a general framework that in a sense is the gcd of previous behavioral frameworks.


#*An interface for &lsquo;flat music&rsquo;
#@Christopher Bailey
#t2004
#cOrganised Sound
#index98500
#!Part of my listening experience has been a coming to terms with a certain set of musical forms that I call &lsquo;flat&rsquo;. Music in flat form means music that avoids obvious or dimensionally conjunct large-scale goals, points of arrival, &lsquo;climaxes&rsquo;, sectional boundaries, and the like, and therefore has proven difficult for many listeners. It has become clear to me that this music demands a different listening approach, one at odds with the way music is typically appreciated in the concert hall. This approach is one that composers of music in flat form can facilitate through today's computer-music resources. What I present here is a specific instance of such an approach: my composition Sand, a twenty-five-minute long work for computer-synthesised and processed sounds, was composed specifically to be experienced through a computer-music interface I built in the MAX&#x002F;MSP environment. This paper explores what I mean by &lsquo;flatness&rsquo;, how I came to terms with it as a listener, and how this coming-to-terms spawned the idea and construction of the interface. I then discuss the interface itself, the process of interaction with the listener, and technical aspects of the software.


#*Jointly optimal downlink beamforming and base station assignment
#@M. Bengtsson
#t2001
#cProceedings of the Acoustics, Speech, and Signal Processing, 2001. on IEEE International Conference - Volume 05
#index428558
#!We present an algorithm that jointly determines the optimal downlink beamformers and the optimal assignment of each mobile to a base station. The optimality criterion is based on a systems perspective; provide sufficient quality of service for all users, transmitting as little excess power as possible. Since the algorithm is centralized and requires knowledge about all the channels in the system, it may be infeasible in a practical implementation. However, it provides the ultimate benchmark in system evaluations. Numerical examples show substantial gain compared to ordinary base station assignment.


#*A pegging algorithm for the nonlinear resource allocation problem
#@Kurt M. Bretthauer,Bala Shetty
#t2002
#cComputers and Operations Research
#index246827
#%160316
#%210836
#%472721
#%556448
#%467885
#!In this paper we present a new algorithm for solving the nonlinear resource allocation problem. The nonlinear resource allocation problem is defined as the minimization of a convex function over a single convex constraint and bounded integer variables. We first present a pegging algorithm for solving the continuous variable problem, and then incorporate the pegging method in a branch and bound algorithm for solving the integer variable problem. We compare the computational performance of the pegging branch and bound algorithm with three other methods: a multiplier search branch and bound algorithm, dynamic programming, and a 0,1 linearization method. The computational results demonstrate that the pegging branch and bound algorithm advances the state of the art in methods for solving the nonlinear resource allocation problem.


#*Systematic Design Of Sigma-delta Analog-to-digital Converters
#@Ovidiu Bajdechi,Johan H. Huijsing
#t2004
#c
#index438399


#*Needs Assessment for Computer-Integrated Surgery Systems
#@Sarah Graham,Russell H. Taylor,Michael Vannier
#t2000
#cProceedings of the Third International Conference on Medical Image Computing and Computer-Assisted Intervention
#index269942


#*Temporal Allocation of Visual Attention in Adult Attention Deficit Hyperactivity Disorder
#@Deidre E. Hollingsworth,Sean P. Mcauliffe,Barbara J. Knowlton
#t2001
#cJournal of Cognitive Neuroscience
#index29356
#!In two experiments, we examined the ability of adults with attention deficit hyperactivity disorder (ADHD) to process multiple targets appearing in a rapid serial visual presentation (RSVP) stream. Using a standard attentional blink (AB) task, subjects were required to both identify a target in the RSVP stream and detect a probe appearing in one of several posttarget serial positions. In Experiment 1, ADHD adults exhibited a protracted AB compared to controls, in that their probe detection did not improve as a function of increasing probe-to-target intervals (450&ndash;720 msec). In Experiment 2, the ADHD group performed as well as controls in detecting probes appearing immediately (i.e., 90 msec) after the target. Taken together, the results demonstrate that adults with ADHD exhibit a selective deficit in rapidly shifting attention between the target and the probe, when the two appear several hundred milliseconds apart. These results suggest that adults with ADHD can use automatic (reflexive) attention to detect items in close temporal proximity in the RSVP stream, but have difficulty allocating controlled attention to multiple stimuli separated by several hundred milliseconds.


#*Active Handwritten Character Recognition Using Genetic Programming
#@Ankur Teredesai,J. Park,Venu Govindaraju
#t2001
#cProceedings of the 4th European Conference on Genetic Programming
#index269957


#*End-user types and end-user support: a study
#@Chittibabu Govindarajulu
#t2000
#cProceedings of the 2000 information resources management association international conference on Challenges of information technology management in the 21st century
#index316581


#*Cloning parallel simulations
#@Maria Hybinette,Richard M. Fujimoto
#t2001
#cACM Transactions on Modeling and Computer Simulation (TOMACS)
#index618535
#%81946
#%86938
#%91227
#%163157
#%459456
#%525216
#%581170
#!We present a cloning mechanism that enables the evaluation of multiple simulated futures. Performance of the mechanism is analyzed and evaluated experimentally on a shared memory multiprocessor. A running parallel discrete event simulation is dynamically cloned at decision points to explore different execution paths concurrently. In this way, what-if and alternative scenario analysis can be performed in applications such as gaming or tactical and strategic battle management. A construct called virtual logical processes avoids repeating common computations among clones and improves efficiency. The advantages of cloning are preserved regardless of the number of clones (or execution paths). Our performance results with a commercial air traffic control simulation demonstrate that cloning can significantly reduce the time required to compute multiple alternate futures.


#*Staging a professional participatory design practice: moving PD beyond the initial fascination of user involvement
#@Susanne Bødker,Ole Sejer Iversen
#t2002
#cProceedings of the second Nordic conference on Human-computer interaction
#index254586
#%93999
#%316956
#%519474
#%580377
#!Use and users have an important and acknowledged role to most designers of interactive systems. Nevertheless any touch of user hands does not in itself secure development of meaningful artifacts. In this article we stress the need for a professional PD practice in order to yield the full potentiality of user involvement. We suggest two constituting elements of such a professional PD practice. The existence of a shared 'where-to' and 'why' artifact and an ongoing reflection and off-loop reflection among practitioners in the PD process.


#*Compositional performance modelling with the TIPPtool
#@H. Hermanns,U. Herzog,U. Klehmet,V. Mertsiotakis,M. Siegle
#t2000
#cPerformance Evaluation
#index294381


#*Sequential Sampling Techniques for Algorithmic Learning Theory
#@Osamu Watanabe
#t2000
#cProceedings of the 11th International Conference on Algorithmic Learning Theory
#index562570


#*The Effect of Mammogram Databases on Algorithm Performance
#@Michael Wirth,Jennifer Lyon,Matteo Fraschini,Dennis Nikitenko
#t2004
#cProceedings of the 17th IEEE Symposium on Computer-Based Medical Systems
#index434734
#!One of the caveats of the process of designing image processing algorithms is that they areoften tested on insignificant numbers of images. This paper discusses the influence ofmammogram databases on the performance evaluation of algorithms. We hope to demonstrate that the use of extensive collections of mammograms with varied characteristics to assess algorithm performance can lead to more robust algorithms.


#*Evaluating Evolutionary Software Systems
#@Teade Punter,Adam Trendowicz,Peter Kaiser
#t2002
#cProceedings of the 4th International Conference on Product Focused Software Process Improvement
#index277696


#*Viscosity Solutions of the Bellman Equation for Exit Time Optimal Control Problems with Vanishing Lagrangians
#@Michael Malisoff
#t2001
#cSIAM Journal on Control and Optimization
#index245901
#!We study the Hamilton--Jacobi--Bellman equation for undiscounted exit time optimal control problems for fully nonlinear systems and fully nonlinear singular Lagrangians using the dynamic programming approach. We prove a local uniqueness theorem characterizing the value functions for these problems as the unique viscosity solutions of the corresponding Hamilton--Jacobi--Bellman equations that satisfy appropriate boundary conditions. The novelty of this theorem is in the relaxed hypotheses on the lower bound on the Lagrangian and the very general assumptions on the target set. As a corollary, we show that the value function for the Fuller problem is the unique viscosity solution of the corresponding Hamilton--Jacobi--Bellman equation that vanishes at the origin and satisfies certain growth conditions. This implies as special cases first that the value function of this problem is the unique proper viscosity solution of the corresponding Hamilton--Jacobi--Bellman equation, in the class of all functions which are continuous in the plane and null at the origin, and second that this value function is the unique viscosity solution of that equation in a class which includes functions which are not bounded below. We also apply our results to the degenerate eikonal equation of geometric optics and to the shape-from-shading equations in image processing. Our theorem also applies to problems with noncompact targets and unbounded control sets whose Lagrangians take negative values.


#*Cooperative Crawling
#@Marina Buzzi
#t2003
#cProceedings of the First Conference on Latin American Web Congress
#index306560
#!Web crawler design presents many different challenges: architecture, strategies, performance and more. One of the most important research topics concerns improving the selection of"interesting" web pages (for the user), according to importance metrics. Another relevant point is content freshness, i.e. maintaining freshness and consistency of temporary stored copies. For this, the crawler periodically repeats its activity going over stored contents (re-crawling process). In this paper, we propose a scheme to permit a crawler to acquire information about the global state of a website before the crawling process takes place. This scheme requires web server cooperation in order to collect and publish information on its content, useful for enabling a crawler to tune its visit strategy. If this information is unavailable or not updated the crawler still acts in the usual manner. In this sense the proposed scheme is not invasive and is independent from any crawling strategy and architecture.


#*Oracle9i Database Administrator II: Backup/Recovery and Network Administration
#@Lannes Morris-Murphy
#t2003
#c
#index16456


#*Design Principles for Tactile Interaction
#@Ben P. Challis,Alistair D. N. Edwards
#t2000
#cProceedings of the First International Workshop on Haptic Human-Computer Interaction
#index378234


#*Multidomain load balancing
#@S. T. Chanson,Wantao Deng,Chi-Chung Hui,Xueyan Tang,Ming Yan To
#t2000
#cProceedings of the 2000 International Conference on Network Protocols
#index120143
#!This paper investigates dynamic load balancing issues in the multidomain environment where local area networks (LANs) are interconnected by the Internet. Because of the much slower Internet communication speed and limited bandwidth, existing load balancing algorithms for LANs are unsuitable for the multidomain environment. New issues such as lag time in updating load information and network cost of transferring jobs must be addressed. To tackle these problems, the conventional least load scheduler is extended to the multidomain environment by employing a hierarchical structure, and several quick update techniques are proposed. Also, a heuristic taking both the machine load and the network cost into consideration is developed to evaluate the benefits of sending jobs to computers in different domains. A set of experiments conducted on the BALANCE testbed showed that the proposed techniques provide significant performance improvement over existing algorithms.


#*Modular techniques in information visualization
#@David Duke
#t2001
#cProceedings of the 2001 Asia-Pacific symposium on Information visualisation - Volume 9
#index250434
#%235019
#%293499
#%523220
#%318548
#%319563
#%525981
#%446529
#!The use of visualization to explore and understand data is often partitioned into two areas, scientific visualization in which the data sets are typically derived from measurements or simulations grounded in physical space, and information visualization where data sets are defined over abstract spaces. Although there are certain pragmatic differences based on the way that visualization is used, this paper argues that there is interesting progress to be made by ignoring such distinctions, and working with a general model in which visualization is about representing structures within particular kinds of space. This applies both at the conceptual level, and at the level of practice and implementation. This paper sets out the motivation for thinking in these terms, and describes initial work on using a toolkit, designed primarily for scientific and engineering applications, in a rather more abstract domain, graph visualization.


#*Preface
#@Elena Barcucci,Alberto Del Lungo
#t2003
#cTheoretical Computer Science
#index304819


#*Adaptive homing: robotic exploration tours
#@Verena Vanessa Hafner
#t2001
#cAdaptive Behavior
#index569350
#!In this article, a minimalistic model for learning and adaptation of visual homing is presented. Normalized Hebbian learning is used during exploration tours of a mobile robot to learn visual homing and to adapt to the sensory modalities. The sensors of the mobile robot (omnidirectional camera, magnetic compass) have been chosen in a way that their data most closely resemble the sensory data at the disposal of insects such as the desert ant Cataglyphis (almost omnidirectional vision, polarized light compass), which is an amazing navigator despite its tiny brain. The learned homing mechanism turned out to be closely related to Lambrinos and colleagues' average landmark vector (ALV) model and is widely independent of any special features of the environment. In contrast to the ALV model or other models of visual homing, feature extraction or landmark segmentation is not necessary. Mobile robot experiments have been performed in an unmodified office environment to test the feasibility of learning of visual homing.


#*Guest-editorial
#@Subra Ganesan,Hossein Mousavinezhad
#t2002
#cIntegrated Computer-Aided Engineering
#index423448


#*Normal forms for representations of representation-finite algebras
#@Peter Draäxler
#t2001
#cJournal of Symbolic Computation
#index615353
#!Using the CREP system we show that matrix representations of representation-finite algebras can be transformed into normal forms consisting of (0, 1)-matrices. Copyright 2001 Academic Press.


#*Automatic Identification of Mathematical Concepts
#@Simon Colton,Alan Bundy,Toby Walsh
#t2000
#cProceedings of the Seventeenth International Conference on Machine Learning
#index384286


#*Erratum: erratum to "VLSI based fuzzy logic controller enabled adaptive interactive multiple model for target tracking"
#@Ramesh Chidambaram,V. Sai Prithvi,V. Vaidehi
#t2003
#cIntegration, the VLSI Journal
#index307984


#*Editorial
#@Constantin Zopounidis,Panos M. Pardalos,Jaime Gil-Aluja
#t2002
#cComputational Economics
#index442459


#*TellMaris and deep map: two navigational assistants
#@Katri Laakso,Christian Kray
#t2003
#cProceedings of the 8th international conference on Intelligent user interfaces
#index441254
#!This demo will present Tellmaris and Deep Map, two system offering navigational assistance and other services to an untrained user. We will put an emphasis on different ways to present route instructions on mobile devices.


#*Live Upgrade Techniques for CORBA Applications
#@L. A. Tewksbury,Louise E. Moser,P. M. Melliar-Smith
#t2001
#cProceedings of the IFIP TC6 / WG6.1 Third International Working Conference on New Developments in Distributed Applications and Interoperable Systems
#index561427


#*Using design patterns to build dynamically extensible collaborative virtual environments
#@Thomas Alexandre
#t2003
#cProceedings of the 2nd international conference on Principles and practice of programming in Java
#index302321
#%232013
#%247998
#%522060
#%319521
#!Although in the past decade a lot of research efforts have been concentrated into building multi-user virtual worlds such as 3D collaborative virtual environments (CVE) and gaming platforms [1], the proprietary nature of such systems and their associated complexity has often resulted in large monolithic applications that are difficult to maintain and extend. At the same time, the openness and scalability of the web let us imagine what could be the next step in the evolution of information sharing and more intuitive collaboration - a web in 3 dimensions to model the world we live in, that would enhance the notion of websites, web pages and hyperlinks navigation with more natural interfaces made of buildings, rooms and people.Undoubtfully, creating such interactive worlds depends on resolving a number of software engineering challenges, most of them resulting from the conflicting requirements of speed vs reliability, scalability vs bandwidth usage, replication vs consistency or flexibility vs tight-coupling.In the next sections we propose a framework to build dynamically extensible networked environments based on existing and well documented design patterns [2] that will help developers creating virtual world applications in java by easily assembling components and behaviors in a reusable manner. This paper also discusses the foundation for an implementation in java of such a framework based on principles of the OMG's emerging Model Driven Architecture (MDA) [3].


#*Introduction to the special issue on finite-state methods in NLP
#@Lauri Karttunen,Kemal Oflazer
#t2000
#cComputational Linguistics
#index309282
#%273235
#%591174


#*Object coloured Petri nets - a formal technique for object oriented modelling
#@Christoph Maier,Daniel Moldt
#t2001
#cConcurrent object-oriented programming and petri nets: advances in petri nets
#index316049


#*Slow decay in linear thermoelasticity
#@Herbert Koch
#t2000
#cQuarterly of Applied Mathematics
#index334914


#*Tech support under the hood
#@Mary Kroening
#t2000
#cPC AI
#index318872


#*Graph-Based Methods for Vision: A Yorkist Manifesto
#@Edwin R. Hancock,Richard C. Wilson
#t2002
#cProceedings of the Joint IAPR International Workshop on Structural, Syntactic, and Statistical Pattern Recognition
#index374737


#*Hodge decompositions on the boundary of non-smooth domains: the non-simply connected case
#@A. Buffa
#t2000
#c
#index124599
#!This paper concerns the characterization of tangential traces for the space ${\bf }H({\bf curl},\Omega)$, when $\Omega$ is a Lipschitz polyhedron in $R^3$ under general topology assumptions. Suitable spaces of tangential vector fields are introduced and characterized. Hodge decompositions are provided and they involve the first cohomology space of the boundary $\Gamma$. Such a space is characterized and a basis is furnished. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Web Hosting
#@Carl Burnham
#t2001
#c
#index241608
#!:A complete strategy for delivering high-quality Web hosting services. Today, most businesses, large and small, rely on the Internet as a central component of their organization. In order to save time and money, many of these businesses are turning to Web hosting companies for support. These hosting companies must be able to provide innovative, secure, and cost-effective solutions in order to remain competitive and keep customers satisfied. This detailed and unique resource delivers a full-range strategy for providing successful solutions that will meet the needs of your customers. From technical support and customer service to Web marketing strategies, this comprehensive guide contains all the essential coverage necessary for delivering state-of-the-art, customized hosting solutions. This resource will help you: Learn the different types of Web hosting plans--shared, dedicated, co-located, ASP, MSP, and more Get insight into successful Web marketing strategies Understand the technology required to ensure quality service Identify and decide upon a standard range of services Enhance network performance through use of monitoring tools Secure your infrastructure--prevent viruses, worms, and other attacks Manage a data center and discover ways to outsource services Gain a competitive edge in an expanding Web hosting market


#*A Gradual Approach to a More Trustworthy, Yet Scalable, Proof-Carrying Code
#@Robert R. Schneck,George C. Necula
#t2002
#cProceedings of the 18th International Conference on Automated Deduction
#index567263


#*Champions of Silicon Valley: Visionary Thinking from Today's Technology Pioneers
#@Charles G. Sigismund
#t2000
#c
#index612540
#!:Cutting-edge ideas flow like water in Silicon Valley. Managers and business professionals all over the world look to this region as a model for creating their own success stories. The growth of the high-tech industry can be attributed to a combination of risk taking and vision coming from a handful of individuals. Taken straight from the mouths and minds of the people who created and now champion them, Champions of Silicon Valley focuses on some of the most important and influential visions and business approaches to come out of Silicon Valley. Charles Sigismund examines the unique accomplishments of these Silicon Valley companies and their visionaries through extensive field research and interviews. He explores high tech's most influential visions and details how these ideas reached fruition. The approaches included are as varied and effective as the individuals and organizations that work with them. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*User-based evaluations
#@Joseph S. Dumas
#t2002
#cThe human-computer interaction handbook: fundamentals, evolving technologies and emerging applications
#index566385
#%81896
#%155436
#%226354
#%231125
#%232582
#%290253
#%329711
#%456237
#%463024
#%473692
#%479799
#%484303
#%510443
#%515127
#%516059
#%521738
#%524757
#%525039
#%536011
#%584924
#%597175
#%599116
#%624448


#*From the teaching laboratory: A half-cage isodrin derivative for demonstrating the nuclear overhauser effect
#@Angela E. Chen,Daniel J. O'Leary,Steve S. Miura,Frank A. L. Anet
#t2000
#cMagnetic Resonance: an Educational Journal
#index280732


#*Embedding Formally Proved Code in a Smart Card: Converting B to C
#@Antoine Requet,Gaëlle Bossu
#t2000
#cProceedings of the 3rd IEEE International Conference on Formal Engineering Methods
#index119293
#!Smart cards are small-embedded devices with strong security requirements. To fulfill those requirements, formal methods appear as promising techniques. The B method has already been used to model smart card components. However, smart cards have also very strong programming constraints, for both memory usage and computing power. Currently the code generated from a B specification does not meet those constraints. This paper presents some classical optimisation techniques that are well suited for B specifications, and that need to be included within a code generator to embed this generated code.


#*Nonuniform Alias Analysis of Recursive Data Structures and Arrays
#@Arnaud Venet
#t2002
#cProceedings of the 9th International Symposium on Static Analysis
#index273747


#*Analysis of the Hamilton--Jacobi Equation in Nonlinear Control Theory by Symplectic Geometry
#@Noboru Sakamoto
#t2001
#cSIAM Journal on Control and Optimization
#index241362
#!In this paper, the geometric property and structure of the Hamilton--Jacobi equation arising from nonlinear control theory are investigated using symplectic geometry. The generating function of symplectic transforms plays an important role in revealing the structure of the Hamilton--Jacobi equation. It is seen that many fundamental properties of the Riccati equation can be generalized in the Hamilton--Jacobi equation, and, therefore, the theory of the Hamilton--Jacobi equation naturally contains that of the Riccati equation.


#*Constellation Shaping, Nonlinear Precoding, and Trellis Coding for Voiceband Telephone Channel Modems with Emphasis on ITU-T Recommendation V.34
#@Steven A. Tretter
#t2002
#c
#index249008


#*Big Book of Lightweight Directory Access Protocol (Ldap) Rfcs, 1st edition
#@
#t2000
#c
#index240359
#!:Lightweight Directory Access Protocol, LDAP, is the mechanism that makes universally interoperable directory services applications possible. The network directory market is emerging as one of the most important, with LDAP playing a central role in all directory solutions. Although no single document specifies LDAP entirely, there are many Requests for Comments (RFCs) that describe LDAP and how it works. This book collects these essential documents in a single printed volume, and adds an introduction and extensive index. This means you no longer have to search through countless RFCs to find the correct answer to your LDAP question  all current RFCs are compiled in a single book, with an index that makes specific information about LDAP even easier to locate. Every current RFC describing or affecting an aspect of LDAP is collected in this volume, including RFCs formally defining LDAP, describing LDAPs interactions with other protocols, and informational documents that explain how LDAP operates. If you buy one LDAP reference, this is the one to choose. Written by members of the Internet Engineering Task Force (IETF) and its steering group, the IESG, this compilation is the most complete and authoritative LDAP reference available. Features: How LDAP data is formatted Connectionless LDAP (CLDAP) The LDAP application program interface (API) The string representation scheme for LDAP search filters The LDAP URL format Common Indexing Protocol (CIP) Use of language codes in LDAP


#*Enterprise engineering and integration in the global environment
#@Kurt Kosanke,François Vernadat,Martin Zelm
#t2000
#c
#index277500


#*Increasing Role of Information Systems in Public Health Care -- Challenge to
#@Jarmo Tähkäpää
#t2004
#cProceedings of the Proceedings of the 37th Annual Hawaii International Conference on System Sciences (HICSS'04) - Track 6 - Volume 6
#index304915
#!Managing public health care organizations is becoming more demanding and complicated task. The ever-increasing demand for health services and at the same time substantially decreasing resources sets new challenges to the area. Expectations towards information systems (IS) are high and it is seen as one solution to increasing problems. However, it is noticed that also development of IS needs professional management and strategic planning to become an effective tool -- again a new challenge to the management.This paper discusses which are the main management areas to pay attention to in ISdevelopment in public health care and which factors in the operational environment affect those areas the most. The areas are: organisations strategy, information management strategy, strategy implementation, implementation and use of IS and evaluation of IS. Results from two large empirical cases show that developing IS in public health care is far more complicated because of a wide operational environment and number of stakeholders compared to the development in other public areas not to mention private industries. The paper is based on experiences in Finnish public health care.


#*A Method for Approximate Equivalence Checking
#@Mitch Thornton,Rolf Drechsler,Wolfgang Guenther
#t2000
#cProceedings of the 30th IEEE International Symposium on Multiple-Valued Logic
#index121995
#!An approximate equivalence checking method is developed based on the use of partial Haar spectral diagrams (HSDs). Partial HSDs are defined and used to represent a subset of the Haar spectral coefficients for two functions. Due to the uniqueness properties of the Haar transform, a necessary condition for equivalence is that the individual coefficients must have the same value. The probability that two functions are equivalent is then computed based on the number of observed, same-valued, Haar coefficients. The method described here can be useful for the case where two candidate functions require extreme amounts of computational resources for exact equivalence checking. For simplicity, the technique is explained for the binary case first and extensions to Multiple Valued Logic (MVL) are shown afterwards. Experimental results are provided to validate the effectiveness of this approach.


#*The Movie Book of Answers
#@Carol Bolt
#t2001
#c
#index8494


#*Survey of requirements and solutions for ubiquitous software
#@Eila Niemelä,Juhani Latvakoski
#t2004
#cProceedings of the 3rd international conference on Mobile and ubiquitous multimedia
#index108836
#%82492
#%327536
#%328028
#%438669
#%563425
#!Ubiquitous computing embeds computer technology in our everyday environment, providing a human with information services and applications through any device over different kinds of networks. Ubiquitous computing can be seen as a prerequisite for pervasive computing that emphasizes mobile data access and the mechanisms needed for supporting a community of nomadic users. Ubiquitous software is the software required in ubiquitous computing environments. This paper surveys the challenges and state-of-the-art software technologies applicable to ubiquitous computing environments. Ubiquitous wireless world systems trigger a set of requirements, e.g. interoperability, adaptability and mobility, for ubiquitous system and software technologies. The main challenges of ubiquitous software are a uniform and adaptive middleware technology, iteroperability of services and networks, and the enabling technologies required in their development. Futhermore guaranteeing secure transactions between service providers, content providers and users is essential in worldwide pervasive computing environments. Although standards, reference architectures and generic software technologies provide the basis for future ubiquitous software development, new kinds of micro architectures and software technologies, and development methods are needed.


#*Improved Rounding Techniques for the MAX 2-SAT and MAX DI-CUT Problems
#@Michael Lewin,Dror Livnat,Uri Zwick
#t2002
#cProceedings of the 9th International IPCO Conference on Integer Programming and Combinatorial Optimization
#index355341


#*Trash fake music
#@Gilbert Held
#t2003
#cInternational Journal of Network Management
#index443035


#*I-DIAG: from community discussion to knowledge distillation
#@Mark S. Ackerman,Anne Swenson,Stephen Cotterill,Kurtis DeMaagd
#t2003
#cCommunities and Technologies
#index306489
#%86004
#%239624
#%281143
#%297256
#%459603
#%539793
#%533779
#%328936
#%514019
#%612146
#!I-DIAG is an attempt to understand how to take the collective discussions of a large group of people and distill the messages and documents into more succinct, durable knowledge. I-DIAG is a distributed environment that includes two separate applications, CyberForum and Consolidate. The goals of the project, the architecture of I- DIAG, and the two applications are described. We focus on technical mechanisms to augment social maintenance and social regulation in the system.


#*Smoothing of contours by using one adaptive filter
#@Ognian Jelezov
#t2000
#cProceedings of the conference on Computer systems and technologies
#index335182


#*Conversions between parametic and implicit forms using polar/spherical coordinate representations
#@Cem Ünsalan,Aytül Erçil
#t2001
#cComputer Vision and Image Understanding
#index322048


#*Why computer science students need language
#@Theresa Beaubouef
#t2003
#cACM SIGCSE Bulletin
#index313041
#%243986
#%517933
#!Many students enter the field of computer science with misconceptions about the importance of communication skills. They often choose this field, thinking they will end up with jobs working alone or with other "techies" developing computer games, and not having to deal with people. These students often do not realize the significance of reading, writing, and speaking skills in computer science. This paper discusses several relevant areas of computer science, and explains why computer science students need skills covered in English, speech, technical writing, and even foreign language courses in order to achieve success as a computing professional.


#*Constructing attack scenarios through correlation of intrusion alerts
#@Peng Ning,Yun Cui,Douglas S. Reeves
#t2002
#cProceedings of the 9th ACM conference on Computer and communications security
#index232581
#%378241
#%381712
#%324331
#%371730
#!Traditional intrusion detection systems (IDSs) focus on low-level attacks or anomalies, and raise alerts independently, though there may be logical connections between them. In situations where there are intensive intrusions, not only will actual alerts be mixed with false alerts, but the amount of alerts will also become unmanageable. As a result, it is difficult for human users or intrusion response systems to understand the alerts and take appropriate actions. This paper presents a practical technique to address this issue. The proposed approach constructs attack scenarios by correlating alerts on the basis of prerequisites and consequences of intrusions. Intuitively, the prerequisite of an intrusion is the necessary condition for the intrusion to be successful, while the consequence of an intrusion is the possible outcome of the intrusion. Based on the prerequisites and consequences of different types of attacks, the proposed approach correlates alerts by (partially) matching the consequence of some previous alerts and the prerequisite of some later ones. The contribution of this paper includes a formal framework for alert correlation, the implementation of an off-line alert correlator based on the framework, and the evaluation of our method with the 2000 DARPA intrusion detection scenario specific datasets. Our experience and experimental results have demonstrated the potential of the proposed method and its advantage over alternative methods.


#*Python Library Reference: February 19, 1999, Release 1.5.2
#@Guido Van Rossum
#t2000
#c
#index619875
#!:Python Library Reference exceptions Python Library Reference is a manual that documents Python's standard library, as well as many optional library modules, which may or may not be available, depending on whether the underlying platform supports them and on the configuration choices made at compile time. The reference also documents the standard types of the language and its built-in functions and exceptions, many of which are not or incompletely documented in the Reference Manual. This volume is designed to be a handy desktop companion, saving you the time and expense of printing the documentation yourself. It is also useful when viewing the online version of the Python documentation is inconvenient. This book was produced by toExcel from open source documentation freely available from the Python website. Any errors in this book are the responsibility of iUniverse.com. All royalties go to the Python Software Activity.


#*Open-domain voice-activated question answering
#@Sanda Harabagiu,Dan Moldovan,Joe Picone
#t2002
#cProceedings of the 19th international conference on Computational linguistics - Volume 1
#index102007
#%448122
#%592683
#%316629
#!Voice-Activated Question Answering (VAQA) systems represent the next generation capability for universal access by integrating state-of-the-art in question answering Q&A and automatic speech recognition (ASR) in such a way that the performance of the combined system is better than the individual components. This paper presents an implemented VAQA system and describes the techniques that enable the terative refinement of both Q&A and ASR. The results of our experiments show that spoken questions can be processed with surprising accuracy when using our VAQA implementation.


#*Guest Editors' Introduction: Micro's Top Picks from Microarchitecture Conferences
#@Charles Moore,Kevin W. Rudd,Ruby B. Lee,Pradip Bose
#t2003
#cIEEE Micro
#index385270


#*Index of Volume 33
#@
#t2003
#cInterfaces
#index307400


#*Efficient decision feedback equalizer for sparse multipath channels
#@K. Berberidis
#t2000
#cProceedings of the Acoustics, Speech, and Signal Processing, 2000. on IEEE International Conference - Volume 05
#index425947
#!This paper addresses the problem of blind channel equalization in the context of digital communications. Recent results have shown that certain operations applied to the source signal at the transmitter help in the blind identification and equalization of the channel at the receiver. For example, cyclostationarity is induced by multiplying the baseband data signal with a periodic sequence. Here, the baseband data signal is multiplied with a chirp sequence. Exploiting certain structural properties arising from this operation, a simple and fast converging algorithm is obtained for estimating the equalizer coefficients. The algorithm is deterministic, i.e. it provides optimal equalizer settings using finite data in the noiseless case.


#*Web Services, E-Business, and the Semantic Web: Second International Workshop, WES 2003, Klagenfurt, Austria, June 16-17, 2003, Revised Selected Papers (Lecture Notes in Computer Science)
#@Christoph Bussler,Dieter Fensel,Maria E. Orlowska,Jian Yang
#t2004
#c
#index8012


#*Consumer Satisfaction for Internet Service Providers: An Analysis of Underlying Processes
#@Sunil Erevelles,Shuba Srinivasan,Steven Rangel
#t2003
#cInformation Technology and Management
#index440351
#!A key managerial challenge, of interest to academics and practitioners alike, is the assessment and management of customer satisfaction. In this paper, we examine the underlying processes involving consumer satisfaction and switching patterns among ISPs using different satisfaction models, including the expectations-disconfirmation model, the attribution model, and an affective model. Our results indicate that the satisfaction levels of ISP consumers are generally relatively low, despite the fact that consumer expectations of ISPs are also low, reflecting &ldquo;mediocrity&rdquo; in the marketplace. In addition, consumers attribute their dissatisfaction to ISP indifference and believe that managing dissatisfaction is within the control of the ISP. Moreover, &ldquo;affective&rdquo; factors play an important role in satisfaction processes and switching behavior. Customer service including technical support and responsiveness of service staff is an important &ldquo;determinant&rdquo; factor in ISP selection. We suggest that as the ISP market matures, service providers that pay attention to affective factors and to building &ldquo;relationships&rdquo; with their customers will have a competitive advantage in the marketplace of the future.


#*Probabilistic Simulation-Based Analysis of Complex Real-Time Systems
#@Anders Wall,Johan Andersson,Christer Norström
#t2003
#cProceedings of the Sixth IEEE International Symposium on Object-Oriented Real-Time Distributed Computing
#index125172
#!Many industrial real-time systems have evolved over a long period of time and were initially so simple that it was possible to predict consequences of adding new functionality by common sense. However, as the system evolves the possibility to predict the consequences of changes becomes more and more difficult unless models and analysis method can be used. Moreover, traditional real-time models, e.g., fixed priority analysis, may be too simple for accurately capturing a complex system's characteristics. For instance, assuming worst-case execution time may not be realistic. Hence, analyses based on these models may give an overly pessimistic result.In this paper we describe our approach to introducing analyzability into complex real-time control systems. The proposed method is based on analytical models and discrete-event based simulation of the system behavior based on these models. The models describe execution times as statistical distributions which are measured and calculated in the existing system. Simulation will not only enable models with statistical execution times, but also correctness criterion other than meeting deadlines, e.g., non-empty communication queues. The simulation result is analyzed by specifying properties in a probabilistic property language. The result of such an analysis is either of probabilistic nature or boolean depending on how the property is specified. Having accurate system models enable analysis of the impact on the temporal behavior of, e.g., customizing or maintaining the software.


#*Split Closure and Intersection Cuts
#@Kent Andersen,Gérard Cornuéjols,Yanjun Li
#t2002
#cProceedings of the 9th International IPCO Conference on Integer Programming and Combinatorial Optimization
#index362532


#*HIRISC - a RISC architecture and machine simulator
#@Timothy S. Margush
#t2001
#cJournal of Computing Sciences in Colleges
#index572135
#!The HiRISC Computer System is a hypothetical computer modeled after a generic RISC architecture. The simulator for the system was developed to support a Systems Programming course, providing a bare bones machine for experimentation with loaders, linkers, and assemblers. The HiRISC Simulator is a Windows-based program that includes independent windows providing visual displays of all internal registers, memory, and IO devices. A simple control panel displays control unit information and allows the operator to start, stop, or single-step the processor. Memory contents may be edited within the simulation environment, but the simulator also includes a built in object file loader and a machine language debugger with breakpoints and single step capability. Logging capabilities facilitate the development of student reports. A cross-assembler is available to produce object files in an acceptable format.


#*An Application of Model Building in a Resolution Decision Procedure for Guarded Formulas
#@Michael Dierkes
#t2000
#cProceedings of the First International Conference on Computational Logic
#index267236


#*ICSE 2003 workshop on software architectures for dependable systems
#@Rogério de Lemos,Cristina Gacek,Alexander Romanovsky
#t2003
#cACM SIGSOFT Software Engineering Notes
#index311028
#!This workshop summary gives a brief overview of a one-day Workshop on "Software Architectures for Dependable Systems" held in conjunction with ICSE 2003.


#*Dynamic Aggregation to Support Pattern Discovery: A Case Study with Web Logs
#@Lida Tang,Ben Shneiderman
#t2001
#cProceedings of the 4th International Conference on Discovery Science
#index557703


#*MCAD/MCSD training Guide (70-320): Developing XML Web Services and Server Components with Visual C# >NET and the .NET Framework
#@Priti Kalani
#t2003
#c
#index113622
#!:This certification exam measures the ability to develop and implement XML Web Services and server components using Visual C# and the Microsoft .NET Framework. This exam, released in September 2002, counts as a core credit toward the new MCAD (Microsoft Certified Application Developer) certification as well as a core credit toward the new MCSD .NET track. Readers preparing for this exam find our Training Guide series to be the most successful self-study tool in the market. This book is their one-stop shop because of its teaching methodology, the accompanying PrepLogic testing software, and superior Web site support. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*String, Ring, Sphere: Visualizing Wavefunctions on Different Topologies
#@Guy Ashkenazi,Ronnie Kosloff
#t2004
#cComputing in Science and Engineering
#index387844
#!A quantum system's state is described by a complex wave function, which can be supported on different topologies--for example, one-dimensional open space, a closed one-dimensional ring, or a two-dimensional surface of a sphere. Interactive tools represent the quantum state of a single particle constrained to different topologies, while stressing the underlying superposition principle, which is independent of topology. The insight gained by visualizing the same phenomena in different geometrical contexts contributes to the students' ability to abstract, which is the key to understanding quantum phenomena in more complex systems.


#*Learning to develop GUIs in Java using closed labs
#@Chuck Leska
#t2003
#cProceedings of the 8th annual conference on Innovation and technology in computer science education
#index309459
#!This paper reviews an experiment in which a closed lab was used to deliver instruction on developing graphic user interfaces, GUIs, within a CS 1 course using Java


#*Complementary antithetic weights for lognormal time-series forecasting
#@Dennis Ridley
#t2000
#cComputers and Operations Research
#index313561


#*On the presentation of computer science problems
#@Orit Hazzan
#t2001
#cACM SIGCSE Bulletin
#index255189
#%473456
#!This paper suggests an alternative way for presenting theorems to students. The discussion focuses on theorems that indicate the existence (or inexistence) of some object. Instead of presenting a given theorem as it is, it is suggested to reformulate the theorem as a (sometimes unsolvable) construction task. Students trials to solve the construction problem, lead them to discover the theorem by themselves.


#*Research sessions: query uncertainty
#@
#t2004
#cProceedings of the 2004 ACM SIGMOD international conference on Management of data
#index437316


#*Slide Edge Algorithm
#@Duy Huynh
#t2002
#cProceedings of the 2002 ACM symposium on Applied computing
#index617783
#%270412
#%438921
#%563917
#!The Traveling Salesman Problem is one of the most well known problems in the class of optimization problems and is still a challenge for many computer scientists today. One approach used to attack this problem is the use of Neighborhood Search Techniques (or Improvement Algorithms) that improve a solution by making a move to a neighbor if it is a better solution. Neighborhood Search Techniques are used either independently itself or plugged in other algorithms such as Iterated Algorithm, Local Search, or Evolutionary Algorithm. At the same time, the running time gets slower quickly as the size of neighborhood grows exponentially. In this paper, we introduce the Slide Edge Algorithm (SEA), which is supposed not to find a move as Neighborhood Search Techniques do but to improve the quality of a move that a Neighborhood Search Technique finds out. While the time to find a move is exponential, the time of SEA is approximately to linear. In experiment results, with the support of SEA in improving a have-just-found move, Neighborhood Search Techniques achieve a better quality of the tour in a reasonable amount of time.


#*Invited Lecture - Accelerating Smith-Waterman Searches
#@Gene Myers,Richard Durbin
#t2002
#cProceedings of the Second International Workshop on Algorithms in Bioinformatics
#index371831


#*ESOLID---A System for Exact Boundary Evaluation
#@John Keyser,Tim Culver,Mark Foskey,Shankar Krishnan,Dinesh Manocha
#t2002
#cProceedings of the seventh ACM symposium on Solid modeling and applications
#index245075
#%75181
#%80789
#%196264
#%220319
#%224543
#%326284
#%285245
#%599681
#%316333
#%454136
#%477556
#%476620
#%288472
#%289463
#%283246
#%328528
#%476234
#%451032
#%465950
#!We present a system, ESOLID, that performs exact boundary evaluation of low degree curved solids in reasonable amounts of time. ESOLID performs accurate Boolean operations using exact representations and exact computations throughout. The demands of exact computation require a different set of algorithms and efficiency improvements than those found in a traditional inexact floating point based modeler. We describe the system architecture, representations, and issues in implementing the algorithms. We also describe a number of techniques that increase the efficiency of the system based on lazy evaluation, use of floating point filters, arbitrary floating point arithmetic with error bounds, and lower dimensional formulation of subproblems. ESOLID has been used for boundary evaluation of many complex solids. These include both synthetic datasets and parts of a Bradley Fighting Vehicle designed using the BRL-CAD solid modeling system. It is shown that ESOLID can correctly evaluate the boundary of solids that are very hard to compute using a fixed-precision floating point modeler. In terms of performance, it is about an order of magnitude slower as compared to a floating point boundary evaluation system on most cases.


#*Microsoft PowerPoint 2002: Core and Expert Certification
#@Nita Hewitt Rutkosky
#t2001
#c
#index243902


#*Upwind Schemes with Exact Conservation Property for One-Dimensional Open Channel Flow Equations
#@Senka Vukovic,Luka Sopta
#t2002
#cSIAM Journal on Scientific Computing
#index565185
#!In this paper we present an application and extension of the upwind schemes with source terms decomposed, developed by Bermúdez, Vázquez, Hubbard, and Garcia-Navarro, to the one-dimensional open channel flow equations with general, i.e., nonprismatic and nonrectangular, geometries. Our specific numerical approximations for terms that appear in these equations and are related to the channel's geometrical properties are quite straightforward and natural, and at the same time respect the balancing of the flux gradient and the source term. As a consequence, the resulting upwind schemes have the exact conservation property. In several test problems we illustrate the achieved improvement, particularly significant for applications to natural watercourses due to their irregular riverbed geometries.


#*Design for Delay Testability in High-Speed Digital ICs
#@H. G. Kerkhoff,H. Speek,M. Shashani,M. Sachdev
#t2001
#cJournal of Electronic Testing: Theory and Applications
#index447453
#!The cost-effective testing of high-speed digital ICs is becoming increasingly problematic. Even advanced, costly testers are not always capable of testing these ICs because of their high-speed limitations. This paper focuses on a Design for Delay Testability (DfDT) technique such that high-speed ICs can be tested using inexpensive, low-speed test systems. Also extensions for possible full BIST of delay faults are addressed.


#*Interactive paraphrasing based on linguistic annotation
#@Ryuichiro Higashinaka,Katashi Nagao
#t2002
#cProceedings of the 19th international conference on Computational linguistics - Volume 2
#index98575
#!We propose a method "Interactive Paraphrasing" which enables users to interactively paraphrase words in a document by their definitions, making use of syntactic annotation and word sense annotation. Syntactic annotation is used for managing smooth integration of word sense definitions into the original document, and word sense annotation for retrieving the correct word sense definition for a word in a document. In this way, documents can be paraphrased so that they fit into the original context, preserving the semantics and improving the readability at the same time. No extra layer (window) is necessary for showing the word sense definition as in conventional methods, and other natural language processing techniques such as summarization, translation, and voice synthesis can be easily applied to the results.


#*Texture Based Look-Ahead for Decision-Tree Induction
#@Ming Dong,Ravi Kothari
#t2001
#cProceedings of the Second International Conference on Advances in Pattern Recognition
#index373656


#*Global eponential stability of cellular neural networks with time-varying coefficients and delays
#@Haijun Jiang,Zhidong Teng
#t2004
#cNeural Networks
#index101061
#%556032
#%237868
#%330066
#%299269
#%321334
#!In this paper, a class of cellular neural networks with time-varying coefficients and delays is considered. By constructing a suitable Liapunov functional and utilizing the technique of matrix analysis, some new sufficient conditions on the global exponential stability of solutions are obtained. The results obtained in this paper improve and extend some of the previous results.


#*Divergence in testing and readiness semantics
#@Michele Boreale,Rocco De Nicola,Rosario Pugliese
#t2001
#cTheoretical Computer Science
#index620176
#%155439
#%155743
#%178410
#%270927
#%456261
#!Many variants of must-testing semantics have been put forward that are equally sensitive to deadlock, but differ for the stress they put on divergence, i.e. on the possibility for systems of getting involved in infinite internal computations. Safe-testing is one such variant, that naturally pops up when studying the behavioural pre-congruences induced by certain basic observables. Here, we study the relationship between safe-testing and Olderog's readiness semantics, a semantics induced by a natural process logic. We show that safe-testing is finer than readiness, and coincides with a refinement of readiness obtained by tuning Olderog's definition. For both safe-testing and the original readiness semantics we propose simple complete axiomatizations, which permit a fuller appreciation of their similarities and differences. Copyright 2001 Elsevier Science B.V.


#*Evolutionary plantographics
#@Alon Gal,Gady Mahal,Moshe Sipper
#t2003
#cArtificial Life
#index115442
#%453302
#%521842
#%239454
#!This letter describes an evolutionary system for creating lifelike three-dimensional plants and flowers, our main goal being the facilitation of producing realistic plant imagery. With these two goals in mind--ease of generation and realism--we designed the plant genotype and the genotype-to-phenotype mapping. Diversity in our system comes about through two distinct processes--evolution and randomization--allowing the creation not only of single plants but of entire gardens and forests. Thus, we are able to readily produce natural-looking artificial scenes.


#*The unbounded vistas of science: evolutionary limitations
#@E. Atlee Jackson
#t2000
#cComplexity
#index315295


#*A quick development and delivery environment for test and exercises
#@D. Del Corso
#t2000
#cProceedings of the 30th Annual Frontiers in Education - Volume 02
#index429072
#!The paper presents a tool (X-LAMP) for quick design, development, and delivery of tests and interactive exercises for self-evaluation. The package allows the user to build groups of tests of various types, either as standalone modules or linked to theory pages. The tests can be delivered through the Internet or on CD-ROMs for independent use by students, or through controlled distribution with accesses monitored by the teacher.


#*ARC Macro Language: Developing ARC/Info Menus and Macros with AML with Cdrom, 2nd edition
#@GeoInformation International
#t2002
#c
#index251179


#*From simulation to practice: cache performance study of a Prolog system
#@Ricardo Lopes,Luís Fernando Castro,Vítor Santos Costa
#t2003
#cACM SIGPLAN Notices
#index556917
#%146041
#%356257
#%363553
#%556242
#!Progress in Prolog applications requires ever better performance and scalability from Prolog implementation technology. Most modern Prolog systems are emulator-based. Best performance thus requires both good emulator design and good memory performance. Indeed, Prolog applications can often spend hundreds of megabytes of data, but there is little work on understanding and quantifying the interactions between Prolog programs and the memory architecture of modern computers.In a previous study of Prolog systems we have shown through simulation that Prolog applications usually, but not always, have good locality, both for deterministic and non-deterministic applications. We also showed that performance may strongly depend on garbage collection and on database operations. Our analysis left two questions unanswered: how well do our simulated results holds on actual hardware, and how much did our results depend on a specific configuration? In this work we use several simulation parameters and profiling counters to improve understanding of Prolog applications. We believe that our analysis is of interest to any system implementor who wants to understand his or her own system's memory performance.


#*A Middleware Architecture for Scalable, QoS-Aware, and Self-Organizing Global Services
#@Franz J. Hauck,Erich Meier,Ulrich Becker,Martin Geier,Uwe Rastofer,Martin Steckermeier
#t2000
#cProceedings of the Third International IFIP/GI Working Conference on Trends in Distributed Systems: Towards a Universal Service Market
#index274869


#*Spatiotemporal patterns in a model of heterogeneous reaction in a porous catalyst particle
#@N. V. Peskov
#t2000
#cPhysica D
#index297163


#*Record Preprocessing for Data Compression
#@Jürgen Abel
#t2004
#cProceedings of the Conference on Data Compression
#index303667


#*Global Information from Local Observation
#@Itai Benjamini,László Lovász
#t2002
#cProceedings of the 43rd Symposium on Foundations of Computer Science
#index357497
#!We observe a certain random process on a graph "locally", i.e., in the neighborhood of a node, and would like to derive information about "global" properties of the graph. For example, what can we know about a graph based on observing the returns of a random walk to a given node?Our main result concerns a graph embedded in an orientable surface with genus g, and a process, consisting of random excitations of edges and random balancing around nodes and faces. It is shown how to obtain the genus of the surface in polynomial time from local observations of the process restricted to a connected subgraph whose size is (essentially)O(g2).


#*Parallel DSP Architecture for Reconstruction of Tomographic Images Using Wavelets Techniques
#@Maurício Fernando Lima Pereira,Luciano Vieira Koenigkan,Paulo Estevão Cruvinel
#t2001
#cProceedings of the 14th Brazilian Symposium on Computer Graphics and Image Processing
#index360703


#*Considering expected utility of future bidding options in bundle purchasing with multiple auctions
#@Scott Buffett
#t2004
#cProceedings of the 6th international conference on Electronic commerce
#index102425
#%273137
#!This paper presents an algorithm for decision-making in multiple open ascending-price (English) auctions where the buyer needs to procure a complete bundle of complementary products. When making bidding decisions, the utility of each choice is determined by considering the buyer's expected utility of future consequential decisions. The problem is modeled as a Markov decision process (MDP), and the value iteration method of dynamic programming is used to determine the value of bidding/not bidding in each state. To ease the computational burden, three state-reducing techniques are employed. When tested against adaptations of two methods from the literature, results show that the algorithm works significantly better when sufficient information on the progress of other concurrently running auctions will be available when future bidding decisions are made.


#*Conference Reports
#@Xiaowei Li
#t2004
#cIEEE Design Test
#index400201


#*Analysis of Ad Hoc Networks
#@
#t2002
#cProceedings of the 5th ACM international workshop on Modeling analysis and simulation of wireless and mobile systems
#index241033


#*Teach++: a cooperative distance learning and teaching environment
#@Maria Barra,Giuseppe Cattaneo,Umberto Ferraro Petrillo,Vincenzo Garofalo,Claudia Rossi,Vittorio Scarano
#t2000
#cProceedings of the 2000 ACM symposium on Applied computing - Volume 1
#index282213
#%148883
#%215941
#%382014
#%528147
#%603374
#%602722


#*An approach for impact structure optimization using the robust genetic algorithm
#@Shen-Yeh Chen
#t2001
#cFinite Elements in Analysis and Design
#index318693


#*Enhanced clustered voltage scaling for low power
#@Monica Donno,Luca Macchiarulo,Alberto Macii,Enrico Macii,Massimo Poncino
#t2002
#cProceedings of the 12th ACM Great Lakes symposium on VLSI
#index626479
#%96687
#%279655
#%282869
#%591336
#!This paper presents a voltage scaling approach that is based on an enhanced variant of clustered voltage scaling originally proposed by Usami and Horowitz ([1]) The results show that subtituting the original depth first strategy with a breadth first one results in improved speed and quality of results. Data are validated through power and timing analysis performed with a commercial tool.


#*Embedded Software Implementation Tools for Fully Programmable Application Specific Systems
#@Sharad Malik
#t2001
#cProceedings of the First International Workshop on Embedded Software
#index263658


#*An Approach to Encode Multilayer Perceptrons
#@Jerzy J. Korczak,Emmanuel Blindauer
#t2002
#cProceedings of the International Conference on Artificial Neural Networks
#index355415


#*The overfull conjecture and the conformability conjecture
#@A. J. W. Hilton,F. C. Holroyd,Cheng Zhao
#t2001
#cDiscrete Mathematics
#index254412


#*Impact of tree mortality in optimal control and parameter selection problems in forest stand management
#@O. Chikumbo,I. M. Y. Mareels
#t2002
#cDevelopment and application of computer techniques to environmental studies
#index572906
#%159352
#!Two mathematical formulations for determining optimal silvicultural regimes and initial number of trees at planting for a forest stand are compared. One formulation incorporates competition mortality of trees and the other does not. The comparison is done for a high site quality and low site quality stands in order to account for any influence that may result from geographical variations. The conventional wisdom is that competition mortality is of no real concern in intensively managed forests, and we set out to investigate this by experiment. The formulations are based on Pontryagin's maximum principle, using dynamical models in each case, for simulating the state dynamics of the optimal control systems.


#*Structuring operating system aspects: using AOP to improve OS structure modularity
#@Yvonne Coady,Gregor Kiczales,Mike Feeley,Norm Hutchinson,Joon Suan Ong
#t2001
#cCommunications of the ACM
#index334207
#%624775


#*Foreword
#@Madan M. Gupta
#t2003
#cAutonomous robotic systems: soft computing and hard computing methodologies and applications
#index113846


#*Perspectives: UTech
#@Judy Hammond
#t2001
#cinteractions
#index325352


#*Standard C++: with object-oriented programming
#@Paul S. Wang
#t2001
#c
#index323745


#*A note on a scale-sensitive dimension of linear bounded functionals in Banach spaces
#@Leonid Gurvits
#t2001
#cTheoretical Computer Science
#index612908
#%207868
#%217932
#%457547
#%519337
#%586607
#!We show that "B is of type p > 1" is a necessary and sufficient condition for a learnability of a class of linear bounded functionals with norm < 1 restricted to the unit ball in Banach space B. On the way, we give very short probabilistic proof for Vapnik's result (Hilbert space and improved) and improve our result with Pascal Koiran for convex halls of indicator functions. The approach we use in this paper allows to connect various results about learnability and approximation.


#*Special issue on computational algebra and number theory: proceedings of the second Magma conference
#@Hoon Hong,Wieb Bosma
#t2001
#cJournal of Symbolic Computation
#index320196


#*Direct execution simulation of load balancing algorithms with real workload distributed
#@Jiannong Cao,Graeme Bennett,Kang Zhang
#t2000
#cJournal of Systems and Software
#index332979


#*Multiple model control of a Buck dc/dc converter
#@D. Alejo,P. Maussion,J. Faucher
#t2003
#cMathematics and Computers in Simulation
#index305987
#!This paper describes a new method for algorithms commutation between two linear laws, for the voltage control of a dc/dc converter with variable loads. A multiple model control (MMC) is the generated, based upon the fusion of only two traditional IP controllers outputs. This strategy improves the performances of the step input responses and robustness.


#*Satisfaction Attainment Theory as a Model for Value Creation
#@Robert O. Briggs,Sajda Qureshi,Bruce Reinig
#t2004
#cProceedings of the Proceedings of the 37th Annual Hawaii International Conference on System Sciences (HICSS'04) - Track 1 - Volume 1
#index313410
#!Organizations exist to create value for their stakeholders that stakeholders cannot create through individual effort. Information systems exist to increase an organization's ability to create value using intellectual capital. A theoretical explanation of value might therefore be useful to increase the likelihood that IS/IT professionals would design and deploy systems inways that increase value for stakeholders. This paper proposes Satisfaction Attainment Theory (SAT) as causal model of value creation. An organizational stakeholder is a person whose wellbeing might be advanced by an organization. Perceptions of value have reference to some object-of-value. The term, object, in the context of this paper, means anything to which one could ascribe value -- e.g. goods, services, states, or outcomes. SAT assumes that people hold multiple, conflicting goals, and so must sacrifice the yield of some goal to attain others. It posits that an individual automatically and subconsciously sets anexpectation for some level of utility from attaining a goal and assesses the likelihood that a goal will be attained. It also posits that individuals automatically and subconsciously assess yield the yield of a Set of Salient Goals (SSG). Any perceived Shift in the Yield Assessment (SYA) for the salient set of goals is automatically accompanied by an affective arousal proportional to and with a valence in the direction of the perceived SYA. SAT proposes that the value of an object is a positive function of the SYA that occurs when an individual contemplates sacrificing the yield of other goals to obtain the yield that could be derived from the object. Value is therefore created by making an individual aware of an opportunity to attain a positive SYA by sacrificing the yield of one set of goals to attain the yield of another set.


#*Generalized Formal Concept Analysis
#@Laurent Chaudron,Nicolas Maille
#t2000
#cProceedings of the Linguistic on Conceptual Structures: Logical Linguistic, and Computational Issues
#index381873


#*Electrical characterization of TiO2 gate Oxides on strained-Si
#@C. K. Maiti,S. K. Samanta,G. K. Dalapati,S. K. Nandi,S. Chatterjee
#t2004
#cMicroelectronic Engineering
#index437874
#!The electrical properties of low temperature (150 °C) plasma deposited TiO2 gate dielectrics on strained-Si are reported. The deposited films have been analyzed by X-ray photoelectron spectroscopy for chemical composition. The interfacial and electrical properties of the deposited films have been characterized using a metal-insulator-semiconductor (MIS) capacitor structure. The charge trapping properties in TiO2 gate dielectrics have been studied using constant current stressing. The leakage current has been found to be dominated by the Poole-Frenkel emission.


#*Inequalities for a product
#@Mihály Bencze
#t2002
#cOctogon Mathematical Magazine
#index444233
#%244563


#*Layer 4 Fault Tolerance: Reliability Techniques for Cluster System in Internet Services
#@Guang Tan,Hai Jin,Liping Pang
#t2001
#cProceedings of the NATO Advanced Research Workshop on Advanced Environments, Tools, and Applications for Cluster Computing-Revised Papers
#index358583


#*Reducing Bloat in Genetic Programming
#@Patrick Monsieurs,Eddy Flerackers
#t2001
#cProceedings of the International Conference, 7th Fuzzy Days on Computational Intelligence, Theory and Applications
#index384503


#*The sixth text REtrieval conference (TREC-6)
#@Tefko Saracevic
#t2000
#cInformation Processing and Management: an International Journal
#index281665


#*The E-Commerce Book: Building the E-Empire, Second Edition, 2nd edition
#@Steffano Korper,Juanita Ellis
#t2000
#c
#index253012
#!:The E-Commerce Book: Building the E-Empire will lead you through e-commerce basics, explaining how both large and small companies are riding the wave to huge success. This book provides the opportunity to participate in what many have called the next "Industrial Revolution." This book is direct result of over 10 years of industry experience and "The E-Commerce Program," developed for professionals in the area of e-commerce. Primarily, the book focuses on business concepts and how to apply this technology in order to be successful. The book covers globalizing your company, marketing and advertising, market trends, vendor solutions and must-know technologies such as credit card verification systems, security, auction technologies, storefronts, and overall technology architecture. The final chapter focuses how to get and deploy e-commerce solutions from process re-engineering to actual deployment and testing. Key Features The E-Commerce Book: Building the E-Empire will lead you through e-commerce basics, explaining how both large and small companies are riding the wave to huge success. This book provides the opportunity to participate in what many have called the next "Industrial Revolution." This book is direct result of over 10 years of industry experience and "The E-Commerce Program," developed for professionals in the area of e-commerce. Primarily, the book focuses on business concepts and how to apply this technology in order to be successful. The book covers globalizing your company, marketing and advertising, market trends, vendor solutions and must-know technologies such as credit card verification systems, security, auction technologies, storefronts, and overall technology architecture. The final chapter focuses how to get and deploy e-commerce solutions from process re-engineering to actual deployment and testing. Key Features The first complete book on deploying an e-commerce solution for small, medium and large businesses Reveals how to open your first e-commerce business and provides a globalized site and deployment planning Walks you through the business aspects of e-commerce and translates these into the overall architecture and design solution Will help any corporation, small business, or entrepreneur to move their company into the 21st century The first complete book on deploying an e-commerce solution for small, medium and large businesses Reveals how to open your first e-commerce business and provides a globalized site and deployment planning Walks you through the business aspects of e-commerce and translates these into the overall architecture and design solution Will help any corporation, small business, or entrepreneur to move their company into the 21st century


#*The award for excellence in teaching, learning and technology
#@Fran White,Laura Byrd
#t2000
#cProceedings of the 28th annual ACM SIGUCCS conference on User services: Building the future
#index318880


#*Course Ilt: FreeHand 9 for Macintosh: Intermediate
#@
#t2001
#c
#index1288


#*Introduction
#@Mioara Mugur-Schächter
#t2002
#cQuantum mechanics, mathematics, cognition and action: proposals for a formalized epistemology
#index115711


#*Heuristic Methods for Large Centroid Clustering Problems
#@Éric D. Taillard
#t2003
#cJournal of Heuristics
#index438545
#%560939
#%487465
#%617678
#!This article presents new heuristic methods for solving a class of hard centroid clustering problems including the p-median, the sum-of-squares clustering and the multi-source Weber problems. Centroid clustering is to partition a set of entities into a given number of subsets and to find the location of a centre for each subset in such a way that a dissimilarity measure between the entities and the centres is minimized. The first method proposed is a candidate list search that produces good solutions in a short amount of time if the number of centres in the problem is not too large. The second method is a general local optimization approach that finds very good solutions. The third method is designed for problems with a large number of centres&semi; it decomposes the problem into subproblems that are solved independently. Numerical results show that these methods are efficient&mdash;dozens of best solutions known to problem instances of the literature have been improved&mdash;and fast, handling problem instances with more than 85,000 entities and 15,000 centres&mdash;much larger than those solved in the literature. The expected complexity of these new procedures is discussed and shown to be comparable to that of an existing method which is known to be very fast.


#*A compactness condition
#@J. M. Soriano
#t2001
#cApplied Mathematics and Computation
#index237264


#*The AGEDIS tools for model based testing
#@A. Hartman,K. Nagin
#t2004
#cACM SIGSOFT Software Engineering Notes
#index438415
#!We describe the tools and interfaces created by the AGEDIS project, a European Commission sponsored project for the creation of a methodology and tools for automated model driven test generation and execution for distributed systems. The project includes an integrated environment for modeling, test generation, test execution, and other test related activities. The tools support a model based testing methodology that features a large degree of automation and also includes a feedback loop integrating coverage and defect analysis tools with the test generator and execution framework. Prototypes of the tools have been tried in industrial settings providing important feedback for the creation of the next generation of tools in this area.


#*Combined pattern search and ranking and selection for simulation optimization
#@Todd A. Sriver,James W. Chrissis
#t2004
#cProceedings of the 36th conference on Winter simulation
#index32616
#%305341
#%316252
#%245830
#%610670
#%329654
#%567631
#%121502
#%568780
#%244386
#!A new algorithm class is presented for optimization of stochastic simulation models. The algorithms, which combine generalized pattern search (GPS) with ranking and selection (R&S), require "black-box" simulation evaluations and are applicable to problems with mixed variables (continuous, discrete numeric, and categorical). Implementation of the Mixed-variable Generalized Pattern Search with Ranking and Selection (MGPS-RS) algorithm with three different R&S procedures is demonstrated and tested on a small set of standard test functions. Results of this preliminary performance evaluation are summarized and compared with existing search methods.


#*Time-Indexed Formulations for Machine Scheduling Problems: Column Generation
#@J.M. Van Den Akker,C.A.J. Hurkens,M.W.P. Savelsbergh
#t2000
#cINFORMS Journal on Computing
#index566364
#!Time-indexed formulations for machine scheduling problems have received a great deal of attention; not only do the linear programming relaxations provide strong lower bounds, but they are good guides for approximation algorithms as well. Unfortunately, time-indexed formulations have one major disadvantage--their size. Even for relatively small instances the number of constraints and the number of variables can be large. In this paper, we discuss how Dantzig-Wolfe decomposition techniques can be applied to alleviate, at least partly, the difficulties associated with the size of time-indexed formulations. In addition, we show that the application of these techniques still allows the use of cut generation techniques.


#*Corel Photopaint(R) 10: The Official Guide
#@David Huss
#t2001
#c
#index254847
#!From the Book:Introduction So, there you stand next to a multicolored wall of computer titles, most of which are nearly as thick as phone books for major metropolitan cities. You ask yourself, "Will this book help me learn PHOTO-PAINT 10, or will it become another dust collector?" Your puzzlement is understandable. After all, the word "idiot" or "dummy" doesn't appear anywhere in the title. By now you have already looked at the dazzling color inserts and noticed it wasn't the typical collection of award-winning art produced by people with years of experience and way too much time on their hands. Instead you've seen a large collection of images that you will create using the step-by-step exercises in this book. If you own one of the previous editions of this book, you have also noticed that the exercises are different from the previous editions. Yet, you may hear that still-small voice in the background (not to be confused with the store announcement of the half-off sale on all organic chemistry textbooks) saying you won't be able to do stuff like that. Let me assure you that you will. Caution: This book contains exercises and information about digital photo-editing that could be harmful to your non-computer literate status. My "day job" (as in "don't give up your day job") for several years involved talking to thousands (OK, dozens) of people every day who began their conversations by telling me how stupid they were regarding their computer knowledge. That was generally just before they handed the phone over to their eight year old. These people are not stupid. However, they have come to believe that they are-convinced by a legion of techno-babble-talking computer types, many of whom simply need to date more often. In creating this book, I have worked with the following assumptions: You have not received the Nobel Prize recently. Your IQ is higher than that of mayonnaise. You would like to learn to use the computer for something other than solitaire or Quake. You are not a graphics arts expert; in fact, you may even be wondering if graphic art is the stuff they hang in motel rooms and sell by the truckload at "Starving Artist" sales. In short, if you want to learn PHOTO-PAINT, this book is for you. There is one tiny secret I must share with you if you really want to learn how to use PHOTO-PAINT: READ THE BOOK and DO THE EXERCISES! Contrary to rumors in the computer industry, you cannot learn anything in this book by any of the following methods: Osmosis Keeping the book near you at all times so the knowledge of the product migrates into your mind. Sleep Teaching Sleeping with a copy of the book as a pillow, hoping that it will somehow jumpstart one or more of your brain cells. Super Speeder Reader method Thumbing through the pages, wondering what all of the pictures mean. Proximity method Placing the book close enough to the computer so the PHOTO-PAINT program can make your computer smarter and do what you want it to do. The Annie method Bet your bottom dollar that tomorrow it'll make sense. The Impress Your Friends method Keeping a copy of this book on your shelf so your friends (or your boss) will think you are really getting into the program. Actually, this technique does work, except you never really learn anything-you just impress your friends. Enough already. Here is the short version. Using PHOTO-PAINT isn't brain surgery; it's electronic finger-painting without the mess to clean up afterward. As I always tell people at the PHOTO-PAINT seminars, if you're not having fun with PHOTO-PAINT, you're probably doing something wrong. Buy the book and then check out that sale of organic chemistry books.


#*Community Websites as a Local Communication Network: "Directory Westfield", an Experience Report
#@Karrie J. Hanson,Gerald M. Karam
#t2001
#cRevised Papers from the Second Kyoto Workshop on Digital Cities II, Computational and Sociological Approaches
#index260984


#*Processor Scheduling and Allocation for 3D Torus Multicomputer Systems
#@Hyunseung Choo,Seong-Moo Yoo,Hee Yong Youn
#t2000
#cIEEE Transactions on Parallel and Distributed Systems
#index286964
#%86460
#%161597
#%447211
#%375292
#!Multicomputer systems achieve high performance by utilizing a number of computing nodes. Recently, by achieving significant reductions in communication delay, the three-dimensional (3D) torus has emerged as a new candidate interconnection topology for message-passing multicomputer systems. In this paper, we propose an efficient processor allocation scheme¿scan search scheme¿for the 3D torus based on a first-fit approach. The scan search scheme minimizes the average allocation time for an incoming task by effectively manipulating the 3D information on a torus as 2D information using a data structure called the CST (Coverage Status Table). Comprehensive computer simulation reveals that the allocation time of the scan search scheme is always smaller than that of the earlier scheme based on a best-fit approach. The difference gets larger as the input load increases, and it is as much a factor of 3 for high load. To investigate the performance of the proposed scheme in different scheduling environments, we also consider a non-FCFS scheduling policy along with the typical FCFS policy. The allocation time complexity of the scan search scheme is $O(LW^{2}H^{2})$. This is significantly smaller than that of the existing scheme which is $O(L^{4}W^{4}H^{4})$. Here, $L$, $W$, and $H$ represent the length, width, and height of 3D torus, respectively.


#*Towards Secure e-Services
#@Claudiu Duma,Almut Herzog,Nahid Shahmehri
#t2000
#cProceedings of the 9th IEEE International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises
#index269742
#!The networked home with refrigerators and washing machines connected to the Internet and reachable through Web browsers will be reality soon. Following this development, the market for electronically deliverable services will evolve. Companies that want to provide electronic services cannot be expected to deal with cable, network and routing problems - they need to rely and build on a common, secure hard- and software infrastructure that allows services to reach the customers' homes. We call such an infrastructure an e-services system (e-SS). In this paper, we present the infrastructure of an example e-SS, highlight a number of specific security issues and show how they can be addressed in the early stages of the design of an e-SS.


#*Maximum likelihood methods for bearings-only target localization
#@L. M. Kaplan
#t2001
#cProceedings of the Acoustics, Speech, and Signal Processing, 2001. on IEEE International Conference - Volume 05
#index429405
#!We develop four maximum likelihood (ML) methods to localize a moving target using a network of acoustical sensor arrays. Each array transmits a direction-of-arrival (DOA) estimate to a central processor, which employs one of the localization techniques. The four ML approaches use different target signal models where the time retardation factor for the target position and the degradation of the target signal through the air may or may not be included in the model. We compare these methods along with a linear least squares approach through a number of simulations at various signal to noise levels.


#*A hierarchical cost estimation tool
#@David Koonce,Robert Judd,Dusan Sormaz,Dale T. Masel
#t2003
#cComputers in Industry
#index110359
#!The estimation of the manufacturing cost of a part in all phases of the design stage is crucial to concurrent engineering. To better estimate the cost for a product, data must be available from both engineering systems and business systems. This paper presents a cost estimation system being developed to support design time cost estimation using the Federated Intelligent Product EnviRonment (FIPER), which is being developed as part of the National Institute of Standards and Technology (NIST) Advanced Technology Program (ATP). The FIPER research team is developing an architecture that interconnects design and analysis software tools in a peer level architecture to support multidisciplinary design optimization (MDO), design for six sigma (DFSS) and robust design.


#*Your UNIX: The Ultimate Guide, 1st edition
#@Sumitabha Das
#t2000
#c
#index622910
#!:Your UNIX: The Ultimate Guide is both an outstanding pedagogical tool and an exhaustive reference. It is the ideal text for any Unix course. It can also be used for any introductory programming course that includes Unix and for advanced courses such as those on Operating Systems and System Administration. Excellent pedagogy is implemented throughout. Real-world examples make it easier for students to grasp concepts while "Going Further" sections take more advanced students beyond the basics. Over nine hundred exercises allow students to test and reinforce their understanding of material at different levels. This book also features coverage of Linux, which is well marked so that instructors can choose to either include it in their courses or omit it. Additionally, Your UNIX has the most extensive set of indices and appendices currently available in a Unix text. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*High resolution magnetic patterning using focused ion beam irradiation
#@C. Vieu,J. Gierak,H. Launois,T. Aign,P. Meyer,J. P. Jamet,J. Ferré,C. Chappert,V. Mathet,H. Bernas
#t2000
#cMicroelectronic Engineering
#index322696


#*Combined dynamic voltage scaling and adaptive body biasing for lower power microprocessors under dynamic workloads
#@Steven M. Martin,Krisztian Flautner,Trevor Mudge,David Blaauw
#t2002
#cProceedings of the 2002 IEEE/ACM international conference on Computer-aided design
#index565971
#%244794
#%300101
#!Dynamic voltage scaling (DVS) reduces the power consumption of processors when peak performance is unnecessary. However, the achievable power savings by DVS alone is becoming limited as leakage power increases. In this paper, we show how the simultaneous use of adaptive body biasing (ABB) and DVS can be used to reduce power in high-performance processors. Analytical models of the leakage current, dynamic power, and frequency as functions of supply voltage and body bias are derived and verified with SPICE simulation. We then show how to determine the correct trade-off between supply voltage and body bias for a given clock frequency and duration of operation. The usefulness of our approach is evaluated on real workloads obtained using real-time monitoring of processor utilization for four applications. The results demonstrate that application of simultaneous DVS and ABB results in an average energy reduction of 48% over DVS alone.


#*Software engineering throughout a traditional computer science curriculum
#@J. Paul Myers, Jr.
#t2001
#cJournal of Computing Sciences in Colleges
#index328825
#%583521
#%463075
#%474600
#%518321
#%601045
#%526976
#!As software engineering (SE) is becoming increasingly important as a discipline for computing professionals, so is it becoming an increasing emphasis in undergraduate computing education. The curricular revisions described here represent an attempt to incorporate SE principles throughout an undergraduate curriculum in Computer Science (CS). The emphasis here, however, is not one of wholesale overhaul into a SE program, possibly to the detriment of other strengths in the previous curriculum. Rather this is a non-radical augmentation and change of focus in certain aspects of a strong, but somewhat traditional CS curriculum.


#*Bias-Variance Error Bounds for Temporal Difference Updates
#@Michael J. Kearns,Satinder P. Singh
#t2000
#cProceedings of the Thirteenth Annual Conference on Computational Learning Theory
#index566210


#*Undecimated wavelet shrinkage estimate of the 1D and 2D spectra
#@P. Carre
#t2000
#cProceedings of the Acoustics, Speech, and Signal Processing, 2000. on IEEE International Conference - Volume 04
#index430191
#!We study the problem of estimating the log-spectrum of a stationary Gaussian time series by thresholding the wavelet coefficients. We propose the use of the undecimated wavelet transform to denoise the log-periodogram. For this, we review a denoising method based on undecimated wavelet transform, and we propose a level-dependent threshold which considers that one undecimated scale has N/b coefficients "repeating" b times. The result corresponds to the average of all log-peridogram circulant shifts denoised by a decimated wavelet transform. The purpose of this undecimated thresholding is to make the reconstructed log-spectrum as nearly noise-free as possible, but with a keep of all small frequential components. Since the wavelet denoising method can be generalized to images, we develop an estimation technique of the 2D log-spectrum based on 2D undecimated wavelet. We derive a new technique, easy to apply, which gives information about the 2D frequential components of an image.


#*Who is an open source software developer?
#@Bert J. Dempsey,Debra Weiss,Paul Jones,Jane Greenberg
#t2002
#cCommunications of the ACM
#index625572
#%449480
#!Profiling a community of Linux developers.


#*Factorial Code Representation of Faces for Recognition
#@Seungjin Choi,Oyoung Lee
#t2000
#cProceedings of the First IEEE International Workshop on Biologically Motivated Computer Vision
#index566940


#*Symmetric Collaborative Filtering Using the Noisy Sensor Model
#@Rita Sharma,David Poole
#t2001
#cProceedings of the 17th Conference in Uncertainty in Artificial Intelligence
#index564580


#*Challenges in the Design of Embedded Real-time DSP SoCs
#@Mahesh Mehendale
#t2004
#cProceedings of the 17th International Conference on VLSI Design
#index311960
#!This paper focuses on the challenges in the design ofembedded real-time DSP SoCs. We first present a genericmicroarchitecture of an SoC based on a programmableDSP CPU. We then discuss customer requirements for atypical SoC and present SoC design as a multidimensionaloptimization problem. We highlight the need to look at thedesign objectives in the context of the complete solutionand not just the chip. The paper looks at the challenges inboth the SoC definition and the design phases. We proposea concurrent engineering approach for SoC definition anda platform based approach for SoC design. The paper usesDM642 programmable digital media processor SoC as anexample to illustrate these approaches.


#*Introduction to C and C++ for Technical Students, 2nd edition
#@Timothy Ramteke
#t2002
#c
#index253179
#!:Unlike many other C++ books, which focus almost entirely on syntax, this one provides explorations of the fundamental principles and logic behind the language. Throughout its coverage, linguistic elements are combined with object-oriented principles and practices, analysis and design. The author's practical, skill-building approach begins by developing a firm foundation for each topic and providing ample practice and reinforcement, thenwhen a thorough understanding has been establishedprogressing forward, focusing only on the information that is necessary to reach the next step. For individuals seeking an introduction to object-oriented programming using C++.


#*Efficient computation of the topology of level sets
#@V. Pascucci,K. Cole-McLaughlin
#t2002
#cProceedings of the conference on Visualization '02
#index439172
#%91112
#%453387
#!This paper introduces two efficient algorithms that compute the Contour Tree of a 3D scalar field F and its augmented version with the Betti numbers of each isosurface. The Contour Tree is a fundamental data structure in scientific visualization that is used to preprocess the domain mesh to allow optimal computation of isosurfaces with minimal overhead storage. The Contour Tree can also be used to build user interfaces reporting the complete topological characterization of a scalar field, as shown in Figure 1.The first part of the paper presents a new scheme that augments the Contour Tree with the Betti numbers of each isocontour in linear time. We show how to extend the scheme introduced in [3] with the Betti number computation without increasing its complexity. Thus, we improve on the time complexity from our previous approach [10] from O(m log m) to O(n log n + m), where m is the number of tetrahedra and n is the number of vertices in the domain of F.The second part of the paper introduces a new divide-and-conquer algorithm that computes the Augmented Contour Tree with improved efficiency. The central part of the scheme computes the output Contour Tree by merging two intermediate Contour Trees and is independent of the interpolant. In this way we confine any knowledge regarding a specific interpolant to an oracle that computes the tree for a single cell. We have implemented this oracle for the trilinear interpolant and plan to replace it with higher order interpolants when needed. The complexity of the scheme is O(n + t log n), where t is the number of critical points of F. For the first time we can compute the Contour Tree in linear time in many practical cases when t = O(n1 - &epsilon;).Lastly, we report the running times for a parallel implementation of our algorithm, showing good scalability with the number of processors.


#*Development of a High-performance Domain-wise Parallel Direct Solver for Large-scale Structural Analysis
#@Jeong Ho Kim,Chang Sung Lee,Seung Jo Kim
#t2004
#cProceedings of the High Performance Computing and Grid in Asia Pacific Region, Seventh International Conference
#index434532
#!Most of researches for large-scale parallel structural analysis using finite element method have focused on iterative solution methods since direct solution methods generally have many difficulties and disadvantages for large-scale problems. However, due to the numerical robustness of direct methods that guarantees the solution to be obtained within estimated time, direct methods are much more desirable for general application of large-scale structural analysis, as well as due to ease of use which makes most of structural engineers prefer direct methods. In this research, we propose a new parallel direct solver for large-scale finite element analysis that can overcome most of difficulties and disadvantages of direct methods by using domain-wise approach for direct methods. By using the proposed solver with our own structural analysis code, we can show good scalability as a direct method and can solve the largest problem ever solved by direct solvers.


#*Using digital certificates for access control in clinical intranet applications
#@I. Mavridis,C. Georgiadis,G. Pangalos,M. Khair
#t2000
#cTechnology and Health Care
#index326470


#*Positive Dynamic Systems with the Entropy Operator
#@Yu. S. Popkov
#t2003
#cAutomation and Remote Control
#index562197
#!The class of positive dynamic systems with the entropy operator argmin was defined. The conditions for continuity, differentiability, and boundedness of the conditional optimal entropy were obtained. For the dynamic systems with this operator, the conditions for solution boundedness were obtained.


#*Web-Based Information Retrieval Using Agent and Ontology
#@Kwang Mong Sim,Pui Tak Wong
#t2001
#cProceedings of the First Asia-Pacific Conference on Web Intelligence: Research and Development
#index376215


#*Autowrite: A Tool for Checking Properties of Term Rewriting Systems
#@Irène Durand
#t2002
#cProceedings of the 13th International Conference on Rewriting Techniques and Applications
#index261063


#*Synthesising Facial Emotions
#@
#t2004
#cProceedings of the Theory and Practice of Computer Graphics 2004 (TPCG'04)
#index435710
#!We present two approaches for the generation of novelvideo textures which portray a human expressing differentemotions. Here training data is provided by video sequencesof an actress expressing specific emotions such asangry, happy and sad. The main challenge of modellingthese video texture sequences is the high variance in headposition and facial expression. Principal Components Analysis(PCA) is used to generate so called ýmotion signaturesýwhich are shown to be complex and have non-Gaussian distributions.The first method uses a combined appearancemodel to transform the video data into a lower dimensionalGaussian space. This can then be modelled using a standardautoregressive process. The second technique presented extractssub-samples from the original data using short temporalwindows, some of which have Gaussian distributionsand can be modelled by an autoregressive process (ARP).We find that the combined appearance technique producesmore aesthetically pleasing clips but does not maintain themotion characteristics as well as the temporal window approach.


#*Human hands as a link between physical and virtual
#@Thomas Pederson
#t2000
#cProceedings of DARE 2000 on Designing augmented reality environments
#index321089
#%91976
#%220356
#%285976
#%606790


#*Negotiating from Mars to Venus: gender in simulated international negotiations
#@Natalie B. Florea,Mark A. Boyer,Scott W. Brown,Michael J. Butler,Magnolia Hernandez,Kimberly Weir,Lin Meng,Paula R. Johnson,Clarisse Lima,Hayley J. Mayall
#t2003
#cSimulation and Gaming
#index119209
#!Gender analysis has emerged as an important conceptual approach to the study of decision making and conflict resolution in the international arena. Although scholars and practitioners within the field of international relations have debated the effect of gender on the negotiation and decision-making process, little systematic evidence to support their assertions has taken place. This article examines a set of data from the GLOBALED PROJECT that provides insights into the different ways men and women perceive world affairs and interact in a negotiation setting. In particular, the authors examine differences in the negotiation styles of all-female, all-male, and mixed-gender groups when negotiating over international or global issues. Findings from the GLOBALED PROJECT, a computer-mediated study of gender differences in decision-making and negotiation skills, show that there are indeed significant differences between the approaches used by various gender groupings. Although much work remains to be done in this area, this research indicates that some of the impressionistic and anecdotal characterizations of the different ways men and women approach negotiations and decision making are indeed well-grounded when examined through systemic evidence.


#*AEGIS: An Active-Network-Powered Defense Mechanism against DDoS Attacks
#@Eric Y. Chen
#t2001
#cProceedings of the IFIP-TC6 Third International Working Conference on Active Networks
#index367085


#*Performance and Analysis
#@
#t2004
#cProceedings of the 3rd international symposium on Principles and practice of programming in Java
#index98243


#*Overview of Mpls
#@
#t2002
#c
#index114792


#*Clustering analysis of microarray gene expression data by splitting algorithm
#@Ruye Wang,Lucas Scharenbroich,Christopher Hart,Barbara Wold,Eric Mjolsness
#t2003
#cJournal of Parallel and Distributed Computing
#index311713
#%200277
#!A clustering method based on recursive bisection is introduced for analyzing microarray gene expression data. Either or both dimensions for the genes and the samples of a given microarray dataset can be classified in an unsupervised fashion. Alternatively, if certain prior knowledge of the genes or samples is available, a supervised version of the clustering analysis can also be carried out. Either approach may be used to generate a partial or complete binary hierarchy, the dendrogram, showing the underlying structure of the dataset. Compared to other existing clustering methods used for microarray data analysis (such as hierarchical and K-means), the method presented here has the advantage of much improved computational efficiency while retaining effective separation of data clusters under a distance metric, a straightforward parallel implementation, and useful extraction and presentation of biological information. Clustering results of both synthesized and experimental microarray data are presented to demonstrate the performance of the algorithm.


#*An SoC Solution for Massive Parallel Processing
#@David Reed,Raymond Hoare
#t2002
#cProceedings of the 16th International Parallel and Distributed Processing Symposium
#index372896


#*Augmented Reality in the Operating Theatre of the Future
#@Heinz Wörn,Harald Hoppe
#t2001
#cProceedings of the 4th International Conference on Medical Image Computing and Computer-Assisted Intervention
#index263996


#*Learning an Agent's Utility Function by Observing Behavior
#@Urszula Chajewska,Daphne Koller,Dirk Ormoneit
#t2001
#cProceedings of the Eighteenth International Conference on Machine Learning
#index379104


#*Implementing and Analysing an Effective Explicit Coscheduling Algorithm on a NOW
#@Francesc Solsona,Francesc Giné,Fermín Molina,Porfidio Hernández,Emilio Luque
#t2000
#cSelected Papers and Invited Talks from the 4th International Conference on Vector and Parallel Processing
#index257237


#*Designware: software development by refinement
#@Douglas R. Smith
#t2001
#cHigh integrity software
#index619089
#%210388
#%269119
#%376571
#!This paper presents a mechanizable framework for software development by refinement. The framework is bawed on a category of higher-order specifications. The key idea is representing knowledge about programming concepts, such as algorithm design, datatype refinement, and expression simplification, by means of taxonomies of specifications and morphisms. The framework is partially implemented in the research systems Specware, Designware, and Planware. Specware provides basic support for composing specifications and refinements via colimit, and for generating code via logic morphisms. Specware is intended to be general-purpose and has found use in industrial settings. Designware extends specware with taxonomies of software design theories and support for constructing refinements from them. Planware builds on designware to provide highly automated support for requirements acquisition and synthesis of high-performance scheduling algorithms.


#*Rate of change load balancing in distributed and parallel systems
#@Luis Miguel Campos,Isaac D. Scherson
#t2000
#cParallel Computing
#index331116


#*Glitch power minimization by selective gate freezing
#@Luca Benini,Giovanni De Micheli,Alberto Macii,Enrico Macii,Massimo Poncino,Riccardo Scarsi
#t2000
#cIEEE Transactions on Very Large Scale Integration (VLSI) Systems
#index285462


#*Cellular Automata: A Discrete Universe
#@Andrew Ilachinski,Zane
#t2001
#c
#index302954


#*Ims Version 9 Implementation Guide: A Technical Overview (IBM Redbooks)
#@Jouko Jantti
#t2004
#c
#index9432


#*Orthosis Design System for Malformed Ears Based on Spline Approximation
#@Akihiko Hanafusa,Tsuneshi Isomura,Yukio Sekiguchi,Hajime Takahashi,Takeyoshi Dohi
#t2002
#cProceedings of the 5th International Conference on Medical Image Computing and Computer-Assisted Intervention-Part II
#index272162


#*The Workflow-Enabled Supply Chain, the Civil Construction Enterprise Case Study
#@Mario Paulo Teixeira Pinto,João José Pinto Ferreira
#t2002
#cProceedings of the IFIP TC5/WG5.5 Third Working Conference on Infrastructures for Virtual Enterprises: Collaborative Business Ecosystems and Virtual Enterprises
#index269875


#*Specification of Constraints in Business Flow
#@Shunsuke Yura,Toshihiro Motoda,Shuichiro Yamamoto
#t2000
#cProceedings of the 4th International conference on Enterprise Distributed Object Computing
#index367145
#!The paper proposes an approach which generates alternative flows and cancel flows necessary in exceptional conditions automatically with transactional constraint rules in business flow. In our approach, modification of a business flow is easier than current workflow systems because modification of the transactional constraint rule is not necessary unless constraints among the services change. The paper shows the effectiveness of our approach with a travel reservation example.


#*An algorithm for nonlinear optimization using linear programming and equality constrained subproblems
#@Richard H. Byrd,Nicholas I. M. Gould,Jorge Nocedal,Richard A. Waltz
#t2004
#cMathematical Programming: Series A and B
#index434968
#!This paper describes an active-set algorithm for large-scale nonlinear programming based on the successive linear programming method proposed by Fletcher and Sainz de la Maza [10]. The step computation is performed in two stages. In the first stage a linear program is solved to estimate the active set at the solution. The linear program is obtained by making a linear approximation to the &#x2113;1 penalty function inside a trust region. In the second stage, an equality constrained quadratic program (EQP) is solved involving only those constraints that are active at the solution of the linear program. The EQP incorporates a trust-region constraint and is solved (inexactly) by means of a projected conjugate gradient method. Numerical experiments are presented illustrating the performance of the algorithm on the CUTEr [1, 15] test set.


#*Windows XP from a to Z: A Quick Reference of More than 300 Microsoft Tasks, Terms, and Tricks
#@Pat Coleman
#t2001
#c
#index247306
#!:Providing more than 300 entries, this latest From A to Z reference shows short step-by-step descriptions and easy-to-understand definitions of all the common Windows XP terms. A handy listing of entries, this book organizes its Windows XP data alphabetically by task. With this logical organization of information, even new Windows XP users can get answers quickly and easily. Important topics covered are Windows tools that are useful to the beginner and the advanced user, such as finding files, using applets for business tasks, making network connections, and performing system maintenance.Pat Coleman is the author of Effective Executives Guide to Project 2000 and MBAs Guide to the Internet. She lives in Houston, Texas.


#*DecisionQoS: An Adaptive, Self-Evolving QoS Arbitration Module for Storage Systems
#@
#t2004
#cProceedings of the Fifth IEEE International Workshop on Policies for Distributed Systems and Networks
#index436453
#!As a consequence of the current trend towards consolidatingcomputing, storage and networking infrastructuresinto large centralized data centers, applications competefor shared resources. Open enterprise systems are not designedto provide performance guarantees in the presenceof sharing; unregulated competition is very likely to resultin a free-for-all where some applications monopolize resourceswhile others starve. Rule-based solutions to the resourcearbitration problem suffer from excessive complexity,brittleness, and limitations in their expressive power.We present DECISIONQOS, a novel approach for arbitratingresources among multiple competing clients while enforcingQoS guarantees. DECISIONQOS requires systemadministrators to provide a minimal, declarative amount ofinformation about the system and the workloads runningon it. That initial input is continuously refined and augmentedat run time, by monitoring the system's performanceand its reaction to resource allocation decisions. Whenfaced with incomplete information, or with changes in theworkload requirements or system capabilities, DECISIONQOSadapts to them by applying machine learning techniques;the resulting scheme is highly resilient to unforeseenevents. Moreover, it overcomes significant shortcomings ofpre-existing, rule-based policy management systems.


#*Scaling trends of on-chip Power distribution noise
#@Andrey V. Mezhiba,Eby G. Friedman
#t2002
#cProceedings of the 2002 international workshop on System-level interconnect prediction
#index622395
#%80738
#%119510
#%125083
#%300468
#%334086
#!The design of power distribution networks in high performance integrated circuits has become significantly more challenging with recent advances in process technology. As on-chip currents exceed tens of amperes and circuit clock periods are reduced well below a nanosecond, the signal integrity of the on-chip power supply has become a primary concern in integrated circuit design. The existing work on power distribution noise scaling is reviewed and extended to include the scaling of the inductance of the on-chip global power distribution networks in high performance flip-chip packaged integrated circuits. As the dimensions of the on-chip devices are scaled by S, where S&rho;1, the resistive voltage drop across the power grids remains constant and the inductive voltage drop increases by S, if the metal thickness is maintained constant. Consequently, the signal-to-noise ratio decreases by S in the case of resistive noise and by S2 in the case of inductive noise. As compared to the constant metal thickness scenario, ideal interconnect scaling in the global power grid mitigates unfavorable scaling of the inductive noise but exacerbates the scaling of resistive noise by a factor of S. On-chip inductive noise will therefore become of greater significance with technology scaling. Careful tradeoffs between the resistance and inductance of the power distribution networks will be necessary in nanometer technologies to achieve minimum power supply noise levels.


#*Performance Analysis of Cellular Mobile Communications under MultipathInterference
#@Jyh-Horng Wen,Di-Yar Han
#t2000
#cWireless Personal Communications: An International Journal
#index439868
#!In a radio communication environment, no matter whether signal is transmitted outdoors or indoors, the phenomenon of multipath interference is unavoidable. Therefore, it is necessary for us to thoroughly study the effect of multipath interference on cellular mobile systems. In this paper, we first investigate the effect of multipath interference on the performance of a single cell system with finite users. In order to use the Markov chain method, a system model with 2-dimensional state vector is presented. With his model, the system performance under multipath interference has been successfully derived. Next, an extended-slot method to reduce the multipath interference triggered by LOS packets occurring in the previous slot is proposed. Numerical results show that this method can remarkably enhance the system performance. Finally, we further analyze the combined effect of co-channel interference and multipath interference on the performance of multicell systems. Numerical results show that the system performance suffers some degradation compared to the single cell environment. However, the degradation under typical environments with path-loss exponent around 4 is insignificant.


#*Theory of Trinomial Heaps
#@Tadao Takaoka
#t2000
#cProceedings of the 6th Annual International Conference on Computing and Combinatorics
#index267951


#*Rectangular Drawings of Plane Graphs Without Designated Corners
#@Md. Saidur Rahman,Shin-Ichi Nakano,Takao Nishizeki
#t2000
#cProceedings of the 6th Annual International Conference on Computing and Combinatorics
#index275378


#*Development of intelligent tutoring systems using knowledge structures
#@Miguel Nussbaum,Ricardo Rosas,Isabel Peirano,Francisco Cárdenas
#t2001
#cComputers Education
#index332889


#*Welcome
#@
#t2004
#cProceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition
#index437467


#*Polyphase scalable complete complementary sets of sequences
#@Xiaojing Huang,Yunxin Li
#t2002
#cProceedings of the The 8th International Conference on Communication Systems - Volume 02
#index431997
#!Extended from their biphase counterparts, biphase scalable complete complementary sets of sequences are discovered in this paper. Starting from biphase scalable complete complementary sets of sequences, the notions of Golay-paired matrix, Golay-paired Hadamard matrix and mutually orthogonal Golay-paired matrices are reviewed and extended to their respective polyphase ones. Synthesis methods, including recursive procedure and closed-form formula, for constructing these polyphase scalable complete complementary sets of sequences represented by mutually orthogonal polyphase Golay-paired Hadamard matrices are also proposed accordingly. Finally, the polyphase cover code and its synthesis methods are discussed and illustrated, which provides the linkage between biphase and polyphase scalable complete complementary sets of sequences.


#*The Effects of Communication Media on Group Performance in Requirements Engineering
#@Daniela E. Herlea Damian,Armin Eberlein,Mildred L. G. Shaw,Brian R. Gaines
#t2000
#cProceedings of the 4th International Conference on Requirements Engineering (ICRE'00)
#index114699
#!Delivering systems that meet all stakeholders' needs is easier said than done in a software development world in which resource constraints are everyday realities. In particular, the negotiation between different stakeholders and the reconciliation of their conflicting viewpoints has been recognized as major problems in requirements engineering. This is even more challenging as organizations become more global, and requirements often come from distributed groups. Although the use of multimedia meeting systems is becoming a reality in distributed software development, our knowledge of how such systems affect group performance and their role in facilitating social processes in requirements engineering is limited.This paper reports on a study that compared the performance of groups in face-to-face and distributed requirements negotiation meetings, paying special consideration to the socio-psychological aspects of group interaction in both communication media.


#*Data Distribution and Communication Schemes for IQMR Method on Massively Distributed Memory Computers
#@Laurence Tianruo Yang
#t2000
#cProceedings of the 2000 International Workshop on Parallel Processing
#index114148
#!In this paper, we study the parallelization of IQMR method for the solutions of linear systems of equations with unsymmetric coefficient matrices. The IQMR method is an improved version of the quasi-minimal residual (IQMR) method by using the Lanczos process as a major component combining elements of numerical stability and parallel algorithm design. The algorithm is derived such that all inner products and matrix-vector multiplications of a single iteration step are independent and communication time required for inner product can be overlapped efficiently with computation time. Two important schemes are discussed. What is the best possible data distribution and which communication network topology is most suitable for IQMR method on massively parallel-distributed memory computers. A theoretical model of data distribution and communication phases is presented mainly based on [14, 15] which allows us to give a detail execution time complexity analysis and investigates its usefulness. It is shown that the implementation of IQMR, with a row-block decomposition of the coefficient matrix, on a ring of communication structure is the most efficient choice. Performance tests of the developed parallel IQMR algorithm have been carried out on the massively distributed memory system and experimental timing results are compared with the theoretical execution time complexity analysis. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Quality Memory Blocks Balancing the Trade-Offs
#@Betty Prince
#t2000
#cProceedings of the 1st International Symposium on Quality of Electronic Design
#index122659
#!Memory blocks have the basic quality requirements shared by all IP blocks. These include transferability between manufacturing areas, transferability from the original technology to the next generation technology, compatibility with available design tools, and qualified manufacturability in available wafer fabs. In addition to these general quality requirements, issues specific to memory blocks need to be considered. These include: memory type and cell for the specific implementation; memory technology generation to be used; cost issues such as requirements for special process modules; design issues such as choice of array compiler or use of predefined memory blocks; yield improvement issues such as redundancy type and implementation; test issues including BIST or direct memory access, special memory test requirements such as bit mapping, and availability of memory testers; reliability issues such as disturb problems, burn-in requirements and soft error considerations; architectural issues such as on-chip bandwidth access, pitch matching of array logic, and refresh implementation. This paper discusses these memory specific quality issues and the trade-offs involved.


#*ACO Algorithm for MKP Using Various Heuristic Information
#@Stefka Fidanova
#t2002
#cRevised Papers from the 5th International Conference on Numerical Methods and Applications
#index564229


#*Scientific papers: Heartweb: A web-based tool for tailoring nutrition counselling in patients at elevated cardiovascular risk
#@Marieke Verheijden,Paul van Genuchten,Marshall Godwin,Chris van Weel,Wija van Staveren
#t2002
#cTechnology and Health Care
#index556710
#%244787


#*Microsoft Word 2002
#@Nita Hewitt Rutkosky
#t2001
#c
#index242337


#*Searching for mobile mice and elephants in GPRS networks
#@Roger Kalden,Hannes Ekström
#t2004
#cACM SIGMOBILE Mobile Computing and Communications Review
#index109500
#!In this paper, we provide statistics on large-scale traffic measurements that have been made in a live cellular GPRS network. We show that the current GPRS traffic is dominated by HTTP- and WAP-based applications, and further show in what direction (uplink and/or downlink) the ensuing traffic is transmitted as well as statistics on the length of the flows on a per application basis. We find that the results differ compared to those found in similar measurement studies that have been carried out in the fixed Internet. In particular, our results suggest that flows are shorter in cellular networks, and that the so-called mice and elephant effect, whereby a small part of the flows make up a majority of the bytes transferred, is not prevalent in GPRS networks. Instead, extremely short flows account for the majority of the total flows and bytes transferred. We also discuss the impact of this finding on future research on TCP loss recovery.


#*Finding and Labeling the Subject of a Captioned Depictive Natural Photograph
#@N. C. Rowe
#t2002
#cIEEE Transactions on Knowledge and Data Engineering
#index441046
#%77759
#%86739
#%94612
#%210152
#%213812
#%443361
#%542374
#%445709
#!We address the problem of finding the subject of a photographic image intended to illustrate some physical object or objects (¿depictive¿) and taken by usual optical means without magnification (¿natural¿). This could help in developing digital image libraries since important image properties like subject size and color of a photograph are not usually mentioned in accompanying captions and can help rank the photograph retrievals for a user. We explore an approach that identifies the ¿visual focus¿ of the image and the ¿depicted concepts¿ in a caption and connects them. The visual focus is determined by using eight domain-independent characteristics of regions in the segmented image, and the caption depiction is identified by a set a rules applied to the parsed and interpreted caption. The visual-focus determination also does combinatorial optimization on sets of regions to find the set that best satisfies focus criteria. Experiments on 100 randomly selected image-caption pairs show significant improvement in precision of retrieval over simpler methods, and, particularly, emphasizes the value of segmentation of the image.


#*Material and process challenges in 100 nm interconnects module technology and beyond
#@Takayuki Ohba
#t2001
#cJournal of Electronic Materials
#index325996


#*Editing Digital Video: The Complete Creative and Technical Guide, 1 edition
#@Robert M. Goodman,Patrick McGrath
#t2002
#c
#index118824
#!:* Demystifies video editing for all styles: narrative, documentary, and music* How to use any available toolfrom the simplest home editing software to complex professional systems to expertly edit their material* CD-ROM contains a digital video editing toolkit


#*Case studies of the CHI2002|AIGA Experience Design FORUM
#@
#t2002
#cConference on Human Factors in Computing Systems
#index624413


#*Using Rough Sets Theory and Database Operations to Construct a Good Ensemble of Classifiers for Data Mining Applications
#@Xiaohua Hu
#t2001
#cProceedings of the 2001 IEEE International Conference on Data Mining
#index375737
#!In this paper we present a new approach to construct a good ensemble of classifiers using rough sets theory and database operations. Ensembles of classifiers is formulated precisely within the framework of rough sets theory and constructed very efficiently by using set-oriented database operations. Our method first computes a set of reductswhich include all the indispensable attributes required for the decision categories. For each reduct, a reduct table is generated by removing those attributes which are not in the reduct. Next, a novel rule induction algorithm is used to compute the maximal generalized rules for each reducttable and a set of reduct classifiers is formed based on thecorresponding reducts. The distinctive features of our method as compared to other methods of constructing ensembles of classifiers are:(1) present a theoretical model to explain the mechanism of constructing ensemble of classifiers, (2) each reduct is a minimum subset of attributes, has the same classification ability as the entire attributes,(3)ea h reduct classifier constructed from the corresponding reduct has a minimal set of classification rules, and is as accurate andcomplete as possible and at the same time as diverse as possible from the other classifiers, (4)the test indicates that the number of classifiers used to improve the accuracy is muchless than other methods


#*Fractionalized View Materialization in Data Cubes
#@Y. Chung,M. Kim,W. Park
#t2001
#cProceedings of the 7th International Conference on Database Systems for Advanced Applications
#index277111


#*Security watch
#@
#t2002
#cCommunications of the ACM
#index249595


#*Joining nested relations and subrelations
#@Georgia Garani,Roger Johnson
#t2000
#cInformation Systems
#index318336


#*Online algorithms for page replication in rings
#@WŁodzimierz GŁazek
#t2001
#cTheoretical Computer Science
#index621740
#%74658
#%152434
#%259686
#%372878
#%480525
#%561809
#%599496


#*Source Animation as a Means of Program Comprehension
#@Harry M. Sneed
#t2000
#cProceedings of the 8th International Workshop on Program Comprehension
#index115578
#!Object-oriented systems are particularly difficult to comprehend because of the distribution of functionality, encapsulation of data, inheritance and polymorphism. Polymorphism, in particular, limits the effectiveness of conventional static analysis methods. This paper proposes a dynamic analysis approach using animation to simulate use cases in a large financial application. The objective is to offer maintenance programmers a means of familiarizing themselves with complex C++ code while at the same time validating the correctness of the code. For this purpose, control flow slicing and concept lattices are used.


#*Sample Selection for Statistical Parsing
#@Rebecca Hwa
#t2004
#cComputational Linguistics
#index579150
#%309866
#%371284
#!Corpus-based statistical parsing relies on using large quantities of annotated text as training examples. Building this kind of resource is expensive and labor-intensive. This work proposes to use sample selection to find helpful training examples and reduce human effort spent on annotating less informative ones. We consider several criteria for predicting whether unlabeled data might be a helpful training example. Experiments are performed across two syntactic learning tasks and within the single task of parsing across two learning models to compare the effect of different predictive criteria. We find that sample selection can significantly reduce the size of annotated training corpora and that uncertainty is a robust predictive criterion that can be easily applied to different learning models.


#*Joint spatial and temporal delta-sigma modulation for wideband antenna arrays and video halftoning
#@D. P. Scholnik
#t2001
#cProceedings of the Acoustics, Speech, and Signal Processing, 2001. on IEEE International Conference - Volume 05
#index428717
#!Extending an existing architecture for delta-sigma conversion of vector inputs, we suggest spectrally shaping quantization noise jointly in the temporal and spatial frequency domains with delta-sigma modulation, and we examine the application of the idea to wideband antenna or acoustic arrays and to halftoning of video imagery.


#*A Hierarchical Multiclassifier System for Hyperspectral Data Analysis
#@Shailesh Kumar,Joydeep Ghosh,Melba M. Crawford
#t2000
#cProceedings of the First International Workshop on Multiple Classifier Systems
#index562178


#*Cooking with Linux: battles inside the computer
#@Marcel Gagné
#t2003
#cLinux Journal
#index572643


#*WDM and Photonic Networks: Noc 2000, 1st edition
#@D. W. Faulkner,A. L. Harmer
#t2000
#c
#index235349
#!:Volume 1 "WDM and Photonic Networks" will focus on recent developments in long-haul WDM and photonic networks and will include invited papers from key vendors and technologists. A paper on DWDM by Lucent will show how Raman amplification enables the quadrupling of the line rate from OC-192 to OC-768 in a recent 1.6 Tb/s experiment.


#*Organisational Usability and the BT Digital Library
#@Sue Fowell,David Alsmeyer,Fay Owston
#t2001
#cProceedings of the 1st International Workshop on New Developments in Digital Libraries: n conjunction with ICEIS 2001
#index381425


#*Consensus Algorithms for the Generation of all Maximal Bicliques
#@Alexe Gabriela,Alexe Sorin,Foldes Stephan,Peter L. Hammer,Simeone Bruno
#t2000
#c
#index110170
#!We describe a consensus-type algorithm for determining all the maximal complete bipartite (not necessarily induced) subgraphs of a graph. We show that by imposing a particular order in which the consensus type operations should be executed, this algorithm becomes totally polynomial. By imposing a further restriction on the way the algorithm has to be executed, we derive an improved variant of it, the complexity of which is bounded by a polynomial that is cubic in the input size, and only linear in the output size, and show its high efficiency on numerous computational experiments on randomly generated graphs with up to 1000 vertices and 6000 edges.


#*Mastering Windows 2000 Programing with Visual C++ with Cdrom, 4th edition
#@Ben Ezzell
#t2000
#c
#index622227


#*Extending superquadrics with exponent functions: modeling and reconstruction
#@Lin Zhou,Chandra Kambhamettu
#t2001
#cGraphical Models
#index319754


#*Spatial decay of transient end effects in functionally graded heat conducting materials
#@C. O. Horgan,R. Quintanilla
#t2001
#cQuarterly of Applied Mathematics
#index245827


#*Optimal Object State Transfer - Recovery Policies for Fault Tolerant Distributed Systems
#@Panagiotis Katsaros,Constantine Lazos
#t2004
#cProceedings of the 2004 International Conference on Dependable Systems and Networks
#index437622
#!Recent developments in the field of object-basedfault tolerance and the advent of the first OMG FT-CORBAcompliant middleware raise new requirementsfor the design process of distributed fault-tolerantsystems. In this work, we introduce a simulation-baseddesign approach based on the optimum effectiveness ofthe compared fault tolerance schemes. Each scheme isdefined as a set of fault tolerance properties for theobjects that compose the system. Its optimumeffectiveness is determined by the tightest effectivecheckpoint intervals, for the passively replicatedobjects. Our approach allows mixing miscellaneousfault tolerance policies, as opposed to the publishedanalytic models, which are best suited in theevaluation of single-server process replicationschemes. Special emphasis has been given to theaccuracy of the generated estimates using anappropriate simulation output analysis procedure. Weprovide showcase results and compare twocharacteristic warm passive replication schemes: onewith periodic and another one with load-dependentobject state checkpoints. Finally, a trade-off analysis isapplied, for determining appropriate checkpointproperties, in respect to a specified design goal.


#*On the open problem OQ. 573
#@József Sándor
#t2001
#cOctogon Mathematical Magazine
#index439864


#*Quasi-birth-and-death processes, level-geometric distributions: an aggregation/disaggregation approach
#@Ivo Marek
#t2003
#cJournal of Computational and Applied Mathematics
#index557903
#%235474
#!A special class of homogeneous continuous time quasi-birth and death (QBD) Markov chains (MCs) which possess level-geometric (LG) stationary distribution are considered. A functional analytic approach is applied which provides not only a clear analytic interpretation of the concepts introduced elsewhere but also represents a suitable basis for computations. An iterative aggregation/disaggregation method is proposed as tool for numerical computations.


#*Die Smarandache'sche Klasse von Paradoxien
#@Herausgegeben von Charles T. Le
#t2004
#cSmarandache Notions Journal
#index433973


#*Uniform Convergence and Mesh Independence of Newton's Method for Discretized Variational Problems
#@A. L. Dontchev,W. W. Hager,V. M. Veliov
#t2000
#cSIAM Journal on Control and Optimization
#index248132
#!In an abstract framework, we study local convergence properties of Newton's method for a sequence of generalized equations which models a discretized variational inequality. We identify conditions under which the method is locally quadratically convergent, uniformly in the discretization. Moreover, we show that the distance between the Newton sequence for the continuous problem and the Newton sequence for the discretized problem is bounded by the norm of a residual. As an application, we present mesh-independence results for an optimal control problem with control constraints.


#*New algorithms for the iterative refinement of estimates of invariant subspaces
#@K. Hüper,P. Van Dooren
#t2003
#cFuture Generation Computer Systems
#index311884
#%151960
#%451851
#%535984
#%313216
#!New methods for refining estimates of invariant subspaces of a non-symmetric matrix are presented. We use global analysis to show local quadratic convergence of our method under mild conditions on the spectrum of the matrix.


#*Singular Values of Differences of Positive Semidefinite Matrices
#@Xingzhi Zhan
#t2000
#cSIAM Journal on Matrix Analysis and Applications
#index233941
#!Let Mn be the space of n &times; n complex matrices. For $A\in M_n,$ let $s(A)\equiv (s_1(A),\dotsc,\break s_n(A)),$ where $s_1(A)\ge\cdots\ge s_n(A)$ are the singular values of A. We prove that if $A,B\in M_n$ are positive semidefinite, then (i) $s_j(A-B)\le s_j(A\oplus B), j=1,2, . . . ,n, and (ii) the weak log-majorization relations $s(A-|z|B)\prec_{wlog} s(A+zB)\prec_{wlog} s(A+|z|B)$ hold for any complex number z. This sharpens some results due to R. Bhatia and F. Kittaneh.


#*Director 8 Demystified: The Official Guide to Director 8 Shockwave Internet Studio with Cdrom
#@Phil Gross,Jason Roberts
#t2000
#c
#index243916
#!:Previous editions of Director Demystified have been hailed as the essential companion to Director  the book that stays next to the computer rather than on the shelf. This new edition will cover features new to Director 8, such as improved design and authoring tools and the ability to sort cast members by name, size, and date with the Cast Manager. Additional features include enhanced media control, multiuser connectivity, and one-click publishing of Shockwave content.


#*Animation and rendering of complex water surfaces
#@Douglas Enright,Stephen Marschner,Ronald Fedkiw
#t2002
#cACM Transactions on Graphics (TOG)
#index252500
#%85503
#%146104
#%154154
#%154881
#%156788
#%172075
#%289427
#%597134
#%596104
#%482376
#%612829
#%333873
#%450905
#%312393
#%472401
#%297124
#%530242
#%478151
#!We present a new method for the animation and rendering of photo-realistic water effects. Our method is designed to produce visually plausible three dimensional effects, for example the pouring of water into a glass (see figure 1) and the breaking of an ocean wave, in a manner which can be used in a computer animation environment. In order to better obtain photorealism in the behavior of the simulated water surface, we introduce a new "thickened" front tracking technique to accurately represent the water surface and a new velocity extrapolation method to move the surface in a smooth, water-like manner. The velocity extrapolation method allows us to provide a degree of control to the surface motion, e.g. to generate a windblown look or to force the water to settle quickly. To ensure that the photorealism of the simulation carries over to the final images, we have integrated our method with an advanced physically based rendering system.


#*TicToc
#@
#t2003
#cACM SIGGRAPH 2003 video review on Animation theater program: part 1 - Volume 145
#index435546
#!Two naughty girls have a night out. They dance and have to cope with strange guys, and a handsome shark. Tic falls in love. Copyright held by creator.


#*A method to ease schema evolution
#@Lex Wedemeijer
#t2000
#cProceedings of the 2000 information resources management association international conference on Challenges of information technology management in the 21st century
#index329735


#*One solution for project management
#@Gina Jones
#t2001
#cProceedings of the 29th annual ACM SIGUCCS conference on User services
#index620334
#!In this paper, I will describe the project management tool that we have developed to track student work on projects. This project management tool is a web-based database using Cold Fusion.


#*Structure and content-based segmentation of speech transcripts
#@Dulce Ponceleon,Savitha Srinivasan
#t2001
#cProceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval
#index321894
#!algorithm for the segmentation of an audio/video source into topically cohesive segments based on automatic speech recognition (ASR) transcriptions is presented. A novel two-pass algorithm is described that combines a boundary-based method with a content-based method. In the first pass, the temporal proximity and the rate of arrival of ngram features is analyzed in order to compute an initial segmentation. In the content- based second pass, changes in content-bearing words are detected by using the ngram features as queries in an information-retrieval system. The second pass validates the initial segments and merges them as needed. Feasibility of the segmentation task can vary enormously depending on the structure of the audio content, and the accuracy of ASR. For real-world corporate training data our method identifies, at worst, a single salient segment of the audio and, at best, a high-level table-of-contents. We illustrate the algorithm in detail with some examples and validate the results with segmentation boundaries generated manually.


#*A New Sequential Algorithm for Regression Problems by Using Mixture Distribution
#@Takafumi Kanamori
#t2002
#cProceedings of the International Conference on Artificial Neural Networks
#index383022


#*Solving the Generalized Nonlinear Schr&ouml;dinger Equation via Quartic Spline Approximation
#@Q. Sheng,A. Q.M. Khaliq,E. A. Al-Said
#t2001
#cJournal of Computational Physics
#index326169


#*Documenting software systems with views III: towards a task-oriented classification of program visualization techniques
#@Scott Tilley,Shihong Huang
#t2002
#cProceedings of the 20th annual international conference on Computer documentation
#index254388
#%110867
#%111315
#%119801
#%446704
#%621393
#!Documentation has long played a key role in aiding program understanding. Graphical forms of documentation rely on software visualization techniques to make complicated information easier to understand. However, it is an open question exactly which types of graphical documentation are most suitable for which types of program understanding tasks (and in which specific usage contexts). This paper describes preliminary work towards a task-oriented classification of program visualization techniques. The classification is currently descriptive in nature, and divides the visualization techniques into three classes (static, interactive, and editable) based on the level of end-user interaction with the generated graphical documentation. The primary advantage of a task-oriented classification is that it will ultimately map common activities related to program understanding to specific types of software visualization. A summary of how the descriptive classification was used to structure the selection of software visualization tools to support program understanding in an industrial context is provided.


#*Pokemon Gold & Silver W/ Poster for Babbages (Prima's Official Strategy Guide)
#@
#t2000
#c
#index1692


#*DisMedJava - A Distributed Application for Medical Image Processing
#@Cristian Butincu,Dan Grigoras
#t2001
#cProceedings of the NATO Advanced Research Workshop on Advanced Environments, Tools, and Applications for Cluster Computing-Revised Papers
#index358060


#*Jitter-based delay-boundary prediction of wide-area networks
#@Qiong Li,David L. Mills
#t2001
#cIEEE/ACM Transactions on Networking (TON)
#index607299
#%83935
#%159352
#%464972
#%509116
#%538565
#!The delay-boundary prediction algorithms currently implemented by transport protocols are lowpass filters based on autoregressive and moving average (ARMA) models. However, recent studies have revealed a fractal-like structure of delay sequences, which may not be well suited to ARMA models. In this paper, we propose a novel delay-boundary prediction algorithm based on a deviation-lag function (DLF) to characterize end-to-end delay variations. Compared to conventional algorithms derived from ARMA models, the new algorithm can adapt to delay variations more rapidly and share delay's robust high-order statistical information (jitter deviation) among competing connections along a common network path. Preliminary experiments show that it outperforms Jacobson's algorithm, which is based on an ARMA model, by significantly reducing the prediction error rate. To show the practical feasibility of the DLF algorithm, we also propose a skeleton implementation model.


#*McGill RedDogs
#@Richard Unger
#t2000
#cRoboCup-99: Robot Soccer World Cup III
#index568327


#*A Scalable Architecture for Differentiated Services
#@C. L. Lee,J. R. Chen,Y. C. Chen
#t2002
#cProceedings of the 22nd International Conference on Distributed Computing Systems
#index267628
#!Differentiated services (DiffServ) model is a potential solution for providing quality of services (QoS) on the Internet. In this paper, we propose a scalable architecture that fulfills the design philosophy of the DiffServ model. Different from other existing architectures, our proposed architecture puts complexity on edge routers so that core routers do not need to support any specific function for service differentiation. Further, the proposed architecture only needs few additional functions in edge routers. Thus its deployment is simpler than most existing architectures. We also address how to achieve weighted proportional fairness solely by edge routers.


#*On structure of some plane graphs with application to choosability
#@Peter Che Bor Lam,Wai Chee Shiu,Baogang Xu
#t2001
#cJournal of Combinatorial Theory Series B
#index237413


#*PC Music Home Studio: Secrets, Tips, & Tricks
#@Roman Petelin,Yury Petelin
#t2002
#c
#index3456


#*An object-oriented framework for distributed hydrologic and geomorphic modeling using triangulated irregular networks
#@Gregory E. Tucker,Stephen T. Lancaster,Nicole M. Gasparini,Rafael L. Bras,Scott M. Rybarczyk
#t2001
#cComputers Geosciences
#index254156


#*A second order scheme for the Navier-Stokes equations: application to the driven-cavity problem
#@Daniel X. Guo
#t2000
#cApplied Numerical Mathematics
#index318376


#*Goal-Focused Self-Modifying Workflow in the Healthcare Domain
#@Eric D. Browne,Michael Schrefl,James R. Warren
#t2004
#cProceedings of the Proceedings of the 37th Annual Hawaii International Conference on System Sciences (HICSS'04) - Track 6 - Volume 6
#index306067
#!This paper introduces the concept of self-modifying workflow in the context of health care planning. Certain tasks in the workflow schema are devoted to modifying the downstream workflow on an instance by instance basis. Such self-modifying schemas provide the necessary flexibility to suit the evolving diagnostic and therapeutic processes encountered in Chronic Disease Management (CDM), particularly in complex areas requiring significant individualisation. The management of Diabetes Mellitus in a community care setting provides an example to illustrate this complexity. Over the past few years, object-oriented modelling tools of inheritance and specialisation have been applied to workflow modelling to assist in schema evolution and workflow migration, thereby potentially empowering new Workflow Management Systems (WfMSs) with the functionality to allow the tailoring of Guideline-based Care Plans to individual patient requirements. However, schema evolution is a necessary butinsufficient requirement for such tailoring. Healthcare WfMSs need to support a paradigm whereby schema evolution becomes a de facto operation for each workflow instance ( i.e.patient episode of care). Self-modifying workflows provide this paradigm. In order to facilitate self-modification of workflow schemas, we annunciate a set of valid operations that can be applied to downstream components of a workflow schema. These operations are primarily concerned with turning abstract subworkflows into concrete ones through completion and alteration of template primitives.


#*The role of requirements, specifications, and implementation in constructing dynamic figures
#@Richard Allen,Stéphane Channac,Laurent Trilling
#t2000
#cJournal of Computers in Mathematics and Science Teaching
#index321612


#*Analyzing the role of aspects in software design
#@J. Andrés Díaz Pace,Marcelo R. Campo
#t2001
#cCommunications of the ACM
#index319862
#%177331
#%196107
#%329038
#%329737


#*Change Profiles
#@Taneli Mielikäinen
#t2003
#cProceedings of the Third IEEE International Conference on Data Mining
#index309573
#!In this paper we introduce a generalization of associationrules: change profiles. We analyze their properties, describetheir relationship to other structures in pattern discoveryand sketch their possible applications. We studyhow the frequent patterns can be clustered based on theirchange profiles and propose methods for approximating thefrequencies of the patterns from the approximate changeprofiles and bounding the intervals where the frequencies ofthe patterns are guaranteed to be. We evaluate empiricallythe methods for estimating the frequencies and the stabilityof their frequency estimates under different kinds of noise.


#*Mechanisms for specifying communication behavior in object oriented database systems
#@Paulo F. Pires,Mário Roberto F. Benevides,Marta Mattoso
#t2000
#cProceedings of the 2000 ACM symposium on Applied computing - Volume 1
#index286822
#%87681
#%155743
#%157343
#%159612
#%210083
#%215222
#%368126
#%472880
#%542079
#%593167
#%379748
#%470398
#%382637
#%471001
#%486196
#%470776


#*Annual Index
#@
#t2002
#cIEEE Design Test
#index448320


#*Yes, you can teach ethics!
#@Cindy Meyer Hanchey
#t2002
#cJournal of Computing Sciences in Colleges
#index566834
#%559952
#%566306
#!The Computing Curricula 2001 (CC2001) project report includes recommendations for both required core and elective components to be included at all levels of the curriculum. One pervasive component is that of ethics. Many computer science faculty members are reluctant to teach even a single module in ethics. This paper and the accompanying presentation will provide a sample lesson that could be used as a module in a variety of courses in the curriculum. The accompanying reference list with URLs provides faculty an outstanding set of resources from which to work as well as opportunities for training in computer ethics.An additional benefit of including such a module is the opportunity for students to consider submitting papers for publication or presentation at conferences. Computer Science faculty can serve as mentors in that process.


#*Ontology-Based Integration of XML Web Resources
#@Bernd Amann,Catriel Beeri,Irini Fundulaki,Michel Scholl
#t2002
#cProceedings of the First International Semantic Web Conference on The Semantic Web
#index277591


#*Congestion control performance of R-DSDV protocol in multihop wireless ad hoc networks
#@Azzedine Boukerche,Sajal K. Das
#t2003
#cWireless Networks
#index571812
#%76901
#%82354
#%237190
#%269013
#%282674
#%586478
#%592256
#%606861
#%584335
#!Ad hoc wireless networks are composed of mobile nodes communicating through wireless links, without any fixed backbone infrastructure. Frequent topology changes due to node mobility make routing in such dynamic networks a challenging problem. Moreover, successful message routing implies every mobile node is potentially capable of acting as a router, thus supporting store-and-forward mechanisms. However, resource limitations on these nodes also require a control on congestion due to message forwarding. In this paper, we consider our recently proposed randomized version of the well-known Destination-Sequenced Distance Vector (DSDV) routing protocol, referred to as R-DSDV, and validate its performance through extensive simulation experiments. Our results demonstrate that a probabilistic control on message traffic based on local tuning of protocol parameters is feasible, and that R-DSDV outperforms the basic DSDV protocol by significantly reducing the average queue size associated with each mobile node and hence the average packet delay.


#*Fast heuristics for large scale covering-location problems
#@Luce Brotcorne,Gilbert Laporte,Frédéric Semet
#t2002
#cComputers and Operations Research
#index439831
#!We propose fast heuristics for large-scale covering-location problems in which the set of demand points is discrete and the set of potential location sites is continuous. These heuristics are compared on a set of 152 real-life instances arising in cytological screening.


#*Understanding Inherent Qualities of Evolved Circuits: Evolutionary History as a Predictor of Fault Tolerance
#@Paul J. Layzell,Adrian Thompson
#t2000
#cProceedings of the Third International Conference on Evolvable Systems: From Biology to Hardware
#index361023


#*Open ITEM Systems are Good ITEM Systems
#@Arthur Tatnall,Bill Davey
#t2001
#cProceedings of the IFIP TC3/WG3.7 Fourth International Working Conference on Information Technology in Educational Management: Pathways to Institutional Improvement with Information Technology in Educational Management
#index275357


#*The Gesture Pendant: A Self-illuminating, Wearable, Infrared Computer Vision System for Home Automation Control and Medical Monitoring
#@Maribeth Gandy,Thad Starner,Jake Auxier,Daniel Ashbrook
#t2000
#cProceedings of the 4th IEEE International Symposium on Wearable Computers
#index117955
#!In this paper, we present a wearable device for control of home automation systems via hand gestures. This solution has many advantages over traditional home automation interfaces in that those with loss of vision, motor skills, and mobility can use it. By combining other sources of context with the pendant, we can reduce the number and complexity of gestures while maintaining functionality. As users input gestures, the system can also analyze their movements for pathological tremors. This information can then be used for medical diagnosis, therapy, and emergency services. Currently, the Gesture Pendant can recognize control gestures with an accuracy of 95% and user-defined gestures with an accuracy of 97% it can detect tremors above 2HZ within plus or minus 0.1 Hz.


#*Logic Design Validation via Simulation and Automatic Test Pattern Generation
#@Hussain Al-Asaad,John P. Hayes
#t2000
#cJournal of Electronic Testing: Theory and Applications
#index334145
#%178287
#%284706
#%531788
#%447750
#!We investigate an automated design validation scheme for gate-level combinational and sequential circuits that borrows methods from simulation and test generation for physical faults, and verifies a circuit with respect to a modeled set of design errors. The error models used in prior research are examined and reduced to five types: gate substitution errors (GSEs), gate count errors (GCEs), input count errors (ICEs), wrong input errors (WIEs), and latch count errors (LCEs). Conditions are derived for a gate to be testable for GSEs, which lead to small, complete test sets for GSEs&semi; near-minimal test sets are also derived for GCEs. We analyze undetectability in design errors and relate it to single stuck-line (SSL) redundancy. We show how to map all the foregoing error types into SSL faults, and describe an extensive set of experiments to evaluate the proposed method. These experiments demonstrate that high coverage of the modeled errors can be achieved with small test sets obtained with standard test generation and simulation tools for physical faults.


#*A case study of open source software development: the Apache server
#@Audris Mockus,Roy T. Fielding,James Herbsleb
#t2000
#cProceedings of the 22nd international conference on Software engineering
#index282654
#%240292
#%461443
#%298107
#%450481
#%443042
#!According to its proponents, open source style software development has the capacity to compete successfully, and perhaps in many cases displace, traditional commercial development methods. In order to begin investigating such claims, we examine the development process of a major open source application, the Apache web server. By using email archives of source code change history and problem reports we quantify aspects of developer participation, core team size, code ownership, productivity, defect density, and problem resolution interval for this OSS project. This analysis reveals a unique process, which performs well on important measures. We conclude that hybrid forms of development that borrow the most effective techniques from both the OSS and commercial worlds may lead to high performance software processes.


#*A Neuro-Fuzzy Model for Software Cost Estimation
#@Xishi Huang,Luiz F. Capretz,Jing Ren,Danny Ho
#t2003
#cProceedings of the Third International Conference on Quality Software
#index304610
#!A novel neuro-fuzzy Constructive Cost Model(COCOMO) for software estimation is proposed. Themodel carries some of the desirable features of the neuro-fuzzy approach, such as learning ability and goodinterpretability, while maintaining the merits of theCOCOMO model. Unlike the standard neural networkapproach, this model is easily validated by experts andcapable of generalization. In addition, it allows inputs tobe continuous-rating values and linguistic values,therefore avoiding the problem of similar projects havingdifferent estimated costs. Also presented in this paper is adetailed learning algorithm. The validation, usingindustry project data, shows that the model greatlyimproves the estimation accuracy in comparison with thewell-known COCOMO model.


#*Reduced feature-set based parallel CHMM speech recognition systems
#@Waleed H. Abdulla,Nikola Kasabov
#t2003
#cInformation Sciences&mdash;Informatics and Computer Science: An International Journal
#index311386
#%116104
#!This paper presents the multi-streams paradigm as a technique for improving speech signal feature set design and as a performance booster for speech recognition systems, based on the continuous-density hidden Markov model (CHMM) framework. In the multi-streams paradigm we are dealing with different feature sets independently to estimate the same task, and then combining their results at a suitable stage. This paradigm combines the strengths of many varied feature vectors to attain better statistical estimation. Under the proposed paradigm the feature vectors are split into three independent streams, and each stream is used to model an independent CHMM. Then the outcomes of these models, when subjected to any speech input, are merged under a certain strategy. This technique alleviates the dominance effect of the features, and reduces the dimensionality of the feature vectors used in each model. The F-ratio technique is used to further reduce the dimensionality of each stream. Experimental results on different datasets show superiority of the developed paradigm over the corresponding single-stream baseline.


#*Guest editors' foreword
#@Magne Haveraaen,Olaf Owe
#t2001
#cNordic Journal of Computing
#index564131


#*Transformation formula for a double Clausenian hypergeometric series, its q-analogue, and its invariance group
#@J. Van der Jeugt
#t2002
#cJournal of Computational and Applied Mathematics
#index571182
#!A transformation formula for a double basic hypergeometric series of type φ1:2;20:2;2 is derived. This transformation yields a double series analogue of Sears' transformation for a terminating 3φ2 series. In the limit q → 1, the formula reduces to a transformation for a terminating double Clausenian hypergeometric series of unit argument (one of the proper Kampé de Fériet series, F1:2;20:2;2(1,1)). This formula is a double series analogue of Whipple's terminating 3F2 transformation. This transformation gives rise to a transformation group (the invariance group) acting on the parameters of the double series. The invariance group is examined and shown to be a subgroup of a double copy of the symmetries of the square.


#*Intelligent Systems in Biomedicine
#@Maysam F. Abbod,Mahdi Mahfouf,Derek A. Linkens
#t2002
#cAdvances in Computational Intelligence and Learning: Methods and Applications
#index259764


#*An Architectural-Based Reflective Approach to Incorporating Exception Handling into Dependable Software
#@Alessandro F. Garcia,Cecília M. F. Rubira
#t2001
#cAdvances in Exception Handling Techniques (the book grow out of a ECOOP 2000 workshop)
#index264814


#*Concept extraction and association from cancer literature
#@Yueyu Fu,Travis Bauer,Javed Mostafa,Mathew Palakal,Snehasis Mukhopadhyay
#t2002
#cProceedings of the 4th international workshop on Web information and data management
#index244274
#%79244
#%233213
#%586598
#%509078
#!There is a large and growing body of web accessible biomedical literature. As this body of electronic literature grows, so does the possibility that document analysis techniques can be used to automatically extract useful biomedical information from them, particularly in the discovery of key concepts dealing with genes, proteins, drugs, and diseases and associations among these concepts. VCGS (Vocabulary Cluster Generating System) was designed to automatically extract and determine associations among tokens from a subset of biomedical literature namely cancer. Such information has notable potential to automate database construction in biomedicine, instead of relying on experts' analysis. This paper reports on the mechanisms for automatically generating clusters of tokens. A formal evaluation of the system, based on a subset of 5338 Pubmed titles and abstracts, has been conducted against the Swiss-Prot database in which the associations among concepts are entered by experts by hand.


#*Strategic Information Technology Management: The City of Anaheim Technological Initiatives
#@Keith Schildt,Suzanne Beaumaster
#t2004
#cProceedings of the Proceedings of the 37th Annual Hawaii International Conference on System Sciences (HICSS'04) - Track 5 - Volume 5
#index309674
#!This paper reports the findings of an exploratory study investigating the role of IT in a municipal-owned and operated public utility. Through the use of case study methodology, the paper finds a confluence of contextual factors fostering changes in an IT management strategy aimed at increasing efficiency and effectiveness of service delivery and improvingcustomer/citizen satisfaction. These factors include changes in the regulatory policy environment, advances in technology, increasing citizen and customer knowledge and sophistication about IT, and managerial and elected official commitment to an IT strategy. The paper begins by proposing a model of the IT strategic planning process that occurs in municipal environments and then details several IT initiatives of the municipality in relation to the proposed model. The study finds that the complex nature of technology and its financial risk due to quick obsolescence poses political risks for the organization attempting to manage the IT infrastructure, which changes at a far faster pace than the organization's other types of infrastructure. The strategic management of IT must take into account the differing value sets among its organizational and political members and how these differing motivations impact the management of the IT infrastructure.


#*Wavefront Diffusion and LMSR: Algorithms for Dynamic Repartitioning of Adaptive Meshes
#@Kirk Schloegel,George Karypis,Vipin Kumar
#t2001
#cIEEE Transactions on Parallel and Distributed Systems
#index318669
#%75549
#%75674
#%85098
#%92280
#%246050
#%281664
#%286236
#%313723
#%476426
#%463953
#%550740
#%595810
#%595276
#%470496
#%449601
#%593496
#!Current multilevel repartitioning schemes tend to perform well on certain types of problems while obtaining worse results for other types of problems. We present two new multilevel algorithms for repartitioning adaptive meshes that improve the performance of multilevel schemes for the types of problems that current schemes perform poorly while maintaining similar or better results for those problems that current schemes perform well. Specifically, we present a new scratch-remap scheme called Locally-matched Multilevel Scratch-remap (or simply LMSR) for repartitioning of adaptive meshes. LMSR tries to compute a high-quality partitioning that has a large amount of overlap with the original partitioning. We show that LMSR generally decreases the data redistribution costs required to balance the load compared to current scratch-remap schemes. We present a new diffusion-based scheme that we refer to as Wavefront Diffusion. In Wavefront Diffusion, the flow of vertices moves in a wavefront from overweight to underweight subdomains. We show that Wavefront Diffusion obtains significantly lower data redistribution costs while maintaining similar or better edge-cut results compared to existing diffusion algorithms. We also compare Wavefront Diffusion with LMSR and show that these provide a trade-off between edge-cut and data redistribution costs for a wide range of problems. Our experimental results on a Cray T3E, an IBM SP2, and a cluster of Pentium Pro workstations show that both schemes are fast and scalable. For example, both are capable of repartitioning a seven million vertex graph in under three seconds on 128 processors of a Cray T3E. Our schemes obtained relative speedups of between nine and 12 when the number of processors was increased by a factor of 16 on a Cray T3E.


#*Social barriers for knowledge databases in professional service firms
#@Georg Disterer
#t2000
#cProceedings of the 2000 information resources management association international conference on Challenges of information technology management in the 21st century
#index332636


#*Job Superscheduler Architecture and Performance in Computational Grid Environments
#@Hongzhang Shan,Leonid Oliker,Rupak Biswas
#t2003
#cProceedings of the 2003 ACM/IEEE conference on Supercomputing
#index104412
#%95553
#%368622
#%178682
#!Computational grids hold great promise in utilizing geographically separated heterogeneous resources to solve large-scale complex scientific problems. However, a number of major technical hurdles, including distributed resource management and effective job scheduling, stand in the way of realizing these gains. In this paper, we propose a novel grid superscheduler architecture and three distributed job migration algorithms. We also model the critical interaction between the superscheduler and autonomous local schedulers. Extensive performance comparisons with ideal, central, and local schemes using real workloads from leading computational centers are conducted in a simulation environment. Additionally, synthetic workloads are used to perform a detailed sensitivity analysis of our superscheduler. Several key metrics demonstrate that substantial performance gains can be achieved via smart superscheduling in distributed computational grids.


#*An Extensible, Human-Centric Framework That Promotes Universal Access to Electronic Commerce
#@Jacob Slonim,Theodore Chiasson,Carrie Gates,Michael McAllister
#t2001
#cProceedings of the Second International Symposium on Topics in Electronic Commerce
#index371371


#*Parameter Estimation in a Three-Dimensional Wind Field Model Using Genetic Algorithms
#@Eduardo Rodríguez,Gustavo Montero,Rafael Montenegro,José María Escobar,José María González-Yuste
#t2002
#cProceedings of the International Conference on Computational Science-Part I
#index357749


#*A Software Process for an Integrated Electronic Commerce Portal System
#@Volker Gruhn,Lothar Schöpe
#t2001
#cProceedings of the 8th European Workshop on Software Process Technology
#index571395


#*Predictive models for wireless fading channels
#@Prachee Sharma
#t2003
#c
#index303722
#!This thesis presents methods for improving the performance of wireless networks through the modeling and prediction of time-varying multipath channels. The Rayleigh fading channel is characterized using first and second-order autoregressive (AR) time-series models. The AR processes model the channel variations at the time-scale of the characteristic Doppler frequency. Small time-scale variations are captured using linear interpolation of the AR model predictions. For defined error performance metrics, the fading signal is characterized using a state-space model that partitions the continuous amplitude variations into error and error-free states. The model parameters and state thresholds are derived as a function of Doppler frequency, signal-to-noise ratio and specified error probability. The aforementioned model is applied for estimating the probability of error as a function of transmission block size. The second-order AR model captures the pseudo-periodic behavior of the Rayleigh channel and produces accurate estimates of block error probabilities relative to the first-order AR process. The fading channel model is applied for both flat and frequency-selective channels in the design of a channel estimator and predictor. A Kalman-filter is designed to forecast the expected channel conditions and the predictions are applied for error control. The performance of the proposed error control approach is compared to a decision feedback equalizer (DFE). The model-based prediction shows at least a 25% improvement over the DFE.


#*Color constancy and the functional significance of McCollough effects
#@T. Vladusich,J. Broerse
#t2002
#cNeural Networks
#index442246
#%146847
#!A central problem in visual perception concerns how humans perceive stable and uniform object colors despite variable lighting conditions (i.e. color constancy). One solution is to 'discount' variations in lighting across object surfaces by encoding color contrasts, and utilize this information to 'fill in' properties of the entire object surface. Implicit in this solution is the caveat that the color contrasts defining object boundaries must be distinguished from the spurious color fringes that occur naturally along luminance-defined edges in the retinal image (i.e. optical chromatic aberration). In the present paper, we propose that the neural machinery underlying color constancy is complemented by an 'error-correction' procedure which compensates for chromatic aberration, and suggest that error-correction may be linked functionally to the experimentally induced illusory colored aftereffects known as McCollough effects (MEs). To test these proposals, we develop a neural network model which incorporates many of the receptive-field (RF) profiles of neurons in primate color vision. The model is composed of two parallel processing streams which encode complementary sets of stimulus features: one stream encodes color contrasts to facilitate filling-in and color constancy; the other stream selectively encodes (spurious) color fringes at luminance boundaries, and learns to inhibit the filling-in of these colors within the first stream. Computer simulations of the model illustrate how complementary color-spatial interactions between error-correction and filling-in operations (a) facilitate color constancy, (b) reveal functional links between color constancy and the ME, and (c) reconcile previously reported anomalies in the local (edge) and global (spreading) properties of the ME. We discuss the broader implications of these findings by considering the complementary functional roles performed by RFs mediating color-spatial interactions in the primate visual system.


#*Guiding Attention Produces Inferences in Diagram-Based Problem Solving
#@Elizabeth R. Grant,Michael J. Spivey
#t2002
#cProceedings of the Second International Conference on Diagrammatic Representation and Inference
#index360489


#*Illustrations with Photoshop: A Designer's Notebook
#@Bengal,Nicolas Bouvier,Judith Darmont,Ben Carre,Nicolas Fructus,Joel Legars,Antoine Quaresma,Marguerite Sauvage,William Rodarmor
#t2004
#c
#index17006
#!World-renowned French artists share their exciting and innovative digital creations in Illustrations with Photoshop: A Designer's Notebook, a first-time English translation of the cutting-edge French work. The images in this book will energize image professionals, graphic artists, photographers, computer graphics designers--all creators of images, whether still or animated--and will forever change the way you see and perform your design work. Photoshop is best known among photographers as a photographic image manipulation tool; it is used largely for retouching and photomontage. But Photoshop is also a powerful and highly sophisticated tool for creating quality digital drawings and artwork. Artists, like the ones showcased within, use it to realize their unique vision through illustration. In this lavish, full-color collection, nine French graphic artists--well-known professionals from a vibrant culture with a reputation for taking creative risks and producing incomparable graphics and art--are turned loose with Photoshop. Ranging from advertising to children's book illustration, science fiction to settings for graphic novels and role-playing games, their groundbreaking creations will inspire you to see your industry anew, appreciate graphic design from a changed perspective, and revitalize your work. Representing the very finest of French creation in the world of graphic design and digital imaging, this notebook leads you into the heart of each author's artistic approach, guiding you through the inception and making of nine unparalleled works of art that spring from widely varying sources of inspiration. But you'll come away with more than ideas and inspiration--you'll find detailed, step-by-step information on making Photoshop do anything and everything you want to accomplish your ideal digital illustration. Unlike any other available, this visually stunning book will give you the creative license and technical know-how you need to create one-of-a-kind digital illustrations with Photoshop that are limited only by your imagination.


#*SIGAda 99, workshop: how do we expedite the commercial use of Ada?
#@Robert C. Leif
#t2000
#cACM SIGAda Ada Letters
#index326096
#%288365
#%290611
#%295167
#%595854


#*Discovering Test Set Regularities in Relational Domains
#@Seán Slattery,Tom M. Mitchell
#t2000
#cProceedings of the Seventeenth International Conference on Machine Learning
#index376161


#*Watermarking Polygonal Lines Using Fourier Descriptors
#@Vassilios Solachidis,Ioannis Pitas
#t2004
#cIEEE Computer Graphics and Applications
#index387417
#!This article presents a blind watermarking method for vector graphics images. Unlike the common watermarking methods, where the image luminance is altered, the coordinates of the polygonal curve vertices are modified in the presented method. The watermark is embedded in the Fourier descriptors of the vertices of the polygonal lines, resulting in slight alterations of the polygonal line's vertex coordinates. Due to the Fourier descriptor properties, the watermark is detectable even after rotation, translation, scaling, additive Gaussian noise, smoothing, reflection attacks, or combination of these attacks.


#*Software Radio Technologies: Selected Readings
#@Zoran Zvonar
#t2001
#c
#index251238
#!:"Bridge the gap from existing regional wireless standards to the next generation global communication system with these selected readings, a companion text to Software Radio Architecture, by Joseph Mitola III. This single-source reference summarizes major trends in software radio technology by combining classic publications, cutting-edge overviews and promising research from leading experts in the field. The role of software and digital signal processing in radio has grown to encompass reconfigurability at all levels of the protocol stack. Research has ignited wider commercial interest in these concepts, which have been endorsed by all segments of industry, from software applications providers to component manufacturers. The software radio approach will increase software content for commercial wireless systems and is a potential solution to the need for increased efficiency in service delivery. This volume covers:*Concepts of software radio, including historical and theoretical foundations*Enabling technologies for realization of software radio, including radio frequency design, converter technologies, digital signal processing, and reconfigurable and programmable hardware structures *Systems and architectures based on software radio concepts*Software radio applications and economics*Emerging technologies SOFTWARE RADIO TECHNOLOGIES is an essential resource for researchers and practicing engineers seeking an in-depth treatment of technical issues raised by software radio architecture evolution. About the Editors Joseph Mitola III is known as "the Godfather of the Software Radio." He is one of the most highly cited authors in the field, contributing over twodozen technical papers as well as his recent text, Software Radio Architecture, the first interdisciplinary treatment of the subject and companion to SOFTWARE RADIO TECHNOLOGIES: SELECTED READINGS. Dr. Mitola edited the landmark May 1995 special issue of the IEEE Communications Magazine and the April 1999 Journal on Selected Areas in Communications on Software Radio. He began his career with the U.S. Department of Defense (DoD) in 1967 and is presently a consulting scientist with the MITRE Corporation, advising the DoD on telecommunications and information-processing technology and policy. Zoran Zvonar, noted author and researcher, has served as editor and coeditor for many distinguished publications, including the International Journal of Wireless Information Networks, the IEEE Transactions on Vehicular Technology, GSM Towards 3rd Generation Systems and Wireless Multimedia Networks Technologies (Kluwer Academic Publishers, 1998 and 1999, respectively), among others. Dr. Zvonar is currently an associate editor of the IEEE Communications Letters and a feature editor of the Series on Software and DSP in Radio in the IEEE Communications Magazine. He is also a systems development manager in the Communications Division, Analog Devices Inc., involved in the design of algorithms and architectures for wireless communications."


#*Hyperplane ranking, nonlinearity and the simple genetic algorithm
#@Darrell Whitley,Robert B. Heckendorn,Soraya Stevens
#t2003
#cInformation Sciences: an International Journal
#index310472
#%517247
#%363068
#%368055
#!We examine the role of hyperplane ranking during genetic search by developing a metric for measuring the degree of ranking that exists with respect to static hyperplane averages taken directly from the function, as well as the dynamic ranking of hyperplanes during genetic search. We show that the degree of dynamic ranking induced by a simple genetic algorithm is highly correlated with the degree of static ranking that is inherent in the function, especially during the initial generations of search. The φ metric is designed to measure the consistency of an arbitrary ranking of hyperplanes in a partition with respect to a target string. Walsh coefficients can be calculated for small functions in order to characterize sources of linear and nonlinear interactions. Correlations between the φ metric and convergence behavior of a simple genetic algorithm are studied over large sets of functions with varying degrees of nonlinearity.


#*Online Gardening to Promote Social Inclusion
#@S. J. Battersby,N. Kelly,David J. Brown,H. M. Powell
#t2002
#cProceedings of the 8th International Conference on Computers Helping People with Special Needs
#index361297


#*Reflections on CRC cards and OO design
#@Robert Biddle,James Noble,Ewan Tempero
#t2002
#cProceedings of the Fortieth International Conference on Tools Pacific: Objects for internet, mobile and embedded applications
#index241374
#%215267
#%232338
#%464382
#%291672
#%609136
#%621109
#%594070
#%470776
#!We recently had the opportunity to introduce object-oriented design to a number of teams, and used CRC cards as one of the key techniques. The team members had varied backgrounds, and we had the opportunity to observe many teams tackle the same design exercises. This allowed us the opportunity to observe the effectiveness of the CRC cards, and reflect on the strengths and weaknesses. This paper documents our observations and reflections, and presents our advice on the strengths of the technique, and strategies we found useful for addressing the weaknesses.


#*Performance analysis of optimized smooth handoff in mobile IP
#@C. Blondia,N. Van den Wijngaert,G. Willems,O. Casals
#t2002
#cProceedings of the 5th ACM international workshop on Modeling analysis and simulation of wireless and mobile systems
#index249711
#%256050
#!Mobile IP allows node mobility involving changes of point-of-attachment to the Internet. In order to reduce the impact on the performance and the signaling overhead, hierarchical mobility management schemes have been introduced. These schemes define protocols that allow movements within a domain to be handled locally, without involvement of the mobile node's home network. In order to reduce more the packet losses during handoff, new schemes have been defined, such as smooth handoff. By storing packets temporarily in the access point after the mobile host has left and forwarding them to the new access point as soon as the mobile has connected to it, it is possible to reduce significantly the packet loss. In this paper we develop an analytical model and a simulation program using OPNET Modeler to evaluate the packet loss and packet delay for UDP streams and the throughput for TCP streams that are involved in a handoff. We show that, in spite of the buffering capabilities of the previous access point, packets may still get lost. The reason for this loss is identified and solutions to this problem are proposed.


#*The grading system of the real world
#@Lynellen D. S. Perry
#t2002
#cCrossroads
#index232144


#*Open-Loop Verification of Motion Planning for an Underwater Eel-Like Robot
#@Kenneth A. McIsaac,James P. Ostrowski
#t2000
#cExperimental Robotics VII
#index383763


#*Implementation and application of automata
#@
#t2004
#cTheoretical Computer Science
#index98583


#*Capitalization Recovery for Text
#@Eric W. Brown,Anni Coden
#t2001
#c
#index555608


#*A Knowledge Based Framework for The Design of Soft-Computing Systems
#@Satheesh Ramachandran,Madhav Erraguntla,Perakath C. Benjamin
#t2002
#cProceedings of the IFIP 17th World Computer Congress - TC12 Stream on Intelligent Information Processing
#index267595


#*Impact of video frame rate on communicative behaviour in two and four party groups
#@Matthew Jackson,Anne H. Anderson,Rachel McEwan,Jim Mullin
#t2000
#cProceedings of the 2000 ACM conference on Computer supported cooperative work
#index315704
#%75630
#%77352
#%290101
#%540435
#%595814
#!There has been relatively little research on the impact of different levels of video quality on users of multimedia communication systems. This paper describes a study examining the impact of two levels of video frame rate on pairs and groups of four engaged on a design task, looking at one particular aspect of communication, namely reference. It was found that a low frame rate made speakers more communicatively cautious, using longer descriptions and more elaborations to refer to pictures used in the task, possibly as a result of being less certain that they had been understood. This only occurred in the two party groups despite a prediction that groups of four would be affected most by the frame rate manipulation. This study shows that video quality can have subtle effects on communication and that identical levels of quality may have different effects depending on the situation.


#*Design patterns in telecommunications system architecture
#@Gerard Meszaros
#t2001
#cDesign patterns in communications software
#index233178
#!The telephone network could be called the world's first distributed computing network. People in telecommunications treat as second nature many of the issues just surfacing in other problem domains. This article describes some of the techniques used in the telecommunications industry to deal with highly distributed high-reliability systems. A number of recurring patterns are identified and used to describe the design of the telecommunications network and its components.


#*Programmable Logic Controllers, 2nd edition
#@Bill Bolton,W. Bolton
#t2000
#c
#index242606
#!:Ideal as an accessible introduction for university students, the second edition includes expanded sections on internal architecture, input-output devices, networks, and programming languages with microprocessor systems, and has been fully revised in line with the new BTEC Higher National unit on PLCs, and the 2000 specifications for the Advanced GNVQ unit from Edexcel.


#*Visual Analysis of Website Browsing Patterns
#@Stephen G. Eick
#t2002
#cVisual Interfaces to Digital Libraries [JCDL 2002 Workshop]
#index367918


#*Short--term recurrences for indefinite preconditioning of saddle point problems
#@M. Rozloznik,V. Simoncini
#t2000
#c
#index115686
#!We are interested in the numerical solution of large structured indefinite symmetric linear systems arising in mixed finite element approximations of the magnetostatic problem; in particular, we analyze definite block--diagonal and indefinite symmetric preconditioners. Relating the algebraic characteristics of the resulting preconditioned matrix to the properties of the continuous problem and of its finite element discretization, we show that the considered preconditioning strategies make the used Krylov subspace solver insensitive to the mesh refinement parameter, in terms of number of iterations. In order to achieve computational efficiency, we also analyze algebraic approximations to the optimal preconditioners, and discuss their performance on real two and three dimensional application problems.


#*OpenMP Parallelism for Multi-dimensional Grid-Adaptive Magnetohydrodynamic Simulations
#@Rony Keppens,Gábor Tóth
#t2002
#cProceedings of the International Conference on Computational Science-Part I
#index356983


#*ISAGA news & notes
#@David Crookall
#t2003
#cSimulation and Gaming
#index560885


#*A globally convergent primal-dual interior-point filter method for nonlinear programming
#@Michael Ulbrich,Stefan Ulbrich,Lu&#x00ed;s N. Vicente
#t2004
#cMathematical Programming: Series A and B
#index437860
#!In this paper, the filter technique of Fletcher and Leyffer (1997) is used to globalize the primal-dual interior-point algorithm for nonlinear programming, avoiding the use of merit functions and the updating of penalty parameters.The new algorithm decomposes the primal-dual step obtained from the perturbed first-order necessary conditions into a normal and a tangential step, whose sizes are controlled by a trust-region type parameter. Each entry in the filter is a pair of coordinates: one resulting from feasibility and centrality, and associated with the normal step; the other resulting from optimality (complementarity and duality), and related with the tangential step.Global convergence to first-order critical points is proved for the new primal-dual interior-point filter algorithm.


#*Development of a secondary-electron detection system for high-speed high-sensitivity inspection SEM imaging (poster session)
#@A. Takafuji,M. Nozoe,H. Shinada
#t2000
#cMicroelectronic Engineering
#index327921


#*Validation and verification
#@
#t2003
#cACM SIGSOFT Software Engineering Notes
#index305678


#*QoS-Assured Service Composition in Managed Service Overlay Networks
#@Xiaohui Gu,Klara Nahrstedt,Rong N. Chang,Christopher Ward
#t2003
#cProceedings of the 23rd International Conference on Distributed Computing Systems
#index123431
#!Many value-added and content delivery services arebeing offered via service level agreements (SLAs). Theseservices can be interconnected to form a service overlaynetwork (SON) over the Internet. Service composition inSON has emerged as a cost-effective approach to quicklycreating new services. Previous research has addressed thereliability, adaptability, and compatibility issues for composedservices. However, little has been done to managegeneric quality-of-service (QoS) provisioning for composedservices, based on the SLA contracts of individual services.In this paper, we present QUEST, a QoS assUredcomposEable Service infrasTructure, to address the problem.QUEST framework provides: (1) initial service composition,which can compose a qualified service path undermultiple QoS constraints (e.g., response time, availability).If multiple qualified service paths exist, QUEST chooses thebest one according to the load balancing metric; and (2)dynamic service composition, which can dynamically recomposethe service path to quickly recover from serviceoutages and QoS violations. Different from the previouswork, QUEST can simultaneously achieve QoS assurancesand good load balancing in SON.


#*Indexing inheritance and aggregation
#@Karen C. Davis,Unmi Tina Kang,Shobha Ravishankar
#t2000
#cProceedings of the ninth international conference on Information and knowledge management
#index328288


#*Program Composition in Isabelle/UNITY
#@Sidi O. Ehmety,Lawrence C. Paulson
#t2002
#cProceedings of the 16th International Parallel and Distributed Processing Symposium
#index372928


#*Streaming format software for usability testing
#@Michael Lister
#t2003
#cCHI '03 extended abstracts on Human factors in computing systems
#index555732
#!Audio and video capture for qualitative usability testing requires multiple video sources to be synchronized for subsequent playback along with any required test data. Windows Media Player 9 is limited to playing only single video streams. This paper describes the architecture of a software system that has been developed to overcome the single stream of video and allow multiple synchronized audio, video and data streams suitable for usability testing. Post processing and the practical application of using multi-stream software tool in usability testing are then discussed with example qualitative testing situations.


#*Oxygen vacancy defects in tantalum pentoxide: a density functional study
#@R. Ramprasad,Michael Sadd,Doug Roberts,Tom Remmel,Mark Raymond,Eric Luckowski,Sriram Kalpat,Carole Barron,Mel Miller
#t2003
#cMicroelectronic Engineering
#index312775
#!First principles total energy calculations were performed in order to characterize O vacancy defects in Ta2O5. A simplified version of the crystalline orthorhombic phase of Ta2O5 was used in this study. Results indicate that O vacancies in Ta2O5 can be broadly classified based on their location in the lattice. One type of vacancy (occupying the 'in-plane' sites) displays deep or mid gap occupied states, and shallow unoccupied states, while a second type (occupying 'cap' sites) results in shallow occupied states. For a wide range of local Fermi level or chemical potential, the neutral and +2 charged states of the in-plane type vacancy and the +2 charge state of the cap type vacancy are found to be most stable.


#*A Generalization of Resource-Bounded Measure, with Application to the BPP vs. EXP Problem
#@Harry Buhrman,Dieter van Melkebeek,Kenneth W. Regan,D. Sivakumar,Martin Strauss
#t2000
#cSIAM Journal on Computing
#index242171
#!We introduce resource-bounded betting games and propose a generalization of Lutz's resource-bounded measure in which the choice of the next string to bet on is fully adaptive. Lutz's martingales are equivalent to betting games constrained to bet on strings in lexicographic order. We show that if strong pseudorandom number generators exist, then betting games are equivalent to martingales for measure on E and EXP. However, we construct betting games that succeed on certain classes whose Lutz measures are important open problems: the class of polynomial-time Turing-complete languages in EXP and its superclass of polynomial-time Turing-autoreducible languages. If an EXP-martingale succeeds on either of these classes, or if betting games have the "finite union property" possessed by Lutz's measure, one obtains the nonrelativizable consequence $\mbox{BPP} \neq \mbox{EXP}$. We also show that if $\mbox{EXP} \neq \mbox{MA}$, then the polynomial-time truth-table-autoreducible languages have Lutz measure zero, whereas if $\mbox{EXP} = \mbox{BPP}$, they have measure one.


#*Review of D-Branes by Clifford V. Johnson. Cambridge University Press 2002.
#@Alex Buchel
#t2003
#cACM SIGSAM Bulletin
#index303719


#*A framework for the admission control of QoS multicast traffic in mobile ad hoc networks
#@Elena Pagani,Gian Paolo Rossi
#t2001
#cProceedings of the 4th ACM international workshop on Wireless mobile multimedia
#index438984
#%299864
#!Recently, QoS issues have initiated to be studied in both wired and wireless networks, to support multimedia and real-time applications. In this paper, we propose a framework for the admission control of multimedia multicast traffic and for the system configuration in MANETs. We present a mechanism to ensure bandwidth guarantees to multicast sessions (Call-Admission Multicast Protocol for MANETs, M-CAMP). M-CAMP is scalable, operates on a per-call basis and supports the group membership dynamics. It adopts a measurement-based approach to evaluate the end-to-end bandwidth availability between the traffic source and the group of destinations. M-CAMP is independent of the underlying wireless technology and protocols, as far as a multicast routing service is available. It does not require any maintenance of status information in the mobile hosts.


#*Firewall policies definition tools: an implementation idea
#@Patrizia Dí,Fabrizio Fabbrini
#t2000
#cIntegrity and internal control information systems: strategic views on the need for control
#index295654


#*Approximation of the inverse frame operator and applications to Gabor frames
#@Peter G. Casazza,Ole Christensen
#t2000
#cJournal of Approximation Theory
#index281047


#*Three learning phases for radial-basis-function networks
#@Friedhelm Schwenker,Hans A. Kestler,Günther Palm
#t2001
#cNeural Networks
#index243266


#*On the performance of interference canceller based I/Q imbalance compensation
#@M. Valkama
#t2000
#cProceedings of the Acoustics, Speech, and Signal Processing, 2000. on IEEE International Conference - Volume 05
#index413985
#!In quadrature receivers, unavoidable imbalances in the analog front-end between the I- and Q-branches result in finite and usually insufficient rejection of the image frequency band. This causes the image signal to appear as interference on top of the desired signal. Both analog and digital techniques to compensate the effects of I/Q imbalance have been presented in the literature. In this paper, we carry out a detailed performance analysis of the interference cancellation based imbalance compensation structure utilizing baseband digital signal processing. Also simulation results are provided for comparison. The results indicate that the interference canceller based solution can offer adequate performance for most communication applications.


#*Multi-relational data mining: a workshop report
#@Sašo Džeroski,Luc De Raedt
#t2002
#cACM SIGKDD Explorations Newsletter
#index562224
#!In this report, we briefly review the Multi-Relational Data Mining workshop, which was held in Edmonton, Canada on July, 23, 2002 as part of the workshop program of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD-02).


#*On intervals in some posets of forests
#@Frédéric Chapoton
#t2003
#cJournal of Combinatorial Theory Series A
#index118286
#%165046
#!We compute the characteristic polynomials of intervals in some posets of leaf-labeled forests of rooted binary trees.


#*Recursion formulae for basic hypergeometric functions
#@Stanislaw Lewanowicz
#t2000
#cJournal of Computational and Applied Mathematics
#index327759


#*A parallel finite element program on a Beowulf cluster
#@V. Sonzogni,A. Yommi,N. Nigro,M. Storti
#t2000
#cDevelopments in engineering computational technology
#index325642


#*Computational Cortical Cell Models for Continuity and Texture
#@Luís M. Santos,J. M. Hans du Buf
#t2002
#cProceedings of the Second International Workshop on Biologically Motivated Computer Vision
#index564893


#*Authentic assessment through electronic portfolios
#@Gary Ury,Pat McFarland
#t2001
#cProceedings of the seventh annual consortium for computing in small colleges central plains conference on The journal of computing in small colleges
#index318625
#!Portfolios are quickly winning favor as a form of authentic assessment at all levels of education. This paper discusses efforts to develop an electronic portfolio assessment strategy as a graduation requirement for all undergraduate students at Northwest Missouri State University. The author explains early efforts of an electronic portfolio pilot project and presents data analysis in the form of student responses to an opinion survey. The conclusions include projections about full implementation of an electronic portfolio assessment strategy at the university level.


#*Discrete-time deterministic and stochastic models for the spread of rabies
#@Linda J. S. Allen,David A. Flores,Ruwan K. Ratnayake,John R. Herbold
#t2002
#cApplied Mathematics and Computation
#index571150
#%333891
#!Discrete spatial and temporal models for the spread and control of rabies are developed, analyzed and simulated. First, a deterministic model is formulated, then an analogous stochastic model. The models are structured with respect to space (m patches), age (juveniles and adults) and disease state. For each patch there are six state variables corresponding to either juveniles or adults and their disease state: susceptible, infected, or vaccinated. The models have seven stages which repeat every year. The impact of different vaccination strategies on the dynamics of the deterministic and stochastic models are compared. In particular, the relationships among the vaccination proportion, the width of the vaccination barrier, the initial number infected, and the transmissibility of the disease are examined. An estimate for the probability of disease elimination is given for the stochastic model. It is shown that in some cases where the deterministic model predicts disease persistence, the stochastic model predicts a high probability of disease elimination.


#*Immersive and interactive exploration of billion-atom systems
#@Ashish Sharma,Aiichiro Nakano,Rajiv K. Kalia,Priya Vashishta,Sanjay Kodiyalam,Paul Miller,Wei Zhao,Xinlian Liu,Timothy J. Campbell,Andy Haas
#t2003
#cPresence: Teleoperators and Virtual Environments
#index561103
#%287847
#%298005
#%319867
#%325615
#%441654
#%518769
#!We have developed a visualization system, named Atomsviewer, to render a billion atoms from the results of a molecular dynamics simulation. This system uses a hierarchical view frustum culling algorithm based on the octree data structure to efficiently remove atoms that are outside of the field of view. A novel occlusion culling algorithm, using a probability function, then selects atoms with a high probability of being visible. These selected atoms are further tested with a traditional occlusion culling algorithm before being rendered as spheres at varying levels of detail. To achieve scalability, Atomsviewer is distributed over a cluster of PCs that execute a parallelized version of the hierarchical view frustum culling and the probabilistic occlusion culling, and a graphics workstation that renders the atoms. We have used Atomsviewer to render a billion-atom data set on a dual processor SGI Onyx2 with an InfiniteReality2 graphics pipeline connected to a four-node PC cluster.


#*A Polynomial Translation of Logic Programs with Nested Expressions into Disjunctive Logic Programs: Preliminary Report
#@David Pearce,Vladimir Sarsakov,Torsten Schaub,Hans Tompits,Stefan Woltran
#t2002
#cProceedings of the 18th International Conference on Logic Programming
#index357635


#*Patient-Specific Simulation of Carotid Artery Stenting Using Computational Fluid Dynamics
#@Juan R. Cebral,Rainald Löhner,Orlando Soto,Peter L. Choyke,Peter J. Yim
#t2001
#cProceedings of the 4th International Conference on Medical Image Computing and Computer-Assisted Intervention
#index270731


#*An Effective Machine Learning Algorithm using Momentum Scheduling
#@Eun-Mi Kim,Seong-Mi Park,Kwang-Hee Kim,Bae-Ho Lee
#t2004
#cProceedings of the Fourth International Conference on Hybrid Intelligent Systems
#index102141
#!This paper proposes a new algorithm to improve learning performance in support vector machine by using the Kernel Relaxation and the dynamic momentum. Compared with the static momentum, the dynamic momentum is simultaneously obtained by the learning process of pattern weight and reflected into different momentum by the current state. Therefore, the proposed dynamic momentum algorithm can effectively control the convergence rate and performance. The experiment using SONAR data shows that the proposed algorithm has better convergence rate and performance than the kernel relaxation using static momentum.


#*Lossy source coding (invited paper)
#@Toby Berger,Jerry D. Gibson
#t2000
#cInformation theory: 50 years of discovery
#index283346


#*Handling FPGA Faults and Configuration Sequencing Using a Hardware Extension
#@Peter Zipf,Manfred Glesner,Christine Bauer,Hans Wojtkowiak
#t2002
#cProceedings of the Reconfigurable Computing Is Going Mainstream, 12th International Conference on Field-Programmable Logic and Applications
#index560998


#*Becoming a blec
#@Bill Michael
#t2001
#cComputer Telephony
#index330659


#*Cache-only write-detection for nautilus DSM
#@M. Marino,G. Campos
#t2000
#cDistributed and parallel systems: from instruction parallelism to cluster computing
#index330944


#*Information Theory, Inference & Learning Algorithms
#@David J. C. MacKay
#t2002
#c
#index303474


#*TEMPLOP/V.2: a computer program for estimation of fully transient temperatures in geothermal wells during circulation and shut-in
#@G. Espinosa-Paredes,A. Garcia,E. Santoyo,I. Hernandez
#t2001
#cComputers Geosciences
#index321428


#*Hardware system of the earth simulator
#@Shinichi Habata,Kazuhiko Umezawa,Mitsuo Yokokawa,Shigemune Kitawaki
#t2004
#cParallel Computing
#index105151
#%319066
#%286584
#!The Earth Simulator (ES), developed under the Japanese government's initiative "Earth Simulator project", is a highly parallel vector supercomputer system. In this paper, an overview of ES, its architectural features, hardware technology and the result of performance evaluation are described.In May 2002, the ES was acknowledged to be the most powerful computer in the world: 35.86 teraflop/s for the LINPACK HPC benchmark and 26.58 teraflop/s for an atmospheric general circulation code (AFES). Such a remarkable performance may be attributed to the following three architectural features; vector processor, shared-memory and high-bandwidth non-blocking interconnection crossbar network.The ES consists of 640 processor nodes (PN) and an interconnection network (IN), which are housed in 320 PN cabinets and 65 IN cabinets. The ES is installed in a specially designed building, 65m long, 50m wide and 17m high. In order to accomplish this advanced system, many kinds of hardware technologies have been developed, such as a high-density and high-frequency LSI, a high-frequency signal transmission, a high-density packaging, and a high-efficiency cooling and power supply system with low noise so as to reduce whole volume of the ES and total power consumption.For highly parallel processing, a special synchronization means connecting all nodes, Global Barrier Counter (GBC), has been introduced.


#*Quality of service based end-to-end SiMO routing framework in differentiated services networks
#@Jian Zhao
#t2002
#cProceedings of the Performance, Computing, and Communications Conference, 2002. on 21st IEEE International
#index425649
#!Differentiated services (DiffServ) is a proposed architecture for the Internet to support variable QoS requirements using a simple classification scheme. Unlike its counterpart model of IntServ (integrated services) plus RSVP (resource reservation protocol), the DiffServ framework does not need to maintain large state information in core routers and only carries out aggregate resource reservation at edge routers. Therefore, DiffServ calls for a very different routing framework from IntServ. We propose two new QoS-based routing algorithms under the SiMO (single service, multiple options) framework for DiffServ architectures. These are kthQoSR (kth-shortest QoS routing) and EVQoSR (maximum energy value QoS routing). We also introduce QoS extensions to OSPF (open shortest path first) and compare it to our SiMO routing protocols. Our core routing strategy in SiMO, kthQoSR, is executed at the path level and selects one or more routes from a set of computed routes according to defined selection metrics. On the other hand, EVQoSR is a link level, online distributed routing algorithm. Through extensive simulation, we show that our proposed SiMO routing framework can achieve better route qualities in terms of load balancing and network throughput.


#*On the generating sequences of regular languages on k symbols
#@Marie-Pierre Béal,Dominique Perrin
#t2003
#cJournal of the ACM (JACM)
#index308186
#%236816
#%293338
#%464309
#%314121
#!The main result is a characterization of the generating sequences of the length of words in a regular language on k symbols. We say that a sequence s of integers is regular if there is a finite graph G with two vertices i, t such that sn is the number of paths of length n from i to t in G. Thus the generating sequence of a regular language is regular. We prove that a sequence s is the generating sequence of a regular language on k symbols if and only if both sequences s = (sn)n&ge;0 and t = (kn &minus; sn)n&ge;0 are regular.


#*Radiation damping with inhomogeneous broadening: limitations of the single bloch vector model
#@Matthew P. Augustine,Erwin L. Hahn
#t2001
#cConcepts in Magnetic Resonance: an Educational Journal
#index314296


#*Perfect Constant-Round Secure Computation via Perfect Randomizing Polynomials
#@Yuval Ishai,Eyal Kushilevitz
#t2002
#cProceedings of the 29th International Colloquium on Automata, Languages and Programming
#index366052


#*Analytical signal integrity verification models for inductance-dominant multi-coupled VLSI interconnects
#@Seongkyun Shin,Yungseon Eo,William R. Eisenstadt,Jongin Shim
#t2002
#cProceedings of the 2002 international workshop on System-level interconnect prediction
#index623268
#%320956
#%602260
#!Novel signal integrity verification models for inductance-dominant RLC interconnect lines are developed by using a traveling-wave-based waveform approximation (TWA) technique. The multi-coupled line responses are decoupled into the eigenmodes of the system in order to exploit the TWA technique. Then, the response signals are mathematically represented by the linear combination of each eigenmode response based on TWA, followed by reporting the signal integrity models for the multi-coupled lines. The signal integrity of VLSI circuit interconnects has a strong correlation with input signal switching-patterns in the multiple lines. With the proposed analytic signal integrity models, the switching-dependent signal delay, crosstalk, ringing, and glitches of the inductance-dominant RLC interconnect lines can be accurately as well as efficiently determined. It is shown that the models have excellent agreement with SPICE simulations.


#*Approaches for generating moving adaptive meshes: location versus velocity
#@Weiming Cao,Weizhang Huang,Robert D. Russell
#t2003
#cApplied Numerical Mathematics
#index312364
#%75942
#%91598
#%156120
#%174654
#%207386
#%240980
#%295851
#%529114
#%613950
#%603792
#%327976
#!A variety of approaches for generating moving adaptive methods are summarized and compared. They basically fall into two groups: the velocity and the location based methods. The features, including the advantage and weakness, of each group are addressed. Brief numerical results are presented for several commonly used approaches to highlight their features and performance.


#*Navigation and interaction
#@
#t2002
#cProceedings of the workshop on Virtual environments 2002
#index619385


#*Special report: Copy protection: Europe's regulatory gridlock
#@John Blau
#t2003
#cIEEE Spectrum
#index123190


#*Shape segmentation using local slippage analysis
#@Natasha Gelfand,Leonidas J. Guibas
#t2004
#cProceedings of the 2004 Eurographics/ACM SIGGRAPH symposium on Geometry processing
#index103996
#%76539
#%94241
#%252776
#%319749
#%244960
#%597375
#%321817
#!We propose a method for segmentation of 3D scanned shapes into simple geometric parts. Given an input point cloud, our method computes a set of components which possess one or more slippable motions: rigid motions which, when applied to a shape, slide the transformed version against the stationary version without forming any gaps. Slippable shapes include rotationally and translationally symmetrical shapes such as planes, spheres, and cylinders, which are often found as components of scanned mechanical parts. We show how to determine the slippable motions of a given shape by computing eigenvalues of a certain symmetric matrix derived from the points and normals of the shape. Our algorithm then discovers slippable components in the input data by computing local slippage signatures at a set of points of the input and iteratively aggregating regions with matching slippable motions. We demonstrate the performance of our algorithm for reverse engineering surfaces of mechanical parts.


#*Software Practice Is Social Practice
#@Jacob Nørbjerg,Philip Kraft
#t2002
#cSocial Thinking - Software Practice
#index258138


#*Dynamic Knowledge Interaction
#@Toyoaki Nishida
#t2000
#c
#index620817
#!:Internet, intranets, the World Wide Web, chat rooms, e-mail, ande-business. With the advent of this widespread networking, it is clear that the nature of human interactions is changing. As communities develop based on common knowledge, connections through traditional social routes are de-emphasized. Dynamic Knowledge Interaction presents groundbreaking, interdisciplinary work on the creation of information tools for people developing modern community support systems. This book bridges the fields of advanced information technology, social psychology, and cognitive psychology. It will pique the interest of anyone concerned with community in the context of human-computer interaction.


#*A mammography tele-consultation pilot system in Taiwan
#@Chien-Shun Lo,Ching-Wen Yang,Pau-Choo Chung,Yen-Chieh Ouyang,San-Kan Lee,Ping-Sung Liao
#t2000
#cJournal of High Speed Networks
#index319826
#!A pilot system for a mammography tele-consultation in TaiChung Veterans General Hospital (TCVGH), Taiwan is proposed in this paper. It is developed and designed based on a distributed system and implemented in a top-down high speed network hierarchy with communication security. It is also integrated with specific diagnostic tools and collaboration awareness tools currently available in TCVGH and linked with the external internet, Taiwan Academic Network (TANet) that will be upgraded into the next generation, TANet2 in the next five years. The distributed system is designed using a JAVA-based remote method invoking system. It allows the transport of images through a firewall combined with peripheral applications that include a Digital Imaging and Communications in Medicine (DICOM) server for image transmission, Picture Archiving and Communication System (PACS), Hospital Information System (HIS) and computer-aided diagnostic systems via a Java native interface. The communication security is implemented using ElGamals public-key cryptosystem for identifications of authorization. Finally the specific mammography diagnostic tools and collaboration awareness tools demonstrated in the proposed system are developed in accordance with the Breast Imaging Reporting And Data System (BI-RADS) suggested by the American College of Radiology.


#*A Note on Maxflow-Mincut and Homomorphic Equivalence in Matroids
#@Winfried Hochstättler,Jaroslav Nešetřil
#t2000
#cJournal of Algebraic Combinatorics: An International Journal
#index333152
#!Graph homomorphisms are used to study good characterizations for coloring problems i>Trans. Amer. Math. Soc. 384 (1996), 1281&ndash;1297&semi; i>Discrete Math. 22 (1978), 287&ndash;300). Particularly, the following concept arises in this context: A pair of graphs (i>A, i>B) is called a i>homomorphism duality if for any graph i>G either there exists a homomorphism &sigma; : i>A &rarr; i>G or there exists a homomorphism &tau; : i>G &rarr; i>B but not both. In this paper we show that maxflow-mincut duality for matroids can be put into this framework using strong maps as homomorphisms. More precisely, we show that, if i>Ci>k denotes the circuit of length i>k + 1, the pairs (i>Ci>k, i>Ci>k + 1) are the only homomorphism dualities in the class of duals of matroids with the strong integer maxflow-mincut property (i>Jour. Comb. Theor. Ser.B 23 (1977), 189&ndash;222). Furthermore, we prove that for general matroids there is only a trivial homomorphism duality.


#*Thermomechanical fatigue behavior of Sn-Ag solder joints
#@S. Choi,K. N. Subramanian,J. P. Lucas,T. R. Bieler
#t2000
#cJournal of Electronic Materials
#index318797


#*Solving and Learning Soft Temporal Constraints; Ceteris Paribus Statements Represented as Soft Constraints Problems
#@Kristen B. Venable
#t2002
#cProceedings of the 8th International Conference on Principles and Practice of Constraint Programming
#index278734


#*Data Entry: Skillbuilding & Applications (with CD-ROM)
#@
#t2004
#c
#index17193


#*VC Rating and Quality Metrics: Why Bother?
#@
#t2002
#cProceedings of the 3rd International Symposium on Quality Electronic Design
#index121500
#!The System-on-a-Chip era needs more than just avail-able silicon to become a reality. A first step was an SoC design methodology roadmap based on IP Reuse. Two significant initiatives were taken. First one by Mentor Graphics and Synopsys at DAC 1997 where the two companies signed a Design Reuse Partnership. A follow up of this initiative was the publishing at DAC'98 of the Reuse Methodology Manual for System-on-a-Chip, a practical methodology to the challenges associated with design reuse. In parallel the electronic industry created the Virtual Socket Initiative (VSI) organization. Both initiatives were well perceived by the electronic design community and significant achievements occurred. VSI focused more on the Virtual Components aspects with its deliverables and Mentor and Synopsys on the authoring part of the Virtual Component (VC). The next step was taken at DAC'2001 when Mentor and Synopsys decided to donate the IP OpenMORE rating system to VSIA and participate strongly together in the next stage towards the VC Open Standards story. Thus giving birth to a VSIA VC Quality Development Working Group. The challenge will be for this forum to convince the elec-tronic design community that VC rating and quality met-rics are achievable and useful, and make them available. We will go through the process that takes place during the SoC complete design and verification phase with existing VC open standards and design methodology rules and guidelines. We will use a mobile radio 3G base station sub-system as an example. This example comes from a fast growing market segment, therefore system designers are under heavy development mile-stone pressure and it shows how a very practical ap-proach can be taken to a very rational VC design repre-sentation choice process. The objective of this paper is to set the stage for the final step towards a VC quality metrics effort that the industry needs to adopt, and de-fine the next achievable goals. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Internet Poker: How to Play and Beat Online Poker Games
#@Lou Krieger,Kathleen Keller Watterson
#t2003
#c
#index7577


#*Sketch-Based User Interface for Inputting Graphic Objects on Small Screen Devices
#@Liu Wenyin,Xiangyu Jin,Zhengxing Sun
#t2001
#cSelected Papers from the Fourth International Workshop on Graphics Recognition Algorithms and Applications
#index359542


#*Application of Genetic Algorithm to Decentralized Control of Robot Manipulators
#@Hamid Reza Miryazdi,Hamid Khaloozadeh
#t2002
#cProceedings of the 2002 IEEE International Conference on Artificial Intelligence Systems (ICAIS'02)
#index123462
#!This paper discusses the genetic algorithm to improve a decentralized adaptive control scheme to reduce tracking errors of robot manipulators. A simple PD conventional controller is used together a cubic feedback and an adaptive controller to ensure about its global stability. Then a genetic algorithm is proposed to determine coefficients of PD, nonlinear and adaptive controller such that tracking errors of robot that is fitness function of genetic algorithm, to be minimized. In order to show the performance of the proposed method, computer simulation are implemented on a simple two link robot manipulator.


#*Internet nuggets
#@
#t2001
#cACM SIGARCH Computer Architecture News
#index231414


#*A hierarchical tag-graph search scheme with layered grammar rules for spontaneous speech understanding
#@Bor-shen Lin,Berlin Chen,Hsin-min Wang,Lin-shan Lee
#t2002
#cPattern Recognition Letters
#index232082
#!It has always been difficult for language understanding systems to handle spontaneous speech with satisfactory robustness, primarily due to such problems as the fragments, disfluencies, out-of-vocabulary words, and ill-formed sentence structures. Also, the search schemes used are usually not flexible enough in accepting different input linguistic units, and great efforts are therefore required when they are used with different acoustic front ends in different tasks, specially in multi-modal and multi-lingual systems. In this paper, a new hierarchical tag-graph-based search scheme for spontaneous speech understanding is proposed. This scheme is based on a layered hierarchy of grammar rules, and therefore can integrate all the statistical and rule-based knowledge including acoustic scores, language model scores and grammar rules into the search process. More robust speech understanding is thus achievable. In addition, this scheme can accept graphs of different linguistic units such as phonemes, syllables, characters, words, spotted keywords, or phrases as the input, thus compatible to different acoustic front ends and multi-modal and multi-lingual applications can be easily developed. This search scheme has been successfully applied to a multi-domain, multi-modal dialogue system.


#*Distributed oblivious function evaluation and its applications
#@Hong-Da Li,Xiong Yang,Deng-Guo Feng,Bao Li
#t2004
#cJournal of Computer Science and Technology
#index108029
#%277598
#%277834
#%277315
#%315103
#%287572
#%335341
#%165953
#!This paper is about distributed oblivious function evaluation (DOFE). In this setting one party (Alice) has a function f(x), and the other party (Bob) with an input α wants to learn f(α) in an oblivious way with the help of a set of servers. What Alice should do is to share her secret function f(x) among the servers. Bob obtains what he should get by interacting with the servers. This paper proposes the model and security requirements for DOFE and analyzes three distributed oblivious polynomial evaluation protocols presented in the paper.


#*Intelligent Agent to Support Design in Supply Chain Based on Semantic Web Services
#@Incheon Paik,Shinjiro Takami,Yuu Watanabe
#t2004
#cProceedings of the Fourth International Conference on Hybrid Intelligent Systems
#index99298
#!In manufacture industry, better supply chain management (SCM) not only improves efficiency of business processes, but play important roles in a series of cost reductions. In a product manufacture, the initial design is more important from viewpoint of the cost reduction in the whole cycle. It becomes important how a designer collects the information on necessary parts for product design, and the system to search information efficiently at design stage is required. Information infrastructure to support design in SCM was developed on a semantic Web service environment that can provide interoperable service interfaces for integrated design attributes to agents and users. Design Support Agent (DSAgent), as a client for information infrastructure, helps the designer to find the desired product information. But this search process requires autonomy that lacks in DSAgent. As designers must change input values repeatedly to complete finding the desired product information, we suggest an autonomous DSAgent (ADSAgent) in this paper. To add autonomy, we used situation calculus, which is the schema for representing the dynamic changing world. The model to define the world was written in ConGolog statements, which is a logic programming language based on situation calculus. This will facilitate user to find the desired product information and reduce user operations.


#*Traffic modeling and performance analysis of commercial web sites
#@Cathy H. Xia,Zhen Liu,Mark S. Squillante,Li Zhang,Naceur Malouch
#t2002
#cACM SIGMETRICS Performance Evaluation Review
#index439960
#%83512
#%254756
#%291670
#%595117
#%586724


#*Design and Implementation of the ROL Deductive Object-Oriented Database System
#@Mengchi Liu
#t2000
#cJournal of Intelligent Information Systems
#index332557
#%90049
#%166707
#%167001
#%219750
#%228311
#%249971
#%602136
#%529708
#%487842
#%449269
#%593508
#%383106
#%606054
#%567189
#%599428
#%559462
#%543003
#%467561
#%379798
#%357639
#%355861
#!ROL is a deductive object-oriented database system that has been implemented at the University of Regina. It provides a uniform rule-based declarative language for defining, manipulating and querying databases, which integrates important features of both deductive databases and object-oriented databases. It supports object identity, complex objects, classes, class hierarchies, multiple inheritance with overriding and blocking, and schema definition. It also supports structured values such as functor objects and sets, treating them as first class citizens, and providing powerful mechanisms for representing both partial and complete information about sets. This paper describes its design and implementation. An important novel feature of the implementation is that it combines top-down and bottom-up evaluation strategies and automatically selects a strategy based on the nature of the query and data in the database.


#*Applying the Resource Description Framework to Web Engineering
#@Reinhold Klapsing,Gustaf Neumann
#t2000
#cProceedings of the First International Conference on Electronic Commerce and Web Technologies
#index372513


#*The Method of Elementary Components for Approximately Studying Systems with Complex Delay
#@S. M. Muzafarov,Yumagulov
#t2003
#cAutomation and Remote Control
#index304478
#!Linear components containing complex delays are studied. Transfer functions, pulse, and pulse-frequency characteristics of such components are decomposed into series of simple fractions. Conditions for the convergence of these series are formulated, their convergence rates are estimated, and application to study the dynamics of linear delay components is investigated.


#*Extracting Knowledge from Association Relationships to Build Navigational Models
#@Manoli Albert,Vicente Pelechano,Joan Fons,Gonzalo Rojas,Oscar Pastor
#t2003
#cProceedings of the First Conference on Latin American Web Congress
#index312646
#!This paper analyzes how the semantics of association relationships in OO conceptual modeling can help to build Navigational Models for Web Applications. The work has been developed in the context of OOWS (a Model-Driven Development Method for building Web Applications). We study some structural and behavioral properties of those conceptual abstractions in order to extract knowledge to be applied in the construction of navigational models. From this study, a set of design rules has been obtained. These rules help the modeler to build navigational models in a systematic way. The results of this work have improved the modeling and code generation processes introduced by OOWS.


#*Hierarchical Routing Overhead in Mobile Ad Hoc Networks
#@John Sucec,Ivan Marsic
#t2004
#cIEEE Transactions on Mobile Computing
#index410747
#!Hierarchical techniques have long been known to afford scalability in networks. By summarizing topology detail via a hierarchical map of the network topology, network nodes are able to conserve memory and link resources. Extensive analysis of the memory requirements of hierarchical routing was undertaken in the 1970s. However, there has been little published work that assesses analytically the communication overhead incurred in hierarchical routing. This paper assesses the scalability, with respect to increasing node count, of hierarchical routing in mobile ad hoc networks (MANETs). The performance metric of interest is the number of control packet transmissions per second per node (\phi). To derive an expression for \phi, the components of hierarchical routing that incur overhead as a result of hierarchical cluster formation and location management are identified. It is shown here that \phi is only polylogarithmic in the node count.


#*A simple iterative approach to parameter optimization
#@Alexander Zein,Ralf Zimmer,Thomas Lengauer
#t2000
#cProceedings of the fourth annual international conference on Computational molecular biology
#index292013
#%95284
#%605319
#%524672
#!Various bioinformatics problems require optimizing several different properties simultaneously. For example, in the protein threading problem, a linear scoring function combines the values for different properties of possible sequence-to-structure alignments into a single score to allow for unambigous optimization. In this context, an essential question is how each property should be weighted. As the native structures are known for some sequences, the implied partial ordering on optimal alignments may be used to adjust the weights. To resolve the arising interdependence of weights and computed solutions, we propose a novel approach: iterating the computation of solutions (here: threading alignments) given the weights and the estimation of optimal weights of the scoring function given these solutions via a systematic calibration method. We show that this procedure converges to structurally meaningful weights, that also lead to significantly improved performance on comprehensive test data sets as measured in different ways. The latter indicates that the performance of threading can be improved in general.


#*Identity construction environments: supporting a virtual therapeutic community of pediatric patients undergoing dialysis
#@Marina U. Bers,Joseph Gonzalez-Heydrich,David Ray DeMaso
#t2001
#cProceedings of the SIGCHI conference on Human factors in computing systems
#index328438
#%23639
#%201374
#%612146
#!We describe a five-month pilot project conducted in the dialysis unit at Boston's Children's Hospital. Pediatric patients with renal disease used the Zora graphical multi-user environment while facing hemodialysis. Zora is an identity construciton environment specifically designed to help young people explore issues of identity, while engaging in a participatory virtual community. This paper presents the experience and evaluates the feasibility and safety of using Zora in a hospital setting. It describes how Zora facilitated explorations of identity and mutual patient support and interaction. Finally it also presents design recommendations for future interventions of this kind. More generally, this paper explores the potential of technology specifically designed with therapeutic purposes to help patients cope with their illness.


#*Scientific papers: digital video library for presentation of thoracic medicine resources
#@Mikolaj Igor Leszczuk,Mariusz Duplaga
#t2002
#cTechnology and Health Care
#index556034


#*On the medial surface approximations of extrusions
#@A. Csabai,P. Xirouchakis
#t2004
#cEngineering with Computers
#index437700
#!Generating the medial surface for a general boundary representation model raises several difficulties. Problems might emerge from the complexity of the resulting equations, singularities caused by unforeseen relative boundary element positions and orientations, etc. The majority of the current algorithms are based on the topology of the boundary representation model and produce wireframes composed of straight lines regardless of the real medial surfaces. Many of the solids used in engineering can be represented by extrusions, delimited by a cross-section and an extrusion distance. This paper develops a fast and efficient method for creating the facetted approximations of the medial surfaces of extrusions generated by sweeping along the normal direction to the generating cross-section.


#*Dynamical Systems Revisited: Hybrid Systems with Zeno Executions
#@Jun Zhang,Karl Henrik Johansson,John Lygeros,Shankar Sastry
#t2000
#cProceedings of the Third International Workshop on Hybrid Systems: Computation and Control
#index268925


#*An intelligent zone-based delivery scheduling approach
#@H. Wang,D. Xue
#t2002
#cComputers in Industry
#index235755
#%161120
#%207371
#%543124
#%617631
#%534189
#%585324
#!This paper introduces a zone-based delivery scheduling approach developed using artificial intelligence techniques. In this approach, delivery scheduling is conducted at three different levels: (1) classification of past delivery demand patterns and prediction of future delivery demand using a multi-level pattern clustering and matching method, (2) creation of delivery zones, including their center locations, delivery frequencies, and delivery cost rates, for each of these delivery demand patterns, and (3) identification of the optimal delivery methods, sequence, and timing parameters of delivery tasks. The system was implemented using Smalltalk, an object oriented programming language.


#*An XML/XSL-based Software Architecture for Application Service Providers (ASPs)
#@Oliver Günther,Oliver Ricou
#t2000
#cProceedings of the First International Conference on Electronic Commerce and Web Technologies
#index368677


#*A Measurement-Based Dynamic Guard Channel Scheme for Handover Prioritization in Cellular Networks
#@Roland Zander,Johan M. Karlsson
#t2002
#cProceedings of the Second International IFIP-TC6 Networking Conference on Networking Technologies, Services, and Protocols; Performance of Computer and Communication Networks; and Mobile and Wireless Communications
#index277543


#*Decision support for extreme programming introduction and practice selection
#@Daniel Karlström,Per Runeson
#t2002
#cProceedings of the 14th international conference on Software engineering and knowledge engineering
#index236070
#%111973
#%443134
#!This paper presents an investigation concerning the introduction of Extreme Programming (XP) in software development organisations. More specifically the concept of using a decision support method known as the Analytical Hierarchy Process (AHP) is evaluated by a group of students and a group of developers and the outcome is compared to experiences from an XP case study. The results provide an indication that different practices are thought to be easier and more effective to implement in the two groups. A company considering implementing only a few practices can use this as help for deciding which practices to implement. Companies introducing all practices can use the results of this kind of method to see where more attention might be needed after or during the introduction of XP.


#*Software Implementation of the NIST Elliptic Curves Over Prime Fields
#@Michael Brown,Darrel Hankerson,Julio López,Alfred Menezes
#t2001
#cProceedings of the 2001 Conference on Topics in Cryptology: The Cryptographer's Track at RSA
#index359533


#*Editorial
#@Deryn M. Watson
#t2003
#cEducation and Information Technologies
#index305397


#*Cyber Threats and Information Security: Meeting the 21st Century Challenge
#@Arnaud De Borchgrave,Sharon L. Cardash
#t2001
#c
#index255036


#*The Information Society and the Black Community
#@John T. Barber,Alice A. Tait
#t2000
#c
#index238987


#*XML and Meta Data Based EDI for Small Enterprises
#@Wolfram Wöß
#t2000
#cProceedings of the 11th International Conference on Database and Expert Systems Applications
#index564685


#*Minimal path broadcast networks
#@
#t2004
#cNetworks
#index102286
#!Broadcasting is the communication process whereby a message that is initially known by one site becomes known to all sites of a network. Messages are transmitted by calls from senders to sets of receivers. In path broadcasting, a site can call nonneighboring sites over paths in the network. A call occupies all sites and edges on the path followed by the call; thus, any calls made concurrently must be vertex-disjoint. We discuss the design of sparse networks that allow path broadcasting to be completed in minimum time under three different path broadcast models. &copy; 2004 Wiley Periodicals, Inc.


#*Storage: using lib C and I/O and performance
#@Henry Newman
#t2002
#cSys Admin
#index568479


#*Bit-Serial AOP Arithmetic Architectures over GF (2m)
#@Hyun-Sung Kim,Kee-Young Yoo
#t2002
#cProceedings of the International Conference on Infrastructure Security
#index277634


#*Building valid models: how to build valid and credible simulation models
#@Averill M. Law,Michael G. McComas
#t2001
#cProceedings of the 33nd conference on Winter simulation
#index247197
#%84582
#%232309
#!In this tutorial we present techniques for building valid and credible simulation models. Ideas to be discussed include the importance of a definitive problem formulation, discussions with subject-matter experts, interacting with the decision-maker on a regular basis, development of a written conceptual model, structured walk-through of the conceptual model, use of sensitivity analysis to determine important model factors, and comparison of model and system performance measures for an existing system (if any). Each idea will be illustrated by one or more real-world examples. We will also discuss the difficulty in using formal statistical techniques (e.g., confidence intervals) to validate simulation models.


#*Sharing Culture - Enabling technologies for Communication Support
#@Thomas Grill,Reinhard Kronsteiner,Gabriele Kotsi
#t2003
#cProceedings of the 2003 International Conference on Cyberworlds
#index301901
#!In cyberworlds as well as in real world environmentsthere is a need to enable cooperation and communication.While IT support has enabled us to overcome the barriersof time and place in communication over distance, thereis still the problem of bridging the gap across differentcultures. In this paper we will study the possibility of ITsupport for "sharing culture", i.e. for communicationacross different cultures.Our attempt to realize this goal is the creation of alearning, proactive agent that keeps track of thecommunication in virtual environments. We try to supportthe communication partners during their interactions byproviding information based on the type and content ofthe communication. The information provided by theagent is based on cultural differences that could lead topotential misunderstandings within a communicationscenario.The idea is to design a pluggable agent to support cross-culturalcommunication for virtual communities indistributed environments.


#*Improving business processes asynchronously
#@Dorrie DeLuca,Ned Kock
#t2000
#cProceedings of the 2000 information resources management association international conference on Challenges of information technology management in the 21st century
#index320250


#*When information retrieval measures agree about the relative quality of document rankings
#@Robert M. Losee
#t2000
#cJournal of the American Society for Information Science
#index286955


#*A KM-enabled architecture for collaborative systems
#@Lina Zhou,Dongsong Zhang
#t2000
#cProceedings of the 2000 information resources management association international conference on Challenges of information technology management in the 21st century
#index318162


#*Frames of periodic shift-invariant spaces
#@Di-Rong Chen
#t2000
#cJournal of Approximation Theory
#index326855


#*Automotive Control Systems: For Engine, Driveline and Vehicle, 1st edition
#@Uwe Kiencke,Lars Nielsen
#t2000
#c
#index238807
#!:This book enables control engineers to understand engine and vehicle models necessary for controller design and introduces mechanical engineers into vehicle-specific signal processing and automatic control. With only a few exceptions the approaches are close to some of those utilized in actual vehicles, rather than being purely theoretical. The authors have large experiences in industrial development (Bosch) as well as in academic research.


#*On a concatenation problem
#@Henry Ibstedt
#t2002
#cSmarandache notions
#index567300
#!This article has been inspired by questions asked by Charles Ashbacher in the Journal of Recreational Mathematics, vol. 29.2. It concerns the Smarandache Deconstructive Sequence. This sequence is a special case of a more general concatenation and sequencing procedure which is the subject of this study. Answers are given to the above questions. The properties of this kind of sequencies are studied with particular emphasis on the divisibility of their terms by primes.


#*Helping students to build mental models of program execution via the &ldquo;boxes&rdquo; software
#@Jerry Shultz
#t2000
#cJournal of Computing Sciences in Colleges
#index317006


#*Information retrieval using word senses: root sense tagging approach
#@Sang-Bum Kim,Hee-Cheol Seo,Hae-Chang Rim
#t2004
#cProceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval
#index434711
#%118311
#%225567
#%288756
#%322944
#!Information retrieval using word senses is emerging as a good research challenge on semantic information retrieval. In this paper, we propose a new method using word senses in information retrieval: root sense tagging method. This method assigns coarse-grained word senses defined in WordNet to query terms and document terms by unsupervised way using co-occurrence information constructed automatically. Our sense tagger is crude, but performs consistent disambiguation by considering only the single most informative word as evidence to disambiguate the target word. We also allow multiple-sense assignment to alleviate the problem caused by incorrect disambiguation.Experimental results on a large-scale TREC collection show that our approach to improve retrieval effectiveness is successful, while most of the previous work failed to improve performances even on small text collection. Our method also shows promising results when is combined with pseudo relevance feedback and state-of-the-art retrieval function such as BM25.


#*Code Placement and Replacement Strategies for Wideband CDMA OVSF Code Tree Management
#@Yu-Chee Tseng,Chih-Min Chao
#t2002
#cIEEE Transactions on Mobile Computing
#index568722
#%235329
#%613609
#!The use of OVSF codes in WCDMA systems has offered opportunities to provide variable data rates to flexibly support applications with different bandwidth requirements. Two important issues in such an environment are the code placement problem and code replacement problem. The former may have significant impact on code utilization and, thus, code blocking probability, while the latter may affect the code reassignment cost if dynamic code assignment is to be conducted. The general objective is to make the OVSF code tree as compact as possible so as to support more new calls by incurring less blocking probability and less reassignment costs. Earlier studies about these two problems either do not consider the structure of the OVSF code tree or cannot utilize the OVSF codes efficiently. To reduce the call blocking probability and the code reassignment cost, we propose two simple yet efficient strategies that can be adopted by both code placement and code replacement: leftmost and crowded-first. Numerical analyses on call blocking probability and bandwidth utilization of OVSF code trees when code reassignment is supported are provided. Our simulation results show that the crowded-first strategy can significantly reduce, for example, the code blocking probability by 77 percent and the number of reassignments by 81 percent, as opposed to the random strategy when the system is 80 percent fully loaded and the max SF = 256.


#*Learning and Making Decisions When Costs and Probabilities are Both Unknown
#@Bianca Zadrozny,Charles Elkan
#t2001
#c
#index192426
#!In many machine learning domains, misclassification costs are different for different examples, in the same way that class membership probabilities are example-dependent. In these domains, both costs and probabilities are unknown for test examples, so both cost estimators and probability estimators must be learned. This paper first discusses how to make optimal decisions given cost and probability estimates, and then presents decision tree learning methods for obtaining well-calibrated probability estimates. The paper then explains how to obtain unbiased estimators for example- dependent costs, taking into account the difficulty that in general, probabilities and costs are not independent random variables, and the training examples for which costs are known are not representative of all examples. The latter problem is called sample selection bias in econometrics. Our solution to it is based on Nobel prize-winning work due to the economist James Heckman. We show that the methods we propose are successful in a comprehensive comparison with MetaCost that uses the well-known and difficult dataset from the KDD''98 data mining contest.


#*Boundaryless behaviour, and knowledge as the ultimate ready-made
#@David Beckett
#t2001
#cDigital developments in higher education: theory and practice
#index248887
#%619937


#*Programming Microsoft SQL Server 2000 for Microsoft Access Developers
#@Natasha Nicol,Ralf Albrecht
#t2002
#c
#index232202
#!:Here's the expert, hands-on guidance that professional Access programmers need to fully exploit the world-class scalability and knowledge-management capabilities in SQL Server 2000. This authoritative guide focuses on understanding and using the innovative Microsoft Data Engine (MSDE) technology that serves as the powerful core of SQL Server 2000. Readers are taken inside its high-performance data-management and data-replication features, developers dive into a whole new subset of Access technologies, known as Access projects, that they must learn in order to effectively program for SQL Server 2000. Topics include the Access project interface, specification table techniques, data types and constraints, and forms techniques. The book digs into stored proceduresa subject that's new to most Access developersin depth and covers ASP and security issues as well. Throughout, the emphasis is on applying the reader's expertise building desktop database tools to accessing the enterprise-level power and performance in SQL Server 2000. The CD-ROM features all the book's sample applications, as well as a complete electronic version of the text for fast searches and reference. The professional Access developer's guide to understanding, using, and developing for SQL Server 2000 The only book of its kind that provides Microsoft Access developers a hands-on guide to programming enterprise business solutions using the Microsoft Data Engine (MSDE) in SQL Server 2000, and the "Access Projects" features in Microsoft Access. Key Book Benefits: * Offers in-depth, focused instruction for building industrial-strength database applications for SQL Server 2000 usingMicrosoft Access * Delivers authoritative coverage of the Microsoft Data Engine, Access projects, stored procedures, and other vital topics * Demonstrates practical real-world applications, complete with code that readers can use to jumpstart their own projects * Features full text on CD-ROM


#*Building a Digital Library from the Ground Up: An Examination of Emergent Information Resources in the Machine Learning Community
#@Sally Jo Cunningham
#t2002
#cProceedings of the 5th International Conference on Asian Digital Libraries: Digital Libraries: People, Knowledge, and Technology
#index373068


#*Reconfigurable computing: a survey of systems and software
#@Katherine Compton,Scott Hauck
#t2002
#cACM Computing Surveys (CSUR)
#index607369
#%76458
#%78973
#%80160
#%82127
#%84343
#%91915
#%94618
#%94933
#%95294
#%95971
#%279920
#%280143
#%286531
#%320637
#%356980
#%441542
#%443986
#%448662
#%513914
#%522153
#%528152
#%596141
#%599809
#%602241
#!Due to its potential to greatly accelerate a wide variety of applications, reconfigurable computing has become a subject of a great deal of research. Its key feature is the ability to perform computations in hardware to increase performance, while retaining much of the flexibility of a software solution. In this survey, we explore the hardware aspects of reconfigurable computing machines, from single chip architectures to multi-chip systems, including internal structures and external coupling. We also focus on the software that targets these machines, such as compilation tools that map high-level algorithms directly to the reconfigurable substrate. Finally, we consider the issues involved in run-time reconfigurable systems, which reuse the configurable hardware during program execution.


#*A MIME is a terrible thing to waste
#@Randal L. Schwartz
#t2001
#cSys Admin
#index334766


#*Information Subsystem of the Difference Between Anions Sum and Hardness of Water and Its Influence on Human Health
#@Nives Štambuk-Giljanović,Berezina Matoković,Drago Štambuk,Neven Elezović,Nilia Jelić
#t2000
#cJournal of Medical Systems
#index323343
#%284512
#%587539
#!Underground and surface waters in Dalmatia (Southern Croatia) have relatively preserved their natural characteristics since the greatest agglomeration of population and industry is located along the coast. The danger of pollution with fecal microorganism and products of biological decomposition is the most immediate problem but can be efficiently eliminated by water chlorination. The ecological need to sum up the work on water quality examination and estimation of future water quality trends resulted in water quality monitoring, i.e. in human health monitoring. It is necessary for large number of analytical and ecological health data to organize them from the informatical aspect into databases, the relational database for chemical analysis studying (the difference between anions sum and hardness) as methodological base for studying the ecological factors that influence human health defined in this paper. Results used for the prototype implementation subsystem of the chemical water analysis control are based on the investigations of Water Examination Department of the Public Health Institute of the Split-Dalmatian County (Croatia). Over 3400 data are comprised what is the sufficient examination sample. The software used included Win '95, Mo '97, and Paradox 4,5, while the hardware used included Pentium II 300 MHz, floppy, 128 MB RAM HDD 4,3 GB, CD &times; 24, HP DeskJet 710C.


#*The SolarisTM companion: storage consolidation -- Part 3 -- Implementation details
#@Peter Baer Galvin
#t2002
#cSys Admin
#index557617


#*Efficient Tests for Realistic Faults in Dual-Port SRAMs
#@S. Hamdioui,A. J. van de Goor
#t2002
#cIEEE Transactions on Computers
#index249806
#%447607
#%441589
#%595754
#%333541
#%525574
#!This paper begins with an overview of realistic fault models for dual-port memories, divided into single-port faults and faults unique for dual-port memories. The latter faults cannot be detected with the conventional single-port memory tests; they require special tests. A precise notation for all faults, such that ambiguities and misunderstandings will be prevented, has been emphasized. Next, the paper presents a methodology to design tests for realistic unique dual-port memory faults, resulting in a set of three linear single-addressing tests which are merged into a single march test (March s2PF), and one linear double-addressing test (March d2PF). March s2PF and March d2PF have been implemented at Intel. The results show that they detect unique faults, i.e., faults that cannot be detected with conventional single-port memory tests. This make them very attractive industrially.


#*Querying Petrographic Descriptions in an Intelligent Database System
#@Cristina Paludo Santos
#t2002
#cProceedings of the 2002 IEEE International Conference on Artificial Intelligence Systems (ICAIS'02)
#index113049
#!This paper describes the query module of the Petrographer System. Petrographer is an Intelligent Database System that supports petrographic descriptions, diagenetic analysis and data management, using resources from expert systems and database technologies. Among the requirements of the application domain, includes to retrieve and to compare the information of an extends amount of rock sample. In this way, a query interface for the application that provides the refinement progressive of a query in the database has been defined. The querying process proposed allows the user to define selection expressions based on rock sample features and hence view the results. The interface supports the basic requirements of the application and consists in an relevant tool to the system.


#*Fingerprint image enhancement using filtering techniques
#@Shlomo Greenberg,Mayer Aladjem,Daniel Kogan
#t2002
#cReal-Time Imaging
#index442928
#%88209
#%160011
#%168955
#%442672
#%458272
#%515999
#%473859
#!Extracting minutiae from fingerprint images is one of the most important steps in automatic fingerprint identification and classification. Minutiae are local discontinuities in the fingerprint pattern, mainly terminations and bifurcations. Most of the minutiae detection methods are based on image binarization while some others extract the minutiae directly from gray-scale images. In this work we compare these two approaches and propose two different methods for fingerprint ridge image enhancement. The first one is carried out using local histogram equalization, Wiener filtering, and image binarization. The second method uses a unique anisotropic filter for direct gray-scale enhancement. The results achieved are compared with those obtained through some other methods. Both methods show some improvement in the minutiae detection process in terms of time required and efficiency.


#*Parallel machine scheduling with earliness-tardiness penalties and additional resource constraints
#@José A. Ventura,Daecheol Kim
#t2003
#cComputers and Operations Research
#index120048
#%618396
#%486142
#%539373
#!This research considers the problem of scheduling jobs on parallel machines with noncommon due dates and additional resource constraints. The objective is to minimize the total absolute deviation of job completion times about the corresponding due dates. All job processing times are assumed to be the same. This problem is motivated by restrictions that occur in the handling and processing of jobs in certain phases of semiconductor manufacturing and other production systems. We examine two special cases. For the first of these, the number of additional resource types and the resource requirements per job are arbitrary. The problem is formulated as a zero-one integer linear program and the Lagrangian relaxation approach is used to obtain tight lower bounds. In the second case, there exist one single type of additional resource and the resource requirements per job are zero or one. This problem is shown to be equivalent to the asymmetric assignment problem.


#*Exterior stokes flows with stick-slip boundary conditions
#@D. Palaniappan,Prabir Daripa
#t2002
#cZeitschrift f&uuml;r Angewandte Mathematik und Physik (ZAMP)
#index253065
#!Steady two-dimensional creeping flows induced by line singularities in the presence of an infinitely long circular cylinder with stick-slip boundary conditions are examined. The singularities considered here include a rotlet, a potential source and a stokeslet located outside a cylinder and lying in a plane containing the cylinder axis. The general exterior boundary value problem is formulated and solved in terms of a stream function by making use of the Fourier expansion method. The solutions for various singularity driven flows in the presence of a cylinder are derived from the general results. The stream function representation of the solutions involves a definite integral whose evaluation depends on a non-dimensional slip parameter &#x03BB;1. For extremal values, &#x03BB;1 = 0 and &#x03BB;1 = 1, of the slip parameter our results reduce to solutions of boundary value problems with stick (no-slip) and perfect slip conditions, respectively.The slip parameter influences the flow patterns significantly. The plots of streamlines in each case show interesting flow patterns. In particular, in the case of a single rotlet/stokeslet (with axis along y-direction) flows, eddies are observed for various values of &#x03BB;1. The flow fields for a pair of singularities located on either side of the cylinder are also presented. In these flows, eddies of different sizes and shapes exist for various values of &#x03BB;1 and the singularity locations. Plots of the fluid velocity on the surface show locations of the stagnation points on the surface of the cylinder and their dependencies on &#x03BB;1 and singularity locations.


#*Fuzzy stage characteristic-preserving product life cycle modeling
#@Ping-Teng Chang
#t2002
#cFuzzy Sets and Systems
#index444690
#%148931
#%153729
#%251603
#!Stage concerns have been important in product life cycles (PLC). Such concerns are stage identification, stage-related strategies and, here newly introduced, 'stage modeling'. Stage modeling is concerned with not only modeling but also aggregation of individual stages in an overall-influencing manner. It not only preserves the respective characteristics of the stages but also may be explored for the stage-related strategy issue later. To date, this aspect of PLC modeling has not yet been explored. In this paper, a fuzzy PLC modeling capable of preserving the fuzzy individual characteristics of the stages is proposed. The various concepts such as boundary identification, fuzzy stages modeling, and stages' inter-influence functions are introduced and discussed. Finally, to illustrate and support the approach, a numerical example and a comparison with classical data-analytic procedures (segmented polynomial regression and autoregressive-integrated moving average) is provided.


#*A simulation-based procedure for expert system evaluation
#@Chunsheng Yang,Kuniji Kose,Sieu Phan,Pikuei Kuo
#t2000
#cProceedings of the 13th international conference on Industrial and engineering applications of artificial intelligence and expert systems: Intelligent problem solving: methodologies and approaches
#index318495


#*Website to Accompany Operating System Concepts 6e, Xp Edition
#@
#t2003
#c
#index1231


#*Tracking weather's flight pattern
#@Tekla S. Perry
#t2000
#cIEEE Spectrum
#index323317


#*Internet Search Technologies XML
#@Matthew Montebello,R. Ciappara
#t2000
#cProceedings of the 11th International Conference on Database and Expert Systems Applications
#index571999


#*Analytic solutions of a second-order iterative functional differential equation
#@Jian-Guo Si,Xin-Ping Wang
#t2000
#cJournal of Computational and Applied Mathematics
#index316957


#*Modeling a garment manufacturer's cash flow using object-oriented simulation
#@José A. Sepúlveda,Haluk M. Akin
#t2004
#cProceedings of the 36th conference on Winter simulation
#index21424
#!Garment manufacturers usually work with a short vision of the demand to come in the following months. So they want to borrow as little as possible while still making a good profit at the end of the year. This study models a garment manufacturer's cash flow with the objective of finding scenarios where the company will be employing a low level of its credit-line and still be making a reasonable profit. To model our problem, we use Silk, an object-oriented simulation library in Java. Input data from a small-sized garment manufacturing company is used to build and test the model. A model where the manufacturer can test decisions like investing on opening new job shops, changing the production scheduling heuristics, or changing the payment agreements with suppliers and an example usage of the simulation are presented.


#*Foreword
#@Colin Fidge
#t2003
#cTheoretical Computer Science
#index567828


#*An Expert Recommendation System using Concept-based Relevance Discernment
#@Takashi Yukawa,Kaname Kasahara,Toshiro Kita,Tsuneaki Kato
#t2001
#cProceedings of the 13th IEEE International Conference on Tools with Artificial Intelligence
#index112414
#!An expert recommendation system using concept-based relevance discernment is proposed. This system processes the description of a technical topic as input and then finds engineers who have a high level of expertise in that area. The technique employed is an extended vector space model that locates both technical topics and engineers in the same multi-dimensional space, and then calculates their relevance. This system can also retrieve engineers or documents that are related to a field matching a given engineer's technical interests. Such a system can be expected to play the role of a person's professional network, and be a valuable tool for knowledge management among several organizations.


#*Integrating active information delivery and reuse repository systems
#@Yunwen Ye,Gerhard Fischer,Brent Reeves
#t2000
#cACM SIGSOFT Software Engineering Notes
#index328109
#%78159
#%86496
#%88557
#%89476
#%162780
#%279830
#%596294
#%612358
#%521069
#%439231
#%439476
#%584054
#%605101
#%519991
#%371833
#%604820
#!Although software reuse can improve both the quality and productivity of software development, it will not do so until software developers stop believing that it is not worth their effort to find a component matching their current problem. In addition, if the developers do not anticipate the existence of a given component, they will not even make an effort to find it in the first place. Even the most sophisticated and powerful reuse repositories will not be effective if developers don't anticipate a certain component exists, or don't deem it worthwhile to seek for it. We argue that this crucial barrier to reuse is overcome by integrating active information delivery, which presents information without explicit queries from the user, and reuse repository systems. A prototype system, CodeBroker, illustrates this integration and raises several issues related to software reuse.


#*A Survey of Silhouette Detection Techniques for Non-Photorealistic Rendering
#@Ao-yu Wang,Min Tang,Jin-xiang Dong
#t2004
#cProceedings of the Third International Conference on Image and Graphics
#index107450
#!Silhouettes play a critical role in non-photorealistic rendering. The effect of the NPR greatly depends on the silhouette performance. And it is also a key technology for real-time NPR applications. This paper introduces the most popular and latest techniques in silhouette detection. We classify and analyze them, and discuss them with the problem of visibility determination. After analyze the advantage and disadvantage of them, the working context of them is also concluded.


#*Increasing accessibility by pooling digital resources
#@Steve Cushion
#t2004
#cReCALL
#index433454
#!There are now many CALL authoring packages that can create interactive websites and a large number of language teachers are writing materials for the whole range of such packages. Currently, each product stores its data in different formats thus hindering interoperability, pooling of digital resources and moving between software packages based in different technology. The use of Extensible Mark-up Language (XML) for data storage goes a long way to solve this problem and allows for the easy conversion of exercises. Starting from a desire to develop a common format between Hot Potatoes, WELTS (part of the WELL project) and the Interactive Language Learning package from London Metropolitan University, a new version of the Interactive Language Learning software, now renamed Guildhall Interactive Software for Multimedia On-line (GISMO), has made such conversion possible. Given the immense resources required to develop the critical mass of material required to make online CALL relevant to an individual&rsquo;s teaching practice, such a common approach is required to facilitate the pooling of resources. Should a bureaucratic or financial decision in an institution result in a change of software, teachers need to be able to easily convert their legacy material. XML technology can facilitate interoperability, thereby increasing potential accessibility by allowing teachers and students to have the use of a greater amount of pedagogical material. It is further proposed, using these developments, to create a large pool of exercises for practice and assessment that is independent of the delivery approach employed. This will obviate the need for teachers to keep reproducing basic language learning material and allow for the expansion of online CALL into more imaginative areas. This possibility introduces the question of standards within XML and whether it is necessary to further specify how the material is stored, perhaps using a standard such as the &lsquo;IMS Question & Test Interoperability Specification&rsquo; or whether XML is a sufficient standard in itself.


#*A sequential pruning strategy for the selection of the number of states in hidden Markov models
#@Manuele Bicego,Vittorio Murino,Mário A. T. Figueiredo
#t2003
#cPattern Recognition Letters
#index557353
#%151954
#%282572
#%304408
#%365292
#%620759
#!This paper addresses the problem of the optimal selection of the structure of a hidden Markov model. A new approach is proposed, which is able to deal with drawbacks of standard general purpose methods, like those based on the Bayesian inference criterion, i.e., computational requirements, and sensitivity to initialization of the training procedures. The basic idea is to perform "decreasing" learning, starting each training session from a "nearly good" situation, derived from the result of the previous training session by pruning the "least probable" state of the model. Experiments with real and synthetic data show that the proposed approach is more accurate in finding the optimal model, is more effective in classification accuracy, while reducing the computational burden.


#*Proceedings of the 2002 ACM symposium on Applied computing
#@
#t2002
#cSymposium on Applied Computing
#index607782
#!Welcome to the 17th Annual ACM Symposium on Applied Computing (SAC'2002) as hosted by Universidad Carlos III de Madrid in Leganes, Spain, which is strategically located South of Madrid! Thanks for attending this international forum for computer scientists, engineers and practitioners that includes many innovative computational ideas and a wide spectrum of applications.SAC is a conference devoted to the study of real-world problem applications using many varieties of computation algorithms. As such, it provides an avenue for discussion and exchange of new ideas, associated computation algorithms, and interesting complex applications. The Symposium is rightly sponsored by the ACM Special Interest Group on Applications (SIGAPP) whose mission is to further the interests of the computing professional engaged in the development of new computing applications, interdisciplinary applications areas, and applied research. Thus, the spectrum of applications and tutorials covers databases and computational finance to evolutionary algorithms, software engineering, and parallel and distributed computing plus others designed to provide a wide range of topics as reflected in the SAC'2002 program. Note that Biomedical Computing is also a special element of the Symposium with an innovative bioinformatics track and associated tutorial and plenary session as directed by Warren Jones.Welcome to the 17th Symposium on Applied Computing (SAC 2002). During the past 16 years, the Symposium provided an opportunity for researchers and practitioners to present their findings and research results in the areas of computer applications and technology. This year, the 3-day technical program offers a wide range of tracks covering major areas of computer applications. Highly qualified referees with strong expertise and special interest in their respective research areas carefully reviewed submitted papers. In addition, the technical program includes a tutorial program offering 3 full-day and 4 half-day and tutorials. The tutorials are described later in this program and are posted on SAC 2002 Website (http ://www.acm.org/conferences/sac/sac2002/TutorialCall.htm).This year, SAC embarked on a radical modification of its established procedure for compiling the list of tracks to which authors would subsequently submit their papers. More to the point, an open call for track proposals was introduced, inviting all parties interested in holding a track to respond to this call by submitting to the Program Chairs a short description of the proposed track, along with a preliminary dissemination plan of the proposed track's call for papers and a short CV of the potential track chairs. In response to this call, 34 track proposals were submitted which were evaluated thoroughly by SAC 2002's Organizing Committee. Some proposals were rejected on thegrounds of either not being appropriate for the areas that SAC covers traditionally or being of rather narrow and specialized nature. Some others were merged to form a single track, on the grounds of having substantial overlap with each other. Eventually, 21 tracks were established, which then went on to produce their own call for papers. In response to these calls, 457 papers were submitted, from which 194 papers were strongly recommended by the referrers for acceptance and inclusion in the Conference Proceedings. This gives SAC 2002 an acceptance rate of 42% across all submissions and an average acceptance rate of 40% over all tracks. It also makes SAC 2002 the most successful conference in the history of SAC so far, but also one of the most popular and competitive conferences in the international field of applied computing.


#*ASEP: A Secure and Flexible Commit Protocol for MLS Distributed Database Systems
#@Indrajit Ray,Luigi V. Mancini,Sushil Jajodia,Elisa Bertino
#t2000
#cIEEE Transactions on Knowledge and Data Engineering
#index449018
#%157343
#%159660
#%180364
#%207535
#%369919
#%380281
#%522577
#!The classical Early Prepare commit protocol (EP), used in many commercial systems, is not suitable for use in multilevel secure distributed databases systems that employ a locking protocol for concurrency control. This is because EP requires that read locks are not released by a participant during its window of uncertainty; however, it is not possible for a locking protocol to provide this guarantee in a multilevel secure system (since the read lock of a higher-level transaction on a lower-level data object must be released whenever a lower-level transaction wants to write the same data). The only available work in the literature, namely the Secure Early Prepare protocol (SEP), overcomes this difficulty by aborting those distributed transactions that release their low-level read locks prematurely. We see this approach as being too restrictive. One of the major benefits of distributed processing is its robustness to failures, and SEP fails to take advantage of this. In this work, we propose the Advanced Secure Early Prepare commit protocol (ASEP) to solve the above problem together with a number of language primitives that can be used as system calls in distributed transactions. These primitives permit features like partial rollback and forward recovery to be incorporated within the transaction model, and allow a distributed transaction to proceed even when a participant has released its low-level read locks prematurely. This not only offers flexibility, but can also be used, if desired, by a sophisticated programmer to trade off consistency for atomicity of the distributed transaction.


#*Certifying usability (professionals): a scheme to qualify practitioners
#@Marisa Campbell
#t2002
#cinteractions
#index619200


#*MAPGEN: Mixed-Initiative Planning and Scheduling for the Mars Exploration Rover Mission
#@Mitchell Ai-Chang,John Bresina,Len Charest,Adam Chase,Jennifer Cheng-jung Hsu,Ari Jonsson,Bob Kanefsky,Paul Morris,Kanna Rajan,Jeffrey Yglesias,Brian G. Chafin,William C. Dias,Pierre F. Maldague
#t2004
#cIEEE Intelligent Systems
#index389934
#!Science is the Mars Exploration Rover mission's primary driver, so making best use of the scientific instruments, within the available resources, is a crucial aspect of the mission. To address this criticality, the MER project team selected MAPGEN (Mixed Initiative Activity Plan GENerator) as an activity-planning tool.


#*special issue on parallel computing for irregular applications
#@G. R. Joubert,J. Chassin de Kergommeaux,P. J. Hatcher,L. Rauchwerger
#t2000
#cParallel Computing
#index327198


#*Some Improvements of the Fast Marching Method
#@David L. Chopp
#t2001
#cSIAM Journal on Scientific Computing
#index239849
#!The fast marching method published by Sethian [Proc. Natl. Acad. Sci. USA, 93 (1996), pp. 1591--1595] is an optimally efficient algorithm for solving problems of front evolution where the front speed is monotonic. It has been used in a wide variety of applications such as robotic path planning [R. Kimmel and J. Sethian, Fast Marching Methods for Computing Distance Maps and Shortest Paths, Tech. Report 669, CPAM, University of California, Berkeley, 1996], crack propagation [M. Stolarska et al., Modelling crack growth by level sets in the extended finite element method, Comput. Methods Appl. Mech. Engrg., to appear; Internat. J. Numer. Methods Engrg., 51 (2001), pp. 943--960; N. Sukumar, D. L. Chopp, and B. Moran, Extended finite element method and fast marching method for three-dimensional fatigue crack propagation, J. Comput. Phys., submitted], seismology [J. Sethian and A. Popovici, Geophysics, 64 (1999), pp. 516--523], photolithography [J. Sethian, Fast marching level set methods for three-dimensional photolithography development, in Proceedings of the SPIE 1996 International Symposium on Microlithography, Santa Clara, CA, 1996], and medical imaging [R. Malladi and J. Sethian, Proc. Natl. Acad. Sci. USA, 93 (1996), pp. 9389--9392]. It has also been a valuable tool for the implementation of modern level set methods where it is used to efficiently compute the distance to the front and/or an extended velocity function.In this paper, we improve upon the second order fast marching method of Sethian [SIAM Rev., 41 (1999), pp. 199--235] by constructing a second order approximation of the interface generated from local data on the mesh. The data is interpolated on a single box of the mesh using a bicubic approximation. The distance to the front is then calculated by using a variant of Newton's method to solve both the level curve equation and the orthogonality condition for the nearest point to a given node. The result is a second order approximation of the distance to the interface which can then be used to produce second order accurate initial conditions for the fast marching method and a third order fast marching method.


#*Software Project Management and Quality Engineering Practices for Complex, Coupled Multiphysics, Massively Parallel Computational Simulations: Lessons Learned From ASCI
#@D. E. Post,R. P. Kendall
#t2004
#cInternational Journal of High Performance Computing Applications
#index109288
#%75294
#%81006
#%89719
#%154225
#%448373
#%449214
#%439208
#%530924
#%232878
#%248851
#%369203
#!Many institutions are now developing large-scale, complex, coupled multiphysics computational simulations for massively parallel platforms for the simulation of the performance of nuclear weapons and certification of the stockpile, and for research in climate and weather prediction, magnetic and inertial fusion energy, environmental systems, astrophysics, aerodynamic design, combustion, biological and biochemical systems, and other areas. The successful development of these simulations is aided by attention to sound software project management and software engineering. We have developed "lessons learned" from a set of code projects that the Department of Energy National Nuclear Security Agency has sponsored to develop nuclear weapons simulations over the last 50 years. We find that some, but not all, of the software project management and development practices (rather than processes) commonly employed for non-technical software add value to the development of scientific software and we identify those that we judge add value. Another key finding, consistent with general software industry experience, is that the optimal project schedule and resource level are solely determined by the requirements once the requirements are fixed.


#*A New Class of Stream Ciphers Combining LFSR and FCSR Architectures
#@François Arnault,Thierry P. Berger,Abdelkader Necer
#t2002
#cProceedings of the Third International Conference on Cryptology: Progress in Cryptology
#index262767


#*Three-way component analysis with smoothness constraints
#@Marieke E. Timmerman,Henk A. L. Kiers
#t2002
#cComputational Statistics Data Analysis
#index446948
#%156157
#%181670
#%471017
#!Tucker3 Analysis and CANDECOMP/PARAFAC (CP) are closely related methods for three-way component analysis. Imposing constraints on the Tucker3 or CP solutions can be useful to improve estimation of the model parameters. In the present paper, a method is proposed for applying smoothness constraints on Tucker3 or CP solutions, which is particularly useful in analysing functional three-way data. The usefulness of smoothness constraints on Tucker3 and CP solutions is examined by means of a simulation experiment. Generally, the results of the experiments indicate better estimations of the model parameters. An empirical example illustrates the use of smoothness constraints. The constrained model is more stable and easier to interpret than the unconstrained model.


#*E-Work and E-Commerce
#@B. Stanford-Smith,E. Chiozza
#t2001
#c
#index237928


#*A 300 MB Turkish Corpus and Word Analysis
#@Gökhan Dalkiliç,Yalçin Çebi
#t2002
#cProceedings of the Second International Conference on Advances in Information Systems
#index363594


#*Buffer insertion with adaptive blockage avoidance
#@Jiang Hu,Charles J. Alpert,Stephen T. Quay,Gopal Gandham
#t2002
#cProceedings of the 2002 international symposium on Physical design
#index607450
#%78752
#%85139
#%85593
#%293862
#%295972
#%297304
#%297851
#%326011
#%446092
#!Buffer insertion is a fundamental technology for VLSI interconnect optimization. Several existing buffer insertion algorithms have evolved from van Ginneken's classic algorithm. In this work, we extend van Ginneken's algorithm to handle blockages in the layout. Given a Steiner tree containing a Steiner point that overlaps a blockage, a local adjustment is made to the tree topology that enables additional buffer insertion candidates to be considered. This adjustment is adaptive to the demand on buffer insertion and is incurred only when it facilitates the maximal slack solution. This approach can be combined with any performance-driven Steiner tree construction. The overall time complexity has linear dependence on the number of blockages and quadratic dependence on the number of potential buffer locations. Experiments on several large nets confirm that high-quality solutions can be obtained through this technique with little CPU cost.


#*Variance Optimized Bagging
#@Philip Derbeko,Ran El-Yaniv,Ron Meir
#t2002
#cProceedings of the 13th European Conference on Machine Learning
#index379602


#*Expert systems at work
#@Mary Kroening
#t2000
#cPC AI
#index314435


#*Stereopsis Method for Visually Impaired to Identify Obstacles Based on Distance
#@G. Balakrishnan,G. Sainarayanan,R. Nagarajan,Sazali Yaacob
#t2004
#cProceedings of the Third International Conference on Image and Graphics
#index102006
#!Identification of obstacles in the real time environment is idempotent for human blind to navigate freely without collision. This paper describes a methodology that is required to support the blind to discriminate obstacles based on their distance. The hardware part consists of a sunglass fitted with two mini cameras, laptop computer and stereo earphones. The two cameras capture the visual information infront of blind user. The captured images are then processed using the proposed methodology. The methodology includes image processing module, which isolate objects from the two camera images, and stereo vision module calculates distance through disparity. In the proposed algorithm disparity is obtained with less computation compared to conventional area based stereo correspondence method. Experimentations were conducted in indoor environment, and the results obtained are supportable.


#*Choose Your Words Carefully: An Empirical Study of Feature Selection Metrics for Text Classification
#@George Forman
#t2002
#cProceedings of the 6th European Conference on Principles of Data Mining and Knowledge Discovery
#index383490


#*Eye communication in a conversational 3D synthetic agent
#@Isabella Poggi,Catherine Pelachaud,Fiorella De Rosis
#t2000
#cAI Communications
#index8543
#%605480
#%293471
#%288088
#%224037
#%297962
#%155311
#%181385
#%212285
#%214359
#%192840
#%283233
#!Our goal is to create an &lsquo;intelligent&rsquo; 3D agent able to send complex, &lsquo;natural&rsquo; messages to users and, in the future, to converse with them. We look at the relationship between the agent's communicative intentions and the way that these intentions are expressed into verbal and nonverbal messages. In this paper, we concentrate on the study and generation of coordinated linguistic and gaze communicative acts. In this view we analyse gaze signals according to their functional meaning rather than to their physical actions. We propose a formalism where a communicative act is represented by two elements: a meaning (that corresponds to a set of goals and beliefs that the agent has the purpose to transmit to the interlocutor) and a signal, that is the nonverbal expression of that meaning. We also outline a methodology to generate messages that coordinate verbal with nonverbal signals.


#*On the Efficiency of Nearest Neighbor Searching with Data Clustered in Lower Dimensions
#@Songrit Maneewongvatana,David M. Mount
#t2001
#cProceedings of the International Conference on Computational Sciences-Part I
#index562110


#*StatCache: a probabilistic approach to efficient and accurate data locality analysis
#@E. Berg,E. Hagersten
#t2004
#cProceedings of the 2004 IEEE International Symposium on Performance Analysis of Systems and Software
#index20727
#!The widening memory gap reduces performance of applications with poor data locality. Therefore, there is a need for methods to analyze data locality and help application optimization. In this paper we present StatCache, a novel sampling-based method for performing data-locality analysis on realistic workloads. StatCache is based on a probabilistic model of the cache, rather than a functional cache simulator. It uses statistics from a single run to accurately estimate miss ratios of fully-associative caches of arbitrary sizes and generate working-set graphs. We evaluate StatCache using the SPEC CPU2000 benchmarks and show that StatCache gives accurate results with a sampling rate as low as 10/sup -4/. We also provide a proof-of-concept implementation, and discuss potentially very fast implementation alternatives.


#*Permanental ideals
#@Reinhard C. Laubenbacher,Irena Swanson
#t2000
#cJournal of Symbolic Computation
#index333691


#*Trellis-coded differential unitary space-time modulation: performance analysis and design criteria
#@Zhenyu Sun
#t2002
#cProceedings of the The 8th International Conference on Communication Systems - Volume 01
#index430686
#!In this paper, we propose the trellis coded differential unitary space-time modulation (TC-DUSTM) and present the derivation of the formulae of the pairwise error-event probability (PEP) and the bit error probability (BEP) for this scheme. We found that in a multi-input multi-output (MIMO) system with M transmit and N receive antennas, apart from the diversity gain of MN, a coding gain of l/sub min/ is also obtained for the TC-DUSTM, where l/sub min/ is the length of the shortest error event. Additional coding gain comes from the product of the dissimilarities along the path of the shortest error event. These performance analyses suggest design criteria for the TC-DUSTM to obtain a best BEP performance. Through simulations we show that these analyses are accurate, especially at high signal-to-noise ratio (SNR). The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Business Information Technology Management: Alternative and Adaptive Futures, 1st edition
#@Ray Hackney,Dennis Dunn
#t2000
#c
#index248675
#!:Business Information Technology ManagementBITMis classified as a range of systems which are enabled by technologies that support decision making for improved business performance. This book explores BITM through a collection of contemporary topics in the field.Author Biography: Ray Hackney and Dennis Dunn are at Manchester Metropolitan University.


#*Transdisciplinary Visualization Techniques
#@Staff
#t2004
#cJournal of Visualization
#index401389


#*An exploration of bugs and debugging in multi-agent systems
#@David Poutakidis,Lin Padgham,Michael Winikoff
#t2003
#cProceedings of the second international joint conference on Autonomous agents and multiagent systems
#index118585
#!Debugging multi-agent systems, which are concurrent, distributed, and consist of complex components, is difficult, yet crucial. In earlier work we have proposed mechanisms whereby protocol specifications available from the design process can be used for monitoring the execution of the multi-agent system they describe. Protocol specifications can be used at run time for reporting any discrepancies in interactions compared to that which was specified. In this paper we describe and categorise a range of bugs found in actual multi-agent systems developed by students in an Agent Oriented Programming and Design class. We then indicate how these bugs manifest to the debugging agent and what information it is able to provide to the user to assist in locating and diagnosing the problem.


#*Analysis of Binary Adjustment Algorithms in Fair Heterogeneous Networks
#@Sergey Gorinsky,Harrick Vin
#t2001
#c
#index185849
#!Many congestion control schemes rely on binary notifications of congestion from the network: on detecting network congestion, they reduce transmission rates; and on receiving a signal indicating no congestion, they increase transmission rates. For conventional networks with First-In First-Out (FIFO) scheduling of packets, the effectiveness of such algorithms has been evaluated with respect to their responsiveness, smoothness, and fairness properties. Recently, it has been argued that it is possible to design high-speed network routers that can guarantee fair allocation of link capacities and buffers. In networks that employ such routers, fairness is ensured by the routers, thereby making responsiveness and smoothness the two main criteria for evaluating and selecting a binary adjustment algorithm. In this paper, we consider binary adjustment algorithms with four increase policies proposed in the literature: multiplicative increase (MI), additive increase (AI), inverse-square-root increase (ISI), and inverse increase (II). We analyze these algorithms in fair heterogeneous networks. We find that the multiplicative increase policy, which is considered inappropriate for conventional networks due to its fairness property, provides superior performance over the other policies in fair networks.


#*Business Planning for Network Services: A Systems Thinking Approach
#@Amitava Dutta
#t2001
#cInformation Systems Research
#index573046
#!As demand for online network services continues to grow, service providers are looking to meet this need and avail themselves of business opportunities. However, despite strong growth in demand, providers continue to have difficulty achieving profitability, customer churn remains high, and network performance continues to draw complaints. We suggest that strategic business planning for network services would benefit from a systems thinking approach that analyzes thefeedback effects present in the underlying business process. These feedback loops can be complex and have significant impact on business performance. For instance, while the size of a provider's customer base depends on price and network performance, network performance is itself dependent on the size of the customer base. In this paper, we develop a planning model that represents thesefeedback effects using the finite difference equations methodology of systems dynamics. The model is validated by showing its fit with essential characteristics of the underlying problem domain, and by showing its ability to replicate observed reference mode behaviors. Simulations are then carried out under a variety of scenarios to examine issues important to service providers. Among other findings, the simulations suggest that (a) under flat-rate pricing, lowering price to increase customer base can hurt profitabilityas well as network performance; (b) under usage-based pricing, lowering price need not necessarily lead to a larger customer base; and Â© in addition to price, the customers' threshold of tolerance for performance degradation plays a significant role in balancing market share with profitability. We briefly present a prototype decision support system based on the systems thinking approach, and suggest ways in which it could be used to help business planning for network services.


#*Database Development For Dummies
#@Allen G. Taylor
#t2000
#c
#index624313
#!:Database Development For Dummies is a prequel to SQL for Dummies, which is used in many college database courses across the country. Database Development For Dummies tells why and how database systems came into being, then using actual examples, describes the many obstacles to success that frequently arise in database development projects, and how to handle them. The key to successful database development is accurate and appropriate modeling of the real-world system that will be placed on the computer. Database Development For Dummies describes in detail two popular modeling methods, the entity-relationship model and the semantic object model. Once the model of a system is complete, the book describes how to convert the model into a database design, then implement the model on the target platform. Database on intranets and the Internet is covered, as are the issues that arise when multiple users simultaneously access the same database. A chapter is devoted to the emerging enterprise database market, including data warehousing. Another chapter covers the new object-relational technology.


#*Mathematical Assessment of Object-Oriented Design Quality
#@Alexander Chatzigeorgiou
#t2003
#cIEEE Transactions on Software Engineering
#index304180
#%288304
#%621109
#%326844
#!A method of link analysis employed for retrieving information from the Web is extended in order to evaluate one aspect of quality in an object-oriented model. The principal eigenvectors of matrices derived from the adjacency matrix of a modified class diagram are used to identify and quantify heavily loaded portions of an object-oriented design that deviate from the principle of distributed responsibilities.


#*Multimodal system processing in mobile environments
#@Sharon Oviatt
#t2000
#cProceedings of the 13th annual ACM symposium on User interface software and technology
#index330624
#%81026
#%286846
#%299207
#%606084
#%513885


#*On-line test for fault-secure fault identification
#@Samuel N. Hamilton,Alex Orailoğlu
#t2000
#cIEEE Transactions on Very Large Scale Integration (VLSI) Systems
#index334013


#*The application of a knowledge based engineering approach to the rapid design and analysis of an automotive structure
#@Craig B. Chapman,Martyn Pinfold
#t2001
#cAdvances in Engineering Software
#index246682


#*Blind source separation combining frequency-domain ICA and beamforming
#@H. Saruwatari
#t2001
#cProceedings of the Acoustics, Speech, and Signal Processing, 2001. on IEEE International Conference - Volume 05
#index430864
#!We describe a new method of blind source separation (BSS) on a microphone array combining subband independent component analysis (ICA) and beamforming. The proposed array system consists of the following three sections: (1) subband-ICA-based BSS section with direction-of-arrival (DOA) estimation; (2) null beamforming section based on the estimated DOA information; and (3) integration of (1) and (2) based on the algorithm diversity. Using this technique, we can resolve the low-convergence problem through optimization in ICA. The results of the signal separation experiments reveal that a noise reduction rate (NRR) of about 18 dB is obtained under the nonreverberant condition, and NRR of 8 dB and 6 dB are obtained in the case that the reverberation times are 150 msec and 300 msec. These performances are superior to those of both simple ICA-based BSS and simple beamforming method.


#*MCSE: Windows 2000 Network Infrastructure Administration Study Guide, 2nd edition
#@Michael Chacon,James Chellis
#t2001
#c
#index239262
#!:Here's the book you need to prepare for Exam 70-216, Implementing and Administering a Microsoft Windows 2000 Network Infrastructure. This study guide provides: * In-depth coverage of every exam objective-all the information you need * Practical information on managing a Windows 2000 network infrastructure * Hundreds of challenging review questions, in the book and on the CD * Leading-edge exam preparation software, including a testing engine and electronic flashcards Authoritative coverage of all exam objectives, including: * DNS in a Windows 2000 network infrastructure * DHCP in a Windows 2000 network infrastructure * Remote access in a Windows 2000 network infrastructure * Network protocols in a Windows 2000 network infrastructure * WINS in a Windows 2000 network infrastructure * IP routing in a Windows 2000 network infrastructure * Certificate Services CD Description The enclosed CD is packed with vital preparation tools and materials, beginning with the Sybex EdgeTest testing engine for the Windows 2000 Network Infrastructure Administration exam. Loaded with hundreds of practice questions, the CD lets you test yourself chapter by chapter or according to objective areas. You'll also find electronic flashcards for your PC and Palm devices, two bonus exams that will help you ready yourself for the test, WinSim 2000 product simulation software, and a fully searchable electronic version of this book and the Dictionary of Networking..


#*Microsensors, Mems and Smart Devices
#@Julian W. Gardner,Vijay K. Varadan
#t2001
#c
#index248135
#!:From the electronic nose and the intelligent ear to the modern ink jet nozzle, the applications of smart devices incorporating microsensors are increasing rapidly. Microsensors are miniature devices that convert a non-electrical quantity into an electrical signal. By integrating a microsensor with a microprocessor, a smart sensor is produced. Further integration with a microactuator produces a microsystem with multifunctional electrical and mechanical components known as micro-electrical mechanical systems (MEMS).


#*Understanding operating systems (3rd ed.)
#@Ida M. Flynn,Ann McIver McHoes
#t2001
#c
#index318979


#*Approximate Gradient Methods in Policy-Space Optimization of Markov Reward Processes
#@Peter Marbach,John N. Tsitsiklis
#t2003
#cDiscrete Event Dynamic Systems
#index449846
#%361966
#%616379
#%540167
#!We consider a discrete time, finite state Markov reward process that depends on a set of parameters. We start with a brief review of (stochastic) gradient descent methods that tune the parameters in order to optimize the average reward, using a single (possibly simulated) sample path of the process of interest. The resulting algorithms can be implemented online, and have the property that the gradient of the average reward converges to zero with probability 1. On the other hand, the updates can have a high variance, resulting in slow convergence. We address this issue and propose two approaches to reduce the variance. These approaches rely on approximate gradient formulas, which introduce an additional bias into the update direction. We derive bounds for the resulting bias terms and characterize the asymptotic behavior of the resulting algorithms. For one of the approaches considered, the magnitude of the bias term exhibits an interesting dependence on the time it takes for the rewards to reach steady-state. We also apply the methodology to Markov reward processes with a reward-free termination state, and an expected total reward criterion. We use a call admission control problem to illustrate the performance of the proposed algorithms.


#*Design and Implementation of an Application Layer Protocol for Reducing UDP Traffic Based on User Hints and Policies
#@William Kulju,Hanan Lutfiyya
#t2002
#cProceedings of the 5th IFIP/IEEE International Conference on Management of Multimedia Networks and Services: Management of Multimedia on the Internet
#index362416


#*Essential ASP for Web Professionals
#@Elijah P. Lovejoy
#t2000
#c
#index619166
#!: Get results from ASP with server-side JavaScript-today! Learn from practical real-world examples with downloadable reusable code Key techniques-quick, clear, and handy! Build shopping carts, guest books, and other applications Database integration, e-mail processing, and much more This compact, example-rich guide teaches Web developers exactly what they need to know to build great dynamic sites and applications with Microsoft's ASP and JavaScript, the world's #1 Web scripting language. Endorsed by the World Organization of Webmasters, Essential ASP for Web Professionals offers no-nonsense, practical coverage built around real-world examples on a live sample Web site. Every chapter includes real-world overviews of key ASP and JavaScript features, reinforcing what you've learned and demonstrating how to adapt it quickly to your own applications. From the basics of embedding ASP code in HTML pages to full-blown database application development, this book delivers practical answers, usable code, and real solutionsfast! Use ASP and JavaScript to do all this, and more! Deliver dynamic content on any Web or intranet site Create database applications that publish content and enable users to edit it Build shopping carts, guest books, and other applications Send e-mail automatically from your Web pages Embed dates and other variable data in your pages Request and check user passwords Look to Essential Books for ALL the Web Skills You Need! All these books share the same great format and similar Web sites containing downloadablecode-so once you've used one, learning from the others is a piece of cake! Essential CSS and DHTML for Web Programmers Essential Flash 4 for Web Programmers Essential Perl 5 for Web Professionals Essential Photoshop for Web Designers Essential JavaScript for Web Programmers Essential PHP for Web Professionals Essential Flash 5 for Web Professionals, Essential Design for Web Professionals, and more coming soon!


#*A simplified EM algorithm for detection of CPM signals in a fading multipath channel
#@Linda M. Zeger,Hisashi Kobayashi
#t2002
#cWireless Networks
#index439923
#!Application of the EM (Expectation-Maximization) algorithm to sequence estimation in an unknown channel can in principle produce MLSE (maximum likelihood sequence estimates) that are not dependent on a particular channel estimate. The Expectation step of this algorithm cannot be directly performed for continuous phase modulated (CPM) signals transmitted in a time varying multipath channel. We therefore derive a simplification of the EM algorithm for CPM signals in this channel. Simulations applied to the Global System for Mobile Communications (GSM) show that the simplified EM algorithm significantly decreases the amount of training data needed for the channel model considered, and removes the majority of the bit errors that are due to imperfect knowledge of the channel.


#*Concepts and Technologies for a Worldwide Grid Infrastructure
#@Alexander Reinefeld,Florian Schintke
#t2002
#cProceedings of the 8th International Euro-Par Conference on Parallel Processing
#index258203


#*Algorithm to extract two-node bridges
#@Sujit Thomas Zachariah,Sreejit Chakravarty
#t2003
#cIEEE Transactions on Very Large Scale Integration (VLSI) Systems
#index308969
#%85593
#%144427
#%163009
#!Current bridge fault extraction techniques are limited by performance and capacity constraints. In this paper, we present a fast and accurate algorithm to extract and rank two-node bridges based on the computation of their weighted critical area. Experimental results showing the algorithm's performance are presented.


#*An exact parametric solution for granular flow in a converging wedge
#@James M. Hill,Grant M. Cox
#t2001
#cZeitschrift f&uuml;r Angewandte Mathematik und Physik (ZAMP)
#index239097


#*Exception handling for a 21st century programming language proceedings
#@
#t2001
#cACM SIGAda Ada Letters
#index237929


#*A Grammar Based Model for XML Schema Integration
#@Ralf Behrens
#t2000
#cProceedings of the 17th British National Conferenc on Databases: Advances in Databases
#index362365


#*Havi Example by Example: Java Programming for Home Entertainment Devices
#@Rodger Lea,Simon Gibbs,Ravi Gauba,Ram Balaraman
#t2001
#c
#index230997
#!From the Book:PrefaceWhat Is HAVi?HAViHome Audio-Video Interoperabilityis a system architecture for the development of home network applications. The HAVi architecture is specified by an organization of consumer electronics and software companies. For HAVi, a home network is a group of connected AV (audio-video) devices within a home. This is sometimes called a home entertainment network or an AV cluster. Devices compliant with the HAVi specification implement a set of system services that allow them to interoperate over IEEE 1394 connections. IEEE 1394, also known as FireWire and i.LINK, is a high-speed serial bus used to connect devices into tree-shaped networks. HAVi specifies services to locate, query, control, and extend IEEE 1394 audio-video devices.Who This Book Is ForThis book is intended primarily for developers with an interest in home entertainment devices and services. Others who may find the book of interest include those studying networking and distributed systems, and designers of audio-video products. Basic knowledge of Java is useful, but some familiarity with programming is all that is needed to follow many of the examples.Programming AidsThe HAVi by Example Web site is located at www.vividlogic.com/hbx. At this Web site you can find: JavaDoc for HJA 1.1 source code examples, and HAVi 1.1 SDK (Software Developers Kit).To run the SDK you will need a Pentium-class PC with Linux 2.4.1 or later (this version of Linux has IEEE 1394 support), a JVM, and JDK 1.1.8 or later. If you want to control HAVi devices, you will need anIEEE 1394 port on your PC. See www.vividlogic.com/hbx/releaseNotes.txt for a list of supported IEEE 1394 cards.


#*Data Structures for Minimization of Total Within-Group Distance for Spatio-temporal Clustering
#@Vladimir Estivill-Castro,Michael E. Houle
#t2001
#cProceedings of the 5th European Conference on Principles of Data Mining and Knowledge Discovery
#index571814


#*Windows 2000: The Complete Reference, 1st edition
#@Kathy Ivens,Kenton Gardinier
#t2000
#c
#index255141
#!:The Ultimate Guide to Microsoft's Revolutionary New Operating System. Take full advantage of all the powerful features Windows 2000 has to offer. Windows 2000: The Complete Reference deconstructs the intricate architecture of the Os,explaining what each of the elements do and how they intereact. You'll learn to handle all kinds of tasks - from configuring computers,to managing users,to designing your Active Directory. Written by Windows NT/2000 experts,this is your all-in-one resource on Microsoft's innovative new operating system.


#*Multistrategy Ensemble Learning: Reducing Error by Combining Ensemble Learning Techniques
#@Geoffrey I. Webb
#t2004
#cIEEE Transactions on Knowledge and Data Engineering
#index437354
#%94584
#%196474
#%214951
#%313960
#%324647
#%364874
#%601824
#%565877
#!Ensemble learning strategies, especially Boosting and Bagging decision trees, have demonstrated impressive capacities to improve the prediction accuracy of base learning algorithms. Further gains have been demonstrated by strategies that combine simple ensemble formation approaches. In this paper, we investigate the hypothesis that the improvement in accuracy of multistrategy approaches to ensemble learning is due to an increase in the diversity of ensemble members that are formed. In addition, guided by this hypothesis, we develop three new multistrategy ensemble learning techniques. Experimental results in a wide variety of natural domains suggest that these multistrategy ensemble learning techniques are, on average, more accurate than their component ensemble learning techniques.


#*Some Parallel Monte Carlo Algorithms
#@G. A. Mikhailov
#t2001
#cProceedings of the 6th International Conference on Parallel Computing Technologies
#index365985


#*Real-Time Face Tracking under Partial Occlusion and Illumination Change
#@Zhihong Zeng,Songde Ma
#t2000
#cProceedings of the Third International Conference on Advances in Multimodal Interfaces
#index382794


#*System of thermal simulation of the flip chip (abstract only)
#@Dmytro Fedasyuk,Evgenia Levus,Juriy Nazar
#t2000
#cProceedings of the symposium on Contemporary computing in Ukraine
#index319003
#!Thermal three-dimensional model built is based on formalisation of conjugate problem of heat exchange in die and substrate with various boundary conditions. Distributed software system developed on the basis of analytical solution of the physical-mathematical problem has been used for the computations. For decreasing of the calculation time the method for parallel processing has been developed. Brought the results of application.


#*Suffix vector: space- and time-efficient alternative to suffix trees
#@Krisztián Monostori,Arkady Zaslavsky,Heinz Schmidt
#t2002
#cAustralian Computer Science Communications
#index232963
#%75231
#%217448
#%222206
#%296895
#%283089
#!Suffix trees are versatile data structures that are used for solving many string-matching problems. One of the main arguments against widespread usage of the structure is its space requirement. This paper describes a new structure called suffix vector, which is not only better in terms of storage space but also simpler than the most efficient suffix tree representation known to date. Alternatives of storage representations are discussed and a linear-time construction algorithm is also proposed in this paper. Space requirement of the suffix vector structure is compared to the space requirement of alternative suffix tree representations. We also make a theoretical comparison on the number of operations required to run algorithms on the suffix vector.


#*Just for Fun: The Story of an Accidental Revolutionary
#@Linus Torvalds,David Diamond
#t2001
#c
#index244284
#!:Ten years ago, college student Linus Torvalds retreated to his own computer to write code. He quips, "I couldn't afford software that I liked, so I wrote my own operating system." Not only did he write the operating system, he gave it away and invited other software engineers to improve it.The rest is history. Today, Torvalds has become the key figure in the open source software movement. The powerful operating system he wrote, Linux, has grown into a major force in the computer industry, while its voluntary development model has made Linux the world's largest collaborative project. Hundreds of the world's best engineers contribute to the improvement of Linux. Over 12 million machines, including many of the servers that power the World Wide Web, now run on Linux, as do the top-of-the-line offerings from such hardware giants as IBM and Compaq.Just for Fun chronicles Torvalds's amazing lifefrom his eccentric childhood in Finland, to his gangly, geeky teenage years when his greatest joy was writing programs on his grandfather's VIC-20 computer, to his rise to world-wide fame with Linux. Brimming with Torvalds's candid observations and opinions, this is a must-read for anyone who wants to know where high tech and business are going in the future.


#*Architectural bias in recurrent neural networks: fractal analysis
#@Peter Tiňo,Barbara Hammer
#t2003
#cNeural Computation
#index118058
#%95357
#%361141
#%623760
#%588926
#%222458
#%530339
#%600520
#!We have recently shown that when initialized with "small" weights, recurrent neural networks (RNNs) with standard sigmoid-type activation functions are inherently biased toward Markov models; even prior to any training, RNN dynamics can be readily used to extract finite memory machines (Hammer & Tino, 2002; Tino, Cernanský, & Benusková, 2002a, 2002b). Following Christiansen and Chater (1999), we refer to this phenomenon as the architectural bias of RNNs. In this article, we extend our work on the architectural bias in RNNs by performing a rigorous fractal analysis of recurrent activation patterns. We assume the network is driven by sequences obtained by traversing an underlying finite-state transition diagram--a scenario that has been frequently considered in the past, for example, when studying RNN-based learning and implementation of regular grammars and finite-state transducers. We obtain lower and upper bounds on various types of fractal dimensions, such as box counting and Hausdorff dimensions. It turns out that not only can the recurrent activations inside RNNs with small initial weights be explored to build Markovian predictive models, but also the activations form fractal clusters, the dimension of which can be bounded by the scaled entropy of the underlying driving source. The scaling factors are fixed and are given by the RNN parameters.


#*Fairness and Aggregation: A Primal Decomposition Study
#@André Girard,Catherine Rosenberg,Mohammed Khemiri
#t2000
#cProceedings of the IFIP-TC6 / European Commission International Conference on Broadband Communications, High Performance Networking, and Performance of Communication Networks
#index257031


#*Characterization of transient wandering tones by dynamic modeling of fractional-Fourier features
#@P. L. Ainsleigh
#t2000
#cProceedings of the Acoustics, Speech, and Signal Processing, 2000. on IEEE International Conference - Volume 02
#index422550
#!A novel approach is presented for characterizing transient wandering tones. These signals are segmented and approximated as time series with piecewise linear instantaneous frequency and piecewise constant amplitude. Frequency rate, center frequency, and energy features are estimated in each segment of data using chirped autocorrelations and the fractional Fourier transform. These features are tracked across segments using linear dynamical models whose parameters are estimated using an expectation-maximization algorithm. A new cross-covariance estimator for adjacent states of the dynamical model is given. The feature extraction/tracking algorithm is used to characterize a measured marine-mammal vocalization. Application of the representation algorithm to signal classification is discussed.


#*Appendix A - Run Statistics
#@
#t2000
#cRevised Papers from the Workshop of Cross-Language Evaluation Forum on Cross-Language Information Retrieval and Evaluation
#index561367


#*The Elements of User Interface Design, 2nd edition
#@Theo Mandel
#t2002
#c
#index236926
#!:With a Ph.D. in cognitive psychology, author Theo Mandel knows how people act and interact with user interfaces. With this book, he covers the basics of effective user interface design and demonstrates different techniques. Divided into three parts, the book first teaches readers the foundations and fundamentals, then shows them how to use those basics to create interfaces, and finally discusses advanced topics and emerging technologies like object oriented user interfaces (OOUIs), voice activation, and Wizards. Mandel also covers different techniques with popular products like Windows NT, Windows 95, OS/2, and Visual Basic. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Advanced eager scheduling for Java-based adaptively parallel computing
#@Michael O. Neary,Peter Cappello
#t2002
#cProceedings of the 2002 joint ACM-ISCOPE conference on Java Grande
#index244443
#%115769
#%608361
#%606718
#%620799
#%320755
#%567293
#%571470
#%285467
#%280227
#%611995
#!Javelin 3 is a software system for developing large-scale, fault tolerant, adaptively parallel applications. When all or part of their application can be cast as a master-worker or branch-and-bound computation, Javelin 3 frees application developers from concerns about inter-processor communication and fault tolerance among networked hosts, allowing them to focus on the underlying application. The paper describes a fault tolerant task scheduler and its performance analysis. The task scheduler integrates work stealing with an advanced form of eager scheduling. It enables dynamic task decomposition, which improves host load-balancing in the presence of tasks whose non-uniform computational load is evident only at execution time. Speedup measurements are presented of actual performance on up to 1,000 hosts. We analyze the expected performance degradation due to unresponsive hosts, and measure actual performance degradation due to unresponsive hosts.


#*A prototype multilingual document browser for ancient Greek texts
#@Jeffrey A. Rydberg-Cox
#t2002
#cThe New Review of Hypermedia and Multimedia
#index563620
#%80840
#%85946
#%280276
#%289425
#%319882
#%441843
#%451075
#%451404
#%529239
#%601965
#%603025
#%615072
#!This paper describes a prototype multilingual keyword extraction and information browsing system for texts written in Classical Greek. This system automatically extracts keywords from Greek texts using a tf x idf keyword discovery routine, clusters documents into thematically coherent groups based on these keywords, translates the keywords into English, and presents this information in two different formats so that users with limited knowledge of Ancient Greek can browse the documents and orient themselves to important concepts in the collections of a digital library.


#*Secrecy and Group Creation
#@Luca Cardelli,Giorgio Ghelli,Andrew D. Gordon
#t2000
#cProceedings of the 11th International Conference on Concurrency Theory
#index275445


#*An empirical evaluation of an adaptive web site
#@Cristina Gena
#t2002
#cProceedings of the 7th international conference on Intelligent user interfaces
#index618511
#!This paper describes the evaluation of an adaptive commercial web site offering a set of utilities tailored on the basis of user needs. We compared the site with the non-adaptive variant in order to study how the adaptivity increases the success in retrieving information and reduces the amount of actions needed to solve the tasks. Moreover, we considered the preference towards the two alternative versions and the user satisfaction.


#*Backtracking
#@Christopher Welty,Louis J. Hoebel
#t2000
#cintelligence
#index296760


#*Reliability Evaluation for Integrated Circuit with Defective Interconnect under Electromigration
#@Xiangdong Xuan,Adit D. Singh,Abhijit Chatterjee
#t2003
#cProceedings of the 4th International Symposium on Quality Electronic Design
#index122951
#!In electromigration degradation process the existingphysical defects on interconnect play a critical role bysignificantly accelerating the EM damage underincreased current density and elevated temperature. Inthis work the simulation models were upgraded in the ICreliability simulator ARET to incorporate the effect ofinterconnect physical defects in expected lifetimeprediction. Then based on the statistical approach, aprobability model was developed to evaluate the system-levelcircuit reliability with defective interconnect underEM degradation. The probability model has beensuccessfully implemented in ARET tool to simulate andevaluate both interconnect and circuit level reliabilities.


#*Multidimensional information visualizations for data mining
#@Patrick E. Hoffman,Georges G. Grinstein
#t2001
#cInformation visualization in data mining and knowledge discovery
#index317796


#*Perspectives on end user development
#@Henry Lieberman,Fabio Paternò,Alexander Repenning,Volker Wulf
#t2003
#cCHI '03 extended abstracts on Human factors in computing systems
#index563393
#!The goal of the workshop is to bring about a coherent research agenda in the field of end user development. We seek contributors concerned with: adaptability, adaptivity, tailoring of system functionality and user interfaces, the use of annotations for individuals and user groups, and use of effective visual and multimedia representations.


#*Client/server and the knowledge directory: a natural relationship
#@Stuart D. Galup,Ronald Dattero
#t2000
#cProceedings of the 2000 information resources management association international conference on Challenges of information technology management in the 21st century
#index313914


#*How do we implement the theory of CM in practice?
#@U. Nyman
#t2001
#cManaging the change: software configuration and change management
#index253461


#*Network Intrusion Detection: An Analyst's Handbook, 2nd edition
#@Stephen Northcutt,Judy Novak,Donald McLachlan
#t2000
#c
#index248306
#!:Written to be both a training aid and a technical reference for intrusion detection analysts, Northcutt's book contains practical experience that can't be found anywhere else. With detailed explanations and illustrative examples from his own career, Northcutt covers the topic completely, from detect evaluation, analysis, and situation handling, through the theories involved in understanding hackers, intelligence gathering, and coordinated attacks, to an arsenal of preventive and aggressive security measures.


#*Abstracting remote object interaction in a peer-2-peer environment
#@Patrick Thomas Eugster,Sebastien Baehni
#t2002
#cProceedings of the 2002 joint ACM-ISCOPE conference on Java Grande
#index241058
#%91278
#%119290
#%211250
#%230455
#%238030
#%240258
#%287260
#%286615
#%374306
#%617071
#%286262
#%333214
#!Leveraged by the success of applications aiming at the "free" sharing of data in the Internet, the paradigm of peer-to-peer (P2P) computing has been devoted substantial consideration recently.This paper presents an abstraction for remote object interaction in a P2P environment, called borrow/lend (BL). We present the principles underlying our BL abstraction, and its implementation in Java. We contrast our abstraction with established abstractions for distributed programming such as the remote method invocation or the tuple space, illustrating how the BL abstraction, obviously influenced by such predating abstractions, unifies flavors of these, but also how it captures the constraints specific to P2P environments.


#*Mechatronic systems techniques and applications (vol. 1): industrial manufacturing
#@Cornelius T. Leondes
#t2000
#c
#index317535


#*Temporal granulation and its application to signal analysis
#@Witold Pedrycz,Adam Gacek
#t2002
#cInformation Sciences&mdash;Informatics and Computer Science: An International Journal
#index560117
#%158575
#%169624
#%180363
#%331917
#%467562
#%613656
#%614673
#%617697
#!In this study, we elaborate on the role of information granulation and the ensuing information granules in description of time series and signal analysis, in general. Information granules are entities of elements (quite commonly, numeric data) that are combined together (aggregated) owing to their vicinity, similarity and alike. Proceeding with a given window of granulation (that is an initial collection of numeric data), we propose an algorithm that produces a complete information granule - fuzzy set. The principle supported by the method leads to the formation of fuzzy sets that are legitimate in terms of experimental data being at the same time maximized with regard to their specificity (compactness). It has been shown that information granules can be are regarded as generic conceptual entities contributing to the description of numeric time series. In this capacity, they are used as building blocks aimed at achieving high level, compact, and comprehensible models of signals. More importantly, the phase of information granulation could be viewed as a prerequisite to more synthetic and abstract processing such as the one witnessed in syntactic pattern recognition.


#*Teaching computer security at a small college
#@Cathie LeBlanc,Evelyn Stiller
#t2004
#cACM SIGCSE Bulletin
#index306011
#%240144
#%288893
#%448624
#!Computer and network security are important topics for computer professionals in US companies today. An adequate education in these topics would probably involve several classes at the undergraduate level but many computer science curricula do not have room to have numerous required courses. In addition, most computer science faculty members have not taken classes covering these topics and have never worked as professionals dealing with these areas. Dealing with these difficult issues can be a challenge, especially in a small college environment. In this paper, we present our experiences teaching computer security topics in both a system administration course and a computer security course.


#*Symbolic transfer function-based approaches to certified compilation
#@Xavier Rival
#t2004
#cACM SIGPLAN Notices
#index309627
#%123902
#%248919
#%534542
#%607502
#!We present a framework for the certification of compilation and of compiled programs. Our approach uses a symbolic transfer functions-based representation of programs, so as to check that source and compiled programs present similar behaviors. This checking can be done either for a concrete semantic interpretation (Translation Validation) or for an abstract semantic interpretation (Invariant Translation) of the symbolic transfer functions. We propose to design a checking procedure at the concrete level in order to validate both the transformation and the translation of abstract invariants. The use of symbolic transfer functions makes possible a better treatment of compiler optimizations and is adapted to the checking of precise invariants at the assembly level. The approach proved successful in the implementation point of view, since it rendered the translation of very precise invariants on very large assembly programs feasible.


#*Presentations for Abstract Context Institutions
#@Wieslaw Pawlowski
#t2001
#cSelected papers from the 15th International Workshop on Recent Trends in Algebraic Development Techniques
#index359616


#*Security Aspects of Internet Voting
#@Guido Schryen
#t2004
#cProceedings of the Proceedings of the 37th Annual Hawaii International Conference on System Sciences (HICSS'04) - Track 5 - Volume 5
#index309697
#!Voting via the Internet has become a feasible option for political as well as non-political ballots. However, there are many obstacles which have to be overcome, especially legal restrictions have to be transformed into technical and security solutions. The article starts with a briefpresentation of advantages and disadvantages of Internet ballots and presents application fields and pilot schemes. Then, technological security aspects are derived due to democratic basic principles. Especially the applied voting procedures are critical in security terms. Hence, the most relevant cryptographic protocols are presented and their drawbacks and shortcomings are identified. However, this article does not propose a new voting protocol. Beyond fixing cryptographic procedures for ballots, more elements are to be specified, e.g. responsibilities and rights of involved authorities or security precautions regarding hardware and software. For this reason, a structural security framework for electronic voting systems is presented which can be used for their composition and analysis.


#*Throughput analysis of IEEE 802.11e EDCA under heterogeneous traffic
#@Shih-Wei Pan,Jung-Shyr Wu
#t2009
#cComputer Communications
#index56614
#%330780
#%247406
#!The amended version of IEEE 802.11e defines the enhanced distributed channel access (EDCA) for quality of service (QoS) connections. EDCA provides a priority scheme to classify different traffic categories by the arbitration inter-frame space (AIFS), and the initial and maximum contention window sizes. Most previous Markov chain analyses of EDCA have concentrated on the effect of contention window size, they neglected the effect of AIFS. In this paper, we consider of AIFS events among each back-off procedure and evaluate the saturation throughput of the IEEE 802.11e EDCA under heterogeneous traffic scenarios. The analytical model is based on the differentiated AIFS and uses the discrete time slot to analyses the external collision time. We take advantage of extensive simulation studies to validate the accuracy of the proposed model. Our models accurately estimate the effects of varied back-off window size and AIFS under heterogeneous traffic.


#*Becoming Virtual: Knowledge Management and Transformation of the Distributed Organization, 1st edition
#@Jane E. Klobas,Paul D. Jackson
#t2007
#cContributions To Management Science
#index126797
#!This book examines the capabilities needed to transform a globally distributed organization into a virtual organization (an organization that exists and operates across time and distance with the support of global communications technologies such as the Internet). It introduces techniques for definition of goals for virtualization, for monitoring progress toward virtualization and for studying the impact of virtualization on social uncertainty, knowledge sharing and knowledge transfer, organizational memory, transactive memory, communities of practice and organizational commitment, power and control. These techniques are applied in an extended case study of a development aid organization's attempts to use knowledge management for virtualization over a two year period. The multidisciplinary team of authors examines virtualization from points of view ranging from the organizational to the technological to the sociological and psychological.


#*Graph Models for Complex Networks
#@
#t2009
#cProceedings of the 6th International Workshop on Algorithms and Models for the Web-Graph
#index60222


#*Regulating air traffic flow with coupled agents
#@Adrian Agogino,Kagan Tumer
#t2008
#cProceedings of the 7th international joint conference on Autonomous agents and multiagent systems - Volume 2
#index396254
#%30500
#%231782
#!The ability to provide flexible, automated management of air traffic is critical to meeting the ever increasing needs of the next generation air transportation systems. This problem is particularly complex as it requires the integration of many factors including, updated information (e.g., changing weather info), conflicting priorities (e.g., different airlines), limited resources (e.g., air traffic controllers) and very heavy traffic volume (e.g., over 40,000 daily flights over the US airspace). Furthermore, because the Federal Flight Administration will not accept black-box solutions, algorithmic improvements need to be consistent with current operating practices and provide explanations for each new decision. Unfortunately current methods provide neither flexibility for future upgrades, nor high enough performance in complex coupled air traffic flow problems. This paper extends agent-based methods for controlling air traffic flow to more realistic domains that have coupled flow patterns and need to be controlled through a variety of mechanisms. First, we explore an agent control structure that allows agents to control air traffic flow through one of three mechanisms (miles in trail, ground delays and rerouting). Second, we explore a new agent learning algorithm that can efficiently handle coupled flow patterns. We then test this agent solution on a series of congestion problems, showing that it is flexible enough to achieve high performance with different control mechanisms. In addition the results show that the new solution is able to achieve up to a 20% increase in performance over previous methods that did not account for the agent coupling.


#*Photoshop Elements 3: Diseno Y Creatividad
#@
#t2005
#c
#index15374


#*Virtualization Technologies in the Undergraduate IT Curriculum
#@Alessio Gaspar,Sarah Langevin,William D. Armitage
#t2007
#cIT Professional
#index336781
#!A Linux-based virtualization solution for IT courses leverages an open source approach for a low-cost, scalable cluster. The tool is suited for student home use for OS and networking lab assignments


#*Design and Implementation of Floating Point Stack on General RISC Architecture
#@Xuehai Qian,He Huang,Hao Zhang,Guoping Long,Junchao Zhang,Dongrui Fan
#t2007
#cProceedings of the 15th Euromicro International Conference on Parallel, Distributed and Network-Based Processing
#index417784
#!This paper presents a framework for implementing the X86 FP stack used in an x86-compliant processor based on a general RISC architecture. Architectural supports are added to a typical RISC architecture to maintain the FP stack status. Some speculative techniques are applied to the decode stage to enable pipelined and efficient FP operations. An optimized register renaming scheme is proposed to eliminate redundant micro-ops in FP programs, resulting in an increased performance while mitigating the burden on register rename table. The simulation results show that on average more than 10% fmov micro-ops are removed. Elimination of micro-ops significantly speeds up the execution of programs. The IPC increases are as high as 30% for some programs, and near 10% on average.


#*MERO: A Statistical Approach for Hardware Trojan Detection
#@Rajat Subhra Chakraborty,Francis Wolff,Somnath Paul,Christos Papachristou,Swarup Bhunia
#t2009
#cProceedings of the 11th International Workshop on Cryptographic Hardware and Embedded Systems
#index498696
#!In order to ensure trusted in---field operation of integrated circuits, it is important to develop efficient low---cost techniques to detect malicious tampering (also referred to as Hardware Trojan) that causes undesired change in functional behavior. Conventional post--- manufacturing testing, test generation algorithms and test coverage metrics cannot be readily extended to hardware Trojan detection. In this paper, we propose a test pattern generation technique based on multiple excitation of rare logic conditions at internal nodes. Such a statistical approach maximizes the probability of inserted Trojans getting triggered and detected by logic testing, while drastically reducing the number of vectors compared to a weighted random pattern based test generation. Moreover, the proposed test generation approach can be effective towards increasing the sensitivity of Trojan detection in existing side---channel approaches that monitor the impact of a Trojan circuit on power or current signature. Simulation results for a set of ISCAS benchmarks show that the proposed test generation approach can achieve comparable or better Trojan detection coverage with about 85% reduction in test length on average over random patterns.


#*An upper bound for the restrained domination number of a graph with minimum degree at least two in terms of order and minimum degree
#@Johannes H. Hattingh,Ernst J. Joubert
#t2009
#cDiscrete Applied Mathematics
#index138875
#%85834
#%284517
#%299779
#%255256
#!Let G=(V,E) be a graph. A set S@?V is a restrained dominating set if every vertex in V-S is adjacent to a vertex in S and to a vertex in V-S. The restrained domination number of G, denoted @c"r(G), is the smallest cardinality of a restrained dominating set of G. We will show that if G is a connected graph of order n and minimum degree @d and not isomorphic to one of nine exceptional graphs, then @c"r(G)@?n-@d+12.


#*EASy-Producer - A Product Line Production Environment
#@Holger Eichelberger,Klaus Schmid
#t2008
#cProceedings of the 2008 12th International Software Product Line Conference
#index410555
#!In this paper, we describe EASy-producer, a prototypical production environment for software product lines (SPL), in particular for the realization of adaptive systems and dynamic SPL.


#*Software Studies: A Lexicon (Leonardo Books)
#@Matthew Fuller,Matthew Fuller
#t2008
#c
#index44296
#!This collection of short expository, critical, and speculative texts offers a field guide to the cultural, political, social, and aesthetic impact of software. Computing and digital media are essential to the way we work and live, and much has been said about their influence. But the very material of software has often been left invisible. In Software Studies, computer scientists, artists, designers, cultural theorists, programmers, and others from a range of disciplines each take on a key topic in the understanding of software and the work that surrounds it. These include algorithms; logical structures; ways of thinking and doing that leak out of the domain of logic and into everyday life; the value and aesthetic judgments built into computing; programming's own subcultures; and the tightly formulated building blocks that work to make, name, multiply, control, and interweave reality. The growing importance of software requires a new kind of cultural theory that can understand the politics of pixels or the poetry of a loop and engage in the microanalysis of everyday digital objects. The contributors to Software Studies are both literate in computing (and involved in some way in the production of software) and active in making and theorizing culture. Software Studies offers not only studies of software but proposes an agenda for a discipline that sees software as an object of study from new perspectives. Contributors: Alison Adam, Wilfried Hou Je Bek, Morten Breinbjerg, Ted Byfield, Wendy Hui Kyong Chun, Geoff Cox, Florian Cramer, Cecile Crutzen, Marco Deseriis, Ron Eglash, Matthew Fuller, Andrew Goffey, Steve Goodman, Olga Goriunova, Graham Harwood, Friedrich Kittler, Erna Kotkamp, Joasia Krysa, Adrian Mackenzie, Lev Manovich, Michael Mateas, Nick Montfort, Michael Murtaugh, Jussi Parikka, Sren Pold, Derek Robinson, Warren Sack, Grzesiek Sedek, Alexei Shulgin, Matti Tedre, Adrian Ward, Richard Wright, Simon Yuill.


#*Liposome logic
#@James Smaldon,Natalio Krasnogor,Cameron Alexander,Marian Gheorghe
#t2009
#cProceedings of the 11th Annual conference on Genetic and evolutionary computation
#index133419
#!VLSI research, in its continuous push toward further miniaturisation, is seeking to break through the limitations of current circuit manufacture techniques by moving towards biomimetic methodologies that rely on self-assembly, selforganisation and evodevo-like processes. On the other hand, Systems and Synthetic biology's quest to achieve ever more detailed (multi)cell models are relying more and more on concepts derived from computer science and engineering such as the use of logic gates, clocks and pulse generator analogs to describe a cell's decision making behavior. This paper is situated at the crossroad of these two enterprises. That is, a novel method of non-conventional computation based on the encapsulation of simple gene regulatory-like networks within liposomes is described. Three transcription Boolean logic gates were encapsulated and simulated within liposomes self-assembled from DMPC (dimyristoylphosphatidylcholine) amphiphiles using an implementation of Dissipative Particle Dynamics (DPD) created with the NVIDIA CUDA framework, and modified to include a simple collision chemistry in a stochastic environment. The response times of the AND, OR and NOT gates were shown to be positively effected by the encapsulation within the liposome inner volume.


#*A voice-to-MIDI system for singing melodies with lyrics
#@Naoki Itou,Kazushi Nishimoto
#t2007
#cProceedings of the international conference on Advances in computer entertainment technology
#index415768
#%287586
#!In this paper, we propose a robust Voice-to-MIDI (V to M) system with which a user can input MIDI sequence data by naturally singing melodies with lyrics. A Voice-to-MIDI system translates singing voices into digital musical data, i.e., MIDI sequence data. Therefore, with such a system, users can input melodies intuitively, which releases them from manual translating memorized melodies into chromatic pitches. However, the quality of translation of ordinary Voice-to-MIDI systems is insufficient. One of the most significant problems is the poor accuracy of the segmentation of notes. We solve this problem by employing "rhythmic tapping" concurrently with singing. We examined the proposed method by the accuracy of the numbers of segmented notes and their pitches. As a result, we confirmed that our system outperformed ordinary Voice-to-MIDI systems. Thus, this system satisfies both of easy and intuitive composition of MIDI sequence data and high accuracy of translation of sung data into MIDI sequence data.


#*Constraining and summarizing association rules in medical data
#@Carlos Ordonez,Norberto Ezquerra,Cesar A. Santana
#t2006
#cKnowledge and Information Systems
#index22754
#%207703
#%362949
#%296403
#%567687
#%81883
#%303155
#%316933
#%371632
#%282384
#%377732
#%294858
#%382686
#%375365
#%475952
#%382861
#%372632
#%236212
#%362734
#%382198
#%305856
#%383469
#%604193
#!Association rules are a data mining technique used to discover frequent patterns in a data set. In this work, association rules are used in the medical domain, where data sets are generally high dimensional and small. The chief disadvantage about mining association rules in a high dimensional data set is the huge number of patterns that are discovered, most of which are irrelevant or redundant. Several constraints are proposed for filtering purposes, since our aim is to discover only significant association rules and accelerate the search process. A greedy algorithm is introduced to compute rule covers in order to summarize rules having the same consequent. The significance of association rules is evaluated using three metrics: support, confidence and lift. Experiments focus on discovering association rules on a real data set to predict absence or existence of heart disease. Constraints are shown to significantly reduce the number of discovered rules and improve running time. Rule covers summarize a large number of rules by producing a succinct set of rules with high-quality metrics.


#*The case for Byzantine fault detection
#@Andreas Haeberlen,Petr Kouznetsov,Peter Druschel
#t2006
#cProceedings of the 2nd conference on Hot Topics in System Dependability - Volume 2
#index423933
#%151253
#%160896
#%265888
#%320284
#%622614
#%584581


#*Experimental evaluation of horizontal and vertical scalability of cluster-based application servers for transactional workloads
#@Daniel F. Garcia,Rodrigo Garcia,Joaquín Entrialgo,Javier Garcia,Manuel Garcia
#t2008
#cProceedings of the 8th conference on Applied informatics and communications
#index70110
#%529634
#!The scalability of the application servers is an essential issue to guarantee the quality of the services provided by any company that sell its products and services through Internet in business-to-business (B2B) environments. This paper deals with the selection of a proper transactional load to evaluate the scalability, in order to obtain representative results that can provide useful insights for a large range of transactional applications. This evaluation work compares the scalability and other related performance metrics when an application server cluster is scaled horizontally, adding new servers, and when it is scaled vertically, adding cores into the servers. Multiple issues related with the proper experimental design to carry out an evaluation work of these characteristics are also presented in this paper. Finally, it is important to remark that there are few works in the literature concerning the scalability evaluation of transactional systems, in spite of the critical importance of the scalability in this kind of systems.


#*Normalization enables robust validation of disparity estimates from neural populations
#@Eric K. C. Tsang,Bertram E. Shi
#t2008
#cNeural Computation
#index400727
#!Binocular fusion takes place over a limited region smaller than one degree of visual angle (Panum's fusional area), which is on the order of the range of preferred disparities measured in populations of disparity-tuned neurons in the visual cortex. However, the actual range of binocular disparities encountered in natural scenes extends over tens of degrees. This discrepancy suggests that there must be a mechanism for detecting whether the stimulus disparity is inside or outside the range of the preferred disparities in the population. Here, we compare the efficacy of several features derived from the population responses of phase-tuned disparity energy neurons in differentiating between in-range and out-of-range disparities. Interestingly, some features that might be appealing at first glance, such as the average activation across the population and the difference between the peak and average responses, actually perform poorly. On the other hand, normalizing the difference between the peak and average responses results in a reliable indicator. Using a probabilistic model of the population responses, we improve classification accuracy by combining multiple features. A decision rule that combines the normalized peak to average difference and the peak location significantly improves performance over decision rules based on either measure in isolation. In addition, classifiers using normalized difference are also robust to mismatch between the image statistics assumed by the model and the actual image statistics.


#*Automated Detection of Optic Disc Location in Retinal Images
#@Carmen Alina Lupascu,Domenico Tegolo,Luigi Di Rosa
#t2008
#cProceedings of the 2008 21st IEEE International Symposium on Computer-Based Medical Systems
#index403131
#!This contribution presents an automated method to locate the optic disc in color fundus images. The method uses texture descriptors and a regression based method in order to determine the best circle that fits the optic disc. The best circle is chosen from a set of circles determined with an innovative method, not using the Hough transform as past approaches. An evaluation of the proposed method has been done using a database of 40 images. On this data set, our method achieved 95% success rate for the localization of the optic disc and 70% success rate for the identification of the optic disc contour (as a circle).


#*Adaptive sorted neighborhood methods for efficient record linkage
#@Su Yan,Dongwon Lee,Min-Yen Kan,Lee C. Giles
#t2007
#cProceedings of the 7th ACM/IEEE-CS joint conference on Digital libraries
#index428341
#%331585
#%575433
#%582319
#%440998
#!Traditionally, record linkage algorithms have played an important role in maintaining digital libraries - i.e., identifying matching citations or authors for consolidation in updating or integrating digital libraries. As such, a variety of record linkage algorithms have been developed and deployed successfully. Often, however, existing solutions have a set of parameters whose values are set by human experts off-lineand are fixed during the execution. Since finding the ideal values of such parameters is not straightforward, or no such single ideal value even exists, the applicability of existing solutions to new scenarios or domains is greatly hampered. To remedy this problem, we argue that one can achieve significant improvement by adaptively and dynamically changing such parameters of record linkage algorithms. To validate our hypothesis, we take a classical record linkage algorithm, the sorted neighborhood method (SNM), and demonstrate how we can achieve improved accuracy and performance by adaptively changing its fixed sliding window size. Our claim is analytically and empirically validated using both real and synthetic data sets of digital libraries and other domains.


#*Privacy-Preserving Alert Correlation: A Concept Hierarchy Based Approach
#@Dingbang Xu,Peng Ning
#t2005
#cProceedings of the 21st Annual Computer Security Applications Conference
#index573937
#!With the increasing security threats from infrastructure attacks such as worms and distributed denial of service attacks, it is clear that the cooperation among different organizations is necessary to defend against these attacks. However, organizations' privacy concerns for the incident and security alert data require that sensitive data be sanitized before they are shared with other organizations. Such sanitization process usually has negative impacts on intrusion analysis (such as alert correlation). To balance the privacy requirements and the need for intrusion analysis, we propose a privacy-preserving alert correlation approach based on concept hierarchies. Our approach consists of two phases. The first phase is entropy guided alert sanitization, where sensitive alert attributes are generalized to high-level concepts to introduce uncertainty into the dataset with partial semantics. To balance the privacy and the usability of alert data, we propose to guide the alert sanitization process with the entropy or differential entropy of sanitized attributes. The second phase is sanitized alert correlation. We focus on defining similarity functions between sanitized attributes and building attack scenarios from sanitized alerts. Our preliminary experimental results demonstrate the effectiveness of the proposed techniques.


#*Information Maximization in a Linear Manifold Topographic Map
#@Peyman Adibi,Reza Safabakhsh
#t2009
#cNeural Processing Letters
#index134872
#%2121
#%49046
#%73447
#%90153
#%251845
#%281540
#%290729
#%601617
#!This article addresses the problem of unsupervised learning of multiple linear manifolds in a topology preserving neural map. The model finds simple linear estimations of the regions of the unknown data manifold. Each neuron of the map corresponds to a linear manifold whose basis and mean vectors and on- and off-manifold standard deviations must be learnt. The learning rules are derived based on competition between neurons and maximizing an approximation of the mutual information between the input and the output of each neuron. Neighborhood functions are also considered in the learning rules in order to develop the topology preserving property for the map. Considering two special density models for the input data, the optimal nonlinear input/output mappings of the neurons are found. Experimental results show a good performance for the proposed method on synthesized and practical problems compared with other relevant techniques.


#*A simple and linear time randomized algorithm for computing sparse spanners in weighted graphs
#@Surender Baswana,Sandeep Sen
#t2007
#cRandom Structures Algorithms
#index419093
#%162337
#%166757
#%179458
#%210693
#%224455
#%227568
#%248163
#%282431
#%318442
#%513235
#%602928
#%482287
#%478071
#%534809
#!Let G = (V,E) be an undirected weighted graph on |V | = n vertices and |E| = m edges. A t-spanner of the graph G, for any t &ge; 1, is a subgraph (V,ES), ES &sube; E, such that the distance between any pair of vertices in the subgraph is at most t times the distance between them in the graph G. Computing a t-spanner of minimum size (number of edges) has been a widely studied and well-motivated problem in computer science. In this paper we present the first linear time randomized algorithm that computes a t-spanner of a given weighted graph. Moreover, the size of the t-spanner computed essentially matches the worst case lower bound implied by a 43-year old girth lower bound conjecture made independently by Erd&odblac;s, Bollob&aacute;s, and Bondy & Simonovits. Our algorithm uses a novel clustering approach that avoids any distance computation altogether. This feature is somewhat surprising since all the previously existing algorithms employ computation of some sort of local or global distance information, which involves growing either breadth first search trees up to &thetas;(t)-levels or full shortest path trees on a large fraction of vertices. The truly local approach of our algorithm also leads to equally simple and efficient algorithms for computing spanners in other important computational environments like distributed, parallel, and external memory. &copy; 2006 Wiley Periodicals, Inc. Random Struct. Alg., 2007 Preliminary version of this work appeared in the 30th International Colloquium on Automata, Languages and Programming, pages 384&ndash;396, 2003.


#*An algebraic condition for product form in stochastic automata networks without synchronizations
#@J. M. Fourneau,B. Plateau,W. J. Stewart
#t2008
#cPerformance Evaluation
#index629248
#%213381
#%359319
#%511509
#%529875
#%623797
#!We consider Stochastic Automata Networks (SANs) in continuous time and we prove a sufficient condition for the steady-state distribution to have product form. We consider synchronization-free SANs in which the transitions of one automaton may depend upon the states of the other automata. This model can represent efficiently multidimensional Markov chains whose transitions are limited to one component but whose rates may depend on the state of the chain. The sufficient condition we obtain is quite simple and our theorem generalizes former results on SANs as well as results on modulated Markovian queues, such as Boucherie's theory on competing Markov chain, on reversible queues considered by Kelly and on modulated Jackson queueing networks studied by Zhu. The sufficient condition and the proof are purely algebraic and are based on the intersection of kernels for a certain set of matrices.


#*Testing Line Search Techniques for Finite Element Discretizations for Unsaturated Flow
#@Fred T. Tracy
#t2009
#cProceedings of the 9th International Conference on Computational Science: Part I
#index128103
#!Unsaturated flow in porous media is often modeled using the finite element (FE) method. When employing an implicit version of the computational equations resulting from the FE discretization, a nonlinear system of equations is generated that must then be solved by techniques such as Newton's method. This paper reveals results of the effectiveness of three line search techniques when employed within the framework of the approximate Newton method. The methods of a bisection line search, a quadratic variation of the norm of the residual line search, and a relaxation technique are considered, all in the context of a parallel computing environment. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Related-Key Chosen IV Attacks on Grain-v1 and Grain-128
#@Yuseop Lee,Kitae Jeong,Jaechul Sung,Seokhie Hong
#t2008
#cProceedings of the 13th Australasian conference on Information Security and Privacy
#index408465
#!The slide resynchronization attack on Grain was proposed in [6]. This attack finds related keys and initialization vectors of Grain that generate the 1-bit shifted keystream sequence. In this paper, we extend the attack proposed in [6] and propose related-key chosen IV attacks on Grain-v1 and Grain-128. The attack on Grain-v1 recovers the secret key with 222.59 chosen IVs, 226.29-bit keystream sequences and 222.90 computational complexity. To recover the secret key of Grain-128, our attack requires 226.59 chosen IVs, 231.39-bit keystream sequences and 227.01 computational complexity. These works are the first known key recovery attacks on Grain-v1 and Grain-128.


#*Modeling individual cognitive structure in contextual information retrieval
#@Xuan Tian,Xiaoyong Du,He Hu,Haihua Li
#t2009
#cComputers Mathematics with Applications
#index68516
#%613731
#%281859
#%479512
#%171898
#%151520
#!In contextual information retrieval (CIR), the retrieval of information depends on the time and place of the submitting query, history of interaction, task in hand, and many other factors that are not given explicitly, but lie implicitly in the interaction and surroundings of searching, namely the context [P. Ingwersen, N. Belkin, Information retrieval in context, ACM SIGIR Forum 2 (2004)]. A user's individual cognition is one of important contextual factors to help understand his or her personal needs. In this paper, we give a formal definition for a user's individual cognitive structure (ICS) in CIR, and propose an approach called DOSAM to model it. DOSAM is inspired by the spreading activation model of psychology, and built on the domain ontology, while its goal is to get a user's cognitive structure. Cost analysis of construction algorithm shows that it is feasible to get ICS by DOSAM, and personalized search experimental results on a digital library indicate that ICS based search can improve the search effectiveness and a user's satisfaction.


#*Molecular Surface Abstraction
#@Gregory Cipriano
#t2007
#cIEEE Transactions on Visualization and Computer Graphics
#index338021
#%210105
#%438803
#%603993
#%449527
#%603715
#!In this paper we introduce a visualization technique that provides an abstracted view of the shape and spatio-physico-chemical properties of complex molecules. Unlike existing molecular viewing methods, our approach suppresses small details to facilitate rapid comprehension, yet marks the location of significant features so they remain visible. Our approach uses a combination of filters and mesh restructuring to generate a simplified representation that conveys the overall shape and spatio-physico-chemical properties (e.g. electrostatic charge). Surface markings are then used in the place of important removed details, as well as to supply additional information. These simplified representations are amenable to display using stylized rendering algorithms to further enhance comprehension. Our initial experience suggests that our approach is particularly useful in browsing collections of large molecules and in readily making comparisons between them.


#*An adaptive volume constraint algorithm for topology optimization with a displacement-limit
#@Chyi-Yeu Lin,Fang-Ming Hsu
#t2008
#cAdvances in Engineering Software
#index391664
#%80330
#%473318
#%584027
#!This paper proposes a novel adaptive volume constraint algorithm (AVC) to replace the fixed volume constraint (FVC) in the traditional topology optimization method, such that a minimum-compliance optimal structure that simultaneously meets the additional displacement limit can be searched. Optimal minimum-compliance structures are subject to the limit of a predetermined amount of material in traditional calculation methods, and often fail to meet practical stress and displacement constraints, or become unnecessarily strong. Without displacement sensitivities, the AVC algorithm iteratively adjusts allowable material usage based on the difference between the actual displacement, and the allowable displacement limit. In this way, topology optimization can efficiently construct a minimum-compliance structure that meets the allowable displacement limit. The regular volume constraint algorithm (RVC), which slightly changes the volume constraint each time at the end of FVC, is also executed in order to demonstrate the advantages of the AVC algorithm. The effectiveness of the AVC algorithm is demonstrated by two illustrative 2-D design problems: a cantilever beam and a simple beam.


#*Milena: Write Generic Morphological Algorithms Once, Run on Many Kinds of Images
#@Roland Levillain,Thierry Géraud,Laurent Najman
#t2009
#cProceedings of the 9th International Symposium on Mathematical Morphology and Its Application to Signal and Image Processing
#index507589
#!We present a programming framework for discrete mathematical morphology centered on the concept of genericity. We show that formal definitions of morphological algorithms can be translated into actual code, usable on virtually any kind of compatible images, provided a general definition of the concept of image is given. This work is implemented in Milena, a generic, efficient, and user-friendly image processing library.


#*Visualization PSE for Multi-Physics Analysis by Using OpenGL API Fusion Technique
#@Hideo Miyachi,Marie Oshima,Yoshitaka Ohyoshi,Takehiro Matsuo,Taiki Tanimae,Nobuyuki Oshima
#t2005
#cProceedings of the First International Conference on e-Science and Grid Computing
#index579980
#!PSE has become increasingly important as the computer environment has become ever more complex. In addition, the development of multi-physics calculations has complicated software systems, and an environment in which multi-simulation codes can be integrated has also become important in the software business. Because of this, we here propose a visualization PSE for multi-physics simulation. We are not proposing a new visualization tool for it, but an integration environment to merge the outputs of two or more existing visualization software visually. We developed a prototype which merges multi-outputs from any OpenGL programs without recompiling or re-linking by using the GLR (GL-DLL Replacement) technique. And the performance characteristics of the system were examined.


#*A survey of insulin-dependent diabetes-part II: control methods
#@Daisuke Takahashi,Yang Xiao,Fei Hu
#t2008
#cInternational Journal of Telemedicine and Applications
#index629783
#!We survey blood glucose control schemes for insulin-dependent diabetes therapies and systems. These schemes largely rely on mathematical models of the insulin-glucose relations, and these models are typically derived in an empirical or fundamental way. In an empirical way, the experimental insulin inputs and resulting blood-glucose outputs are used to generate a mathematical model, which includes a couple of equations approximating a very complex system. On the other hand, the insulin-glucose relation is also explained from the well-known facts of other biological mechanisms. Since these mechanisms are more or less related with each other, a mathematical model of the insulin-glucose system can be derived from these surrounding relations. This kind of method of the mathematical model derivation is called a fundamental method. Along with several mathematical models, researchers develop autonomous systems whether they involve medical devices or not to compensate metabolic disorders and these autonomous systems employ their own control methods. Basically, in insulin-dependent diabetes therapies, control methods are classified into three categories: open-loop, closed-loop, and partially closed-loop controls. The main difference among these methods is how much the systems are open to the outside people.


#*What is Itanium Memory Consistency from the Programmer's Point of View?
#@Lisa Higham,LillAnne Jackson,Jalal Kawash
#t2007
#cElectronic Notes in Theoretical Computer Science (ENTCS)
#index427740
#%522886
#!A programmer-centric model describes the memory consistency rules of amultiprocessor as a collection, one for each processor, of 'views' of instructions and some agreements between these views. It also requires the natural notion of validity: the value read from a shared memory location is the one that was most recently stored, according to a given view. This allows reasoning about programs at a non-operational level in the natural way, not obscured by the implementation details of the underlying architecture. In this paper, we formulate a programmer-centric description of the memory consistency model provided by the Itanium architecture. However, our definition is not tight. We provide two very similar definitions and show that the specification of the Itanium memory model lies between the two. These two definitions are motivated by slightly different implementations of load-acquire instructions. A further entertainment of a handful of other load-acquire rules leads us to question whether the specification of the Itanium memory order [Intel Corporation. A formal specification of the intel itanium processor family memory ordering. http://www.intel.com/, Oct 2002] is indeed faithful to the Itanium architecture intentions.


#*On identification of wakes and trails at sea with IRS-P4 OCM data
#@S. K. Sasamal
#t2007
#cInternational Journal of Remote Sensing
#index45803
#!Ship wakes and aircraft contrails were identified in the IRS-P4 OCM data. The ship wake signatures were analysed for the observations made in shipping corridors of the Persian Gulf on 3 June 1999 and in the of the Arabian Sea on 17 February 2000. While the aircraft contrails were studied with OCM data on 17 November 1999 off Mumbai, India and 18 February 2002 in the Arabian Sea. The study of wakes and trails helped discriminating ships and aircraft location at the sea.


#*Web service-driven framework for maintaining global version consistency in distributed enterprise portal
#@Hui-Ling Lin,Shao-Shin Hung,Derchian Tsaih,Chiehyao Chang
#t2009
#cWSEAS Transactions on Computers
#index126506
#%68266
#%111477
#%541119
#%384698
#%430255
#%430479
#!The explosion of the web has led to a situation where a majority of the traffic on the Internet is web related. Today, practically all of the popular web sites arc served from single locations. This necessitates frequent long distance network transfers of data (potentially repeatedly) which results in a high response time for users, and is wasteful of the available network bandwidth. This paper presents a new approach to web replication, where each of the replicas resides in a different part of the network, and the browser is automatically and transparently directed to the "best" server. This paper presents a transnational hierarchical global patch consistent model called THGPCM (Transnational Hierarchical Global Patch Consistent Model). Improving the OPDS (Original Patching Data Source) enabled network equipments, capable of updating patch parameter that existed in enterprise with specified OPDS partially dependency relationships. Apply scenario can reduce the global patch service cost of transnational enterprise network equipments and minimum the turnaround time of patch service delay.


#*The citation advantage of open-access articles
#@Michael Norris,Charles Oppenheim,Fytton Rowland
#t2008
#cJournal of the American Society for Information Science and Technology
#index393374
#!Four subjectsecology, applied mathematics, sociology, and economicswere selected to assess whether there is a citation advantage between journal articles that have an open-access (OA) version on the Internet compared to those articles that are exclusively toll access (TA). Citations were counted using the Web of Science, and the OA status of articles was determined by searching OAIster, OpenDOAR, Google, and Google Scholar. Of a sample of 4,633 articles examined, 2,280 (49%) were OA and had a mean citation count of 9.04 whereas the mean for TA articles was 5.76. There appears to be a clear citation advantage for those articles that are OA as opposed to those that are TA. This advantage, however, varies between disciplines, with sociology having the highest citation advantage, but the lowest number of OA articles, from the sample taken, and ecology having the highest individual citation count for OA articles, but the smallest citation advantage. Tests of correlation or association between OA status and a number of variables were generally found to weak or inconsistent. The cause of this citation advantage has not been determined. &copy; 2008 Wiley Periodicals, Inc.


#*Towards implementation of a novel scheme for data prefetching on distributed shared memory systems
#@Hsiao-Hsi Wang,Kuan-Ching Li,Ssu-Hsuan Lu,Chun-Chieh Yang
#t2009
#cThe Journal of Supercomputing
#index56253
#%379165
#%261338
#%362265
#%375774
#%98161
#!High speed networks and rapidly improving microprocessor performance make the network of workstations an extremely important tool for parallel computing in order to speedup the execution of scientific applications. Shared memory is an attractive programming model for designing parallel and distributed applications, where the programmer can focus on algorithmic development rather than data partition and communication. Based on this important characteristic, the design of systems to provide the shared memory abstraction on physically distributed memory machines has been developed, known as Distributed Shared Memory (DSM). DSM is built using specific software to combine a number of computer hardware resources into one computing environment. Such an environment not only provides an easy way to execute parallel applications, but also combines available computational resources with the purpose of speeding up execution of these applications. DSM systems need to maintain data consistency in memory, which usually leads to communication overhead. Therefore, there exists a number of strategies that can be used to overcome this overhead issue and improve overall performance. Strategies as prefetching have been proven to show great performance in DSM systems, since they can reduce data access communication latencies from remote nodes. On the other hand, these strategies also transfer unnecessary prefetching pages to remote nodes. In this research paper, we focus on the access pattern during execution of a parallel application, and then analyze the data type and behavior of parallel applications. We propose an adaptive data classification scheme to improve prefetching strategy with the goal to improve overall performance. Adaptive data classification scheme classifies data according to the accessing sequence of pages, so that the home node uses past history access patterns of remote nodes to decide whether it needs to transfer related pages to remote nodes. From experimental results, we can observe that our proposed method can increase the accuracy of data access in effective prefetch strategy by reducing the number of page faults and misprefetching. Experimental results using our proposed classification scheme show a performance improvement of about 9---25% over the same benchmark applications running on top of an original JIAJIA DSM system.


#*Bayesian Combinatorial Auctions
#@George Christodoulou,Annamária Kovács,Michael Schapira
#t2008
#cProceedings of the 35th international colloquium on Automata, Languages and Programming, Part I
#index389307
#!We study the following Bayesian setting: m items are sold to n selfish bidders in m independent second-price auctions. Each bidder has a private valuation function that expresses complex preferences over all subsets of items. Bidders only have beliefs about the valuation functions of the other bidders, in the form of probability distributions. The objective is to allocate the items to the bidders in a way that provides a good approximation to the optimal social welfare value. We show that if bidders have submodular valuation functions, then every Bayesian Nash equilibrium of the resulting game provides a 2-approximation to the optimal social welfare. Moreover, we show that in the full-information game a pure Nash always exists and can be found in time that is polynomial in both m and n.


#*Classification for accuracy and insight: a weighted sum approach
#@Anthony Quinn,Andrew Stranieri,John Yearwood
#t2007
#cProceedings of the sixth Australasian conference on Data mining and analytics - Volume 70
#index46345
#%214951
#%586607
#!This research presents a classifier that aims to provide insight into a dataset in addition to achieving classification accuracies comparable to other algorithms. The classifier called, Automated Weighted Sum (AWSum) uses a weighted sum approach where feature values are assigned weights that are summed and compared to a threshold in order to classify an example. Though naive, this approach is scalable, achieves accurate classifications on standard datasets and also provides a degree of insight. By insight we mean that the technique provides an appreciation of the influence a feature value has on class values, relative to each other. AWSum provides a focus on the feature value space that allows the technique to identify feature values and combinations of feature values that are sensitive and important for a classification. This is particularly useful in fields such as medicine where this sort of micro-focus and understanding is critical in classification.


#*Real-Time News Event Extraction for Global Crisis Monitoring
#@Hristo Tanev,Jakub Piskorski,Martin Atkinson
#t2008
#cProceedings of the 13th international conference on Natural Language and Information Systems: Applications of Natural Language to Information Systems
#index403198
#!This paper presents a real-time news event extraction system developed by the Joint Research Centre of the European Commission. It is capable of accurately and efficiently extracting violent and disaster events from online news without using much linguistic sophistication. In particular, in our linguistically relatively lightweight approach to event extraction, clustered news have been heavily exploited at various stages of processing. The paper describes the system's architecture, news geo-tagging, automatic pattern learning, pattern specification language, information aggregation, the issues of integrating event information in a global crisis monitoring system and new experimental evaluation.


#*Approximating total flow time on parallel machines
#@Stefano Leonardi,Danny Raz
#t2007
#cJournal of Computer and System Sciences
#index432927
#%83385
#%251785
#%435061
#%528218
#!We consider the problem of optimizing the total flow time of a stream of jobs that are released over time in a multiprocessor setting. This problem is NP-hard even when there are only two machines and preemption is allowed. Although the total (or average) flow time is widely accepted as a good measurement of the overall quality of service, no approximation algorithms were known for this basic scheduling problem. This paper contains two main results. We first prove that when preemption is allowed, Shortest Remaining Processing Time (SRPT) is an O(log(min{nm,P})) approximation algorithm for the total flow time, where n is the number of jobs, m is the number of machines, and P is the ratio between the maximum and the minimum processing time of a job. We also provide an @W(log(nm+P)) lower bound on the (worst case) competitive ratio of any randomized algorithm for the on-line problem in which jobs are known at their release times. Thus, we show that up to a constant factor SRPT is an optimal on-line algorithm. Our second main result addresses the non-preemptive case. We present a general technique that allows to transform any preemptive solution into a non-preemptive solution at the expense of an O(nm) factor in the approximation ratio of the total flow time. Combining this technique with our previous result yields an O(nmlognm) approximation algorithm for this case. We also show an @W(n^1^3^-^@e) lower bound on the approximability of this problem (assuming P


#*Advances in Grid Computing - EGC 2005: European Grid Conference, Amsterdam, The Netherlands, February 14-16, 2005, Revised Selected Papers (Lecture Notes in Computer Science)
#@P. M. A. Sloot,A. G. Hoekstra,T. Priol,A. Reinefeld,M. Bubak
#t2005
#c
#index13113


#*Part 2: CA Applications: Crowds and Cellular Automata
#@
#t2008
#cProceedings of the 8th international conference on Cellular Automata for Reseach and Industry
#index394600


#*A-PARM: Adaptive Division of Sub-cells in the PARM for Efficient Volume Ray Casting
#@Sukhyun Lim,Byeong-Seok Shin
#t2007
#cProceedings of the 7th international conference on Computational Science, Part I: ICCS 2007
#index392289
#!The PARM is a data structure to ensure interactive frame rates on a PC platform for CPU-based volume ray casting. After determining candidate cells that contribute to the final images, it partitions each candidate cell into several sub-cells. Then, it stores trilinearly interpolated scalar value and an index of encoded gradient vector for each sub-cell. Since the information that requires time-consuming computations is already stored in the structure, the rendering time is reduced. However, it requires huge memory space because most precomputed values are loaded in the system memory. We solve it by adaptively dividing candidate cells into different sub-cells. That is, we divide a candidate cell in which the gradient is strictly changed into a large number of sub-cells, and vice versa. By this approach, we acquire moderate images while reducing the memory size.


#*On the Error Modeling of Dead Reckoned Data in a Distributed Virtual Environment
#@Dai Hanawa,Tatsuhiro Yonekura
#t2005
#cProceedings of the 2005 International Conference on Cyberworlds
#index581128
#!In this paper, the authors aim to analyze the error of dead reckoned data generated from received data in a discrete temporal axis in a distributed virtual environment (DVE). That is, compared with the data received in continuous time, data acquired in discrete time has a certain degradation or uncertainty of information. Our way of analysis is to introduce a mathematical model of this degradation with regard to the metrics of the temporal interval. We introduced polynomial models for dead reckoning method between frames using parametrics calculated from the data over the last several frames. By employing the method of error analysis of a numerical analysis to the above polynomial models, we formulate theoretical models which approximate the statistical error of dead reckoned data based on parameters such as the update interval and changes in the data. This study enables the discussion on the optimality of the update interval in a DVE using dead reckoning. Finally, we evaluate the adaptability of the theoretical model by conducting simulation experiments generated by pen motion of writing string of letters by human. As a result, we confirm that the proposed theoretical model closely approximates the average error in the simulation.


#*A reproducing kernel Hilbert space framework for pairwise time series distances
#@Zhengdong Lu,Todd K. Leen,Yonghong Huang,Deniz Erdogmus
#t2008
#cProceedings of the 25th international conference on Machine learning
#index45919
#%35476
#%35521
#%570651
#%435316
#!A good distance measure for time series needs to properly incorporate the temporal structure, and should be applicable to sequences with unequal lengths. In this paper, we propose a distance measure as a principled solution to the two requirements. Unlike the conventional feature vector representation, our approach represents each time series with a summarizing smooth curve in a reproducing kernel Hilbert space (RKHS), and therefore translate the distance between time series into distances between curves. Moreover we propose to learn the kernel of this RKHS from a population of time series with discrete observations using Gaussian process-based non-parametric mixed-effect models. Experiments on two vastly different real-world problems show that the proposed distance measure leads to improved classification accuracy over the conventional distance measures.


#*Quality, Reliability and Information Technology
#@Alok K. Verma,P. K. Kapur
#t2006
#c
#index7790


#*Handwritten Character Recognition Using Gradient Feature and Quadratic Classifier with Multiple Discrimination Schemes
#@Hailong Liu,Xiaoqing Ding
#t2005
#cProceedings of the Eighth International Conference on Document Analysis and Recognition
#index577935
#!In the research of statistical approach for handwritten character recognition, directional element feature (DEF) and modified quadratic discriminant function (MQDF) have been extremely successful and widely used in practical applications. In this paper, we apply several state-of-the-art techniques of handwritten character recognition on this baseline system to improve the recognition accuracy. In feature extraction stage, gradient feature is extracted to replace DEF, which provides higher resolution on both magnitude and angle of the directional strokes in character image. In classification stage, the performance of MQDF classifier is enhanced by multiple discrimination schemes, including minimum classification error (MCE) training on the classifier parameters and modified distance representation for similar characters discrimination. All these techniques we use lead to improvement on the character recognition rate. The performance of the improved recognition system has been evaluated by both handwritten digit recognition and handwritten Chinese character recognition experiments, in which very promising results are achieved.


#*Uniform Interpolation by Resolution in Modal Logic
#@Andreas Herzig,Jérôme Mengin
#t2008
#cProceedings of the 11th European conference on Logics in Artificial Intelligence
#index394712
#!The problem of computing a uniform interpolant of a given formula on a sublanguage is known in Artificial Intelligence as variable forgetting. In propositional logic, there are well known methods for performing variable forgetting. Variable forgetting is more involved in modal logics, because one must forget a variable not in one world, but in several worlds. It has been shown that modal logic K has the uniform interpolation property, and a method has recently been proposed for forgetting variables in a modal formula (of mu-calculus) given in disjunctive normal form. However, there are cases where information comes naturally in a more conjunctive form. In this paper, we propose a method, based on an extension of resolution to modal logics, to perform variable forgetting for formulae in conjunctive normal form, in the modal logic K .


#*Cognitive Support: A Machine-Mediated Communication Perspective
#@Adel Elsayed,Yongqiang Qiu
#t2006
#cProceedings of the Sixth IEEE International Conference on Advanced Learning Technologies
#index23694
#!This paper provides an MMC perspective for the provision of cognitive support. First, an overview of cognitive operations and categorization of cognitive tools is given. It then briefly describes a cognitive support application based on the provision of semantic structures of content. The suggested tool is shown to provide an 'operational' dimension that extends its intrinsic nature as an 'observable' asset.


#*Some Observations on the Theory of Cryptographic Hash Functions
#@D. R. Stinson
#t2006
#cDesigns, Codes and Cryptography
#index581143
#%107708
#%226929
#%265015
#!In this paper, we study issues related to the notion of "secure" hash functions. Several necessary conditions are considered, as well as a popular sufficient condition (the so-called random oracle model). We study the security of various problems that are motivated by the notion of a secure hash function. These problems are analyzed in the random oracle model, and we prove that the obvious trivial algorithms are optimal. As well, we look closely at reductions between various problems. In particular, we consider the important question "does collision resistance imply preimage resistance?". We provide partial answers to this question --- both positive and negative! --- based on uniformity properties of the hash function under consideration.


#*Machine learning and its application at Nooksack falls hydroelectric station
#@Scott Alexander,Jianna Zhang
#t2005
#cProceedings of the 20th national conference on Artificial intelligence - Volume 4
#index490744
#%481895


#*Coupling Metrics for Predicting Maintainability in Service-Oriented Designs
#@Mikhail Perepletchikov,Caspar Ryan,Keith Frampton,Zahir Tari
#t2007
#cProceedings of the 2007 Australian Software Engineering Conference
#index417646
#!Service-Oriented Computing (SOC) is emerging as a promising paradigm for developing distributed enterprise applications. Although some initial concepts of SOC have been investigated in the research literature, and related technologies are in the process of adoption by an increasing number of enterprises, the ability to measure the structural attributes of service-oriented designs thus predicting the quality of the final software product does not currently exist. Therefore, this paper proposes a set of metrics for quantifying the structural coupling of design artefacts in service-oriented systems. The metrics, which are validated against previously established properties of coupling, are intended to predict the quality characteristic of maintainability of service-oriented software. This is expected to benefit both research and industrial communities as existing object-oriented and procedural metrics are not readily applicable to the implementation of service-oriented systems.


#*Single polarization guidance in liquid-crystal photonic bandgap fibers
#@J. Sun,C. C. Chan,Y. F. Zhang
#t2008
#cProceedings of the 2008 International Conference on Advanced Infocomm Technology
#index69993
#!Bandgap formation in nematic liquid crystal photonic bandgap fiber made of high-index nonsilica glass has been investigated. Scalar wave approximation indicates the possibility of constructing the full bandgap structure through two isotropic simulations for the two polarization components. Furthermore, analogous to an isotropic photonic bandgap fiber, refractive index scaling laws are also valid. The anisotropic property of nematic liquid crystal opens up several practically interesting guiding regimes, which enable the construction of novel polarization controllers or switching devices.


#*Gradient Based Error Concealment for H.264 Inter Frames
#@Toan Nguyen Dinh,GueeSang Lee
#t2007
#cProceedings of the 7th IEEE International Conference on Computer and Information Technology
#index351795
#!In this paper, an improved BMA(Boundary Matching Algorithm) using gradient vectors is presented to conceal channel errors in inter-frames of H.264 video images. BMA computes the sum of pixel differences around the perimeter of the lost block between the candidate block and its neighboring blocks to estimate the validity of the candidate block, assuming that adjacent pixels in an image have almost the same value. In real images, however, there exist some gradients in local area of the image, which means that the pixel values are increasing or decreasing in a specific slope. A simple and efficient method for estimating candidate blocks using gradient information has been developed and thereby the modified BMA has been applied to recover lost blocks. Experiments show the proposed method improves picture quality of about 1 3dB compared to existing methods.


#*Proceedings of the 6th international conference on Energy Minimization Methods in Computer Vision and Pattern Recognition
#@Alan L. Yuille,Song-Chun Zhu,Daniel Cremers,Yongtian Wang
#t2007
#cLecture Notes In Computer Science; Vol. 4679
#index411639


#*A methodological approach for user interface development of collaborative applications: A case study
#@Ana Isabel Molina,Miguel Ángel Redondo,Manuel Ortega
#t2009
#cScience of Computer Programming
#index127488
#%268091
#%510822
#%451229
#%310944
#%144724
#%276651
#%205097
#!In the last few years, the production of systems which support learning and group work has been high. However, the design and development of these types of systems are difficult, mainly due to the multidisciplinarity involved. Furthermore, the Graphic User Interface (GUI) of an application is receiving greater attention, since it can be decisive in determining if the application is accepted or rejected by users. Model-based design is a widespread technique in the user interface development process. While reviewing approaches that deal with the modeling and design of user interfaces supporting collaborative tasks, we have detected that there is no proposal that links interactive and collaborative issues. We have introduced a methodological approach to solve this shortcoming. This approach is called CIAM (Collaborative Interactive Application Methodology) and it is composed of several stages in which conceptual models are created using CIAN (Collaborative Interactive Application Notation). These models start by modeling the organization in which the application will be used, as well as the tasks that must be supported. In the initial stages, the organization and the collaborative tasks are modeled using high-level specifications. In the following stages, the level of detail increases and, finally, the interaction between the individual users and the application is modeled using ConcurTaskTrees (CTT) notation. The interaction model acts as a bridge between the design and the implementation of the Graphic User Interface. In this paper we present our methodological approach and an example of applying this method for user interface design of collaborative and interactive applications.


#*Introducing a Method to Derive an Enterprise-Specific SOA Operating Model
#@Christian Schröpfer,Marten Schönherr
#t2008
#cProceedings of the 2008 12th International IEEE Enterprise Distributed Object Computing Conference
#index399538
#!Considering that each IT-organization is based on an established IT-governance the introduction of SOA as a new overall architectural approach will change the requirements for the specific governance model. The paper presents a SOA-specific governance model which differentiates an operating model, service lifecycle management, service ownership, cost allocation, and meta-data management support. Based on the company´s maturity along the SOA-relevant dimensions IT-governance, SOA experience, and process maturity, its size, as well as its organizational structure the paper discusses an SOA operating model with organizational structure, roles, responsibilities, and KPI´s. The main assumption of the approach is the alignment of the organizational structure of IT with a functional domain model. This operating model is the outcome of ten industrial workshops and one complex case study based on standards as CobiT and ITIL.


#*On the time-splitting scheme used in the Princeton Ocean Model
#@V. M. Kamenkovich,D. A. Nechaev
#t2009
#cJournal of Computational Physics
#index63344
#%86624
#!The analysis of the time-splitting procedure implemented in the Princeton Ocean Model (POM) is presented. The time-splitting procedure uses different time steps to describe the evolution of interacting fast and slow propagating modes. In the general case the exact separation of the fast and slow modes is not possible. The main idea of the analyzed procedure is to split the system of primitive equations into two systems of equations for interacting external and internal modes. By definition, the internal mode varies slowly and the crux of the problem is to determine the proper filter, which excludes the fast component of the external mode variables in the relevant equations. The objective of this paper is to examine properties of the POM time-splitting procedure applied to equations governing the simplest linear non-rotating two-layer model of constant depth. The simplicity of the model makes it possible to study these properties analytically. First, the time-split system of differential equations is examined for two types of the determination of the slow component based on an asymptotic approach or time-averaging. Second, the differential-difference scheme is developed and some criteria of its stability are discussed for centered, forward, or backward time-averaging of the external mode variables. Finally, the stability of the POM time-splitting schemes with centered and forward time-averaging is analyzed. The effect of the Asselin filter on solutions of the considered schemes is studied. It is assumed that questions arising in the analysis of the simplest model are inherent in the general model as well.


#*TRIBA: a cable television retrieval & awareness system
#@Michael Tseng,Jon Kolko
#t2005
#cCHI '05 extended abstracts on Human factors in computing systems
#index98745
#%590349
#%591446
#%326821
#!This paper discusses the design of a physical and digital system intended to allow for easy manipulation and interaction with the tremendous amount of options present in advanced multimedia devices, such as digital cable television. As user demand for access to large quantities of data increases, and cable companies offer more choices to their audiences, traditional content selection techniques become less useful and much more difficult to understand. TRIBA is the result of a ten week research and design exploration investigating how users can easily manipulate and comprehend tremendously large data sets. The findings of this research indicate a need for utilizing interactive agents to bridge the gap between the user and their goal. As technology is created and consumer electronics becomes more integrated into our lives, devices speak a language that users are expected to learn. TRIBA is a product embracing the philosophical idea that users should not have to learn a new language to interact with a futuristic and useful product, but instead products and devices must learn to speak the same language as the user.


#*Automatically and accurately conflating road vector data, street maps and orthoimagery
#@Cyrus Shahabi,Craig Knoblock
#t2005
#c
#index580668
#!Recent growth of the geospatial information on the web has made it possible to access various spatial data. By integrating diverse spatial datasets, one can support the queries that could have not been answered given any of these sets in isolation. However, accurately integrating different geospatial data remains a challenging task because diverse geospatial data may have different projections and different accuracy levels. Most of the existing conflation algorithms only handle vector-vector data integration or require human intervention to accomplish vector-raster or raster-raster data integration. In this dissertation, I propose an approach, named AMS-Conflation, that achieves automatic geospatial data integration by exploiting multiple sources of geospatial information. In particular, I focus on vector-imagery and map-imagery conflation. For vector-imagery conflation, I describe techniques to automatically generate control points by exploiting the information from the road vectors to perform localized image processing on the imagery. I also evaluate various filtering algorithms to eliminate inaccurate control point pairs. Based on the experimental results, these techniques automatically align the roads to orthoimagery, such that in one of my experiments, 85% of the conflated roads are within 4.5 m from the real road axes compared to 55% for the original roads for partial areas in St. Louis, MO. For map-imagery conflation, my approach can take a map of unknown coordinates and automatically align it with an image. My approach first aligns road vectors with imagery using vector-imagery conflation techniques to generate control points on the imagery. For the maps, my approach utilizes image processing techniques to detect intersections. Furthermore, I present an algorithm (called GeoPPM) to compute the matched point pattern from the two point sets. The experimental results show that GeoPPM only misidentified one point pattern from the fifty tested maps. The experimental results also show that my approach can align a set of TIGER maps with imagery for an area in St. Louis, MO, such that 85.2% of the conflated map roads are within 10.8 m from the real road axes compared to 51.7% for the original and geo-referenced TIGER map roads.


#*Influence of Routing Protocol on VoIP Quality Performance in Wireless Mesh Backbone
#@Arlen Nascimento,Saulo Queiroz,Edjair Mota,Leandro Galvão,Edson Nascimento
#t2008
#cProceedings of the 2008 The Second International Conference on Next Generation Mobile Applications, Services, and Technologies
#index73111
#!In this paper we focus on the following question: how routing protocols, working under different channel conditions, can influence the human perceived quality of VoIP calls in a wireless mesh backbone? In order to respond this question, we propose a study case where we analyze two routing approaches in a 802.11 Wireless Mesh Backbone, namely, reactive AODV and proactive OLSR. We calculated the voice speech quality by making use of a reviewed version of ITU-T E-Model proposed in previous work. Results obtained from highly credible stochastic simulation environment, also described in this paper, showed that AODV performs better in very hostile mediums while OLSR presents better results when more friendly mediums take place.


#*Provisioning of network paths
#@
#t2006
#cProceeding from the 2006 workshop on Game theory for communications and networks
#index28881


#*An OptimizedWorkload for Failure Data Analysis of Mobile P2P over Bluetooth Ad-Hoc Networks
#@G. Carrozza,M. Cinque,F. Cornevilli,S. Russo
#t2006
#cProceedings of the 26th IEEE International ConferenceWorkshops on Distributed Computing Systems
#index32162
#!Mobile Peer-to-Peer (P2P) is a base paradigm for many new killer applications for mobile ad-hoc networks and the Mobile Internet. Currently, it is not well understood whether this paradigm is able to meet business and consumer dependability expectations. Dependability assessment of P2P applications can be achieved by field failure data analysis. The collection of failure data from wireless ad-hoc networks is a challenging task due to the intermittent usage and the mobility of users that do not allow to measure time-based dependability parameters. For this reason, we propose to deploy automated workloads on the actual peer nodes which have to operate continuously. Specifically, this paper formalizes the problem and presents the design of a workload for mobile P2P that aims to orchestrate the peers uniformly, letting the failure occurrence be independent of the network load. Simulation results and experimentation over an actual Bluetooth network demonstrate that the proposed workload meets the defined requirements.


#*Multiple Face Model of Hybrid Fourier Feature for Large Face Image Set
#@Wonjun Hwang,Gyutae Park,Jongha Lee,Seok-Cheol Kee
#t2006
#cProceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 2
#index34499
#!The face recognition system based on the only single classifier considering the restricted information can not guarantee the generality and superiority of performances in a real situation. To challenge such problems, we propose the hybrid Fourier features extracted from different frequency bands and multiple face models. The hybrid Fourier feature comprises three different Fourier domains; merged real and imaginary components, Fourier spectrum and phase angle. When deriving Fourier features from three Fourier domains, we define three different frequency bandwidths, so that additional complementary features can be obtained. After this, they are individually classified by Linear Discriminant Analysis. This approach makes possible analyzing a face image from the various viewpoints to recognize identities. Moreover, we propose multiple face models based on different eye positions with a same image size, and it contributes to increasing the performance of the proposed system. We evaluated this proposed system using the Face Recognition Grand Challenge (FRGC) experimental protocols known as the largest data sets available. Experimental results on FRGC version 2.0 data sets has proven that the proposed method shows better verification rates than the baseline of FRGC on 2D frontal face images under various situations such as illumination changes, expression changes, and time elapses.


#*Aesthetics and credibility in web site design
#@David Robins,Jason Holmes
#t2008
#cInformation Processing and Management: an International Journal
#index340573
#%607103
#!Web sites often provide the first impression of an organization. For many organizations, web sites are crucial to ensure sales or to procure services within. When a person opens a web site, the first impression is probably made in a few seconds, and the user will either stay or move on to the next site on the basis of many factors. One of the factors that may influence users to stay or go is the page aesthetics. Another reason may involve a user's judgment about the site's credibility. This study explores the possible link between page aesthetics and a user's judgment of the site's credibility. Our findings indicate that when the same content is presented using different levels of aesthetic treatment, the content with a higher aesthetic treatment was judged as having higher credibility. We call this the amelioration effect of visual design and aesthetics on content credibility. Our study suggests that this effect is operational within the first few seconds in which a user views a web page. Given the same content, a higher aesthetic treatment will increase perceived credibility.


#*E-voting, ethics, and infastructure for computing education
#@
#t2005
#cACM SIGCSE Bulletin
#index30235


#*Industry Track Portals at BNP Paribas: a brief testimony (April 2005)
#@Marc Idelson
#t2005
#cProceedings of the IEEE International Conference on e-Business Engineering
#index578190
#!This paper intends to bear witness on the past, present and future of portals at BNP Paribas with a focus on: the B2E intranet portal (Echo'net) the French B2C home banking portal (BNPPARIBAS.NET) It will introduce the challenges that confronted BNP Paribas in each case, reflect on lessons learnt and future trends and finally suggest what financial services firms expect from e-business infrastructure hardware and software vendors and service providers .


#*Decision support communication: integrating communicative plans from multiple sources to plan messages for a dynamic user and environment
#@Sandra M. Carberry,Keith S. Decker
#t2007
#c
#index428217
#!When computers communicate with humans to facilitate a decision process, they must do so in an unambiguous and concise manner which reflects the needs and preferences of the user, and takes into account the situation in which the system performs. This dissertation explores the fulfillment of these requirements of decision support in the context of systems that receive information from multiple, independent sources. In the first part of this thesis I present my hypothesis that independent text plans, analyzed in terms of their rhetorical structure [MT87], can be integrated to enhance conciseness and coherence. An implemented system, RTPI, demonstrates the application of this hypothesis to improve message sets generated by an existing decision support system through the integration of related messages. An evaluation of RTPI shows that it reduces repetition and overall message length, and human subjects prefer its integrated messages to the original sets of messages. The second part of this thesis explores the additional challenges presented when decision support information is obtained and integrated from multiple sources in a dynamic information environment. In this environment, information attributes such as quality, cost, length, and production time can vary over time; in addition, user preferences regarding those attributes can also change. I present my hypothesis that this problem can be computationally addressed, by a flexible, responsive, agent-based system that takes into account both user preferences and information attributes that change over time. The implemented system MADSUM demonstrates a multi-agent architecture that addresses all of these issues. An evaluation of the system's output shows that human subjects, when presented with a scenario including user preferences and information, agree with MADSUM's selection and ordering of information from a proposition set.


#*Game Character's Active Facial Color Engine based on the Theory of Emotion-Color Association
#@Kyu-Ho Park,Kyoung-Nam Kim,Nam-Keum Doh,Tae-Yong Kim
#t2006
#cProceedings of the 2006 International Conference on Hybrid Information Technology - Volume 02
#index30455
#!The graphical expressions and artificial intelligence of Characters have been continuously improving, spurred by the astonishing growth of the game technology industry. Despite such improvements, users are still demanding a more natural gaming environment and reflections of true human emotions. However, the emotions that can be expressed are strictly limited because the facial colors and expressions of current Game Characters are hardly noticeable. Such restrictions can prevent the users from getting into the game. To address this, we developed the Facial Color Engine, which is a combination emotional model based on human cultural theory, emotional expression pattern using colors, and emotional reaction speed function, as opposed to the past methods that expressed emotion through blood flow, pulse, or skin temperature. The reflection of the game character's emotion on it's skin color will increase user immersion into the game and encourage further game development using our sensibility engine.


#*Note: The number of possibilities for random dating
#@Aaron Abrams,Rod Canfield,Andrew Granville
#t2008
#cJournal of Combinatorial Theory Series A
#index408379
#!Let G be a regular graph and H a subgraph on the same vertex set. We give surprisingly compact formulas for the number of copies of H one expects to find in a random subgraph of G.


#*Parallel distributed genetic fuzzy rule selection
#@Yusuke Nojima,Hisao Ishibuchi,Isao Kuwajima
#t2008
#cSoft Computing - A Fusion of Foundations, Methodologies and Applications
#index64876
#!Genetic fuzzy rule selection has been successfully used to design accurate and compact fuzzy rule-based classifiers. It is, however, very difficult to handle large data sets due to the increase in computational costs. This paper proposes a simple but effective idea to improve the scalability of genetic fuzzy rule selection to large data sets. Our idea is based on its parallel distributed implementation. Both a training data set and a population are divided into subgroups (i.e., into training data subsets and sub-populations, respectively) for the use of multiple processors. We compare seven variants of the parallel distributed implementation with the original non-parallel algorithm through computational experiments on some benchmark data sets.


#*Directional Invariance of Co-occurrence Matrices within the Liver
#@Carl Philips,Daniel Li,Daniela Raicu,Jacob Furst
#t2008
#cProceedings of the 2008 International Conference on Biocomputation, Bioinformatics, and Biomedical Technologies
#index44417
#!Co-occurrence matrices are one of three texture algorithms commonly used on Computed Tomography (CT) images. In this paper we analyze the directional invariance of Co-occurrence matrices for the purpose of reducing their runtime by reducing the number of directions analyzed without negatively affecting the quality of the texture data extracted.


#*Towards Trajectory Anonymization: a Generalization-Based Approach
#@Mehmet Ercan Nergiz,Maurizio Atzori,Yücel Sayg&#x131;n,Bar&#x131;ʂ Güç
#t2009
#cTransactions on Data Privacy
#index127338
#%52356
#%54177
#%105698
#%402426
#%578981
#%387378
#%344575
#%445076
#%558869
#%347072
#!Trajectory datasets are becoming popular due to the massive usage of GPS and location-based services. In this paper, we address privacy issues regarding the identification of individuals in static trajectory datasets. We first adopt the notion of k-anonymity to trajectories and propose a novel generalization-based approach for anonymization of trajectories. We further show that releasing anonymized trajectories may still have some privacy leaks. Therefore we propose a randomization based reconstruction algorithm for releasing anonymized trajectory data and also present how the underlying techniques can be adapted to other anonymity standards. The experimental results on real and synthetic trajectory datasets show the effectiveness of the proposed techniques.


#*Do Innovations Really Pay Off? Total Stock Market Returns to Innovation
#@Ashish Sood,Gerard J. Tellis
#t2009
#cMarketing Science
#index139848
#%85556
#%96003
#%156762
#%215369
#%309251
#!Critics often decry an earnings-focused short-term orientation of management that eschews spending on risky, long-term projects such as innovation to boost a firm's stock price. Such critics assume that stock markets react positively to announcements of immediate earnings but negatively to announcements of investments in innovation that have an uncertain long-term pay off. Contrary to this position, we argue that the market's true appreciation of innovation can be estimated by assessing the total market returns to the entire innovation project. We demonstrate this approach via the Fama-French 3-factor model (including Carhart's momentum factor) on 5,481 announcements from 69 firms in five markets and 19 technologies between 1977 and 2006. The total market returns to an innovation project are $643 million, more than 13 times the $49 million from an average innovation event. Returns to negative events are higher in absolute value than those to positive events. Returns to initiation occur 4.7 years ahead of launch. Returns to development activities are the highest and those to commercialization the lowest of all activities. Returns to new product launch are the lowest among all eight events tracked. Returns are higher for smaller firms than larger firms. Returns to the announcing firm are substantially greater than those to competitors across all stages. We discuss the implications of these results.


#*Random Fault Attack against Shrinking Generator
#@Marcin Gomułkiewicz,Mirosław Kutyłowski,Paweł Wlaź
#t2008
#cAlgorithmic Aspects of Wireless Sensor Networks: Fourth International Workshop, ALGOSENSORS 2008, Reykjavik, Iceland, July 2008. Revised Selected Papers
#index61815
#!We concern security of shrinking generator against fault attacks. While this pseudorandom bitstream generator is cryptographically strong and well suited for hardware implementations, especially for cheap artefacts, we show that using it for the devices that are not fault resistant is risky. That is, even if a device concerned is tamper-proof, generating random faults and analyzing the results may reveal secret keys stored inside the device.For the attack we flip a random bit and observe propagation of errors. The attack uses peculiar properties of the shrinking generator and presents a new kind of threats for designs based on combining weaker generators. In particular, it indicates that potentially all designs based on combining LFSR generators might be practically weak due to slow propagation of errors in a single LFSR.


#*Efficient and Scalable Algorithms for Inferring Likely Invariants in Distributed Systems
#@Guofei Jiang,Haifeng Chen,Kenji Yoshihira
#t2007
#cIEEE Transactions on Knowledge and Data Engineering
#index347205
#%178950
#%250081
#%327001
#%442924
#%595117
#%522542
#%453387
#%428593
#%615961
#!Distributed systems generate large amount of monitoring data such as log files to track their operational status. However, it is hard to correlate such monitoring data effectively across distributed systems and along observation time for system management. In previous work, we proposed a concept named flow intensity to measure the intensity with which internal monitoring data reacts to the volume of user requests. We calculated flow intensity measurements from monitoring data and proposed an algorithm to automatically search constant relationships between flow intensities measured at various points across distributed systems. If such relationships hold all the time, we regard them as invariants of the underlying systems. Invariants can be used to characterize complex systems and support various system management tasks. However, the computational complexity of previous invariant search algorithm is high so that it may not scale well in large systems with thousands of measurements. In this paper, we propose two efficient but approximate algorithms for inferring invariants in large-scale systems. The computational complexity of new randomized algorithms is significantly reduced and experimental results from a real system are also included to demonstrate the accuracy and efficiency of our new algorithms.


#*Whose call is it? Targeting universal service programs to low-income households' telecommunications preferences
#@Janice A. Hauge,Eric P. Chiang,Mark A. Jamison
#t2009
#cTelecommunications Policy
#index71886
#!Do universal service programs give customers what they want? This paper uses new survey data to study low-income households' telecommunications choices in the United States and to consider the degree to which such households' preferences are addressed by existing universal service programs. The research shows that households that choose only one form of telecommunications increasingly are choosing a mobile phone, while those that choose to have both modes of communications are shifting their usage towards their mobile phones. These trends are less pronounced among higher-income households. One implication for universal service policy is that traditional subsidies for landline phones are increasingly ineffective in reaching low-income households such subsidies are designed to help; subsidies for acquiring and using mobile phone services might be more beneficial to low-income households than traditional subsidies for landline phones.


#*KCMAC: A Novel Fuzzy Cerebellar Model for Medical Decision Support
#@S. D. Teddy
#t2008
#cProceedings of the 18th international conference on Artificial Neural Networks, Part II
#index388978
#!Most of the current advanced clinical decision support systems rely on some form of computational intelligence methodologies. As the machine intelligence paradigm shifted towards brain-inspired computing approach, it is interesting to investigate the performance of such a computing methodology in clinical data analysis. The human cerebellum constitutes a vital part of the brain system that possesses the capability to accurately model highly nonlinear physical dynamics. This paper presents a novel brain-inspired computational model of the human cerebellum named the kernel density-based CMAC (KCMAC) model for clinical decision support. The structure of the KCMAC model is inspired by the neurophysiological aspects of cerebellar learning and development process. The proposed KCMAC model is then applied to two medical case studies; namely, breast cancer diagnosis and the modeling of the human glucose metabolic process. The experimental results are encouraging.


#*Query Translation and Expansion for Searching Normal and OCR-Degraded Arabic Text
#@Tarek Elghazaly,Aly Fahmy
#t2009
#cProceedings of the 10th International Conference on Computational Linguistics and Intelligent Text Processing
#index73132
#!This paper provides a novel model for English/Arabic Query Translation to search Arabic text, and then expands the Arabic query to handle Arabic OCR-Degraded Text. This includes detection and translation of word collocations, translating single words, transliterating names, and disambiguating translation and transliteration through different approaches. It also expands the query with the expected OCR-Errors that are generated from the Arabic OCR-Errors simulation model which proposed inside the paper. The query translation and expansion model has been supported by different libraries proposed in the paper like a Word Collocations Dictionary, Single Words Dictionaries, a Modern Arabic corpus, and other tools. The model gives high accuracy in translating the Queries from English to Arabic solving the translation and transliteration ambiguities and with orthographic query expansion; it gives high degree of accuracy in handling OCR errors.


#*Error Correcting Codes from Quasi-Hadamard Matrices
#@V. Álvarez,J. A. Armario,M. D. Frau,E. Martin,A. Osuna
#t2007
#cProceedings of the 1st international workshop on Arithmetic of Finite Fields
#index408608
#!Levenshtein described in [5] a method for constructing error correcting codes which meet the Plotkin bounds, provided suitable Hadamard matrices exist. Uncertainty about the existence of Hadamard matrices on all orders multiple of 4 is a source of difficulties for the practical application of this method. Here we extend the method to the case of quasi-Hadamard matrices. Since efficient algorithms for constructing quasi-Hadamard matrices are potentially available from the literature (e.g. [7]), good error correcting codes may be constructed in practise. We illustrate the method with some examples.


#*Characterizing fault tolerance in genetic programming
#@Daniel Lombraña González,Francisco Fernández de Vega,Henri Casanova
#t2009
#cProceedings of the 2009 workshop on Bio-inspired algorithms for distributed systems
#index137106
#%92982
#%106414
#%237848
#%263627
#%299680
#%542574
#%445168
#!Evolutionary Algorithms (EAs), and particularly Genetic Programming (GP), are techniques frequently employed to solve difficult real-life problems, which can require up to days or months of computation. One approach to reduce the time to solution is to use parallel computing on distributed platforms. Distributed platforms are prone to failures, and when these platforms are large and/or low-cost, failures are expected events rather than catastrophic exceptions. Therefore, fault tolerance and recovery techniques often become necessary. It turns out that Parallel GP (PGP) applications have an inherent ability to tolerate failures. This ability is quantified via simulation experiments performed using failure traces from real-world distributed platforms, namely, desktop grids (DGs), for two well-known GP problems. A simple technique is then proposed by which PGP applications can better tolerate the different, and often high, failures rates seen in different platforms.


#*A Ubiquitous Computing Network Framework for Assisting People in Urban Areas
#@Minsoo Lee,Yoonsik Uhm,Zion Hwang,Yong Kim,Joohyung Jo,Sehyun Park
#t2007
#cProceedings of the 32nd IEEE Conference on Local Computer Networks
#index337760
#!This paper presents a framework to address the combination of ubiquitous computing interests as an Intelligent Assisting Location-Aware Service and development of its hardware and software systems. In our real testbed, the system can dynamically localize the areas of interest and adapt to changes in the ubiquitous intelligence landscape.


#*Column-matching based mixed-mode test pattern generator design technique for BIST
#@Petr Fišer,Hana Kubátová
#t2008
#cMicroprocessors Microsystems
#index44380
#%306845
#%449677
#%81895
#%577095
#%557252
#%350400
#%441729
#%307014
#!A novel test-per-clock built-in self-test (BIST) equipment design method for combinational or full-scan sequential circuits is proposed in this paper. Particularly, the test pattern generator is being designed. The method is based on similar principles as are well known test pattern generator design methods, like bit-fixing and bit-flipping. The novelty comprises in proposing a brand new algorithm to synthesize the test pattern generator. In principle, we synthesize a combinational block - the decoder, transforming pseudo-random code words into deterministic test patterns pre-computed by an ATPG tool. The column-matching algorithm to design the decoder is proposed. Here the maximum of output variables of the decoder is tried to be matched with the decoder inputs, yielding the outputs be implemented as mere wires, thus without any logic. No memory elements are needed to store the test patterns, which reduces the BIST area overhead. Our BIST exploits mixed-mode testing principles. The BIST execution is divided into two disjoint phases - the pseudorandom phase and the deterministic phase. This enables to reach high fault coverage in a short test time and with a low area overhead. The choice of the lengths of the two phases directly influences the test time, BIST design time and BIST area overhead. A big effort has been put to a capability of trading-off the design criteria. The method allows for scaling the test time, BIST area overhead, BIST design time, etc. The time complexity of the algorithm is studied and experimentally evaluated.


#*Ultrawideband directsequence impulse radio wireless communications -- Dissertation
#@Chu Xiaoli
#t2006
#c
#index10638


#*Democratic group signatures with collective traceability
#@Xiangxue Li,Dong Zheng,Kefei Chen,Jianhua Li
#t2009
#cComputers and Electrical Engineering
#index494328
#%256141
#%277549
#%277797
#!Recently, democratic group signatures (DGSs) particularly catch our attention due to their great functionalities, i.e., no group manager, anonymity, and individual traceability. In existing DGS schemes, individual traceability says that any member in the group can reveal the actual signer's identity from a given signature. In this paper, we strengthen the security notions of DGS by taking insider attack against anonymity into account, and present a concrete DGS construction with collective traceability. The idea behind collective traceability is that a sender can first choose (ad-hoc) a set of n members (including himself), and then sign a message by using the public keys of all the members, in such a way that his identity would be recovered, in case of disputes, if and only if all n members collectively cooperate. The security properties of our scheme are formally proved under reasonable assumptions.


#*Dynamic Evolution Systems and Applications in Intrusion Detection Systems
#@Xian-Ming Xu,Justin Zhan
#t2008
#cProceedings of the 2008 International Conference on Information Security and Assurance (isa 2008)
#index48500
#!In this paper, we present a dynamic evolution system and build up a model to trace the transition of the system state. This new model differs from the previous methods, such as Bayesian network, artificial neural network, in two aspects: it can adapt the changes of the environment automatically, and it does not need a special training phase to build up a model. Theoretical analysis shows that it is applicable and practical, and furthermore, experimental results show that it has good performance especially in dynamic environment.


#*Mobile Payment: Towards a Customer-Centric Model
#@Krassie Petrova
#t2008
#cProceedings of the 2008 international workshops on Web Information Systems Engineering
#index391113
#!Mobile payment normally occurs as a wireless transaction of monetary value and includes the initiation, authorization and the realization of the payment. Such transactions are facilitated by purpose-built mobile payment systems that are part of the service infrastructure supporting the functioning of mobile business applications. A number of stakeholder groups may be involved in concluding a mobile payment transaction, among them customers, mobile operators, financial institutions, merchants, and intermediaries. In this paper, mobile payment systems are characterised from the point of view of the stakeholder groups. Building on existing work, a supply and demand model for the investigation of mPayment services is presented, and applied to a case study.


#*Plenary lecture 3: statistical global metabolic control analysis
#@Zelimir Kurtanjek
#t2009
#cProceedings of the 10th WSEAS international conference on Mathematics and computers in biology and chemistry
#index139929
#!Metabolic Control Analysis (MCA) is a mathematical theory stemming from elec-trical engineering network analysis applied to biological systems. Availability of annotated genome, metabolomics and proteomics of numerous industrial important microorganism leads fundamental research of industrial microbiology "in silico". From engineering point of view, open are possibilities for computer design of synthetic genome for development of new tech-nologies, most importantly for bioenergetics based on synthetic microorganism with integrated photosynthesis and fermentation metabolisms. The main obstacles toward this far reaching goal are not in chemical synthesis of genome, but rather in biological and computer analysis of intricate metabolism control on a molecular level. At present, most of MCA analy-sis is based on steady state (homeostatic constraint) analysis and study of "one factor at a time" infinitesimal effects of perturbations of each individual enzyme and metabolite concen-tration on metabolic fluxes and individual reaction rates. This work introduces the concept of global sensitivity based on simultaneous variation of a complete set of enzymes and metabo-lite concentrations (elasticities) in finite ranges of activities (concentrations). Perturbations are defined by corresponding finite ranges of concentrations and corresponding general probabil-ity density distributions. The flux sensitivities are determined as first and second order rela-tive multidimensional variances. The first order effects are reflection of variation of each individual enzyme. Importantly, the second order effects imply synergic effects of the whole ensemble of enzymes which completely escapes in the traditional MCA analysis. The disper-sions of fluxes due to each enzyme are evaluated through computer simulation and Fourier Amplitude Sensitivity Test algorithm. The implications of the proposed theory are demon-strated by computer simulation of theoretical metabolism pathways and experimental analysis of E. coli central metabolism unsteady perturbation by glucose impulse.


#*Stronger Domain Name System Thwarts Root-Server Attacks
#@George Lawton
#t2007
#cComputer
#index432078
#!Domain Name System security measures and quick, coordinated responses by Internet engineers are helping to make distributed denial-of-service attacks less effective.


#*Self-Configuration of Network Security
#@Huoping Chen,Youssif B. Al-Nashif,Guangzhi Qu,Salim Hariri
#t2007
#cProceedings of the 11th IEEE International Enterprise Distributed Object Computing Conference
#index344915
#!The proliferation of networked systems and services along with their exponential growth in complexity and size has increased the control and management complexity of such systems and services by several orders of magnitude. As a result, management tools have failed to cope with and handle the complexity, dynamism, and coordination among network attacks. In this paper, we present a self-configuration approach to control and manage the security mechanisms of large scale networks. Self-configuration enables the system to automatically configure security system and change the configuration of its resources and their operational policies at runtime in order to manage the system security. Our Self-configuration approach is implemented using two software modules: Component Management Interface (CMI) to specify the configuration and operational policies associated with each component that can be a hardware resource or a software component; and Component Runtime Manger (CRM) that manages the component operations using the policies defined in CMI. We have used the Self-configuration framework to experiment with and evaluate different mechanisms and strategies to detect and protect against a wide range of network attacks.


#*How Useful Are Tags? -- An Empirical Analysis of Collaborative Tagging for Web Page Recommendation
#@Daniel Zeng,Huiqian Li
#t2008
#cProceedings of the IEEE ISI 2008 PAISI, PACCF, and SOCO international workshops on Intelligence and Security Informatics
#index392221
#!As a representative Web 2.0 application, collaborative tagging has been widely adopted and inspires significant interest from academies. Roughly, two lines of research have been pursued: (a) studying the structure of tags, and (b) using tag to promote Web search. However, both of them remain preliminary. Research reported in this paper is aimed at addressing some of these research gaps. First, we apply complex network theory to analyze various structural properties of collaborative tagging activities to gain a detailed understanding of user tagging behavior and also try to capture the mechanism that can help explain such tagging behavior. Second, we conduct a preliminary computational study to utilize tagging information to help improve the quality of Web page recommendation. The results indicate that under the user-based recommendation framework, tags can be fruitfully exploited as they facilitate better user similarity calculation and help reduce sparsity related to past user-Web page interactions.


#*Modeling methodology b: COTS simulation package interoperability standards II
#@
#t2006
#cProceedings of the 38th conference on Winter simulation
#index12746


#*Towards Sensor Integration into Multimedia Applications
#@Christine Louberry,Philippe Roose,Marc Dalmau
#t2007
#cProceedings of the Fourth European Conference on Universal Multiservice Networks
#index421477
#!Since few years, several applications are proposed on mobile devices. However, these applications are not aware of their physical environment. The emergence of wireless sensors, able to monitor their close environment, can provide this service to such applications. This implies an exchange of information between sensors and software components, but they do not use the same communication mode (different protocols, different data structures). In this paper, we are interested in the design of multimedia flow in this type of sensors. We propose a unique component model that enables collaboration between different components without knowing if there are hardware or software and we also propose different mechanisms to transform data between such heterogeneous components.


#*D&D Tactics (Prima Official Game Guide)
#@Bryan Dawson
#t2007
#c
#index11384


#*Levy models and long correlations applied to the study of exchange traded funds
#@M. C. Mariani,J. D. Libbin,K. J. Martin,E. Ncheuguim,M. P. Beccar Varela,V. Kumar Mani,C. A. Erickson,D. J. Valles-Rosales
#t2009
#cInternational Journal of Computer Mathematics
#index138823
#!This work is devoted to the study of statistical properties of Exchange Traded Funds (ETF). Some of the leading ETF in the market are analysed by using the Hurst and DFA methods to detect long range correlations, and the Levy models to describe the return distributions. It is concluded that the statistical behaviour of the ETF is very similar to the behaviour of the corresponding financial indices that they mimic.


#*Japanese Hand Sign Recognition System
#@Hirotada Fujimura,Yuuichi Sakai,Hiroomi Hikawa
#t2007
#cNeural Information Processing: 14th International Conference, ICONIP 2007, Kitakyushu, Japan, November 13-16, 2007, Revised Selected Papers, Part I
#index397940
#!This paper discusses a Japanese hand sign recognition system with a simple classifier network. In the system, input hand images are preprocessed through horizontal/vertical projection followed by discrete Fourier transforms (DFTs) that calculate the magnitude spectrum. The magnitude spectrum is used as the feature vector. Use of the magnitude spectrum makes the system very robust against the position changes of the hand image. The final classification is carried out by the classifier network, which uses simple neurons. Each neuron evaluates the possibility of the input vector belonging to assigned cluster. From the evaluation results, the hand sign is identified. The feasibility of the system is verified by simulations. The simulation results show that the average recognition rate of the system is 93% even though the hand positions are changed randomly.


#*Grooming of traffic using improved evolutionary algorithm in universal optical network
#@Yishi Han,Zhanbin Ao
#t2008
#cProceedings of the 2008 International Conference on Advanced Infocomm Technology
#index63156
#%335373
#!In this paper, the traffic grooming based on Adaptive Immune Evolutionary Algorithm (AIEA) was proposed. The problem of traffic grooming was formulated in optical networks, including main constrain, upper limit and optimized objectives. The process of AIEA was also given by flowchart. Computer simulations were performed with arbitrary traffic pattern and universal optical network topologies, such as ring networks and mesh networks. Comparison with other heuristic algorithms, the results show AIEA has better resource utilization, good convergence rate and global optimization features in optical network, especial in complex mesh optical network.


#*Reviews: iPod + rockbox = entertainment extravaganza
#@Shawn Powers
#t2008
#cLinux Journal
#index41600


#*Relaxed maximum a posteriori fault identification
#@Argyrios Zymnis,Stephen Boyd,Dimitry Gorinevsky
#t2009
#cSignal Processing
#index63234
#%484762
#%153962
#%84300
#!We consider the problem of estimating a pattern of faults, represented as a binary vector, from a set of measurements. The measurements can be noise corrupted real values, or quantized versions of noise corrupted signals, including even 1-bit (sign) measurements. Maximum a posteriori probability (MAP) estimation of the fault pattern leads to a difficult combinatorial optimization problem, so we propose a variation in which an approximate maximum a posteriori probability estimate is found instead, by solving a convex relaxation of the original problem, followed by rounding and simple local optimization. Our method is extremely efficient, and scales to very large problems, involving thousands (or more) of possible faults and measurements. Using synthetic examples, we show that the method performs extremely well, both in identifying the true fault pattern, and in identifying an ambiguity group, i.e., a set of alternate fault patterns that explain the observed measurements almost as well as our estimate.


#*Heuristics And Qualitative Rules For The Performance Design Of Collaborative Systems
#@Tad Gonsalves,Kiyoshi Itoh
#t2006
#cJournal of Integrated Design Process Science
#index48129
#%214879
#!The domain expert's heuristics in the performance design and improvement of collaborative systems are systematized as Qualitative rules. A knowledge base system built by using the Qualitative rules diagnoses the bottlenecks in the system operation and suggests improvements or tuning. However, the bottlenecks cannot be completely resolved due to the constraints imposed on the system resources. In such a case, our strategy is to resolve the local bottlenecks, while maintaining the global stability of the system. To enforce this strategy, we demarcate the system model into local, upstream and downstream sections, and set up the Qualitative improvement rules for each of these sections. A performance improvement task is then guided by a set of local, forward propagation, backward propagation and global rules. Local rules correspond to a local improvement. When the local rules fail to yield satisfactory results, the backward propagation rules are called upon to indicate the improvements to be made in the upstream of the network so as to resolve the problematic local bottleneck. The forward propagation rules estimate the effects on the downstream of the network due to the resolution of the chosen bottleneck. Finally, the advisability of resolving a local bottleneck, while keeping the global adverse effects to a minimum, is given by the global rules.


#*Matching Hierarchies Using Shared Objects
#@Robert Ikeda,Kai Zhao,Hector Garcia-Molina
#t2008
#cProceedings of the 12th European conference on Research and Advanced Technology for Digital Libraries
#index410604
#!One of the main challenges in integrating two hierarchies (e.g., of books or web pages) is determining the correspondence between the edges of each hierarchy. Traditionally, this process, which we call hierarchy matching, is done by comparing the text associated with each edge. In this paper we instead use the placement of objects present in both hierarchies to infer how the hierarchies relate. We present two algorithms that, given a hierarchy with known facets (attribute-value pairs that define what objects are placed under an edge), determine feasible facets for a second hierarchy, based on shared objects. One algorithm is rule-based and the other is statistics-based. In the experimental section, we compare the results of the two algorithms, and see how their performances vary based on the amount of noise in the hierarchies.


#*Neural Network Modeling of a Magnetorheological Damper
#@Mauricio Zapateiro,Ningsu Luo
#t2007
#cProceeding of the 2007 conference on Artificial Intelligence Research and Development
#index134377
#!This paper presents the results of modeling a magnetorheological (MR) damper by means of a neural network. TheMR damper is a device extensively used to mitigate hazardous vibrations in systems such as vehicles, bridges and buildings. The advantages of these dampers over other devices of their class rely on the cost, size, simplicity and performance. However, these devices are highly nonlinear; their dynamics is characterized by friction and hysteresis, phenomena that has been difficult to model following physical laws. In this paper, a recurrent neural network is trained to reproduce the behavior of the damper and it will be shown that the results are better that those obtained by approximate physical models.


#*A Consistency-Based Secure Localization Scheme against Wormhole Attacks in WSNs
#@Honglong Chen,Wei Lou,Zhi Wang
#t2009
#cProceedings of the 4th International Conference on Wireless Algorithms, Systems, and Applications
#index500232
#!Wormhole attacks can negatively affect the localization in wireless sensor networks. A typical wormhole attack can be launched by two colluding external attackers, one of which sniffs packets at one point in the network, tunnels them through a wired or wireless link to another point, and the other of which relays them within its vicinity. In this paper, we investigate the impact of the wormhole attack on the localization process and propose a novel consistency-based secure localization scheme against wormhole attacks, which includes wormhole attack detection, valid locators identification and self-localization. We also conduct the simulations to demonstrate the effectiveness of our proposed scheme.


#*On learning thresholds of parities and unions of rectangles in random walk models
#@Sébastien Roch
#t2007
#cRandom Structures Algorithms
#index349459
#!In a recent breakthrough, [Bshouty et al., J Comput Syst Sci 71 (2005), 250265] obtained the first passive-learning algorithm for DNFs under the uniform distribution. They showed that DNFs are learnable in the Random Walk and Noise Sensitivity models. We extend their results in several directions. We first show that thresholds of parities, a natural class encompassing DNFs, cannot be learned efficiently in the Noise Sensitivity model using only statistical queries. In contrast, we show that a cyclic version of the Random Walk model allows to learn efficiently polynomially weighted thresholds of parities. We also extend the algorithm of Bshouty et al. to the case of Unions of Rectangles, a natural generalization of DNFs to {0, ,b - 1}n. &copy; 2007 Wiley Periodicals, Inc. Random Struct. Alg., 2007


#*The Phonemic Approach for Sanskrit Text
#@R. K. Joshi,T. N. Dharmadhikari,Vijay Vasudev Bedekar
#t2009
#cSanskrit Computational Linguistics: First and Second International Symposia Rocquencourt, France, October 29-31, 2007 Providence, RI, USA, May 15-17, 2008 Revised Selected and Invited Papers
#index55734
#!Professor Joshi proposes that a phonemic encoding scheme be adopted as the standard for machine processing of Sanskrit text. In the scheme he details, each phoneme is represented by a single character code that represents a single Sanskrit sound. Graphic units in Devanagari corresponding to syllabic units, including consonant plus /a/, are represented as sequences. Glyphs corresponding to intial vowels verses dependent vowels are not given distinct encodings; rather they are selected based upon context. (P. Scharf)


#*Scaling parallel I/O performance through I/O delegate and caching system
#@Arifa Nisar,Wei-keng Liao,Alok Choudhary
#t2008
#cProceedings of the 2008 ACM/IEEE conference on Supercomputing
#index396980
#%157343
#%222177
#%339680
#%363684
#%589603
#!Increasingly complex scientific applications require massive parallelism to achieve the goals of fidelity and high computational performance. Such applications periodically offload checkpointing data to file system for post-processing and program resumption. As a side effect of high degree of parallelism, I/O contention at servers doesn't allow overall performance to scale with increasing number of processors. To bridge the gap between parallel computational and I/O performance, we propose a portable MPI-IO layer where certain tasks, such as file caching, consistency control, and collective I/O optimization are delegated to a small set of compute nodes, collectively termed as I/O Delegate nodes. A collective cache design is incorporated to resolve cache coherence and hence alleviates the lock contention at I/O servers. By using popular parallel I/O benchmark and application I/O kernels, our experimental evaluation indicates considerable performance improvement with a small percentage of compute resources reserved for I/O.


#*A novel fabrication process of MEMS devices on polyimide flexible substrates
#@S. Y. Xiao,L. F. Che,X. X. Li,Y. L. Wang
#t2008
#cMicroelectronic Engineering
#index351200
#!Micro-electro-mechanic-system (MEMS) devices on flexible substrate are important for non-planar and non-rigid surface applications. In this paper, a novel and cost-effective fabrication process for an 8x8 MEMS temperature sensor array with a lateral dimension of 2.5mmx5.5mm on a polyimide flexible substrate is developed. A 40@mm thick polyimide substrate is formed on a rigid silicon wafer using as a mechanical carrier throughout the fabrication by four successive spin coating liquid polyimide. The arrayed temperature sensing elements made of 1200A sputtered platinum thin film on polyimide substrate show excellent linearity with a temperature coefficient of resistance of 0.0028/^oC. The purposed sensor obtains a high sensitivity of 0.781@W/^oC at 8mA at constant drive current. Because of the low heat capacity and excellent thermal isolation, the temperature sensing element shows excellent high sensitivity and a fast thermal response. The finished devices are flexible enough to be folded and twisted achieving any desired shape and form. Employing spin-coated liquid polyimide substrate instead of solid polyimide sheet minimizes the thermal cycling as well as improves the production yield. This fabrication technique first introduces the spin-coated PDMS (Polydimethylsiloxane) interlayer between the silicon carrier and the polyimide substrate and makes the polyimide-based devices separate much easier and greatly simplifies the fabrication process with a high production yield. A non-successive two-stage cure procedure for the polyimide precursor is developed to meet low-temperature requirement of the PDMS interlayer. The fabrication procedure developed in this research is compatible with conventional MEMS technology through an optimized integration process. The novel flexible MEMS technology can benefit the development of other new flexible polyimide-based devices.


#*GATE to Accessibility of Computer Graphics
#@Ivan Kopeček,Radek Ošlejšek
#t2008
#cProceedings of the 11th international conference on Computers Helping People with Special Needs
#index387842
#!This paper presents a framework for integrating current information technologies into a platform enabling the blind and visually impaired people to access computer graphics based on the annotated SVG format. We also present a technique enabling the conversion of any graphical object to the annotated SVG format and easy annotation supported by OWL based ontology. This approach is not limited to vector graphics only, but enables also the flexible annotation and application of raster graphics (e.g. photographs). We briefly describe the architecture of the GATE (Graphics Accessible To Everyone) project, which contains the corresponding implemented modules. As an illustration, we provide an example showing how the blind can access the annotated graphics.


#*Visualization Model of Virtual Plant Growth and its Application
#@Qingrong Zhang,Wenyong Wang,Shaochun Zhong,Ying Liang,Qian Xu,Xiaolin Quan
#t2006
#cProceedings of the 16th International Conference on Artificial Reality and Telexistence--Workshops
#index415856
#!The virtual plant is a research area which develops rapidly along with the development of computer simulation technology, it has become the research hot spot in computer graphics, agriculture information technology and virtual teaching. In the paper, we apply the fractal theory in simulating plants growth process on computer. The constructed plant model can reflect the realistic plants' shape structure and its physiological phenomenon. The timer is used to realize the dynamic control of virtual plants' growth. The visualization model of virtual plants' dynamic growth is applied to the biological teaching, and we obtain a satisfactory result.


#*The Book: The Life Story of a Technology (Greenwood Technographies)
#@Nicole Howard
#t2005
#c
#index872


#*Highly scalable server architecture for massive multi-player 3D virtual spaces
#@Moldoveanu Alin Dragos Bogdan,Moldoveanu Florica,Asavei Victor
#t2009
#cProceedings of the international conference on Computational and information science 2009
#index142380
#%54647
#!3D massive multiplayer virtual spaces are getting more and more popular, not only as computer games but as complex simulation and interaction environments, heading to become the next paradigm of multi-user interface. Still their universal adoption is hindered by some serious practical issues, mainly revolving around development costs and scalability limitations. The authors consider that the main cause for these limitations resides in the particularities of server-side software architectures - traditionally designed as clusters of single processor machines. The paper gives a brief overview of current solutions and their limitations and propose two innovative architectural concepts which have a big potential for creating cheaper and more scalable solutions. We describe a region based decomposition of the virtual space together with supporting middlewares of messaging, distributed control and persistence, which allow an efficient and flexible work effort distribution on server side. The solution allows for both horizontal and vertical scalability The vertical scalability is then mapped in an innovative manner on the last generation of SIMD-like multi-processor graphics cards. The huge processing power of these cards, with the right architecture, can take over the bulk of the server-side effort. Our prototype tests indicated that the solution is feasible and may represent an important turnaround in the development of more scalable and much cheaper massive multi-player server architectures for various types of virtual spaces.


#*Analytical High-Level Power Model for LUT-Based Components
#@Ruzica Jevtic,Carlos Carreras
#t2009
#cIntegrated Circuit and System Design. Power and Timing Modeling, Optimization and Simulation: 18th International Workshop, PATMOS 2008, Lisbon, Portugal, September 10-12, 2008. Revised Selected Papers
#index69226
#!This paper presents an extended high-level model for logic power estimation of multipliers and adders implemented in FPGAs in the presence of glitching and correlation. The model is based on an analytical computation of the switching activity produced in the component and the FPGA implementation details of the component structure. It is extended to consider operands of different word-lengths, both zero-mean and non-zero mean signals, and the glitching produced inside the component, taking into account the sign nature of the autocorrelation coefficients of the components' inputs. The number of simulations needed for the model characterization is extremely small and can be reduced to only two. As the final power model is analytical, it is capable of providing power estimates in miliseconds. The results show that the mean relative error is within 10% of low-level power estimates given by the XPower tool.


#*Querying Encrypted XML Documents
#@Ravi Chandra Jammalamadaka,Sharad Mehrotra
#t2006
#cProceedings of the 10th International Database Engineering and Applications Symposium
#index32159
#!This paper proposes techniques to query encrypted XML documents. Such a problem predominantly occurs in "Database as a Service (DAS) architectures, where a client may outsource data to a service provider that provides data management services. Security is of paramount concern, as the service provider itself may be untrusted. Encryption offers a natural solution to preserve the confidentiality of the client's data. The challenge now is to execute queries over the encrypted data, without decrypting them at the server side. In this paper we develop: 1) primitives using which a client can specify the sensitive parts of the XML documents; 2) mechanisms to map the XML documents to encrypted representations that hides sensitive portions of the documents; and 3) techniques to run SPJ (Selection-projection-join) queries over encrypted XML documents. A strategy, where indices/ancillary information is maintained along with the encrypted XML documents is exploited, which helps in pruning the search space during query processing.


#*A Vision-Based Control and Interaction Framework for a Legged Underwater Robot
#@Junaed Sattar,Gregory Dudek
#t2009
#cProceedings of the 2009 Canadian Conference on Computer and Robot Vision
#index498642
#!We present a vision-based control and interaction framework for mobile robots, and describe its implementation in a legged amphibious robot. The control scheme enables the robot to navigate, follow targets of interest, and interact with human operators. The visual framework presented in this paper enables deployment of the vehicle in underwater environments along with a human scuba diver as the operator, without requiring any external tethered control. We present the current implementation of this framework in our particular family of underwater robots, with a focus on the underlying software and hardware infrastructure. We look at the practical issues pertaining to system implementation as it applies to our framework, from choice of operating systems to communication bus design. While our system has been effectively used in both open-ocean andclosed-water environments, we perform some quantitative measurements with an effort to analyze the responsiveness and robustness of the complete architecture.


#*Learning dictionaries of stable autoregressive models for audio scene analysis
#@Youngmin Cho,Lawrence K. Saul
#t2009
#cProceedings of the 26th Annual International Conference on Machine Learning
#index131855
#%71822
#%299297
#!In this paper, we explore an application of basis pursuit to audio scene analysis. The goal of our work is to detect when certain sounds are present in a mixed audio signal. We focus on the regime where out of a large number of possible sources, a small but unknown number combine and overlap to yield the observed signal. To infer which sounds are present, we decompose the observed signal as a linear combination of a small number of active sources. We cast the inference as a regularized form of linear regression whose sparse solutions yield decompositions with few active sources. We characterize the acoustic variability of individual sources by autoregressive models of their time domain waveforms. When we do not have prior knowledge of the individual sources, the coefficients of these autoregressive models must be learned from audio examples. We analyze the dynamical stability of these models and show how to estimate stable models by substituting a simple convex optimization for a difficult eigenvalue problem. We demonstrate our approach by learning dictionaries of musical notes and using these dictionaries to analyze polyphonic recordings of piano, cello, and violin.


#*Improved Bounds on Security Reductions for Discrete Log Based Signatures
#@Sanjam Garg,Raghav Bhaskar,Satyanarayana V. Lokam
#t2008
#cProceedings of the 28th Annual conference on Cryptology: Advances in Cryptology
#index389298
#!Despite considerable research efforts, no efficient reduction from the discrete log problem to forging a discrete log based signature (e.g. Schnorr) is currently known. In fact, negative results are known. Paillier and Vergnaud [PV05] show that the forgeability of several discrete log based signatures cannot be equivalent to solving the discrete log problem in the standard model, assuming the so-called one-more discrete log assumption and algebraic reductions. They also show, under the same assumptions, that, any security reduction in the Random Oracle Model (ROM) from discrete log to forging a Schnorr signature must lose a factor of at least $\sqrt{q_h}$ in the success probability. Here q h is the number of queries the forger makes to the random oracle. The best known positive result, due to Pointcheval and Stern [PS00], also in the ROM, gives a reduction that loses a factor of q h . In this paper, we improve the negative result from [PV05]. In particular, we show that any algebraic reduction in the ROM from discrete log to forging a Schnorr signature must lose a factor of at least $q_h^{2/3}$, assuming the one-more discrete log assumption. We also hint at certain circumstances (by way of restrictions on the forger) under which this lower bound may be tight. These negative results indicate that huge loss factors may be inevitable in reductions from discrete log to discrete log based signatures.


#*Hybrid digital-analog coding with bandwidth compression for Gaussian source-channel pairs
#@Yadong Wang,Fady Alajaji,Tamás Linder
#t2009
#cIEEE Transactions on Communications
#index19118
#!Three hybrid digital-analog (HDA) systems, denoted by HDA-I, HDA* and HDA-II, for the coding of a memoryless discrete-time Gaussian source over a discrete-time additive memoryless Gaussian channel under bandwidth compression are studied. The systems employ simple linear coding in their analog component and superimpose their analog and digital signals before channel transmission. Information-theoretic upper bounds on the asymptotically optimal mean squared error distortion of the systems are obtained under both matched and mismatched channel conditions. Allocation schemes for distributing the channel input power between the analog and the digital signals are also examined. It is shown that systems HDA* and HDA-II can asymptotically achieve the optimal Shannon-limit performance under matched channel conditions. Low-complexity and low-delay versions of systems HDA-I and HDA-II are next designed and implemented without the use of error correcting codes. The parameters of these HDA systems, which employ vector quantization in conjunction with binary phase-shift keying modulation in their digital part, are optimized via an iterative algorithm similar to the design algorithm for channel-optimized vector quantizers. Both systems have low complexity and low delay, and guarantee graceful performance improvements for high CSNRs. For memoryless Gaussian sources the designed HDA-II system is shown to be superior to the HDA-I designed system. When applied to a Gauss-Markov source under Karhunen-Loeve processing, the HDA-I system is shown to provide considerably better performance.


#*Universal Display Book for PIC Microcontrollers
#@Richard Grodzik
#t2008
#c
#index65265


#*Formal concept analysis applied to fault localization
#@Peggy Cellier
#t2008
#cCompanion of the 30th international conference on Software engineering
#index43455
#%207703
#%104591
#%575591
#%252685
#!One time-consuming task in the development of software is debugging. Recent work in fault localization crosschecks traces of correct and failing execution traces, it implicitly searches for association rules which indicate that executing a line will most probably cause the whole execution to fail. This technique has some limitations: it assumes that an error has a single faulty statement origin, and that lines are independent. Our research hypothesis is that using association rules with more expressive premises, some limitations can be alleviated. The solution that we propose combines association rules and formal concept analysis. Our technique is already usable when the size of the execution traces is not too large. We conjecture that the technique can be used to analyze large executions, thanks to the information contained in the Abstract Syntax Tree.


#*Wavelet-based multiresolution analysis of ridges for fingerprint liveness detection
#@Shankar Bhausaheb Nikam,Suneeta Agarwal
#t2009
#cInternational Journal of Information and Computer Security
#index126618
#%28847
#%31987
#%32853
#%2121
#%448151
#%531457
#%311413
#%146978
#%471236
#%425221
#%371037
#%333734
#%586607
#!In this paper, a new wavelet-based perspiration detection algorithm is proposed for fingerprint liveness detection. It is based on processing time-series ridge lines in the wavelet domain. The existing perspiration detection algorithm proposed in the literature captures perspiration information by processing ridge lines in the time (spatial) domain. However, for some kinds of fingers (e.g., dry and perspiration-saturated fingers), changes in perspiration are minute. These changes are difficult to extract from the grey-level intensities processed in the time domain. Due to this, such fingers may be misclassified, thus reducing overall accuracy. In practice, we often encounter poor quality, dry or wet fingers. Therefore, it is necessary to take due care of such fingers, and have an enhanced algorithm that can process these fingers as well. To alleviate the problem, this paper discusses a new algorithm that processes time-series ridge lines using the multiresolution theory of wavelets. Major sweating changes are extracted at the coarse level, and then resolution is gradually increased to notice minute details. Such a coarse-to-fine strategy provides us with rich sweating information compared to that obtained directly from grey-level intensities in the time domain, which naturally leads to improved liveness results.


#*Proceedings of the 6th international workshop on Adaptive and reflective middleware: held at the ACM/IFIP/USENIX International Middleware Conference
#@
#t2007
#cMiddleware Conference
#index36717


#*L-Cover: Preserving Diversity by Anonymity
#@Lei Zhang,Lingyu Wang,Sushil Jajodia,Alexander Brodsky
#t2009
#cProceedings of the 6th VLDB Workshop on Secure Data Management
#index501357
#!To release micro-data tables containing sensitive data, generalization algorithms are usually required for satisfying given privacy properties, such as k-anonymity and l-diversity. It is well accepted that k-anonymity and l-diversity are proposed for different purposes, and the latter is a stronger property than the former. However, this paper uncovers an interesting relationship between these two properties when the generalization algorithms are publicly known. That is, preserving l-diversity in micro-data generalization can be done by preserving a new property, namely, l-cover, which is to satisfy l-anonymity in a special way. The practical impact of this discovery is that it may potentially lead to better heuristic generalization algorithms in terms of efficiency and data utility, that remain safe even when publicized.


#*A Quality of Service Support Module (QASM) for a Wireless Multi-Segment Integrated 3G Network
#@Paolo Dini,Francesco Delli Priscoli
#t2007
#cWireless Personal Communications: An International Journal
#index353542
#!Deployment of IP multimedia services with guaranteed Quality of Service (QoS) is a primary requirement for Beyond 3G (B3G) systems. In this paper we propose a new architecture to support Internet QoS-sensitive services (e.g., video-conferencing, voice over IP, interactive gaming), thus providing users with end-to-end QoS guarantees. In particular, the paper discloses a new hybrid Intserv/Diffserv scheme for handling IP packets and an interworking procedure with the RSVP protocol which allows to support QoS over an integrated, multi-segment network. Such scheme is implemented by means of a suitable Quality of service Support Module (QASM). Advantages and drawbacks of QASM are discussed and the impact on both system architecture and Multi-Mode Mobile Terminal is investigated. Performance evaluations, carried out via computer simulations, confirm the effectiveness of the proposed solution.


#*Three models for gene assembly in ciliates: a comparison
#@Miika Langille,Ion Petre,Vladimir Rogojin
#t2008
#cProceedings of the 3rd International Conference on Bio-Inspired Models of Network, Information and Computing Sytems
#index67791
#%29678
#%387561
#%302724
#%389101
#%627687
#!We survey in this paper the main differences among three variants of an intramolecular model for gene assembly: the general, the simple, and the elementary models. We present all of them in terms of sorting signed permutations and compare their behavior with respect to: (i) completeness, (ii) confluence (with the notion defined in three different setups), (iii) decidability, (iv) characterization of the sortable permutations in each model, (v) sequential complexity, and (vi) experimental validation.


#*Agent-Based Semantic Service Discovery for Healthcare: An Organizational Approach
#@Cesar Caceres,Alberto Fernandez,Sascha Ossowski,Matteo Vasirani
#t2006
#cIEEE Intelligent Systems
#index35638
#!This article is part of a special issue on Intelligent Agents in Healthcare. E-health is one of the fastest-growing application areas for intelligent mobile services. The ever-growing number and variety of health-related devices and tasks calls for mechanisms to automatically discover, invoke, and coordinate the corresponding services. This, in turn, requires languages and tools that support a semantically rich description of e-health services. This article focuses on service discovery for medical-emergency management. A new mechanism for semantic service discovery complements existing approaches by considering relevant parts of the organizational context in which e-health services are used, to improve system usability in emergencies. This approach is reusable in other application areas, especially in the medical field.


#*Windows XP from A to Z
#@Pat Coleman
#t2005
#c
#index2896


#*A Flash-Based Mobile Learning System for Learning English as Second Language
#@Firouz B. Anaraki
#t2009
#cProceedings of the 2009 International Conference on Computer Engineering and Technology - Volume 01
#index59214
#!This paper explains the development of a Flash-Based mobile learning system for learning English as a second language (FML4ESL). Adobe Flash CS3 was used to develop this system which works on smart mobile phones and PDAs that support Adobe Flash Lite. Twelve English lessons were developed for this system. University students at Assumption University tried out this system using their mobile devices for a period of 4 weeks. A pretest, posttest, and surveys were used to evaluate the effectiveness and usability of this system.


#*Sensor Network Grids: Agent Environments Combined with QoS in Wireless Sensor Networks
#@Kostas Stathis,Stella Kafetzoglou,Symeon Papavassiliou,Stefano Bromuri
#t2007
#cProceedings of the Third International Conference on Autonomic and Autonomous Systems
#index429530
#!We present a distributed systems architecture that uses Grid computing to combine basic nodes of wireless sensor networks with complex sensor nodes of wired networks. Three kinds of complex sensor nodes are identified: objects, agents and containers. The decision making capabilities of the complex nodes are then combined with a quality of service (QoS) framework for gathering data from the wireless sensor nodes. The resulting combination provides a powerful conceptual framework for developing ambient intelligence and ubiquitous computing applications on the Grid.


#*Advances in online learning-based spam filtering
#@Carla E. Brodley
#t2008
#c
#index128368
#!The low cost of digital communication has given rise to the problem of email spam, which is unwanted, harmful, or abusive electronic content. In this thesis, we present several advances in the application of online machine learning methods for automatically filtering spam. We detail a sliding-window variant of Support Vector Machines that yields state of the art results for the standard online filtering task. We explore a variety of feature representations for spam data. We reduce human labeling cost through the use of efficient online active learning variants. We give practical solutions to the one-sided feedback scenario, in which users only give labeling feedback on messages predicted to be non-spam. We investigate the impact of class label noise on machine learning-based spam filters, showing that previous benchmark evaluations rewarded filters prone to overfitting in real-world settings and proposing several modifications for combating these negative effects. Finally, we investigate the performance of these filtering methods on the more challenging task of abuse filtering in blog comments. Together, these contributions enable more accurate spam filters to be deployed in real-world settings, with greater robustness to noise, lower computation cost and lower human labeling cost.


#*Practical Cryptanalysis of iso/iec 9796-2 and emv Signatures
#@Jean-Sébastien Coron,David Naccache,Mehdi Tibouchi,Ralf-Philipp Weinmann
#t2009
#cProceedings of the 29th Annual International Cryptology Conference on Advances in Cryptology
#index506252
#!In 1999, Coron, Naccache and Stern discovered an existential signature forgery for two popular rsa signature standards, iso/iec 9796-1 and 2. Following this attack iso/iec 9796-1 was withdrawn. iso/iec 9796-2 was amended by increasing the message digest to at least 160 bits. Attacking this amended version required at least 261 operations.In this paper, we exhibit algorithmic refinements allowing to attack the amended (currently valid) version of iso/iec 9796-2 for all modulus sizes. A practical forgery was computed in only two days using 19 servers on the Amazon ec2 grid for a total cost of $\simeq\mbox{{\sc us\$800}}$. The forgery was implemented for e = 2 but attacking odd exponents will not take longer. The forgery was computed for the rsa-2048 challenge modulus, whose factorization is still unknown.The new attack blends several theoretical tools. These do not change the asymptotic complexity of Coron et al.'s technique but significantly accelerate it for parameter values previously considered beyond reach.While less efficient (us$45,000), the acceleration also extends to emv signatures. emv is an iso/iec 9796-2-compliant format with extra redundancy. Luckily, this attack does not threaten any of the 730 million emv payment cards in circulation for operational reasons.Costs are per modulus: after a first forgery for a given modulus, obtaining more forgeries is virtually immediate.


#*Organizing Committees
#@
#t2007
#cProceedings of the 2007 International Conference on Parallel Processing Workshops
#index342149


#*Efficient order basis computation (abstract only)
#@Wei Zhou
#t2008
#cACM Communications in Computer Algebra
#index48493
#!Order basis (also known as 3/4-basis, minimal approximant basis), originally developed by Beckermann and Labahn in 1994 for rational approximation and interpolation problems, has recently been applied to many other important problems in polynomial matrix computation. These include column reduction, matrix inverse, determinant, and null space basis computation. Storjohann, in 2006, provided an efficient way to compute a part of order basis that is within a given degree bound. We extend Storjohann's result by providing a way to compute a complete order basis with a similar computational cos.


#*Design of a self-balancing tower crane
#@J. J. Rubio Avila,R. Alcántara-Ramírez,J. Jaimes-ponce,I. I. Siller-Alcalá
#t2008
#cProceedings of the 2nd WSEAS International Conference on Circuits, Systems, Signal and Telecommunications
#index44175
#!This paper presents the design of a new concept of tower crane, which was greatly reduced the burden and eliminates the anchor, as will be "self-balancing" which involves removing the anchor replaced by a sliding counterweight trolley. The paper involves the design of the mechanics and simulations based on its model and a PID control in order to check optimal performance.


#*Best Practices for Lotus Domino on System Z Z9 And Zseries
#@Mike Ebbers
#t2006
#c
#index7337


#*A Multi-stage Graph Decomposition Algorithm for Distributed Constraint Optimisation
#@Terence H. -W. Law,Adrian R. Pearce
#t2006
#cProceedings of the IEEE/WIC/ACM international conference on Intelligent Agent Technology
#index33684
#%286236
#%447358
#!In this paper, we propose a novel approach to solving the distributed constraint optimisation problem (DCOP) that guarantees completeness, while having linear communication complexity. The key to performance advantages, in terms of both computation and communication, derives from the application of the repeatedly-half principle to manage complexity by a combination of problem distribution through graph decomposition and multi-stage solution quality propagation. Experimental result shows that our new algorithm is faster than a recent competitive distributed algorithm for solving MaxSAT graph colouring problems. It also indicates the potential for the decomposition approach over a centralised method based on the same search strategy, and is consistent with recent results on domain propagation and structural decomposition in the CSP literature.


#*301 Inkjet Tips and Techniques: An Essential Printing Resource for Photographers
#@Andrew Darlow
#t2007
#c
#index7130


#*Predicting fingerprint biometrics performance from a small gallery
#@Rong Wang,Bir Bhanu
#t2007
#cPattern Recognition Letters
#index5558
#%449944
#!Predicting the performance of a biometrics is an important problem in a real-world application. In this paper, we present a binomial model to predict both the fingerprint verification and identification performance. The match and non-match scores are computed, using the number of corresponding triangles as the match metric, between the query and gallery fingerprints. The triangles are formed using the minutiae features. The match score and non-match score in a binomial prediction model are used to predict the performance on large (relative to the size of the gallery) populations from a small gallery. We apply the model to the entire NIST-4 database and show the results for both the fingerprint verification and the identification.


#*Keynote III: Aspect-Oriented Modeling
#@
#t2008
#cProceedings of the 11th international conference on Model Driven Engineering Languages and Systems
#index386796


#*Beyond Theory: Development of a Real World Localization Application as Low Power WSN
#@Marcel Baunach,Reiner Kolla,Clemens Muhlberger
#t2007
#cProceedings of the 32nd IEEE Conference on Local Computer Networks
#index344681
#!The real-world implementation of a just theoretically elaborated idea is sometimes cumbersome, often a couple of obstacles have to be overcome. That's likewise in the area of Wireless Sensor Networks (WSN), but complicated by some further restrictions, e.g. little memory or low power consumption. One well-known and often required application within WSN is the geographical localization of several sensor nodes. That's why this paper deals with some problems arising during the development of a WSN using the time difference of arrival (TDoA) of ultrasound and radio signals for positioning. Its focus is on handling of microcontroller difficulties like little memory, low computational power or low energy consumption as well as hardware driven failures like inaccurate measurements or node failures.


#*Describing and Verifying Web Service Using CCS
#@Li Bao,Weishi Zhang,Xiuguo Zhang
#t2006
#cProceedings of the Seventh International Conference on Parallel and Distributed Computing, Applications and Technologies
#index20525
#!Formal method is an effective way for modeling and verifying concurrent system. An important research field is to describe and verify Web services by formal method. Guaranteeing the validity of Web services composition is necessary for enhancing the value of this composite service. CCS is a kind of process algebra which can be used to model concurrent systems. Web services and their composition are described and modeled based on CCS in this paper. Rules about applying CCS to Web services are explained. Finally, a case study is carried and the validity of composition model is verified. Some important points in verification are discussed.


#*Practical synchronization techniques for multi-channel MAC
#@Hoi-Sheung Wilson So,Giang Nguyen,Jean Walrand
#t2006
#cProceedings of the 12th annual international conference on Mobile computing and networking
#index21771
#%298814
#%100300
#%307018
#%119527
#!Researchers have proposed many wireless MAC protocols such as [20], [8], [25], [24], [6], and [17] which exploit frequency-agile radios and multiple available channels to increase network through-put. These protocols usually only require each node to have one radio. By carefully coordinating the frequency hopping of different nodes, different node pairs can use multiple channels simultaneously. In [17], Mo et al classified these protocols into four generalized categories and compared their performances through both analysis and simulation. They found that the Parallel Rendezvous family of protocols has the best overall performance by removing the bottleneck of a single control channel. These protocols show good promise for use with multi-hop networks because these networks suffer from self-interference and traditional MAC protocols using only one channel often fail to provide satisfactory throughput. However, we are not aware of any implemented Parallel Rendezvous multi-channel MAC protocols. We argue one major reason is that existing proposals such as McMAC[17] and SSCH[6] have not thoroughly considered a practical aspect of the design essential for a working implementation, namely: synchronization. Through an exploration including an implementation exercise on hardware, we show that synchronization for multi-channel MAC protocols is a non-trivial problem. We designed and implemented a synchronization mechanism specifically for this purpose and show that it has tackled the problem of synchronizing one-hop neighbor pairs effectively, thereby paving the way for efficient multi-channel MAC protocols.


#*The Abella Interactive Theorem Prover (System Description)
#@Andrew Gacek
#t2008
#cProceedings of the 4th international joint conference on Automated Reasoning
#index405461
#!Abella [3] is an interactive system for reasoning about aspects of object languages that have been formally presented through recursive rules based on syntactic structure. Abella utilizes a two-level logic approach to specification and reasoning. One level is defined by a specification logic which supports a transparent encoding of structural semantics rules and also enables their execution. The second level, called the reasoning logic, embeds the specification logic and allows the development of proofs of properties about specifications. An important characteristic of both logics is that they exploit the ¿-tree syntax approach to treating binding in object languages. Amongst other things, Abella has been used to prove normalizability properties of the ¿-calculus, cut admissibility for a sequent calculus and type uniqueness and subject reduction properties. This paper discusses the logical foundations of Abella, outlines the style of theorem proving that it supports and finally describes some of its recent applications.


#*1/f Noise Reduction and Image Enhancement on CMOS Image Sensors by Autocorrelation Based on Adaptive Algorithm
#@Kunsu Hwang,T. H. Nishimura
#t2008
#cProceedings of the Advances in Electrical and Electronics Engineering - IAENG Special Edition of the World Congress on Engineering and Computer Science 2008
#index493976
#!In CMOS image sensor, 1/f noise is determined by width and length of gate at the circuit. Reducing the 1/f noise, a correlative multi sampling and an autocorrelation method have been used, mainly. Nevertheless, a correlative multi sampling has a practical problem of limitation which is the band of applied frequency. Because of the problem, an autocorrelation method is used for the reducing of 1/f noise better than correlative multi sampling. General noise reduction filters along with the smoothing effect. In this study, the autocorrelation method based on adaptive algorithm is proposed to reduce the smoothing effect at the edge of image.


#*Improving risk management practices for IT projects
#@Tak Wah Kwan,Hareton K. N. Leung
#t2007
#cProceedings of the third conference on IASTED International Conference: Advances in Computer Science and Technology
#index349114
#%307671
#%624993
#%446528
#%443482
#!Although a number of risk management processes and guidelines have been developed, many IT projects still fail due to inadequate management of project risks. In fact, risk management is an emerging practice to be applied in managing IT projects, and very few studies have been conducted to transfer it into industrial practices. In this paper, some weaknesses are identified in the available tools and techniques that affect the effective use of risk management practices. Two new practices and an implementation model are proposed to address these weaknesses.


#*Bit-interleaved coded multiple beamforming with imperfect CSIT
#@Ersin Sengul,Hong Ju Park,Ender Ayanoglu
#t2009
#cIEEE Transactions on Communications
#index19827
#%162102
#!This paper addresses the performance of bit-interleaved coded multiple beamforming (BICMB) [1], [2] with imperfect knowledge of beamforming vectors. Most studies for limited-rate channel state information at the transmitter (CSIT) assume that the precoding matrix has an invariance property under an arbitrary unitary transform. In BICMB, this property does not hold. On the other hand, the optimum precoder and detector for BICMB are invariant under a diagonal unitary transform. In order to design a limited-rate CSIT system for BICMB, we propose a new distortion measure optimum under this invariance. Based on this new distortion measure, we introduce a new set of centroids and employ the generalized Lloyd algorithm for codebook design. We provide simulation results demonstrating the performance improvement achieved with the proposed distortion measure and the codebook design for various receivers with linear detectors. We show that although these receivers have the same performance for perfect CSIT, their performance varies under imperfect CSIT.


#*The Open-Source Fixed-Point Model Checker for Symbolic Analysis of Security Protocols
#@Sebastian Mödersheim,Luca Viganò
#t2009
#cFoundations of Security Analysis and Design V: FOSAD 2007/2008/2009 Tutorial Lectures
#index492915
#!We introduce the Open-source Fixed-point Model Checker OFMC for symbolic security protocol analysis, which extends the On-the-fly Model Checker (the previous OFMC). The native input language of OFMC is the AVISPA Intermediate Format IF. OFMC also supports AnB, a new Alice-and-Bob-style language that extends previous similar languages with support for algebraic properties of cryptographic operators and with a simple notation for different kinds of channels that can be used both as assumptions and as protocol goals. AnB specifications are automatically translated to IF.OFMC performs both protocol falsification and bounded session verification by exploring, in a demand-driven way, the transition system resulting from an IF specification. OFMC's effectiveness is due to the integration of a number of symbolic, constraint-based techniques, which are correct and terminating. The two major techniques are the lazy intruder, which is a symbolic representation of the intruder, and constraint differentiation, which is a general search-reduction technique that integrates the lazy intruder with ideas from partial-order reduction. Moreover, OFMC allows one to analyze security protocols with respect to an algebraic theory of the employed cryptographic operators, which can be specified as part of the input. We also sketch the ongoing integration of fixed-point-based techniques for protocol verification for an unbounded number of sessions.


#*Separating Precision and Mean in Dirichlet-Enhanced High-Order Markov Models
#@Rikiya Takahashi
#t2007
#cProceedings of the 18th European conference on Machine Learning
#index396898
#!Robustly estimating the state-transition probabilities of high-order Markov processes is an essential task in many applications such as natural language modeling or protein sequence modeling. We propose a novel estimation algorithm called Hierarchical Separated Dirichlet Smoothing (HSDS), where Dirichlet distributions are hierarchically assumed to be the prior distributions of the state-transition probabilities. The key idea in HSDS is to separate the parameters of a Dirichlet distribution into the precision and mean, so that the precision depends on the context while the mean is given by the lower-order distribution. HSDS is designed to outperform Kneser-Ney smoothing especially when the number of states is small, where Kneser-Ney smoothing is currently known as the state-of-the-art technique for N-gram natural language models. Our experiments in protein sequence modeling showed the superiority of HSDS both in perplexity evaluation and classification tasks. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Computational Integral Imaging Reconstruction Technique with High Image Resolution
#@Yan Piao,Yu Wang,Jingfeng Zang
#t2009
#cProceedings of the 2009 Asia-Pacific Conference on Information Processing - Volume 02
#index491454
#!This paper presents a new method to improve the resolution of integral imaging. According to integral imaging system principle, a volume pixel of 3D scene is projected in several elemental images through micro-lens array. Contrary optic-ray pickup method is introduced in the CIIR process to reconstruct integral image by acquiring multiple pixels from various elemental images for corresponding volume pixel. To show the feasibility of proposed method, some experiments are performed, and the results are compared and discussed with those of the conventional method. The resolution of reconstruction image can be dramatically improved by the proposed method.


#*Using Ontologies to Support Customisation and Maintain Interoperability in Distributed Information Systems with Application to the Domain Name System
#@Nickolas J. G. Falkner,Paul D. Coddington,Andrew L. Wendelborn
#t2006
#cProceedings of the Second International Conference on Semantics, Knowledge, and Grid
#index22335
#!Global distributed systems must be standards-based to allow interoperability between all of their components. While this guarantees interoperability, it often causes local inflexibility and an inability to adapt to specialised local requirements. We show how local flexibility and global consistency can coexist by changing the way that we represent these systems. The proven technologies already in use in the Semantic Web, to support and interpret metadata annotation, provide a well-tested starting point. We can use OWL ontologies and RDF to describe distributed systems using a knowledge-based approach. This allows us to maintain separate local and global operational spaces which, in turn, gives us local flexibility and global consistency. The annotated and well-defined data is better structured, more easily maintained and less prone to errors since its purpose can be clearly determined prior to use. To illustrate the application of our approach in distributed systems, we present our implementation of an ontologically-based Domain Name System (DNS) server and client. We also present performance figures to demonstrate that the use of this approach does not add significant overhead to system performance.


#*An Algorithm of Adaptive Video Coding Scheme Based on FGS
#@Yang Jie,Wang Kecheng,Chen De
#t2009
#cProceedings of the 2009 WRI International Conference on Communications and Mobile Computing - Volume 01
#index64612
#!An improved fine granular adaptive video coding algorithm based on fine granular scalable (FGS) is presented in this paper, which chooses high quality reference in enhancement layer coding, and uses the leaky prediction techniques which can control error propagation by the leaky factor. The simulation and experiments indicate that the proposed scheme can make a better trade-off between the coding efficiency and drift attenuation.


#*A Simple Bayesian Framework for Content-Based Image Retrieval
#@Katherine A. Heller,Zoubin Ghahramani
#t2006
#cProceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 2
#index32913
#!We present a Bayesian framework for content-based image retrieval which models the distribution of color and texture features within sets of related images. Given a userspecified text query (e.g. "penguins") the system first extracts a set of images, from a labelled corpus, corresponding to that query. The distribution over features of these images is used to compute a Bayesian score for each image in a large unlabelled corpus. Unlabelled images are then ranked using this score and the top images are returned. Although the Bayesian score is based on computing marginal likelihoods, which integrate over model parameters, in the case of sparse binary data the score reduces to a single matrix-vector multiplication and is therefore extremely efficient to compute. We show that our method works surprisingly well despite its simplicity and the fact that no relevance feedback is used. We compare different choices of features, and evaluate our results using human subjects.


#*Quantifying the Uncertainty in Measurements for MBAC
#@Anne Nevin,Peder J. Emstad,Yuming Jiang,Guoqiang Hu
#t2009
#cProceedings of the 15th Open European Summer School and IFIP TC6.6 Workshop on The Internet of the Future
#index505500
#!In Measurement Based Admission Control (MBAC), the decision of accepting or rejecting a new flow is based on measurements of the current traffic situation. An in-depth understanding of the measurement error and its uncertainty is vital for the design of a robust MBAC. In this work, we study the measured parameters used by the MBAC and characterize their error. Our work differs significantly from previous work in that we find how the uncertainty in the measurements varies with the length of the observation window.


#*Preface
#@Joseph M. Jasinski
#t2007
#cIBM Systems Journal
#index336731


#*Trust and reputation in peer-to-peer networks
#@Hector Garcia-Molina
#t2005
#c
#index581722
#!The increasing availability of high bandwidth Internet connections and low-cost, commodity computers in people's homes has stimulated the use of resource sharing peer-to-peer networks. These systems employ scalable mechanisms that allow anyone to offer content and services to other system users. However, the open accessibility of these systems make them vulnerable to malicious users wishing to poison the system with corrupted data or harmful services and worms. Because of this danger, users must be wary of the quality or validity of the resources they access. To mitigate the adverse behavior of unreliable or malicious peers in a network, researchers have suggested using reputation systems. Yet our understanding of how to incorporate an effective reputation system into an autonomous network is limited. This thesis categorizes and evaluates the components and mechanisms necessary to build robust, effective reputation systems for use in decentralized autonomous networks. Borrowing techniques from game theory and economic analysis, we begin with high-level models in order to understand general trends and properties of reputation systems and their effect on a user's behavior and experience. We then closely examine the effects of limited reputation sharing through simulations based on large-scale measurements from actual, operating P2P networks. Finally, we propose new mechanisms for improving message routing throughput in decentralized networks of untrusted peers: one geared towards structured DHTs (SPROUT) and two other complementary mechanisms for mobile ad hoc networks (Watchdog and Pathrater).


#*A Predictive Technique for Replica Selection in Grid Environment
#@Rashedur M. Rahman,Ken Barker,Reda Alhajj
#t2007
#cProceedings of the Seventh IEEE International Symposium on Cluster Computing and the Grid
#index416643
#!Replication in a Data Grid reduces access latency and bandwidth consumption. However, when different sites hold replicas of a particular file, there is a significant benefit realized by selecting the best replica from among them. The best replica is the one that optimizes the desired performance criterion such as absolute performance (i.e. speed), cost, security or transfer time. By selecting the best replica, the access latency can be minimized. We develop a predictive framework that uses data from various sources and predicts transfer times of the sites that host replicas. With this estimate, one site can request the replica from the site that has the lowest transfer time. We use a neural network (NN) for transfer time prediction of different sites that currently hold file replicas. We compare the results with a multi-regression model and the simulation results demonstrate that the neural network technique is capable of predicting transfer time more accurately than the regression based model.


#*Robot Cognition and Navigation: An Experiment with Mobile Robots (Cognitive Technologies)
#@Srikanta Patnaik
#t2005
#c
#index102203


#*Distributed data-parallel computing using a high-level programming language
#@Michael Isard,Yuan Yu
#t2009
#cProceedings of the 35th SIGMOD international conference on Management of data
#index132657
#%49321
#%439104
#%436417
#%421692
#%442115
#%426822
#!The Dryad and DryadLINQ systems offer a new programming model for large scale data-parallel computing. They generalize previous execution environments such as SQL and MapReduce in three ways: by providing a general-purpose distributed execution engine for data-parallel applications; by adopting an expressive data model of strongly typed .NET objects; and by supporting general-purpose imperative and declarative operations on datasets within a traditional high-level programming language. A DryadLINQ program is a sequential program composed of LINQ expressions performing arbitrary side-effect-free operations on datasets, and can be written and debugged using standard .NET development tools. The DryadLINQ system automatically and transparently translates the data-parallel portions of the program into a distributed execution plan which is passed to the Dryad execution platform. Dryad, which has been in continuous operation for several years on production clusters made up of thousands of computers, ensures efficient, reliable execution of this plan on a large compute cluster. This paper describes the programming model, provides a high-level overview of the design and implementation of the Dryad and DryadLINQ systems, and discusses the tradeoffs and connections to parallel and distributed databases.


#*Non-Invasive Intracranial Pulse Wave Monitoring
#@Arminas Ragauskas,Gediminas Daubaris,Vytautas Petkus,Romanas Chomskis,Renaldas Raisutis,Vytautas Deksnys,Jonas Guzaitis,Gintautas Lengvinas,Vaidas Matijosaitis
#t2008
#cInformatica
#index629323
#%391043
#%400489
#!Non-invasive physiological monitors are important subsystems of intensive care informatic systems. New innovative information methods and technology are presented for non-invasive human brain volumetric pulse wave physiological monitoring. Experimental study of a new, non-invasive ultrasonic intracranial pulse wave monitoring technology show the reactions of non-invasively recorded intracranial blood volume pulse waves (IBVPW) on healthy volunteers in different human body positions. A group of 13 healthy volunteers was studied. Body posture caused IBVPW, subwaves changes, &Delta;P2 = 18% and &Delta;P3 = 11%. The value of the IBVPW amplitude's ratio in supine and upright positions was 1.55&thinsp;&plusmn;&thinsp;0.61.


#*Modeling and Verification of IPSec and VPN Security Policies
#@Hazem Hamed,Ehab Al-Shaer,Will Marrero
#t2005
#cProceedings of the 13TH IEEE International Conference on Network Protocols
#index575723
#!IPSec has become the defacto standard protocol for secure Internet communications, providing traffic integrity, confidentiality and authentication. Although IPSec supports a rich set of protection modes and operations, its policy configuration remains a complex and error-prone task. The complex semantics of IPSec policies that allow for triggering multiple rule actions with different security modes/operations coordinated between different IPSec gateways in the network increases significantly the potential of policy misconfiguration and thereby insecure transmission. Successful deployment of IPSec requires thorough and automated analysis of the policy configuration consistency for IPSec devices across the entire network.In this paper, we present a generic model that captures various filtering policy semantics using Boolean expressions. We use this model to derive a canonical representation for IPSec policies using Ordered Binary Decision Diagrams. Based on this representation, we develop a comprehensive framework to classify and identify conflicts that could exist in a single IPSec device (intra-policy conflicts) or between different IPSec devices (inter-policy conflicts) in enterprise networks. Our testing and evaluation study on different network environments demonstrates the effectiveness and efficiency of our approach.


#*Scheduling a Flexible Batching Machine
#@Baoqiang Fan,Jianzhong Gu,Guochun Tang
#t2007
#cProceedings of the 3rd international conference on Algorithmic Aspects in Information and Management
#index387686
#!Minimizing total completion time ¿ C j on normal batching machine is solvable in polynomial time for fixed B(B > 1), while Minimizing total completion time ¿ C j for arbitrary B and minimizing total weighted completion time ¿ W j C j are open problems. In this paper, we consider the problem of scheduling jobs on a flexible batching machine in order to minimizing the total completion time. We prove that the problem is strongly NP-hard. Then the problem with agreeable is NP-hard even if there have three fixed capacities all the time.


#*The Minimax Distribution Free Procedure for an Inventory Model in Mixed Fuzzy and Stochastic Environment
#@Xiaobin Wang,Lin Xu,Quqnsheng Wu
#t2009
#cProceedings of the 2009 International Conference on Advanced Computer Control
#index57393
#!This paper investigates the mixture inventory control system in which the lead time demand is a random variable with general distribution, and the defective rate of the arrived order lot is also a random variables. Furthermore, the backorder rate, setup cost, shortage penalty cost and marginal profit per unit in different cycles are iid fuzzy variables, respectively. In addition, a mathematic formulation about the expected annual total cost is presented. And then some useful properties are analyzed for establishing an efficient solution procedure. In order to search the optimal solution of the model, an iterative algorithm are designed. Finally, a numerical example is given to illustrate the procedure of searching the optimal solution.


#*A Fast and Log-Euclidean Polyaffine Framework for Locally Linear Registration
#@Vincent Arsigny,Olivier Commowick,Nicholas Ayache,Xavier Pennec
#t2009
#cJournal of Mathematical Imaging and Vision
#index74325
#%239468
#%80633
#%576689
#%554115
#!In this article, we focus on the parameterization of non-rigid geometrical deformations with a small number of flexible degrees of freedom. In previous work, we proposed a general framework called polyaffine to parameterize deformations with a finite number of rigid or affine components, while guaranteeing the invertibility of global deformations. However, this framework lacks some important properties: the inverse of a polyaffine transformation is not polyaffine in general, and the polyaffine fusion of affine components is not invariant with respect to a change of coordinate system. We present here a novel general framework, called Log-Euclidean polyaffine, which overcomes these defects.We also detail a simple algorithm, the Fast Polyaffine Transform, which allows to compute very efficiently Log-Euclidean polyaffine transformations and their inverses on regular grids. The results presented here on real 3D locally affine registration suggest that our novel framework provides a general and efficient way of fusing local rigid or affine deformations into a global invertible transformation without introducing artifacts, independently of the way local deformations are first estimated.


#*DESIGN OF DECISION TREE VIA KERNELIZED HIERARCHICAL CLUSTERING FOR MULTICLASS SUPPORT VECTOR MACHINES
#@Zhao Lu,Feng Lin,Hao Ying
#t2007
#cCybernetics and Systems
#index47340
#%13519
#%98847
#%244656
#!As a very effective method for universal purpose pattern recognition, support vector machine (SVM) was proposed for dichotomic classification problem, which exhibits a remarkable resistance to overfitting, a feature explained by the fact that it directly implements the principle of structural risk minimization. However, in real world, most of classification problems consist of multiple categories. In an attempt to extend the binary SVM classifier for multiclass classification, decision-tree-based multiclass SVM was proposed recently, in which the structure of decision tree plays an important role in minimizing the classification error. The present study aims at developing a systematic way for the design of decision tree for multiclass SVM. Kernel-induced distance function between datasets was discussed and then kernelized hierarchical clustering was developed and used in determining the structure of decision tree. Further, simulation results on satellite image interpretation show the superiority of the proposed classification strategy over the conventional multiclass SVM algorithms.


#*The Bounds on the Rate of Uniform Convergence of Learning Process on Uncertainty Space
#@Xiankun Zhang,Minghu Ha,Jing Wu,Chao Wang
#t2009
#cProceedings of the 6th International Symposium on Neural Networks on Advances in Neural Networks
#index128651
#!Statistical Learning Theory on uncertainty space is investigated. The definitions of empirical risk functional, expected risk functional and empirical risk minimization principle on uncertainty space are introduced. Based on these concepts, the bounds on the rate of uniform convergence of learning process are given, which estimate the value of achieved risk for the function minimizing the empirical risk and the difference between the value of achieved risk and the value of minimal possible risk for a given set of functions.


#*Delayed multiattribute product differentiation
#@Thomas A. Weber
#t2008
#cDecision Support Systems
#index348860
#%80170
#%109131
#%280969
#%297417
#%571809
#!We develop a two-stage model for versioning products with respect to both vertical and horizontal attributes. At first, a firm positions its top-quality ''flagship'' product in a market with an imperfectly known distribution of tastes and reservation prices. In the second stage, the firm learns these consumer characteristics and has the option of extending its product line by versioning the flagship product using pure horizontal differentiation, quality degrading, or both. The firm's nonconvex versioning problem is solved analytically for the two-product case. We find that ex ante extending the product line through vertical differentiation is optimal for low marginal cost of quality (development cost); otherwise pure horizontal differentiation is superior. Given quasilinear consumer preferences and a uniform distribution of consumer characteristics, versioning with respect to both horizontal and vertical attributes is never optimal. Under delayed differentiation the optimal policy is contingent on the observed demand realization and may lead to horizontal cannibalization and price dispersion for equal-quality products. The firm tends to increase its investment in product quality unless it adopts a state-contingent policy of horizontal versioning for high and vertical versioning for low demand realizations. Following a state-contingent policy, the optimal upfront development effort may be significantly lower than under full ex-ante commitment. The option value of delayed differentiation is generally nonmonotonic in the firm's development cost.


#*Flexible Querying of Fuzzy RDF Annotations Using Fuzzy Conceptual Graphs
#@Patrice Buche,Juliette Dibie-Barthélemy,Gaëlle Hignette
#t2008
#cProceedings of the 16th international conference on Conceptual Structures: Knowledge Visualization and Reasoning
#index395219
#!This paper presents a flexible querying system of fuzzy RDF annotations which consists in translating fuzzy RDF annotations into fuzzy conceptual graphs and using an "approximate"-projection operation in order to compare fuzzy query graphs with fuzzy annotation graphs. The fuzzy sets in the query graphs having a semantic of preferences are compared with the fuzzy sets in the annotation graphs having a semantic of similarity or imprecision. These comparisons deliver several scores which are used by our flexible querying system to sort the answers according to a total order even if these scores are not commensurable.


#*Learn the TiVo for 5 Bucks (Learn for 5 Bucks)
#@Terry White
#t2005
#c
#index100839


#*Intelligent Electronic Navigational Aids: A New Approach
#@Costin Barbu,Maura Lohrenz,Geary Layne
#t2006
#cProceedings of the 5th International Conference on Machine Learning and Applications
#index20574
#!Intelligent devices, with smart clutter management capabilities, can enhance a user's situational awareness under adverse conditions. Two approaches to assist a user with target detection and clutter analysis are presented, and suggestions on how these tools could be integrated with an electronic chart system are further detailed. The first tool, which can assist a user in finding a target partially obscured by display clutter, is a multiple-view generalization of AdaBoost. The second technique determines a meaningful measure of clutter in electronic displays by clustering features in both geospatial and color space. The clutter metric correlates with preliminary, subjective, clutter ratings. The user can be warned if display clutter is a potential hazard to performance. Synthetic and real data sets are used for performance evaluation of the proposed technique compared with recent classifier fusion strategies.


#*Proposing a new architecture for mobile information and consultation support systems
#@Morteza Mosavi,Mahdi Jalili-Kharaajoo
#t2005
#cProceedings of the 4th WSEAS International Conference on Telecommunications and Informatics
#index36757
#%366685
#%564554
#%562942
#!Access to the real-time information and consultations, irrelevant of their complexity, focused on exact needs and independent of location are essential factors to all busy people, specifically businessmen and specialists nowadays. In this paper, we present a new m-service concept, which could be employed as a very widespread commercial service among people holding any kind of mobile devices. To implement, we propose a model consists of front-end, a GUI receiving user's commands and requests through his/her mobile device and back-end, a database-support expert system, provides the expected services to users. Due regard to the nature of the m-commerce, this model should be enriched by an encrypted authentication level, also a method to determine the precise geographical location and local time of users. Predictive and situation-sensitive information and intellectual and self-tuning consultations are the most concerned services could be served. From the architectural point of view, the proposed system has a layered model, each rely on the service that its sub-layer provides and completes requests come from its super-layer. This model is formed by a five-layered architecture, namely Physical Communication (PC), Data Control (DC), Knowledge Management and Data Base (KMDB), Intelligent Process (IP) and User Interface (UI), respectively. We call this system: Mobile Information and Consultation Support System (MICSS).


#*Regional Traffic Assignment by ACO
#@Vittorio Maniezzo,Matteo Roffilli,Roberto Gabrielli,Alessandra Guidazzi,Manuel Otero,Rolando Trujillo
#t2008
#cProceedings of the 6th international conference on Ant Colony Optimization and Swarm Intelligence
#index410493
#!An established research line in ACO systems supports the intuition that ant algorithms are particularly fit for dynamic optimization problems because of their ability to construct an internal representation of the essential elements of the problem to solve, a representation which needs to be updated and not reconstructed when the instance changes.


#*Special issue on wireless access in vehicular environments
#@
#t2009
#cEURASIP Journal on Wireless Communications and Networking
#index138144


#*Optical Design with Epsilon-Dominated Multi-objective Evolutionary Algorithm
#@Shaine Joseph,Hyung W. Kang,Uday K. Chakraborty
#t2007
#cProceedings of the 8th international conference on Adaptive and Natural Computing Algorithms, Part I
#index396194
#!Significant improvement over a patented lens design is achieved using multi-objective evolutionary optimization. A comparison of the results obtained from NSGA2 and ¿-MOEA is done. In our current study, ¿-MOEA converged to essentially the same Pareto-optimal solutions as the one with NSGA2, but ¿-MOEA proved to be better in providing reasonably good solutions, comparable to the patented design, with lower number of lens evaluations. ¿-MOEA is shown to be computationally more efficient and practical than NSGA2 to obtain the required initial insight into the objective function trade-offs while optimizing large and complex optical systems.


#*A Novel Parallel Processing for Continuous k-Nearest Neighbor Queries
#@Chenghua Yan,Chen Qixiang
#t2009
#cProceedings of the 2009 International Conference on Environmental Science and Information Application Technology - Volume 01
#index491364
#!Continuous nearest neighbor queries in road networks have recently received many attentions. To evaluate multiple concurrent continuous k nearest neighbors queries towards moving objects, we propose a Multi-threading Processing of Multiple Continuous Queries (MPMCQ) framework, which exploits pipeline strategy and departs the continuous query processing into three simultaneous stages: query processing, query executing and query results dispatching to improve the parallelism with multi-threading technology. Considering the computational capability of mobile client to locate the edge containing it, we use memory-resident hash table and linear list structures to describe the moving objects and store the directional model. We propose the unidirectional network expansion algorithm to reduce the CPU cost of continuous k-NN queries processing. Experimental results show that the algorithm outperforms existing algorithms including IMA and MKNN algorithms.


#*Pacific Asia Workshop on Intelligence and Security Informatics (PAISI 2008): Currency and Data Protection
#@
#t2008
#cProceedings of the IEEE ISI 2008 PAISI, PACCF, and SOCO international workshops on Intelligence and Security Informatics
#index404771


#*Strong scaling analysis of a parallel, unstructured, implicit solver and the influence of the operating system interference
#@Onkar Sahni,Christopher D. Carothers,Mark S. Shephard,Kenneth E. Jansen
#t2009
#cScientific Programming
#index496563
#%47816
#%53831
#%105338
#%182604
#%619744
#!PHASTA falls under the category of high-performance scientific computation codes designed for solving partial differential equations (PDEs). Its a massively parallel unstructured, implicit solver with particular emphasis on fluid dynamics (CFD) applications. More specifically, PHASTA is a parallel, hierarchic, adaptive, stabilized, transient analysis code that effectively employs advanced anisotropic adaptive algorithms and numerical models of flow physics. In this paper, we first describe the parallelization of PHASTA's core algorithms for an implicit solve, where one of our key assumptions is that on a properly balanced supercomputer with appropriate attributes, PHASTA should continue to strongly scale on high core counts until the computational workload per core becomes insufficient and inter-processor communications start to dominate. We then present and analyze PHASTA's parallel performance across a variety of current near petascale systems, including IBM BG/L, IBM BG/P, Cray XT3, and custom Opteron based supercluster; this selection of systems with inherently different attributes covers a majority of potential candidates for upcoming petascale systems. On one hand, we achieve near perfect (linear) strong scaling out to 32,768 cores of IBM BG/L; showing that a system with desirable attributes will allow implicit solvers to strongly scale on high core counts (including petascale systems). On the contrary, we find that the relative tipping point for strong scaling fundamentally differs among current supercomputer systems. To understand the loss of scaling observed on a particular system (Opteron based supercluster) we analyze the performance and demonstrate that such a loss can be associated to an unbalance in a system attribute; specifically compute-node operating system (OS). In particular, PHASTA scales well to high core counts (up to 32,768 cores) during an implicit solve on systems with compute nodes using lightweight kernels (for example, IBM BG/L); however, we show that on a system where the compute node OS is more heavy weight (e.g., one with background processes) a loss in strong scaling is observed relatively at much fewer number of cores (4,096 cores).


#*Sensor fusion and automatic vulnerability analysis
#@Rayford B. Vaughn,John Farrell,Ronda Henning,Margaret Knepper,Kevin Fox
#t2005
#cProceedings of the 4th international symposium on Information and communication technologies
#index106071
#%236463
#%308528
#%178498
#!Security analysis of networked computing systems continues to present a challenge. The growing complexity of network and computing systems, the increasing sophistication of computer attacks, and the limited supply of security specialist make automated security solutions a necessity. A number of independent solutions are often suggested for a system and then implemented as independent sensors. Little work has been done in fusing sensor outputs in a meaningful way in order to recognize an attack in progress in time to mitigate its impact.


#*Global convergence for two-pulse rest-to-rest learning for single-degree-of-freedom systems with stick-slip Coulomb friction
#@Brian J. Driessen,Nader Sadegh
#t2007
#cRobotica
#index423649
#!In this paper, we consider the problem of rest-to-rest maneu-ver learning, via iterative learning control (ILC), for single-degree-of-freedom systems with stick-slip Coulomb friction and input bounds. The static coefficient of friction is allowed to be as large as three times the kinetic coefficient of friction. The input is restricted to be a two-pulse one. The desired input's first pulse magnitude is required to be five times the largest possible kinetic (sliding) friction force. The theory therefore allows the stiction force to be as large as the desired second input pulse. Under these conditions, we prove global convergence of a simple iterative learning controller. To the best of our knowledge, such a global-convergence proof has not been presented previously in the literature for the rest-to-rest problem with stick-slip Coulomb friction.


#*A Flexibility-Based Damage Identification Method Using Ambient Modal Data
#@Q. W. Yang,C. H. Li
#t2009
#cProceedings of the 2009 Asia-Pacific Conference on Information Processing - Volume 02
#index499385
#!Structural damage identification using ambient vibration modes has become a very important research area in recent years. The main issue surrounding the use of ambient vibration modes is the mass normalization of the measured mode shapes. This paper presents a promising approach that extends the flexibility sensitivity technique to tackle the ambient vibration case. By introducing the mass normalization factors, manipulating the flexibility sensitivity equation, the unknown damage parameters and mass normalization factors can be computed simultaneously by the least-square technique. The effectiveness of the proposed method is illustrated using simulated data with measurement noise on a steel truss structure. The results show the good efficiency and stability of the proposed method on the identification of damage on more than one element. It has been shown that the proposed procedure is simple to implement and may be useful for structural damage identification under ambient vibration case.


#*Matching Problems in Polymatroids Without Double Circuits
#@Márton Makai,Gyula Pap,Jácint Szabó
#t2007
#cProceedings of the 12th international conference on Integer Programming and Combinatorial Optimization
#index404270
#!According to the present state of the theory of the matroid matching problem, the existence of a good characterization to the size of a maximum matching depends on the behavior of certain substructures, called double circuits. In this paper we prove that if a polymatroid has no double circuits at all, then a partition-type min-max formula characterizes the size of a maximum matching. We provide applications of this result to parity constrained orientations and to a rigidity problem.A polynomial time algorithm is constructed by generalizing the principle of shrinking blossoms used in Edmonds' matching algorithm [2].


#*Editorial: Special issue on "Intelligent Software Design"
#@Hamido Fujita
#t2009
#cKnowledge-Based Systems
#index62927


#*Design and Optimization of Low-Voltage Low-Power Quasi-Floating Gate Digital Circuits
#@Kenneth A. Townsend,James W. Haslett,Krzysztof Iniewski
#t2005
#cProceedings of the Fifth International Workshop on System-on-Chip for Real-Time Applications
#index578918
#!This paper explores the design and optimization of Quasi-Floating Gate MOS techniques to low-voltage/low-powerdigital circuitry. The simulated power consumption of standard CMOS gates is compared to that of QFGMOS implementations in a 0.18µm process for different supply voltages and device sizes. A 0.4V VDD full-adder biased for propagation delay similar to that of 0.8V CMOS is simulated and shown to consume 1.2µW for a 50MHz input, representing more than a 50% power reduction over the CMOS equivalent. A divide-by-16 circuit designed for operation at a maximum frequency of 400MHz uses 25µW, 45µW, and 75µW for supplies of 0.4V, 0.6V and 0.8V.


#*Debug Support Strategy for Systems-on-Chips with Multiple Processor Cores
#@Andrew B. T. Hopkins Klaus D. McDonald-Maier
#t2006
#cIEEE Transactions on Computers
#index580713
#%445293
#%446485
#%447900
#!On-chip program and data tracing is now an essential part of any system level development platform for System-on-Chip (SoC). Current debug support solutions are platform specific and incompatible with processors and active peripherals from other sources, restricting effective design reuse. In order to overcome this reuse challenge, this paper defines interfaces to decouple the debug support from processor cores and other active data accessing units. The on-chip debug support infrastructure is also decoupled from each core's debug support and from the trace port or trace memory, using an additional interface. As a result, this decoupling of the debug support infrastructure provides freedom from a specific SoC platform. These interfaces are applied through a reference design modeled using VHDL that is based on a novel low overhead trace message framework. Compared with a leading implementation of a relevant standard, the reference design is 50 percent more compact while providing improvements in trace compression of 8.4 percent for program trace messages and almost 24 percent for data trace messages. This reference design is a multiple core solution that is compatible with most SoC architectures, including those based on emerging Network-on-Chip architectures.


#*Design of a Multiagent System over Mobile Devices for the Planning of Touristic Travels
#@Miguel Valdés,Claudio Cubillos
#t2008
#cProceedings of the 11th Pacific Rim International Conference on Multi-Agents: Intelligent Agents and Multi-Agent Systems
#index56510
#!This work presents the results of designing a multiagent system for the tourism sector, whose objective is to give support to the tourist before and during his travel by means of mobile devices. The system focuses on the creation of itineraries, but besides allows the booking, publication and notification of changes in the services. The system was designed with the PASSI methodology and a prototype is being implemented over Jade.


#*Type-safe disks
#@Gopalan Sivathanu,Swaminathan Sundararaman,Erez Zadok
#t2006
#cProceedings of the 7th USENIX Symposium on Operating Systems Design and Implementation - Volume 7
#index426653
#!We present the notion of a type-safe disk (TSD). Unlike a traditional disk system, a TSD is aware of the pointer relationships between disk blocks that are imposed by higher layers such as the file system. A TSD utilizes this knowledge in two key ways. First, it enables active enforcement of invariants on data access based on the pointer relationships, resulting in better security and integrity. Second, it enables semanticsaware optimizations within the disk system. Through case studies, we demonstrate the benefits of TSDs and show that a TSD presents a simple yet effective general interface to build the next generation of storage systems.


#*Automatic Word Spacing Using Probabilistic Models Based on Character n-grams
#@Do-Gil Lee,Hae-Chang Rim,Dongsuk Yook
#t2007
#cIEEE Intelligent Systems
#index419196
#%306883
#!Automatic word spacing decides the correct boundaries between words in a sentence. Word spacing is important in Korean, and word spacing errors are frequent. Several proposed probabilistic word-spacing models resolve problems with previous statistical approaches. These models regard automatic word spacing as a classification problem similar to part-of-speech tagging. By generalizing hidden Markov models, the models can consider a broader context and estimate more accurate probabilities. The authors tested these models under a wide range of conditions to compare them with the state of the art and performed detailed error analysis of them.


#*An integrated architecture for speech-input multi-target machine translation
#@Alicia Pérez,M. Inés Torres,M. Teresa González,Francisco Casacuberta
#t2007
#cHuman Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers on XX
#index498489
#%306162
#%580365
#!The aim of this work is to show the ability of finite-state transducers to simultaneously translate speech into multiple languages. Our proposal deals with an extension of stochastic finite-state transducers that can produce more than one output at the same time. These kind of devices offer great versatility for the integration with other finite-state devices such as acoustic models in order to produce a speech translation system. This proposal has been evaluated in a practical situation, and its results have been compared with those obtained using a standard mono-target speech transducer.


#*Relaxed K-best MIMO signal detector design and VLSI implementation
#@Sizhong Chen,Tong Zhang,Yan Xin
#t2007
#cIEEE Transactions on Very Large Scale Integration (VLSI) Systems
#index344232
#!Signal detector is a key element in a multiple-input multiple-output (MIMO) wireless communication receiver. It has been well demonstrated that nonlinear tree search MIMO detectors can achieve near-optimum detection performance, nevertheless their efficient high-speed VLSI implementations are not trivial. For example, the hardware design of hard- or soft- output detectors for a 4 × 4 MIMO system with 64 quadrature amplitude modulation (QAM) still remains missing in the open literature. As an attempt to tackle this challenge, this paper presents an implementation-oriented breadth-first tree search MIMO detector design solution. The key is to appropriately modify the conventional breadth-first tree search detection algorithm in order to largely improve the suitability for efficient hardware implementation, while maintaining good detection performance. To demonstrate the effectiveness of the proposed design solution, using 0.13-µm CMOS standard cell and memory libraries, we designed a soft-output signal detector for 4 × 4 MIMO with 64-QAM. With the silicon area of about 31 mm2, the detector can achieve above 100 Mb/s and realize the performance very close to that of the sphere decoding algorithm.


#*Component Deployment: Third International Working Conference, CD 2005, Grenoble, France, November 28-29, 2005, Proceedings (Lecture Notes in Computer Science)
#@Alan Dearle,Susan Eisenbach
#t2006
#c
#index16568


#*Research Collaborations between Academia and Industry
#@Dieter Rombach,Reinhold Achatz
#t2007
#c2007 Future of Software Engineering
#index432153
#!The rapid and complex research and innovation processes require high-tech companies to optimize their technology transfer processes. It is clearly not sufficient to solely rely on internal R&D; strategic cooperations with external research centers of excellence are needed in order to compete in the global innovation market. Candidates for such strategic cooperations are universities, research institutions, and technology focused consulting companies. Key challenge is the effective integration of external competences into the company-internal innovation processes. In this paper we present a survey of the state-of-the-art in technology transfer, high-light promising success cases for the future, and derive success criteria for successful technology transfer in a global world. The cooperation between Siemens and Fraunhofer IESE is presented as a concrete example.


#*Energy-Aware Grid Multipath Routing Protocol in MANET
#@Zhengyu Wu,Hantao Song,Shaofeng Jiang,Xiaomei Xu
#t2007
#cProceedings of the First Asia International Conference on Modelling & Simulation
#index414866
#!A Mobile Ad hoc NETwork (MANET) is one consisting of a set of mobile hosts capable of communicating with each other without the assistance of base stations. Earlier research has proposed several unipath routing protocols specifically on MANET, but most studies have not focused on the limitations of battery resource. To alleviate these problems, a new routing protocol called Energy-Aware Grid Multipath Routing (EAGMR) protocol is proposed. The proposed protocol can conserve energy and provide the best path to route according to probability. Simulation results indicate that this new energy-aware protocol can save energy of mobile hosts and improve data packet delivery ratio.


#*Research Track: Evaluation and Benchmarking
#@
#t2009
#cProceedings of the 6th European Semantic Web Conference on The Semantic Web: Research and Applications
#index139346


#*Training for Work in the Informal Micro-Enterprise Sector: Fresh Evidence from Sub-Sahara Africa (Technical and Vocational Education and Training: Issues, Concerns and Prospects)
#@Hans Christiaan Haan
#t2006
#c
#index2051


#*A Low-Latency Multi-layer Prefix Grouping Technique for Parallel Huffman Decoding of Multimedia Standards
#@Tsung-Han Tsai,Chun-Nan Liu
#t2008
#cJournal of Signal Processing Systems
#index629660
#%343461
#!Huffman coding is a popular and important lossless compression scheme for various multimedia applications. This paper presents a low-latency parallel Huffman decoding technique with efficient memory usage for multimedia standards. First, the multi-layer prefix grouping technique is proposed for sub-group partition. It exploits the prefix characteristic in Huffman codewords to solve the problem of table size explosion. Second, a two-level table lookup approach is introduced which can promptly branch to the correct sub-group by level-1 table lookup and decode the symbols by level-2 table lookup. Third, two optimization approaches are developed; one is to reduce the branch cycles and the other is parallel processing between two-level table lookup and direct table lookup approaches to fully utilize the advantage of VLIW parallel processing. An AAC Huffman decoding example is realized on the Parallel Architecture Core DSP (PAC DSP) processor. The simulation results show that the proposed method can further improve about 89% of decoding cycles and 33% of table size comparing to the linear search method.


#*Name Disambiguation Boosted by Latent Topics from Web Directories
#@Quang Minh Vu,Atsuhiro Takasu,Jun Adachi
#t2008
#cProceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Volume 01
#index629020
#!Search results for personal name queries often contain documents relevant to several people as a personal name is often shared by several people. In order to differentiate people in these search results, it is required to extract contexts relevant to people in documents. However, since web documents are noisy and the texts related to people might be short, it is difficult to extract contexts of people effectively. We propose a new method that uses web directories as additional information in order to recognize topic terms in documents more easily and to extract contexts of people more effectively. First, we apply latent Dirichlet allocation method to extract latent topics in web directories. Then, the extracted topics are used to recognize topics contained in name ambiguity documents so that common context measurements can be calculated more effectively. Our experiments, conducted with documents of real people in the web and several well-known web directories, show that our approach disambiguates personal names better than some other conventional approaches like vector space model approach and named entity recognition approach.


#*Dynamic fringe-saving A*
#@Xiaoxun Sun,William Yeoh,Sven Koenig
#t2009
#cProceedings of The 8th International Conference on Autonomous Agents and Multiagent Systems - Volume 2
#index139987
#%171710
#%391852
#!Fringe-Saving A* is an incremental version of A* that repeatedly finds shortest paths from a fixed start cell to a fixed goal cell in a known gridworld in case the traversability of cells changes over time. It restores the content of the OPEN and CLOSED lists of A* at the point in time when an A* search for the current search problem could deviate from the A* search for the previous search problem. Thus, Fringe-Saving A* reuses the beginning of the previous A* search that is identical to the current A* search. In this paper, we generalize the correctness proof of Fringe-Saving A* to cover the case where the goal cell changes over time in addition to the traversability of cells. We then apply Fringe-Saving A* to the problem of moving an agent along a shortest path from its current cell to a fixed destination cell in a known gridworld, where the shortest path is replanned whenever the traversability of cells changes. Our experimental results show that the resulting Dynamic Fringe-Saving A* algorithm can outperform both repeated A* searches and D* Lite (a state-of-the-art incremental version of A*) in highly dynamic gridworlds, with runtime savings of up to a factor of about 2.5.


#*Ink features for diagram recognition
#@Rachel Patel,Beryl Plimmer,John Grundy,Ross Ihaka
#t2007
#cProceedings of the 4th Eurographics workshop on Sketch-based interfaces and modeling
#index39887
#%26680
#%288787
#%231763
#%324037
#%313189
#%373703
#%583773
#%597175
#%76379
#%282008
#%568640
#%532519
#%305105
#%449185
#!The ability to automatically recognize a sketch accurately is important to computer-based diagramming. Many recognition techniques have been proposed but few researchers have reported the use of formal methods to select the most appropriate ink features for recognition algorithms. We have used a statistical approach to identify the most important distinguishing features of ink for dividing text and shapes. We implemented these into an existing recognition engine and conducted a comparative evaluation. Our feature set more successfully classified a range of common diagram elements than two existing dividers.


#*Logics and Automata for Totally Ordered Trees
#@Marco Kuhlmann,Joachim Niehren
#t2008
#cProceedings of the 19th international conference on Rewriting Techniques and Applications
#index405090
#!A totally ordered tree is a tree equipped with an additional total order on its nodes. It provides a formal model for data that comes with both a hierarchical and a sequential structure; one example for such data are natural language sentences, where a sequential structure is given by word order, and a hierarchical structure is given by grammatical relations between words. In this paper, we study monadic second-order logic (MSO) for totally ordered terms. We show that the MSO satisfiability problem of unrestricted structures is undecidable, but give a decision procedure for practically relevant sub-classes, based on tree automata.


#*Fast Software Encryption: 16th International Workshop, FSE 2009 Leuven, Belgium, February 22-25, 2009 Revised Selected Papers
#@Orr Dunkelman
#t2009
#cLecture Notes In Computer Science; Vol. 5665
#index502944


#*Power and negotiation: lessons from agent-based participatory simulations
#@Paul Guyot,Alexis Drogoul,Shinichi Honiden
#t2006
#cProceedings of the fifth international joint conference on Autonomous agents and multiagent systems
#index35008
#%567330
#!Participatory simulations are conducted to improve our knowledge of human behaviors, to help in solving conflicts, to shape interaction protocols between humans and to teach some aspects of collective management.Agent-based participatory simulations differ from other kinds of participatory simulations including role playing games and experimental economics simulations. The control architecture of the agents, in these simulations, is more or less integrally replaced by a human player and the interactions between players are limited by the communication protocols designed for the agents, usually the exchange of electronic messages logged for further analysis. Such systems can be considered as ideal multi-agent systems featuring cognitive and intelligent agents. Previous work demonstrated that running this kind of simulations helps to design and improve multi-agent simulations.In this paper, we present a series of agent-based participatory experiments studying negotiation in an abstract case of common resource pool management. The roles were designed in such a way that conflicts should emerge during the negotiations. Observing the behavior of human players, we noticed the apparition of power relations between players. We observed that this power in negotiations was unrelated to any a priori dependence between agents or between roles but was instead drawn from strategies and, more surprisingly, this power was built on an emerging ontology.


#*Guest Editorial: special issue on the Euromicro Conference on Real-Time Systems (ECRTS 2007)
#@Michael González Harbour
#t2008
#cReal-Time Systems
#index628505


#*A new numerical algorithm for the Abel equation of the second kind
#@Coskun Guler
#t2007
#cInternational Journal of Computer Mathematics
#index41586
#%560973
#!An algorithm based on the Taylor matrix method is proposed and applied to the non-linear Abel equation of the second kind. A Padé approximation of the problem is also obtained. The results are compared and tabulated.


#*Auctions for Resource Allocation in Overlay Networks
#@Pablo Belzarena,Andrés Ferragut,Fernando Paganini
#t2009
#cNetwork Control and Optimization: Second Euro-NF Workshop, NET-COOP 2008 Paris, France, September 8-10, 2008. Revised Selected Papers
#index60911
#!The paper studies the problem of allocating bandwidth resources of a Service Overlay Network, to optimize revenue. Clients bid for network capacity in periodically held auctions, under the condition that resources allocated in an auction are reserved for the entire duration of the connection, not subject to future contention. This makes the optimal allocation coupled over time, which we formulate as a Markov Decision Process (MDP). Studying first the single resource case, we develop a receding horizon approximation to the optimal MDP policy, using current revenue and the expected revenue in the next step to make bandwidth assignments. A second approximation is then found, suitable for generalization to the network case, where bids for different routes compete for shared resources. In that case we develop a distributed implementation of the auction, and demonstrate its performance through simulations.


#*Robust synchronization for asynchronous multi-user chaos-based DS-CDMA
#@Georges Kaddoum,Daniel Roviras,Pascal Chargé,Danièle Fournier-Prunaret
#t2009
#cSignal Processing
#index66462
#!In this paper we propose two systems for achieving synchronization in asynchronous multi-user chaos-based DS-CDMA. For the first system, synchronization process is realized thanks to a binary code used as an additive pilot sequence to the spreaded signal. Gold sequences are used as pilot signals for the different users to accomplish the synchronization. For the second synchronization system, the synchronization is made through a binary code used as a multiplicative pilot signal for the spreaded data sequence. These synchronization processes are evaluated under the assumption of an additive white Gaussian noise channel together with multi-user interferences. In this paper we will focus on the initial synchronization phase (code acquisition) and we assume that the system can achieve correctly the code tracking after this first synchronization phase. The code acquisition for the two systems is evaluated in terms of the probability of detection and probability of false alarm.


#*High and low speed output buffer design with reduced switching noise for USB applications
#@Hwang-Cherng Chow,C. Huang,Hsing-Chung Liang
#t2005
#cProceedings of the 9th International Conference on Circuits
#index40512
#!Novel frequency doubler circuits and dividers for clock signal generation are presented. In combination with two edge detectors and two duty cycle control buffers a low cost frequency doubler circuit is achieved as compared to Phase-Locked Loop (PLL) design. An input clock signal with an unpredictable duty cycle is inputted to a rising (or falling) edge detector. The edge detector converts the positive (or negative) transitions to a one shot pulse train whose frequency is the same as that of the input clock. However, the one shot pulse train has its duty cycle far less than 50%. By a first 50% duty cycle control buffer the output waveform of the resulted clock signal is symmetrical. The output of the first-stage duty cycle buffer is then edge detected by a rising and falling edge detector, so that the resulted one shot pulse train has twice the frequency of the incoming 50% duty cycle signal. Finally, the second one shot signals are duty cycle adjusted in the second-stage duty cycle control buffer, to restore its 50% duty cycle. Therefore, two times frequency multiplication is achieved with low cost as compared to Phase-Locked Loop (PLL) design. Furthermore, a novel design approach for frequency dividers using duty cycle control circuit is also demonstrated. Simulation results for both frequency multiplication and division confirm the validity of the proposed design approach.


#*Selecting and Weighting Data for Building Consensus Gene Regulatory Networks
#@Emma Steele,Allan Tucker
#t2009
#cProceedings of the 8th International Symposium on Intelligent Data Analysis: Advances in Intelligent Data Analysis VIII
#index506290
#!Microarrays are the major source of data for gene expression activity, allowing the expression of thousands of genes to be measured simultaneously. Gene regulatory networks (GRNs) describe how the expression level of genes affect the expression of the other genes. Modelling GRNs from expression data is a topic of great interest in current bioinformatics research. Previously, we took advantage of publicly available gene expression datasets generated by similar biological studies by drawing together a richer and/or broader collection of data in order to produce GRN models that are more robust, have greater confidence and place less reliance on a single dataset. In this paper a new approach, Weighted Consensus Bayesian Networks, introduces the use of weights in order to place more influence on certain input networks or remove the least reliable networks from the input with encouraging results on both synthetic data and real world yeast microarray datasets.


#*Coldfusion Mx: Integracion Con Flash Mx (Diseno Y Creatividad)
#@Ben Forta
#t2005
#c
#index11237


#*Wiley Plus/Blackboard Stand-alone to accompany Object Oriented Design and Patterns (Wiley Plus Products)
#@Cay S. Horstmann
#t2006
#c
#index2449


#*Embedded Laboratory Environment Monitor System
#@Jiang Linying,Zhu Zhiliang,Li Hailong,Guo Zhenhua
#t2009
#cProceedings of the 2009 WASE International Conference on Information Engineering - Volume 02
#index507930
#!This paper presents an introduction of an embedded processor-based laboratory environment monitor system and its design for hardware and software. This system aims at completing monitoring a variety of real-time data and the states of laboratory, judging environmental index automatically, and detecting intrusions from outside companied with sound and light alarm. To sum up, this system achieves the intelligent management of laboratory. By wired or wireless means, the laboratory monitoring system can communicate with PC and realize telemetry, meeting the needs of unmanned laboratory.


#*Language Strength Reduction
#@Nicholas Kidd,Akash Lal,Thomas Reps
#t2008
#cProceedings of the 15th international symposium on Static Analysis
#index397616
#!This paper concerns methods to check for atomic-set serializability violations in concurrent Java programs. The straightforward way to encode a reentrant lock is to model it with a context-free language to track the number of successive lock acquisitions. We present a construction that replaces the context-free language that describes a reentrant lock by a regular language that describes a non-reentrant lock. We call this replacement language strength reduction. Language strength reduction produces an average speedup (geometric mean) of 3.4. Moreover, for 2 programs that previously exhausted available space, the tool is now able to run to completion.


#*Achieving better coordination through revenue sharing and bargaining in a two-stage supply chain
#@Jing Hou,Amy Z. Zeng,Lindu Zhao
#t2009
#cComputers and Industrial Engineering
#index125697
#%6553
#!Coordination is essential for improving supply chain wide performance. In this paper, we focus on a two-stage supply chain consisting of one supplier and one retailer, and in the chain, the retailer's profit is sensitive to the supplier's lead time, which is influenced by the supplier's target inventory level. The coordination between the two parties is achieved through revenue sharing and bargaining in such a way that their respective profit is better than that resulted from a decentralized optimization. The key contract parameter, the revenue-sharing fraction, along with the maximum amount of monetary bargain space, is obtained under explicit and implicit information, respectively. Numerical illustrations of the contracts for various scenarios are also given.


#*Digital Image Stabilization Based on Log-Polar Transform
#@Fei Yuan,Hong Zhang,Ruiming Jia
#t2007
#cProceedings of the Fourth International Conference on Image and Graphics
#index343242
#!In this paper we present a novel log-polar transform based digital image stabilization algorithm to estimate large global transformations among consecutive frames. In our proposed algorithm, multi-resolution log-polar transform techniques in spatial domain are introduced as an initial motion estimation module to estimate arbitrary rotations, arbitrary translations and moderate scale changes. Then, a gradient-based nonlinear least squares optimization module is used to achieve sub-pixel accuracy. The experimental results show that the proposed algorithm can stabilize 15 frames per second in 320×240 image sequences with large interframe motions on a 3.0-GHZ Pentium 4 machine .


#*An evaluation of coordination techniques for protecting objects and territories in tabletop groupware
#@David Pinelle,Mutasem Barjawi,Miguel Nacenta,Regan Mandryk
#t2009
#cProceedings of the 27th international conference on Human factors in computing systems
#index57827
#%26172
#%49633
#%625738
#%82376
#%579816
#%301737
#%424897
#%287410
#!Indirect input techniques allow users to quickly access all parts of tabletop workspaces without the need for physical access; however, indirect techniques restrict the available social cues that are seen on direct touch tables. This reduced awareness results in impoverished coordination; for example, the number of conflicts might increase since users are more likely to interact with objects that another person is planning to use. Conflicts may also arise because indirect techniques reduce territorial behavior, expanding the interaction space of each collaborator. In this paper, we introduce three new tabletop coordination techniques designed to reduce conflicts arising from indirect input, while still allowing users the flexibility of distant object control. Two techniques were designed to promote territoriality and to allow users to protect objects when they work near their personal areas, and the third technique lets users set their protection levels dynamically. We present the results of an evaluation, which shows that people prefer techniques that automatically provide protection for personal territories, and that these techniques also increase territorial behavior.


#*Efficient BP Algorithms for General Feedforward Neural Networks
#@S. España-Boquera,F. Zamora-Martínez,M. J. Castro-Bleda,J. Gorbe-Moya
#t2007
#cProceedings of the 2nd international work-conference on The Interplay Between Natural and Artificial Computation, Part I: Bio-inspired Modeling of Cognitive Tasks
#index408574
#!The goal of this work is to present an efficient implementation of the Backpropagation (BP) algorithm to train Artificial Neural Networks with general feedforward topology. This will lead us to the "consecutive retrieval problem" that studies how to arrange efficiently sets into a sequence so that every set appears contiguously in the sequence. The BP implementation is analyzed, comparing efficiency results with another similar tool. Together with the BP implementation, the data description and manipulation features of our toolkit facilitates the development of experiments in numerous fields.


#*Fast nearest neighbor retrieval for bregman divergences
#@Lawrence Cayton
#t2008
#cProceedings of the 25th international conference on Machine learning
#index41214
#%35476
#%329883
#%437942
#%278093
#%123459
#%295568
#!We present a data structure enabling efficient nearest neighbor (NN) retrieval for bregman divergences. The family of bregman divergences includes many popular dissimilarity measures including KL-divergence (relative entropy), Mahalanobis distance, and Itakura-Saito divergence. These divergences present a challenge for efficient NN retrieval because they are not, in general, metrics, for which most NN data structures are designed. The data structure introduced in this work shares the same basic structure as the popular metric ball tree, but employs convexity properties of bregman divergences in place of the triangle inequality. Experiments demonstrate speedups over brute-force search of up to several orders of magnitude.


#*Stream Programming on General-Purpose Processors
#@Jayanth Gummaraju,Mendel Rosenblum
#t2005
#cProceedings of the 38th annual IEEE/ACM International Symposium on Microarchitecture
#index575675
#%100279
#%143208
#%292137
#%330851
#%439727
#%445404
#%526816
#!In this paper we investigate mapping stream programs (i.e., programs written in a streaming style for streaming architectures such as Imagine and Raw) onto a general-purpose CPU. We develop and explore a novel way of mapping these programs onto the CPU. We show how the salient features of stream programming such as computation kernels, local memories, and asynchronous bulk memory loads and stores can be easily mapped by a simple compilation system to CPU features such as the processor caches, simultaneous multi-threading, and fast inter-thread communication support, resulting in an executable that efficiently uses CPU resources. We present an evaluation of our mapping on a hyperthreaded Intel Pentium 4 CPU as a canonical example of a general-purpose processor. We compare the mapped stream program against the same program coded in a more conventional style for the general-purpose processor. Using both micro-benchmarks and scientific applications we show that programs written in a streaming style can run comparably to equivalent programs written in a traditional style. Our results show that coding programs in a streaming style can improve performance on today¿s machines and smooth the way for significant performance improvements with the deployment of streaming architectures.


#*A Privacy-Preserving Ticketing System
#@Kristof Verslype,Bart Decker,Vincent Naessens,Girma Nigusse,Jorn Lapon,Pieter Verhaeghe
#t2008
#cProceeedings of the 22nd annual IFIP WG 11.3 working conference on Data and Applications Security
#index385335
#!Electronic identity (eID) cards are deployed in an increasing number of countries. These cards often provide digital authentication and digital signature capabilities, but have at the same time serious privacy shortcomings. We can expect that ordering and issuing tickets for events (e.g. soccer matches) will be increasingly done using eID cards, hence, severely threatening the user's privacy. This paper proposes two alternative ticketing systems that are using the eID card in a bootstrap procedure, but still are providing a high degree of privacy to the user.


#*DNA Inspired Digital Signal Pattern Matching Algorithm
#@Oh Hyuk Kwon,Kyu Yrul Wang,Ji Yoon Kim,Jeahyun Park,Duck Jin Chung,Chong Ho Lee
#t2007
#cProceedings of the 2007 Frontiers in the Convergence of Bioscience and Information Technologies
#index38892
#!In this paper, a new algorithm for supervised pattern classification is proposed. One application area of DNA computing is the pattern matching problem which arise signal processing applications. The noise tolerance pattern matching can be achieved using hybridization property of DNA computing. The proposed algorithm overcomes some of the limitations that DNA computing as in this field. In the algorithm, a set of sample data is replicated and compared with test data permitting some of different features. These processes emulate the replication and hybridization of DNA computing. The results of classification for cardiovascular disease show better accuracy. Because of the simpler procedure, the proposed algorithm can be implemented on hardware employing parallel architecture, which mimics the as massive parallelism of DNA computing.


#*On Faster Integer Calculations Using Non-arithmetic Primitives
#@Katharina Lürwer-Brüggemeier,Martin Ziegler
#t2008
#cProceedings of the 7th international conference on Unconventional Computing
#index391631
#!The unit cost model is both convenient and largely realistic for describing integer decision algorithms over + ,×. Additional operations like division with remainder or bitwise conjunction, although equally supported by computing hardware, may lead to a considerable drop in complexity. We show a variety of concrete problems to benefit from such non-arithmetic primitives by presenting and analyzing corresponding fast algorithms.


#*Budgeting process for information security expenditures
#@Lawrence A. Gordon,Martin P. Loeb
#t2006
#cCommunications of the ACM
#index576217
#!Empirical evidence shows that cost-benefit analysis is a sound basis for budgeting information security expenditures.


#*Home-Explorer: Ontology-based physical artifact search and hidden object detection system
#@Bin Guo,Satoru Satake,Michita Imai
#t2008
#cMobile Information Systems
#index50545
#%29508
#%290340
#%280819
#%446168
#%265186
#%565216
#!A new system named Home-Explorer that searches and finds physical artifacts in a smart indoor environment is proposed. The view on which it is based is artifact-centered and uses sensors attached to the everyday artifacts (called smart objects) in the real world. This paper makes two main contributions: First, it addresses, the robustness of the embedded sensors, which is seldom discussed in previous smart artifact research. Because sensors may sometimes be broken or fail to work under certain conditions, smart objects become hidden ones. However, current systems provide no mechanism to detect and manage objects when this problem occurs. Second, there is no common context infrastructure for building smart artifact systems, which makes it difficult for separately developed applications to interact with each other and uneasy for them to share and reuse knowledge. Unlike previous systems, Home-Explorer builds on an ontology-based knowledge infrastructure named Sixth-Sense, which makes it easy for the system to interact with other applications or agents also based on this ontology. The hidden object problem is also reflected in our ontology, which enables Home-Explorer to deal with both smart objects and hidden objects. A set of rules for deducing an object's status or location information and for locating hidden objects are described and evaluated.


#*A Framework for Web Science (Foundations and Trends(R) in Web Science)
#@Tim Berners-Lee,Wendy Hall,James A. Hendler
#t2006
#c
#index11418


#*Direct Pore Matching for Fingerprint Recognition
#@Qijun Zhao,Lei Zhang,David Zhang,Nan Luo
#t2009
#cProceedings of the Third International Conference on Advances in Biometrics
#index128908
#!Sweat pores on fingerprints have proven to be useful features for personal identification. Several methods have been proposed for pore matching. The state-of-the-art method first matches minutiae on the fingerprints and then matches the pores based on the minutia matching results. A problem of such minutia-based pore matching method is that the pore matching is dependent on the minutia matching. Such dependency limits the pore matching performance and impairs the effectiveness of the fusion of minutia and pore match scores. In this paper, we propose a novel direct approach for matching fingerprint pores. It first determines the correspondences between pores based on their local features. It then uses the RANSAC (RANdom SAmple Consensus) algorithm to refine the pore correspondences obtained in the first step. A similarity score is finally calculated based on the pore matching results. The proposed pore matching method successfully avoids the dependency of pore matching on minutia matching results. Experiments have shown that the fingerprint recognition accuracy can be greatly improved by using the method proposed in this paper.


#*A Pure Nash Equilibrium-Based Game Theoretical Method for Data Replication across Multiple Servers
#@Samee Ullah Khan,Ishfaq Ahmad
#t2009
#cIEEE Transactions on Knowledge and Data Engineering
#index61676
#!This paper proposes a non-cooperative game based technique to replicate data objects across a distributed system of multiple servers in order to reduce user perceived Web access delays. In the proposed technique computational agents represent servers and compete with each other to optimize the performance of their servers. The optimality of a non-cooperative game is typically described by Nash equilibrium, which is based on spontaneous and non-deterministic strategies. However, Nash equilibrium may or may not guarantee system-wide performance. Furthermore, there can be multiple Nash equilibria, making it difficult to decide which one is the best. In contrast, the proposed technique uses the notion of pure Nash equilibrium, which if achieved, guarantees stable optimal performance. In the proposed technique, agents use deterministic strategies that work in conjunction with their self-interested nature but ensure system-wide performance enhancement. In general, the existence of a pure Nash equilibrium is hard to achieve, but we prove the existence of such equilibrium in the proposed technique. The proposed technique is also experimentally compared against some well-known conventional replica allocation methods, such as branch and bound, greedy, and genetic algorithms.


#*Accurate Camera Calibration from Multi-View Stereo and Bundle Adjustment
#@Yasutaka Furukawa,Jean Ponce
#t2009
#cInternational Journal of Computer Vision
#index130011
#%25926
#%35874
#%102080
#%197330
#%324260
#%323660
#!The advent of high-resolution digital cameras and sophisticated multi-view stereo algorithms offers the promise of unprecedented geometric fidelity in image-based modeling tasks, but it also puts unprecedented demands on camera calibration to fulfill these promises. This paper presents a novel approach to camera calibration where top-down information from rough camera parameter estimates and the output of a multi-view-stereo system on scaled-down input images is used to effectively guide the search for additional image correspondences and significantly improve camera calibration parameters using a standard bundle adjustment algorithm (Lourakis and Argyros 2008). The proposed method has been tested on six real datasets including objects without salient features for which image correspondences cannot be found in a purely bottom-up fashion, and objects with high curvature and thin structures that are lost in visual hull construction even with small errors in camera parameters. Three different methods have been used to qualitatively assess the improvements of the camera parameters. The implementation of the proposed algorithm is publicly available at Furukawa and Ponce (2008b).


#*Picture Yourself Creating with Photoshop Elements 5.0
#@Diane Koers
#t2006
#c
#index2069


#*Efficiency Enhancement of Protein Folding for Complete Molecular Simulation via Hardware Computing
#@Wen-Tsai Sung
#t2009
#cProceedings of the 2009 Ninth IEEE International Conference on Bioinformatics and Bioengineering
#index505909
#!Accelerating a protein folding by implementing it in a reconfigurable field programmable gate array (FPGA) is described. This paper presents a methodology for the design of a reconfigurable computing system applied to a complex problem in molecular biology: the protein folding problem. This paper employed VMD tool and force field simulation theorem based on FPGA for protein folding solution. This technique consists of two components: finished protein folding process and found out active sites for drug docking. The goal of protein folding simulation is to search the global energy minimum location with stability state and the when the protein is finished the folding task, we can find out the active sites for pre-process of ligand protein docking. An efficient hardware-based approach was devised to achieve a significant reduction of the search space of possible foldings. Several simulations were done to evaluate the performance of the system as well as the demand for FPGA’s resources.


#*Double patterning technology friendly detailed routing
#@Minsik Cho,Yongchan Ban,David Z. Pan
#t2008
#cProceedings of the 2008 IEEE/ACM International Conference on Computer-Aided Design
#index61188
#%296925
#%319323
#!Double patterning technology (DPT) is a most likely lithography solution for 32/22nm technology nodes as of 2008 due to the delay of Extreme Ultra Violet lithography. However, it should hurdle two challenges before being introduced to mass production, layout decomposition and overlay error. In this paper, we present the first detailed routing algorithm for DPT to improve layout decomposability and robustness against overlay error, by minimizing indecomposable wirelength and the number of stitches. Experimental results show that the proposed approach improves the quality of layout significantly in terms of decomposability and the number of stitches with 3.6x speedup, compared with a current industrial DPT design flow.


#*Proceedings of the 5th international conference on Articulated Motion and Deformable Objects
#@Francisco J. Perales,Robert B. Fisher
#t2008
#cLecture Notes In Computer Science; Vol. 5098
#index390501


#*DOA: DSR over AODV Routing for Mobile Ad Hoc Networks
#@Rendong Bai Mukesh Singhal
#t2006
#cIEEE Transactions on Mobile Computing
#index31178
#%82354
#%236253
#%435712
#%441394
#%481320
#!We present a lightweight hierarchical routing model, Way Point Routing (WPR), in which a number of intermediate nodes on a route are selected as waypoints and the route is divided into segments by the waypoints. Waypoints, including the source and the destination, run a high-level intersegment routing protocol, while the nodes on each segment run a low-level intrasegment routing protocol. One distinct advantage of our model is that when a node on the route moves out or fails, instead of discarding the whole original route and discovering a new route from the source to the destination, only the two waypoint nodes of the broken segment have to find a new segment. In addition, our model is lightweight because it maintains a hierarchy only for nodes on active routes. On the other hand, existing hierarchical routing protocols such as CGSR and ZRP maintain hierarchies for the entire network. We present an instantiation of WPR, where we use DSR as the intersegment routing protocol and AODV as the intrasegment routing protocol. This instantiation is termed DSR over AODV (DOA) routing protocol. Thus, DSR and AODV—two well-known on-demand routing protocols for MANETs—are combined into one hierarchical routing protocol and become two special cases of our protocol. Furthermore, we present two novel techniques for DOA: one is an efficient loop detection method and the other is a multitarget route discovery. Simulation results show that DOA scales well for large networks with more than 1,000 nodes, incurring about 60 percent-80 percent less overhead than AODV, while other metrics are better than or comparable to AODV and DSR.


#*A Real-Time Image Recognition System for Tiny Autonomous Mobile Robots
#@Stefan Mahlknecht,Roland Oberhammer,Gregor Novak
#t2005
#cReal-Time Systems
#index109360
#!Intelligent sensors for mobile robots play an important role in many technical applications. In this paper a real-time image recognition system for a tiny autonomous mobile robot is presented, capable of detecting objects in real-time at a frame rate of up to 60 frames/s. The image recognition module has very low power consumption of less than 250 mW and fits into a package of only 35 × 35 mm including a CMOS camera and a low power, high performance signal processor. We propose an object recognition algorithm that is optimized for deeply embedded systems used in energy and performance constrained devices. The algorithm is based on a combination of edge and color detection and uses a fixed model for each object to be recognized. Results of the ball recognition application show that its relative polar coordinates are found within 11 ms.


#*Design of a Web-based Symptom Management Intervention for Cancer Patients
#@Christine M. Newlon,Chin-Chun A. Hu,Renee M. Stratton,Anna M. Mcdaniel
#t2009
#cProceedings of the 1st International Conference on Human Centered Design: Held as Part of HCI International 2009
#index506171
#!The discipline of Human-Computer Interaction design has potential for significant benefit to the field of health informatics. This paper describes the design approach used to develop a web-based interface to help cancer patients manage their chemotherapy side effects. Previous versions of this intervention utilizing telephone technology had been efficacious, but limited. The paper discusses the design decisions made in order to leverage the potential benefits of the Internet in supporting patients while avoiding the potential pitfalls that the patients may encounter with a web-based approach.


#*Patently false?
#@Laurie Rowell
#t2008
#cnetWorker
#index50349
#!A lawsuit now in federal appeals court may spell the end for software patents


#*Special Session Papers: Object Identification: Techniques and Applications
#@
#t2008
#cProceedings of the 5th international conference on Ubiquitous Intelligence and Computing
#index389528


#*Mathematical Logic
#@Ian Chiswell,Wilfrid Hodges
#t2007
#cOxford Texts In Logic
#index51401
#!Assuming no previous study in logic, this informal yet rigorous text covers the material of a standard undergraduate first course in mathematical logic, using natural deduction and leading up to the completeness theorem for first-order logic. At each stage of the text, the reader is given an intuition based on standard mathematical practice, which is subsequently developed with clean formal mathematics. Alongside the practical examples, readers learn what can and can't be calculated; for example the correctness of a derivation proving a given sequent can be tested mechanically, but there is no general mechanical test for the existence of a derivation proving the given sequent. The undecidability results are proved rigorously in an optional final chapter, assuming Matiyasevich's theorem characterising the computably enumerable relations. Rigorous proofs of the adequacy and completeness proofs of the relevant logics are provided, with careful attention to the languages involved. Optional sections discuss the classification of mathematical structures by first-order theories; the required theory of cardinality is developed from scratch. Throughout the book there are notes on historical aspects of the material, and connections with linguistics and computer science, and the discussion of syntax and semantics is influenced by modern linguistic approaches. Two basic themes in recent cognitive science studies of actual human reasoning are also introduced. Including extensive exercises and selected solutions, this text is ideal for students in logic, mathematics, philosophy, and computer science.


#*An Approach for Stemming in Symbolically Compressed Indian Language Imaged Documents
#@Utpal Garain,Alok Kumar Datta
#t2005
#cProceedings of the Eighth International Conference on Document Analysis and Recognition
#index579214
#!Stemming is used in many information retrieval (IR) systems to reduce variant word forms to common roots, and thereby improving the overall retrieval efficiency. This paper presents an algorithm for stemming in the context of document image retrieval system. The algorithm assumes that the documents are symbolically compressed and stemming has been attempted in the compressed domain itself. Experiments have been conducted on Indian language imaged documents for which efficient OCR still remains a challenging task. Results obtained from a set 150 document images (in Bangla script, the second most popular script in the Indian sub-continent) consisting of about 12K word show a promising performance of the proposed approach.


#*Limitations of Hardness vs. Randomness under Uniform Reductions
#@Dan Gutfreund,Salil Vadhan
#t2008
#cProceedings of the 11th international workshop, APPROX 2008, and 12th international workshop, RANDOM 2008 on Approximation, Randomization and Combinatorial Optimization: Algorithms and Techniques
#index404404
#!We consider (uniform) reductions from computing a function f to the task of distinguishing the output of some pseudorandom generator G from uniform. Impagliazzo and Wigderson [10] and Trevisan and Vadhan [24] exhibited such reductions for every function f in PSPACE. Moreover, their reductions are "black box," showing how to use any distinguisher T, given as oracle, in order to compute f (regardless of the complexity of T). The reductions are also adaptive, but with the restriction that queries of the same length do not occur in different levels of adaptivity. Impagliazzo and Wigderson [10] also exhibited such reductions for every function f in EXP, but those reductions are not black-box, because they only work when the oracle T is computable by small circuits.Our main results are that: Nonadaptive black-box reductions as above can only exist for functions f in BPPNP (and thus are unlikely to exist for all of PSPACE). Adaptive black-box reductions, with the same restriction on the adaptivity as above, can only exist for functions f in PSPACE (and thus are unlikely to exist for all of EXP). Beyond shedding light on proof techniques in the area of hardness vs. randomness, our results (together with [10,24]) can be viewed in a more general context as identifying techniques that overcome limitations of black-box reductions, which may be useful elsewhere in complexity theory (and the foundations of cryptography).


#*On the Collision-Propagation and Gather-Update Formulations of a Cellular Automata Rule
#@Bastien Chopard,Jean-Luc Falcone,Ranaivo Razakanirina,Alfons Hoekstra,Alfonso Caiazzo
#t2008
#cProceedings of the 8th international conference on Cellular Automata for Reseach and Industry
#index392653
#!We consider two formulations of a cellular automata: the first one uses a gather-update paradigm and the second one a collision-propagation paradigm. We show the equivalence of both descriptions and, using the latter paradigm, we propose a simple way to define a Cellular Automata on a graph with arbitrary topology. Finally, we exploit the duality of formulation to reconsider the problem of characterizing invertible cellular automata.


#*Enabling eParticipation of the Youth in the Public Debate on Legislation in Austria: A Critical Reflection
#@Sabrina Scherer,Christoph Neuroth,Günther Schefbeck,Maria A. Wimmer
#t2009
#cProceedings of the 1st International Conference on Electronic Participation
#index503354
#!Legislation formation is an area of democracy, in which participation of target groups (citizens, companies, interest groups, experts) plays a crucial role. With the emergence of the Internet and the growing maturity of more recent technologies a new potential emerged for supporting participation in the legislation process. The use of ICT does, however, not automatically enhance the participation in democratic processes and may even impose new [technically based] barriers. Therefore, software development of legislative eParticipation applications should carefully investigate and bear in mind the specific targeted users. It is not feasible to just provide the necessary ICT and the legislative documents in order to start a consultation, especially with young citizens. When introducing not only a new tool but even a new procedure, the whole process needs to be planned in detail and accompanied by an expert team. In this respect, the paper at hand describes the implementation of a pilot within the LEX-IS project that aimed to facilitate and enable participation of the youth in the public debate on legislation in Austria. The subject of online discussion via the platform was a ministerial draft bill and the formulation of a comment statement based on the previous discussions to be uploaded on the Austrian Parliament's platform. The paper introduces the evaluation methodology and the results of the pilot regarding the use of the argumentation support system, participation of the youth and potential impact on the Austrian legislature. Finally, concluding remarks are provided.


#*An approach to derive the use case diagrams from an event table
#@Mohammad I. Muhairat,Rafa E. Al-Qutaish
#t2009
#cProceedings of the 8th WSEAS International Conference on Software engineering, parallel and distributed systems
#index142196
#%16508
#%117850
#%618972
#%441413
#%162436
#%460813
#%249403
#!Building the use-case diagram is a very important task since it represents a transition between the requirements and design phases. However, building such diagram is a time consuming process and needs a complete understanding of the requirements. In this paper, we introduce an approach to derive use case diagrams from an event table. This new approach will facilitate and speed the generation process of the use case diagrams. However, this approach will completely depends on the availability of a comprehensive event table which to be built from the available requirements.


#*Enhancing Document Clustering through Heuristics and Summary-Based Pre-processing
#@Sri Harsha Allamraju,Robert Chun
#t2009
#cProceedings of the Symposium on Human Interface 2009 on Human Interface and the Management of Information. Information and Interaction. Part II: Held as part of HCI International 2009
#index508159
#!Knowledge workers are burdened with information overload. The information they need might be scattered in many places, buried in a file system, in their email, or on the web. Traditional Clustering algorithms help in assimilating these wide sources of information and generating meaningful relationships amongst them. A typical clustering preprocessing involves tokenization, removal of stop words, stemming, pruning etc. In this paper, we propose the use of summary and heuristics of a document as a pre-processing technique. This technique preserves the formatting of a document and uses this information for producing better clusters. In addition, only a summary of a document is used as the basis for clustering instead of the whole document. Clustering algorithms using the proposed pre-processing technique on formatted documents resulted in improved and more meaningful clusters.


#*Analysis of production authorization card schemes using simulation and neural network metamodels
#@Corinne MacDonald,Eldon A. Gunn
#t2005
#cProceedings of the 37th conference on Winter simulation
#index33623
#!We have developed a framework to model and analyze the performance of complex manufacturing systems operating under a variety of production control strategies. This framework involves a production authorization card scheme, which enables emulation of many popular strategies such as kanban or Base Stock systems. A discrete-event simulation model of the manufacturing system produces estimates of the multiple system performance measures, such as average work-in-process inventory and customer service rates, for combinations of control parameters. Finally, neural network metamodels are trained to approximate the expected value of these system performance measures, using a subset of parameter combinations and the corresponding performance estimates generated by the simulation model. We will show that this framework provides a flexible means of conducting analysis of the impact of parameter settings on the performance of the system, and is a viable alternative to simulation optimization.


#*Robust design of products and processes
#@Corneliu Neagu,Madalin Catana
#t2008
#cProceedings of the 10th WSEAS international conference on Mathematical and computational methods in science and engineering
#index127493
#!This paper presents a model for robust design, by means of a cost-based allocation of economic tolerances for products and/or processes. The concept of economic tolerance has evolved similarly to the concept of quality. For a long period of time, the manufacturers considered that the meeting of function-based tolerance limits set for products/processes represents a prerequisite for the satisfaction of quality requirements. However, Taguchi studies on quality brought a new perspective in judging and designing economic tolerances of products and/or processes. Following the ideas of Taguchi, a new model for economic tolerances design was developed by the authors and is presented in this paper. The proposed model may be considered an extension of Taguchi approach, by taking into account not only the Taguchi Loss Function but also a quality improvement costs function, referred shortly as the Additional Costs Function. The balance of the two functions yields the values of economic tolerances.


#*Arabic Handwriting Recognition Competition
#@V. Margner,H. El Abed
#t2007
#cProceedings of the Ninth International Conference on Document Analysis and Recognition - Volume 02
#index352138
#!This paper describes the Arabic handwriting recognition competition held at ICDAR 2007. This second competition (the first was at ICDAR 2005) again uses the IFN/ENIT- database with Arabic handwritten Tunisian town names. Today, more than 54 research groups from universities, re- search centers, and industry are working with this database worldwide. This year, 8 groups with 14 systems are par- ticipating in the competition. The systems were tested on known data and on two datasets which are unknown to the participants. The systems are compared on the most impor- tant characteristic, the recognition rate. Additionally, the relative speed of the different systems were compared. A short description of the participating groups, their systems, and the results achieved are finally presented.


#*Cross-Site Management of User Online Attributes
#@Jin Liu
#t2009
#cProceedings of the 9th International Conference on Smart Spaces and Next Generation Wired/Wireless Networking and Second Conference on Smart Spaces
#index501109
#!People spend time on web 2.0 sites to contribute contents and make connections with each other. On these sites a user wants to selectively reveal parts his attributes to other users, and he also wants to know more attributes of another user. Users' online attributes are often distributed across multiple sites since most users visit more than one web sites. Currently only the attributes within a specific web site can be queried on that site. This paper proposes a new solution, based on federated identity management, to enable an end user to query the cross-site attributes of another person as easily as possible.


#*Accurate estimates without local data?
#@Tim Menzies,Steve Williams,Oussama Elrawas,Daniel Baker,Barry Boehm,Jairus Hihn,Karen Lum,Ray Madachy
#t2009
#cSoftware Process: Improvement and Practice
#index498606
#!Models of software projects input project details and output predictions via their internal tunings. The output predictions, therefore, are affected by variance in the project details P and variance in the internal tunings T. Local data is often used to constrain the internal tunings (reducing T). While constraining internal tunings with local data is always the preferred option, there exist some models for which constraining tuning is optional. We show empirically that, for the USC COCOMO family of models, the effects of P dominate the effects of T i.e. the output variance of these models can be controlled without using local data to constrain the tuning variance (in ten case studies, we show that the estimates generated by only constraining P are very similar to those produced by constraining T with historical data). We conclude that, if possible, models should be designed such that the effects of the project options dominate the effects of the tuning options. Such models can be used for the purposes of decision making without elaborate, tedious, and time-consuming data collection from the local domain. Copyright &copy; 2009 John Wiley & Sons, Ltd.


#*Low Dimensional Surface Parameterisation with Applications in Biometrics
#@Wei Quan,Bogdan J. Matuszewski,Lik-Kwan Shark,Djamel Ait-Boudaoud
#t2007
#cProceedings of the International Conference on Medical Information Visualisation - BioMedical Visualisation
#index426060
#!This paper describes initial results from a novel low dimensional surface parameterisation approach based on a modified Iterative Closest Point (ICP) registration process which uses vertex based Principal Component Analysis (PCA) to incorporate a deformable element into registration process. Using this method a 3-D surface is represented by a shape space vector of much smaller dimensionality than the dimensionality of the original data space vector. The proposed method is tested on both simulated 3-D faces with different facial expressions and real face data. It is shown that the proposed surface representation can be potentially used as feature space for a facial expression recognition system.


#*Towards a conceptual framework and tool support for linking long-term product and business planning with agile software development
#@Jarno Vähäniitty,Kristian T. Rautiainen
#t2008
#cProceedings of the 1st international workshop on Software development governance
#index40764
#%22450
#%2456
#!For a software company it is essential to understand how to link business management and software development decision-making. Agile methods adhere to the viewpoint of individual development projects, leaving business concerns such as long-term product and release planning and multi-project management mostly unaddressed. With poorly governed fast-paced development, the big picture of the ongoing work and its link to the company's overall business goals and strategy may become unclear. The difficulties in linking business and development are also reflected in current project management/issue tracking tool support. In this paper we present a conceptual framework of the links between long-term business, product and release planning and agile software development. The framework aims to provide a common language through which the big picture of software development - including needed roles, responsibilities and decision structures - can be analyzed, communicated and discussed. We also present Agilefant, a proof-of-concept tool based on the framework.


#*Enchanted Arms (Prima Official Game Guide)
#@
#t2006
#c
#index6343


#*Plug-in Power!: The Comprehensive DSP Guide (Power!)
#@Ashley Shepherd
#t2005
#c
#index12370


#*A note on unique games
#@Adi Avidor,Ricky Rosen
#t2006
#cInformation Processing Letters
#index25386
#%88008
#%248901
#%621987
#%607416
#%294537
#!We give a tighter analysis of the algorithm of Khot [S. Khot, On the power of unique 2-prover 1-round games, in: Proceedings of the 34th Annual ACM Symposium on Theory of Computing, Montreal, Quebec, Canada, 2002, pp. 767-775] which shows that given a unique 2-prover-1-round game with value 1 - ε, one can find in polynomial time an assignment to the game with an expected weight of 1 - O(k6/5ε1/5 (log 1/εk)2/5), where k is the size of the answer domain. This shows that if the Unique Games Conjecture is true then the domain size k, must be at least Ω((ε1/6 log1/3(1/ε)) -1), which is an improvement over the previous Ω((ε1/10 log1/4(1/ε))-1) bound.


#*Poster session 2
#@
#t2007
#cProceedings of the 1st international conference on Robot communication and coordination
#index52686


#*New Products
#@Keith Farkas,Eyal de Lara
#t2005
#cIEEE Pervasive Computing
#index578882
#!In this column, editors Keith Farkas and Eyal de Lara review a Bluetooth-based proximity broadcasting system and a Wi-Fi watchdog system, both of which raise some privacy issues. They also review a video display that projects into thin air, technology enabling 3D TVs, and a production-quality two-way display, which is similar in spirit to the prototype we reviewed in the last column. Finally, they examine a virtual computer, an ultraportable personal server, a novel keyboard, and a bionic arm that suggests the future of human-computer integration.


#*Towards a Requirements-driven Workbench for Supporting Software Certification and Accreditation
#@Seok-Won Lee,Robin A. Gandhi,Siddharth Wagle
#t2007
#cProceedings of the 29th International Conference on Software Engineering Workshops
#index422849
#!Security certification activities for software systems rely heavily on requirements mandated by regulatory documents and their compliance evidences to support accreditation decisions. Therefore, the design of a workbench to support these activities should be grounded in a thorough understanding of the characteristics of certification requirements and their relationships with certification activities. To this end, we utilize our findings from the case study of a certification process of The United States Department of Defense (DoD) to identify the design objectives of a requirements-driven workbench for supporting certification analysts. The primary contributions of this paper are: identifying key areas of automation and tool support for requirements-driven certification activities; an ontology-driven dynamic and flexible workbench architecture to address process variability; and a prototype implementation.


#*Simple and Accurate Models for Capacitance Increment due to Metal Fill Insertion
#@Youngmin Kima,D. Petranovic,D. Sylvestera
#t2007
#cProceedings of the 2007 Asia and South Pacific Design Automation Conference
#index335690
#!Inserting metal fill to improve inter-level dielectric thickness planarity is an essential part of the modern design process. However, the inserted fill shapes impact the performance of signal interconnect by increasing capacitance. In this paper, we analyze and model the impact of the metal dummy on the signal capacitance with various parameters including their electrical characteristic, signal dimensions, and dummy shape and dimensions. Fill has differing impact on interconnects depending on whether the signal of interest is in the same layer as the fill or not. In particular intra-layer dummy has its greatest impact on coupling capacitance while inter-layer dummy has more impact on the ground capacitance component. Based on an analysis of fill impact on capacitance, we propose simple capacitance increment models (Cc for intra-layer dummy and Cg for inter-layer dummy). To consider the realistic case with both signals and metal fill in adjacent layers, we apply a weighting function approach in the ground capacitance model. We verify this model using simple test patterns and benchmark circuits and find that the models match well with field solver results (1.2% average error with much faster runtime than commercial extraction tools, the runtime overhead reduced by ~75% for all benchmark circuits).


#*Introduction to classification: likelihoods, margins, features, and kernels: tutorial for NAACL-HLT 2007
#@Dan Klein
#t2007
#cProceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Tutorial Abstracts on XX
#index497670
#!Statistical methods in NLP have exploited a variety of classification techniques as core building blocks for complex models and pipelines. In this tutorial, we will survey the basic techniques behind classification. We first consider the basic principles, including the principles of maximum likelihood and maximum margin. We then discuss several core classification technologies: naive Bayes, perceptrons, logistic regression, and support vector machines. The discussion will include the key optimization ideas behind their training and the empirical trade-offs between the various classifiers. Finally, we consider the extension to kernels and kernelized classification: what can kernels offer and what is their cost? The presentation is targeted to NLP researchers new to these methods or those wanting to understand more about how these techniques are interconnected.


#*Vote-Based Classifier Selection for Biomedical NER Using Genetic Algorithms
#@Nazife Dimililer,Ekrem Varoğlu,Hakan Altınçay
#t2007
#cProceedings of the 3rd Iberian conference on Pattern Recognition and Image Analysis, Part II
#index396745
#!We propose a genetic algorithm for constructing a classifier ensemble using a vote-based classifier selection approach for biomedical named entity recognition task. Assuming that the reliability of the predictions of each classifier differs among classes, the proposed approach is based on dynamic selection of the classifiers by taking into account their individual votes. During testing, the classifiers whose votes are considered as being reliable are combined using weighted majority voting. The classifier ensemble formed by the proposed scheme surpasses the full object F-score of the best individual classifier and the ensemble of all classifiers by 2.5% and 1.3% respectively.


#*Multivariable system identification for integral controllability
#@Mark L. Darby,Michael Nikolaou
#t2009
#cAutomatica (Journal of IFAC)
#index492855
#%89714
#%92161
#!Integral controllability is necessary and sufficient for a multivariable model to be usable in a decoupling controller with integral action that can be arbitrarily detuned without jeopardizing closed-loop robust stability. The design of experiments for identification of integral controllable models is challenging, because it must satisfy cumbersome eigenvalue inequalities involving a coupling between the real system and its model. To address this challenge, an optimization-based mathematical framework is developed that characterizes efficient identification experiments ensuring integral controllability. The proposed framework recovers well known experiment designs but also produces new ones of both theoretical and practical interest. Such designs are expressed either analytically or as a result of numerical optimization and are demonstrated in a number of examples. These designs can be easily implemented in industrial practice. By combining additional objectives or constraints of interest, the proposed framework can further serve as a basis for new experiment designs in future work.


#*Data mining middleware for wide-area high-performance networks
#@Robert L. Grossman,Yunhong Gu,David Hanley,Michal Sabala,Joe Mambretti,Alex Szalay,Ani Thakar,Kazumi Kumazoe,Oie Yuji,Minsun Lee,Yoonjoo Kwon,Woojin Seok
#t2006
#cFuture Generation Computer Systems
#index26816
#%438686
#%579625
#%232509
#%242522
#!In this paper, we describe two distributed, data intensive applications that were demonstrated at iGrid 2005 (iGrid Demonstration US 109 and iGrid Demonstration US121). One involves transporting astronomical data from the Sloan Digital Sky Survey (SDSS) and the other involves computing histograms from multiple high-volume data streams. Both rely on newly developed data transport and data mining middleware. Specifically, we describe a new version of the UDT network protocol called Composible-UDT, a file transfer utility based upon UDT called UDT-Gateway, and an application for building histograms on high-volume data flows called BESH (for Best Effort Streaming Histogram). For both demonstrations, we include a summary of the experimental studies performed at iGrid 2005.


#*Enhancing Animated Agents in an Instrumented Poker Game
#@Marc Schröder,Patrick Gebhard,Marcela Charfuelan,Christoph Endres,Michael Kipp,Sathish Pammi,Martin Rumpler,Oytun Türk
#t2008
#cProceedings of the 31st annual German conference on Advances in Artificial Intelligence
#index404142
#!In this paper we present an interactive poker game in which one human user plays against two animated agents using RFID-tagged poker cards. The game is used as a showcase to illustrate how current AI technologies can be used for providing new features to computer games. A powerful and easy-to-use multimodal dialog authoring tool is used for modeling game content and interaction. The poker characters rely on a sophisticated model of affect and a state-of-the art speech synthesizer. Through the combination of these methods, the characters show a consistent expressive behavior that enhances the naturalness of interaction in the game.


#*Development of telecommunication and broadcasting infrastructure indices at the global level
#@Adnan Al-mutawkkil,Almas Heshmati,Junseok Hwang
#t2009
#cTelecommunications Policy
#index73566
#!The importance of information and communication technology (ICT) in economic development has been increasing rapidly along with the Internet and mobile telecommunication networks. ICT development is becoming a main growth factor of many countries. As they realize the importance of the ICT industry, developing nations work to catch up with established economies. Therefore, many nations are formulating an ICT-enhanced policy. This paper introduces a number of telecommunication and broadcasting sub-indices, which include the fixed telephone network, the Internet, and mobile networks, which are aggregated into a composite Telecommunication Index (TI). The indices are computed using principal component analysis and human development type index methods. The country rankings, by different ICT-related indices, help identify the strengths and weaknesses of infrastructure development such that each country can foster economic growth. The performance of TI is compared with several other indices, such as the digital access, human development, and ArCo technology indices. The type of indices affects the country ratings. Results suggest that the parametric index approach may be preferred over those methods in which the subjective weighted summation of normalized variables used (non-parametric indices).


#*The Unofficial Guide to Microsoft Office Excel 2007 (Unofficial Guides)
#@Julia Kelly,Curt Simmons
#t2007
#c
#index6225


#*Cognitive Spectrum and Its Security Issues
#@S. Arkoulis,L. Kazatzopoulos,C. Delakouridis,G. F. Marias
#t2008
#cProceedings of the 2008 The Second International Conference on Next Generation Mobile Applications, Services, and Technologies
#index63535
#!The current trend for opportunistic use of the licensed or licensed-exempt wireless spectrum with limited rules, or even without rules, introduces significant scientific and technical challenges for the Networks of the Future. Until now, for the realization of the cognitive radio paradigm, several spectrum sharing schemes have been proposed, such as centralized and distributed schemes, and cooperative or noncooperative spectrum sharing mechanisms. Unfortunately, some of the existing proposals for spectrum sharing and management introduce significant security leakages, putting into effect unfairness, unavailability, and selfishness, or even malicious behaviors. Additionally, the identification, recording and reporting of selfish, free-riders, malicious and anomalous actions by peers is still an open issue in the majority of the existing spectrum management schemes. This paper discusses and classifies the weak points and the vulnerabilities of the spectrum sharing mechanisms.


#*Maran Illustrated Windows Vista
#@Richard Maran
#t2007
#c
#index45279


#*Creacion y diseno web / Creation and Design Web: Guias Practicas para usarios / Practical Guides for users
#@Claudia Valdes-miranda,Enrique Alvarez Rodriguez
#t2005
#c
#index7847


#*User interfaces for interactive control of physics-based 3D characters
#@Peng Zhao,Michiel van de Panne
#t2005
#cProceedings of the 2005 symposium on Interactive 3D graphics and games
#index105545
#%529974
#%282943
#%235757
#%299102
#!We present two user interfaces for the interactive control of dynamically-simulated characters. The first interface uses an 'action palette' and targets sports prototyping applications. When used online, the user selects from a palette of actions (e.g., stand, pike, extend) during an ongoing simulation. Actions are defined in terms of a set of target joint angles for PD controllers or as feedback-based balance controllers. When used offline, the timing of the key motion events can be adjusted manually or optimized automatically to produce desired outcomes. We demonstrate the action palette interface with simulations of platform diving, freestyle aerial ski jumps, and half-pipe snowboarding. The second interface explores the feasibility of using a game-pad to control a 13-link rigid body simulation of snowboarding for game applications. Unlike traditional video game play, the stunts accessible through our interface need not be preconceived by the game author and can emerge as the product of the physics, the terrain, and the player skill. We describe the control mapping and provide a mechanism to simplify balance control. We demonstrate the system using numerous snowboarding stunts.


#*Virtual Camera Tools for an Image2Video Application
#@Fernando Barreiro Megino,José M. Martínez Sánchez,Víctor Valdés López
#t2008
#cProceedings of the 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services
#index413018
#!This paper proposes a set of virtual camera tools developed as a part of an image to video system, oriented to the adaptation of large images to be viewed on small displays without a significant loss of information. This transmoding system automates the process of scrolling and zooming through an image with a minimal user interaction by simulating a virtual camera movement through the picture. The process is automatic and the user interaction will be limited to establish some preferences on the video generation. The focus of this article is the presentation of the algorithms designed to obtain smooth, user-customizable camera movements.


#*Certified Static Analysis by Abstract Interpretation
#@Frédéric Besson,David Cachera,Thomas Jensen,David Pichardie
#t2009
#cFoundations of Security Analysis and Design V: FOSAD 2007/2008/2009 Tutorial Lectures
#index508364
#!A certified static analysis is an analysis whose semantic validity has been formally proved correct with a proof assistant. We propose a tutorial on building a certified static analysis in Coq. We study a simple bytecode language for which we propose an interval analysis that allows to verify statically that no array-out-of-bounds accesses will occur.


#*Next generation of transportation & information technologies
#@Eduard Babulak
#t2009
#cProceedings of the 2009 Euro American Conference on Telematics and Information Systems: New Opportunities to increase Digital Citizenship
#index126145
#%621004
#!Transportation and Internet Technologies have evolved dramatically during the last decade, laying solid foundation for the future generation of the Ubiquitous Internet access, omnipresent web technologies and ultimate automated information cyberspace. As a result, the current efforts in the research and development in the areas of Future Transportation and Next Generation of Internet Technologies promotes formation of inter-disciplinary international teams of experts, scientists, researchers and engineers to create a new generation of applications and technologies that will facilitate the future transportation system. The author discusses the current state of the art in the world of Telecommunications and Internet Technologies, new technological trends directions in the application in the Future Transportation.


#*Power and stability in connectivity games
#@Yoram Bachrach,Jeffrey S. Rosenschein,Ely Porat
#t2008
#cProceedings of the 7th international joint conference on Autonomous agents and multiagent systems - Volume 2
#index409411
#%222078
#%245784
#%254768
#%610564
#!We consider computational aspects of a game theoretic approach to network reliability. Consider a network where failure of one node may disrupt communication between two other nodes. We model this network as a simple coalitional game, called the vertex Connectivity Game (CG). In this game, each agent owns a vertex, and controls all the edges going to and from that vertex. A coalition of agents wins if it fully connects a certain subset of vertices in the graph, called the primary vertices. We show that power indices, which express an agent's ability to affect the outcome of the vertex connectivity game, can be used to identify significant possible points of failure in the communication network, and can thus be used to increase network reliability. We show that in general graphs, calculating the Banzhaf power index is #P-complete, but suggest a polynomial algorithm for calculating this index in trees. We also show a polynomial algorithm for computing the core of a CG, which allows a stable division of payments to coalition agents.


#*The law of ultrasonic energy conversion in thermosonic flip chip bonding interfaces
#@Li Junhui,Wang Ruishan,He Hu,Wang Fuliang,Han Lei,Zhong Jue
#t2009
#cMicroelectronic Engineering
#index129222
#!In this paper, the vibration characteristics during the flip chip (FC) bonding process were observed by using a laser Doppler vibrometer (LDV), and the atom diffusion features in vertical section of the FC bonding interfaces were inspected by using a high resolution transmission electron microscope (HRTEM). Results show that the vibration velocity of a die was about 500mm/s during the traditional FC bonding process, and that of a substrate was only about 180mm/s. It led to the difference of atom diffusion in the FC interfaces. For the given variables, the thickness of atom diffusion at an up-interface (i.e. Au/Al interface) of the FC bonding was about 500nm where was an inter-metallic compound (i.e. AuAl"2), and that of atom diffusion at a down-interface (i.e. Au/Ag interface) was about 200nm. Furthermore, the law of ultrasonic energy conversion was found that the ratio of the up-interface to the down-interface in the FC bonding was statistically about 2.21:1. According to this principle, different bonding processes are suggested to improve the performance of two interfaces. The experimental evaluation confirms the effectiveness of the suggested processes on minimizing the inter-metallic compound layer and equilibrating the thickness of atom diffusion at two interfaces.


#*E-Government: Towards Electronic Democracy: International Conference, TCGOV 2005, Bolzano, Italy, March 2-4, 2005, Proceedings (Lecture Notes in Computer ... / Lecture Notes in Artificial Intelligence)
#@Michael Böhlen,Johann Gamper,Wolfgang Polasek,Maria A. Wimmer
#t2005
#c
#index17762


#*Research on Artificial Target Image Matching
#@Zhanli Li,Yue Xi
#t2009
#cProceedings of the 2009 International Conference on Environmental Science and Information Application Technology - Volume 02
#index508085
#!Image matching is one of most important problems in close-range photogrammetry. In order to improve the speed of image matching, many artificial targets are placed in measurement scene. There are two kinds of artificial targets, encoded target and non-coded target. How to match the target images is discussed in detail in the paper. An image matching method for encoded targets is introduced, in which several geometry invariants is used. An image matching method for non-coded target is presented, which make full use of the image matching results for en-coded targets, and in which epipolar geometry constraint is used. The three dimensional reconstruction is used in the method, which make the image matching for non-coded targets more fast and. exact A software is developed based on the method. An experiment has been done, and the results show the method is correct and effective.


#*A Branch and Bound Algorithm for Matching Protein Structures
#@Janez Konc,Dušanka Janežič
#t2007
#cProceedings of the 8th international conference on Adaptive and Natural Computing Algorithms, Part II
#index385609
#!An efficient branch and bound algorithm for matching protein structures has been developed. The compared protein structures are represented as graphs and a product graph of these graphs is calculated. The resulting product graph is then the input to our algorithm. A maximum clique in the product graph corresponds to the maximum common substructure in the original graphs. Our algorithm, which gives an approximate solution to the maximum clique problem, is compared with exact algorithms commonly used in bioinformatics for protein structural comparisons. The computational results indicate that the new algorithm permits an efficient protein similarity calculation used for protein structure analysis and protein classification.


#*SPARQL graph pattern rewriting for OWL-DL inference queries
#@Yixin Jing,Dongwon Jeong,Doo-Kwon Baik
#t2009
#cKnowledge and Information Systems
#index493628
#!This paper focuses on the issue of OWL-DL ontology queries implemented in SPARQL. Currently, ontology repositories construct inference ontology models, and match SPARQL queries to the models, to derive inference results. Because an inference model uses much more storage space than the original model, and cannot be reused as inference requirements vary, this method is not suitable for large-scale deployment. To solve this problem, this paper proposes a novel method that passes rewritten SPARQL queries to the original ontology model, to retrieve inference results. We define OWL-DL inference rules and apply them to rewriting Graph Patterns in queries. The paper classifies the inference rules and discusses how these rules affect query rewriting. To illustrate the advantages of our proposal, we present a prototype system based on Jena, and address query optimization, to eliminate the disadvantages of augmented query sentences. We perform a set of query tests and compare the results with related works. The results show that the proposed method results in significantly improved query efficiency, without compromising completeness or soundness.


#*Multi-criteria decision analysis for customization of estimation by analogy method AQUA+
#@Jingzhou Li,Guenther Ruhe
#t2008
#cProceedings of the 4th international workshop on Predictor models in software engineering
#index48126
#%24127
#%8300
#%523992
#%91452
#%184299
#%614673
#!The quality of results from a predictor model depends on the proper customization of the parameters of the model. For Estimation by Analogy (EBA), the impact of the parameter "Attribute weighting technique" has been shown by several authors. The decision problem "Which attribute weighting technique is preferable for EBA in which situation?" is considered in this paper from the perspective of multi-criteria decision analysis (MCDA). The empirical results are given for the EBA method AQUA+. More specifically, two MCDA techniques, ELECTRE and Pareto-optimality are applied. Three evaluation criteria MMRE (Mean Magnitude of Relative Error), Pred (Prediction at certain accuracy level), and Strength are considered. We discuss the insights gained from this more in-depth decision analysis for the stated decision problem.


#*Foreword to the article: Computing representations for radicals of finitely generated differential ideals
#@Fran&#x00e7;ois Boulier
#t2009
#cApplicable Algebra in Engineering, Communication and Computing
#index140873
#!No abstract


#*Random Features Applied to Face Recognition
#@Roberto A. Vazquez,Humberto Sossa
#t2007
#cProceedings of the Eighth Mexican International Conference on Current Trends in Computer Science
#index336462
#!In this paper we show how a simplified version of a describing vector can be used to efficiently recognize complex objects. We describe how simplified vectors are randomly obtained from complete describing vectors and how these simplified versions can be used to recognize faces. We compare the efficiency of the proposal against PCA using several known distance classifiers with a benchmark of faces.


#*Pose and Motion Recovery from Feature Correspondences and a Digital Terrain Map
#@Ronen Lerner Ehud Rivlin,Hector P. Rotstein
#t2006
#cIEEE Transactions on Pattern Analysis and Machine Intelligence
#index21299
#%460488
#%333535
#%464443
#%609001
#%444391
#%484451
#!A novel algorithm for pose and motion estimation using corresponding features and a Digital Terrain Map is proposed. Using a Digital Terrain (or Digital Elevation) Map (DTM/DEM) as a global reference enables the elimination of the ambiguity present in vision-based algorithms for motion recovery. As a consequence, the absolute position and orientation of a camera can be recovered with respect to the external reference frame. In order to do this, the DTM is used to formulate a constraint between corresponding features in two consecutive frames. Explicit reconstruction of the 3D world is not required. When considering a number of feature points, the resulting constraints can be solved using nonlinear optimization in terms of position, orientation, and motion. Such a procedure requires an initial guess of these parameters, which can be obtained from dead-reckoning or any other source. The feasibility of the algorithm is established through extensive experimentation. Performance is compared with a state-of-the-art alternative algorithm, which intermediately reconstructs the 3D structure and then registers it to the DTM. A clear advantage for the novel algorithm is demonstrated in variety of scenarios.


#*Establishing latch correspondence for embedded circuits of PowerPC microprocessors
#@H. Anand,J. Bhadra,A. Sen,M. S. Abadir
#t2005
#cProceedings of the High-Level Design Validation and Test Workshop, 2005. on Tenth IEEE International
#index420792
#!A mutation-based validation paradigm that can handle complete high-level microprocessor implementations is presented. First, a control-based coverage measure is presented that is aimed at exposing design errors that incorrectly set control signal values. A method of automatically generating a complete set of modeled errors from this coverage metric is presented such that the instantiated modeled errors harness the rules of cause-and-effect that define mutation-based error models. Finally, we introduce an automatic test pattern generation technique for high-level hardware descriptions that solves multiple concurrent constraints and is empowered by concurrent programming.


#*Fair K Mutual Exclusion Algorithm for Peer to Peer Systems
#@Vijay Anand Reddy,Prateek Mittal,Indranil Gupta
#t2008
#cProceedings of the 2008 The 28th International Conference on Distributed Computing Systems
#index397125
#!k-mutual exclusion is an important problem for resource-intensive peer-to-peer applications ranging from aggregation to file downloads. In order to be practically useful, k-mutual exclusion algorithms not only need to be safe and live, but they also need to be fair across hosts. We propose a new solution to the k-mutual exclusion problem that provides a notion of time-based fairness. Specifically, our algorithm attempts to minimize the spread of access time for the critical resource. While a client's access time is the time between it requesting and accessing the resource, the spread is defined as a system-wide metric that measures some notion of the variance of access times across a homogeneous host population, e.g., difference between max and mean. We analytically prove the correctness of our algorithm, and evaluate its fairness experimentally using simulations. Our evaluation under two settings - a LAN setting and a WAN based on the King latency data set - shows even with 100 hosts accessing one resource, the spread of access time is within 15 seconds.


#*Special Issue: Embedded computing systems for DSP
#@
#t2008
#cJournal of Signal Processing Systems
#index36125


#*Task Allocation in Massively Multi-agent Systems
#@
#t2008
#cMassively Multi-Agent Technology: AAMAS Workshops, MMAS 2006, LSMAS 2006, and CCMMS 2007 Hakodate, Japan, May 9, 2006 Honolulu, HI, USA, May 15, 2007 Selected and Revised Papers
#index408727


#*Efficient cycle-accurate simulation of the UltraSPARC III CPU
#@Peter Strazdins,Bill Clarke,Andrew Over
#t2007
#cProceedings of the thirtieth Australasian conference on Computer science - Volume 62
#index431016
#%236287
#%323529
#%331948
#%600386
#%439428
#%574094
#!This paper presents a novel technique for cycle-accurate simulation of the Central Processing Unit (CPU) of a modern superscalar processor, the UltraSPARC III Cu processor. The technique is based on adding a module to an existing fetch-decode-execute style of CPU simulator, rather than the traditional method of fully modelling the CPU microarchitecture. It is also suitable for accurate SMP modelling. The main functions of the module are the simulation of instruction grouping, register interlocks and the store buffer. Its simple table-driven implementation permits easy modification for exploring microarchitectural variations. The technique results in a 40% loss of simulation speed, instead of a 10 times or greater performance loss by fully implementing the detailed micro-architecture. The technique is validated against an actual UltraSPARC III Cu processor, and achieves high levels of accuracy over a range of scientific benchmarks.


#*An Algorithm for a Constraint Optimization Problem in Mobile Ad-hoc Networks
#@Abdellah Idrissi,Chu Min Li,Jean Frederic Myoupo
#t2006
#cProceedings of the 18th IEEE International Conference on Tools with Artificial Intelligence
#index23523
#!A mobile ad-hoc network is considered as a dynamic autonomous system composed of mobile devices interconnected by links without wire, without the use of a fixed infrastructure and without centralized administration. The absence of a centralized infrastructure forces each device to work in a peer to peer distributed environment, and to act as a router to relay communications, or to generate its own data. The management of the network thus is strongly distributed on all elements of the network. In this paper, we present a modelling of the Mobile Ad-hoc NETwork (MANET) problem in form of a Constraint Satisfaction/ Optimization Problem called CSPADhoc. Then, to minimize the consumption of batteries for devices, we describe an approach based on an adaptation of the A star algorithm to the MANET problem called (MANET-Astar). Finally, we present some experimental results using our approach.


#*Dot-Size Variant Visual Cryptography
#@Jonathan Weir,Wei-Qi Yan
#t2009
#cProceedings of the 8th International Workshop on Digital Watermarking
#index506831
#!In this paper, we propose a scheme by which a secure random share can be generated using a dot-size variant form of visual cryptography (VC). We generate two extended style VC shares, when the share is viewed, it appears as a normal random visual cryptography share. However, this scheme is designed with spatial filtering in mind, this is the dot-size variant part of the scheme. Dot-size variant means that instead of having single black and white dots which make up a VC share, we use a cluster of smaller dots to represent these black and white pixels. This means that after printing, if the share is scanned or photocopied or even viewed with a mobile phone or digital camera, the smallest dots in the scheme are filtered. This loss of information during the copying process allows the original share to have additional security in that accurate copies cannot be created, as well as the fact that due to this loss, the copied share looks totally different from the original. This technique can be used to detect possible counterfeit shares and copies as they will be noticeably different from the original. One major advantage of our scheme is that it works with traditional print techniques and required no special materials. We present our results within this paper.


#*Quantum-Adaptive Scheduling for Multi-Core Network Processors
#@Yue Zhang,Bin Liu,Lei Shi,Jingnan Yao,Laxmi Bhuyan
#t2008
#cProceedings of the 2008 The 28th International Conference on Distributed Computing Systems
#index393847
#!Efficiency and effectiveness are always the emphases of a scheduler, for both link and processor scheduling. Well-known scheduling algorithms such as Surplus Round Robin (SRR) and Elastic Round Robin (ERR) suffer from two fold shortcomings: 1) additional pre-processing queuing delay and post-processing resequencing delay are incurred due to the lack of short-term load-balancing; 2) bursty scheduling is caused due to blind preservation of scheduling history under non-backlogged traffic. In this paper, we propose a Quantum-Adaptive Scheduling (QAS) algorithm, which: 1) synchronizes all the quanta in a fine-grained manner and, 2) adjusts the quanta intelligently based on processor utilization. We theoretically prove that the Queuing Fairness Bound (QFB) for QAS is one third tighter than SRR and ERR. This result approaches the optimal value as obtained in Shortest Queue First (SQF) algorithm, while still maintaining O(1) complexity. Trace-driven simulations show that QAS reduces average packet delay by 18%~24% while cutting down the resequencing buffer size by more than 40% compared to SRR and ERR.


#*On Absorbing Cycles in Min--Max Digraphs
#@Harald Günzel,Hubertus Th. Jongen
#t2005
#cJournal of Global Optimization
#index108809
#%1989
#!We consider smooth finite dimensional optimization problems with a compact, connected feasible set M and objective function f. The basic problem, on which we focus, is: how to get from one local minimum to all the other ones. To this aim we introduce a bipartite digraph ¿ as follows. Its nodes are formed by the set of local minima and maxima of f|M, respectively. Given a smooth Riemannian (i.e. variable) metric, there is an arc from a local minimum x to a local maximum y if the ascent (semi-)flow induced by the projected gradients of f connects points from a neighborhood of x with points from a neighborhood of y. The existence of an arc from y to x is defined with the aid of the descent (semi-)flow. Strong connectedness of ¿ ensures that, starting from one local minimum, we may reach any other one using ascent and descent trajectories in an alternating way. In case that no inequality constraints are present or active, it is well known that for a generic Riemannian metric the resulting min-max digraph ¿ is indeed strongly connected. However, if inequality constraints are active, then there might appear obstructions. In fact, we show that ¿ may contain absorbing two-cycles. If one enters such a cycle, one cannot leave it anymore via ascent and descent trajectories. Moreover, the cycles being constructed are stable with respect to small perturbations (in the C1-topology) of the Riemannian metric.


#*Good learners for evil teachers
#@Ofer Dekel,Ohad Shamir
#t2009
#cProceedings of the 26th Annual International Conference on Machine Learning
#index142414
#%45391
#%437942
#%425193
#!We consider a supervised machine learning scenario where labels are provided by a heterogeneous set of teachers, some of which are mediocre, incompetent, or perhaps even malicious. We present an algorithm, built on the SVM framework, that explicitly attempts to cope with low-quality and malicious teachers by decreasing their influence on the learning process. Our algorithm does not receive any prior information on the teachers, nor does it resort to repeated labeling (where each example is labeled by multiple teachers). We provide a theoretical analysis of our algorithm and demonstrate its merits empirically. Finally, we present a second algorithm with promising empirical results but without a formal analysis.


#*Special Section on Advanced Image Technology
#@Kiyoharu Aizawa
#t2007
#cIEICE - Transactions on Information and Systems
#index8607


#*Artificial Immune System for Short-Term Electric Load Forecasting
#@Grzegorz Dudek
#t2006
#cProceedings of the 9th international conference on Artificial Intelligence and Soft Computing
#index411037
#!This paper proposes a novel model, based on the artificial immune system, to solve the problem of short-term load forecasting. An artificial immune system is trained to recognize antigens which encode sequences of load time series. The created immune memory is a representation of these sequences. In the forecast procedure a new incomplete antigen, containing only the first part of the sequence, is presented to the model. The second forecasted part of the sequence is reconstructed from activated antibodies. The model was verified using several real data examples of the short-term load forecast.


#*Layerless Design of A Power-efficient Clustering Algorithm for Wireless Ad Hoc Networks under Fading
#@Chih-Cheng Tseng,Kwang-Cheng Chen
#t2008
#cWireless Personal Communications: An International Journal
#index339610
#!Traditional wireless ad hoc network power-efficient design proceeds separately on access and clustering algorithms by assuming perfect distance (that is, no fading and channel impairments) at most. In this paper, we discard the traditional layer-concept to tackle this important power-efficient wireless ad hoc networks under shadow fading, by identifying distance between a node pair as a sort of random distance to accommodate fading effect, which of course can be considered as a cross-layer design from traditional concept. By deriving the probability distribution of the distance between two nodes and the probability distribution of the distances between nodes and a randomly selected common reference node, the impacts of shadow fading on the link connectivity and node degree of the randomly constructed network topology are studied. Next, we propose a critical node first (CNF) based clustering algorithm to organize such a shadow faded random network topology into a power-efficient network architecture. By taking the shadow fading effects into considerations, our results show that the cluster-based network architecture generated by the proposed CNF-based clustering algorithm is power-efficient since the required number of exchanges of the cluster maintenance overheads is reduced.


#*Learning Recursive Patterns for Biomedical Information Extraction
#@Margherita Berardi,Donato Malerba
#t2007
#cInductive Logic Programming: 16th International Conference, ILP 2006, Santiago de Compostela, Spain, August 24-27, 2006, Revised Selected Papers
#index387232
#!Information in text form remains a greatly unexploited source of biological information. Information Extraction (IE) techniques are necessary to map this information into structured representations that allow facts relating domain-relevant entities to be automatically recognized. In biomedical IE tasks, extracting patterns that model implicit relations among entities is particularly important since biological systems intrinsically involve interactions among several entities. In this paper, we resort to an Inductive Logic Programming (ILP) approach for the discovery of mutual recursive patterns from text. Mutual recursion allows dependencies among entities to be explored in data and extraction models to be applied in a context-sensitive mode. In particular, IE models are discovered in form of classification rules encoding the conditions to fill a pre-defined information template. An application to a real-world dataset composed by publications selected to support biologists in the task of automatic annotation of a genomic database is reported.


#*Smart Home Sensor Networks Pose Goal-Driven Solutions to Wireless Vacuum Systems
#@Huan Chen,Bo-Chao Cheng,Chih-Chuan Cheng,Li-Kuang Tsai
#t2006
#cProceedings of the 2006 International Conference on Hybrid Information Technology - Volume 02
#index28595
#!Home sensor nodes are devices embedded in home appliances and are designed to sense environments, to process collected information, to perform a specific task, and to cooperate with other units. The advances of VLSI technologies and wireless sensor networks (WSN) turn the inspirational idea of intelligent home appliances into reality. In this paper, we focus on a category of home appliances, Smart Home Vacuum (SHV), where mobility and battery are critical design concerns. The emphasis of this paper is on the design of SHV system and the development of a goal driven task planning (GDTP) engine which can be implemented in the wireless vacuum systems to maximize the network lifetime as well as the cleaning efficiency. Unlike LEACH, proposed GDTP engine is a goal-driven approach to select the cluster heads to satisfy the design goals. Simulations are conducted by the network simulator (ns-2) and the experiment results indicate that GDTP performs better than other algorithms in terms of the network lifetime and the cleaning area coverage.


#*Flattened butterfly: a cost-efficient topology for high-radix networks
#@John Kim,William J. Dally,Dennis Abts
#t2007
#cProceedings of the 34th annual international symposium on Computer architecture
#index426336
#%119086
#%157936
#%301293
#%384311
#%461117
#%443028
#!Increasing integrated-circuit pin bandwidth has motivateda corresponding increase in the degree or radix of interconnection networksand their routers. This paper introduces the flattened butterfly, a cost-efficient topology for high-radix networks. On benign (load-balanced) traffic, the flattened butterfly approaches the cost/performance of a butterfly network and has roughly half the cost of a comparable performance Clos network.The advantage over the Clos is achieved by eliminating redundant hopswhen they are not needed for load balance. On adversarial traffic, the flattened butterfly matches the cost/performance of a folded-Clos network and provides an order of magnitude better performance than a conventional butterfly.In this case, global adaptive routing is used to switchthe flattened butterfly from minimal to non-minimal routing - usingredundant hops only when they are needed. Minimal and non-minimal, oblivious and adaptive routing algorithms are evaluated on the flattened butterfly.We show that load-balancing adversarial traffic requires non-minimalglobally-adaptive routing and show that sequential allocators are required to avoid transient load imbalance when using adaptive routing algorithms.We also compare the cost of the flattened butterfly to folded-Clos, hypercube,and butterfly networks with identical capacityand show that the flattened butterfly is more cost-efficient thanfolded-Clos and hypercube topologies.


#*Software reuse and evolution with generative techniques
#@Krzysztof Czarnecki
#t2007
#cProceedings of the twenty-second IEEE/ACM international conference on Automated software engineering
#index341913
#%626222
#!Generative software development aims at modeling and implementing product lines in such a way that all or a substantial part of the desired system can be automatically generated from a specification written in one or more domain-specific languages (DSLs). The tutorial will explore several techniques of generative software development and show how they can help address software evolution and reuse challenges.


#*Semi-automatic Creation of a Dictionary of Nominal Compounds
#@Tomasz Stępień,Bartosz Podlejski
#t2009
#cHuman Language Technology. Challenges of the Information Society: Third Language and Technology Conference, LTC 2007, Poznan, Poland, October 5-7, 2007, Revised Selected Papers
#index495445
#!This paper presents a method of semi-automatic creation of a dictionary of nominal compounds. For each English expression, several possible Polish translations are generated and the number of occurrences on the Internet is checked for each of them separately. The most frequent form is supposed to be the right one, which is proved by analysis of ca. 500 phrases.


#*The Microsoft Project Management 2007 Toolkit: Microsoft Office Project 2007 Step by Step and In the Trenches with Microsoft Office Project 2007
#@Carl Chatfield
#t2009
#c
#index492984


#*Genetic hybrid tuning of VARMAX and state space algorithms
#@Ralf &#x00d6;stermark
#t2009
#cSoft Computing - A Fusion of Foundations, Methodologies and Applications
#index499898
#!The aim of the study was to monitor the system theoretic exogenous variables augmented state space algorithm of Aoki (State space modelling of time series. Springer, Heidelberg, 1987) and the VARMAX algorithm of Spliid (J Am Stat Assoc 78(384):843&#x2013;849, 1983) within a geno-mathematical framework towards optimal parametric conditions/search intervals. Both algorithms were implemented as an integrated support library for a general computational platform, the Genetic Hybrid Algorithm (GHA), where some key parameters of the algorithms are defined in a search process utilizing a mixed geno-mathematical search technique. The empirical results of our tests using real economic data from the European stock market are encouraging. Specifically, the information criteria used in the VARMAX-search (Vector Autoregressive Moving Average algorithm with Exogenous variables) algorithm tend to favor parsimonious model representations automatically. Furthermore, the state space algorithm captures almost the same dynamics as the complex VARMAX-model estimated in the study. Both algorithms have encouraging in sample properties. When generating k-steps forecasts out-of-sample, k&#x00a0;>&#x00a0;1, the state space algorithm seems to deteriorate faster than the VARMAX algorithm, however. The results suggest that more empirical testing is needed, especially in different situations with different degrees of model order and stationarity conditions, in order to provide more evidence on the suitability of the competing methods in particular cases. We demonstrated that the Genetic Hybrid Algorithm can be used as a generic platform for parametric search in vector valued time series modelling. Efficient procedures for optimal grouping of the individual time series processes and recognition of heteroskedasticity may improve the performance of the algorithms further.


#*Addressing Radiometric Nonidealities: A Unified Framework
#@Anatoly Litvinov,Yoav Y. Schechner
#t2005
#cProceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Volume 2 - Volume 02
#index98481
#!Cameras may have non-ideal radiometric aspects, including spatial non-uniformity, e.g., due to vignetting; nonlinear radiometric response of the sensor; and temporal variations due to automatic gain control (AGC). Often, these characteristics exist simultaneously, and are typically unknown. They thus hinder consistent photometric-measurements. In particular, they create annoying seams in image mosaics. Prior studies approached part of these problems while excluding others. We handle all these problems a unified framework. We suggest an approach for simultaneously estimating the radiometric response, the spatial non-uniformity and the temporally varying gain. The approach does not rely on dedicated processes that intentionally vary exposure settings. Rather, it is based on an ordinary frame sequence acquired during camera motion. The estimated non-ideal characteristics are then compensated for. We state fundamental ambiguities associated with this recovery problem, while exposing a novel image invariance. The method is demonstrated in several experiments, where different frames are brought into mutual radiometric consistency. The accuracy achieved is sufficient for seamless mosaicing, with no need to resort to dedicated seam-feathering methods.


#*Speech Acts, Epistemic Planning and Grice's Maxims
#@Allan Ramsay,Debora Field
#t2008
#cJournal of Logic and Computation
#index42602
#!Work on speech acts has generally involved the introduction of sets of different actions such as informing, reminding, bluffing and lying. These actions have different preconditions and effects, and hence can be used to achieve a wide variety of different real-world goals. The problem is that they tend to have indistinguishable surface forms. As such, it is extremely difficult for the hearer to decide which action she thinks has been performed, and it is therefore also extremely difficult for the speaker to be confident about how the hearer will respond. We will show how to achieve complex goals on the basis of a very simple set of linguistic actions. These actions have clearly marked surface forms, and hence can easily be distinguishable by a hearer. In order to do this, we have developed an epistemic planner with a number of interesting features, and with a number of optimisations that relate directly to aspects of the task at hand.


#*The All-in-One Box
#@Forouzan Golshani
#t2008
#cIEEE MultiMedia
#index404646


#*A finite element penalty-projection method for incompressible flows
#@M. Jobelin,C. Lapuerta,J.-C. Latché,Ph. Angot,B. Piar
#t2006
#cJournal of Computational Physics
#index13405
#%450161
#%523410
#%592192
#%586031
#%156528
#!The penalty-projection method for the solution of Navier-Stokes equations may be viewed as a projection scheme where an augmentation term is added in the first stage, namely the solution of the momentum balance equation, to constrain the divergence of the predicted velocity field. After a presentation of the scheme in the time semi-discrete formulation, then in fully discrete form for a finite element discretization, we assess its behaviour against a set of benchmark tests, including in particular prescribed velocity and open boundary conditions. The results demonstrate that the augmentation always produces beneficial effects. As soon as the augmentation parameter takes a significant value, the projection method splitting error is reduced, pressure boundary layers are suppressed and the loss of spatial convergence of the incremental projection scheme in case of open boundary conditions does not occur anymore. For high values of the augmentation parameter, the results of coupled solvers are recovered. Consequently, in contrast with standard penalty methods, there is no need for a dependence of the augmentation parameter with the time step, and this latter can be kept to reasonable values, to avoid to degrade too severely the conditioning of the linear operator associated to the velocity prediction step.


#*ITSSIP: Interval-parameter two-stage stochastic semi-infinite programming for environmental management under uncertainty
#@P. Guo,G. H. Huang,L. He,B. W. Sun
#t2008
#cEnvironmental Modelling Software
#index49594
#%283259
#%243753
#!In this study, an interval-parameter two-stage stochastic semi-infinite programming (ITSSIP) method is developed for municipal solid waste (MSW) management under uncertainty. In order to better account for uncertainties, the uncertainties are expressed with discrete intervals, functional intervals and probability distributions. The ITSSIP method integrates the two-stage stochastic programming (TSP), interval programming (IP), chance-constrained programming (CCP) and semi-infinite programming (SIP) within a general optimization framework. ITSSIP has infinite constraint because it uses functional intervals with time (s) being an independent variable. At the same time, ITSSIP also presents probability distribution information. The ITSSIP method can incorporate pre-regulated MSW management policies directly into its optimization process to analyze various policy scenarios having different economic penalties when the promised amounts are not delivered. The model is applied to a MSW management system with three waste treatment facilities, three cities and three periods. As an extension of mathematical programming methods, the developed ITSSIP approach has advantages in uncertainty reflection and policy analysis. Firstly, ITSSIP can help generate optimal solutions for decision variables under different levels of waste-generation rate and different levels of constraint-violation probability, which are informative for decision makers; secondly, it has the capability in addressing the parameter's dynamic feature, i.e., variations of the parameters with time; this could hardly be reflected in the previous methods. The obtained solutions are useful for decision makers to obtain insight regarding the tradeoffs between environmental, economic and system-reliability criteria.


#*Application Protocol for a DICOM Real Time Collaborative System
#@D. D. Abdala,M. ,. Prusse,A. G. Regert,A. von Wangenheim
#t2006
#cProceedings of the 19th IEEE Symposium on Computer-Based Medical Systems
#index20278
#!This work presents a new generic application protocol for DICOM conformant medical collaborative systems. It implements simple techniques for data flow and encapsulation between two or more clients and a single server, using an extension of the DICOM Communication Layer within a server or a client as a session manager. The protocol was tested working over two image viewer clients remotely distributed and the synchronization level shows that collaborative systems can be executed in real time.


#*Scalable and Efficient End-to-End Network Topology Inference
#@Xing Jin,Wanqing Tu,S. -H. Gary Chan
#t2008
#cIEEE Transactions on Parallel and Distributed Systems
#index37857
#!We consider using tools like traceroute to infer the underlay topology among a group of hosts. Traditional Max-Delta inference relies on a central server and is not scalable. In this paper, we investigate a distributed inference scheme to support scalable inference. In our scheme, each host joins an overlay tree before conducting traceroute. A host then independently selects paths to traceroute and exchanges traceroute results with others through the overlay tree. As a result, each host can maintain a partially discovered topology. Furthermore, we propose several techniques to reduce the measurement cost, including (a) integrating the Doubletree algorithm to reduce measurement redundancy; (b) setting up a lookup table for routers to reduce traceroute size, and (c) conducting topology abstraction and reducing the computing frequency to reduce computational overhead. In our scheme, the computation loads for target selection are distributed to all the hosts instead of a single server, and the consumption of edge bandwidth at a host is hence limited. We have done simulations on Internet-like topologies and conducted measurements on PlanetLab. The results show that the constructed tree has a low diameter. Furthermore, the proposed improvements can efficiently reduce measurement redundancy, computational overhead and bandwidth consumption.


#*Image Processing and Modeling for Active Needle Steering in Liver Surgery
#@Bing Nan Li,Phu Binh Nguyen,S. H. Ong,Jing Qin,Liang Jing Yang,C. K. Chui
#t2009
#cProceedings of the 2009 International Asia Conference on Informatics in Control, Automation and Robotics
#index59846
#!Image-guided intervention and needle steering for radiofrequency ablation (RFA) of the liver is reviewed in this paper. In particular, the concept of active needle is proposed for RFA treatment. Methods and techniques of image processing and modeling are presented for a stereo liver model. The liver model and constituent components extracted from computerized tomography (CT) images can be used to plan the navigation paths of the RFA needle. The system also provides an option for active needles, which are more amenable to those refractory cases of RFA treatment.


#*Beginning Windows CardSpace: From Novice to Professional
#@Marc Mercuri
#t2007
#c
#index9086


#*Introduction to the special issue
#@Jeff Jackson
#t2007
#cACM SIGBED Review
#index16629


#*Change management
#@
#t2005
#cProceedings of the 27th international conference on Software engineering
#index98468


#*Arabic Stemming Without A Root Dictionary
#@Kazem Taghva,Rania Elkhoury,Jeffrey Coombs
#t2005
#cProceedings of the International Conference on Information Technology: Coding and Computing (ITCC'05) - Volume I - Volume 01
#index97076
#!We have implemented a root-extraction stemmer for Arabic which is similar to the Khoja stemmer but without a root dictionary. Our stemmer was found to perform equivalently to the Khoja stemmer as well as so-called llightm stemmers in monolingual document retrieval tasks performed on the Arabic Trec-2001 collection. A root dictionary, therefore, does not improve Arabic monolingual document retrieval.


#*Discovering regulatory motifs in the Plasmodium genome using comparative genomics
#@Jie Wu,Douglas H. Sieglaff,Joshua Gervin,Xiaohui S. Xie
#t2008
#cBioinformatics
#index628210
#!Motivation: Understanding gene regulation in Plasmodium, the causative agent of malaria, is an important step in deciphering its complex life cycle as well as leading to possible new targets for therapeutic applications. Very little is known about gene regulation in Plasmodium, and in particular, few regulatory elements have been identified. Such discovery has been significantly hampered by the high A-T content of some of the genomes of Plasmodium species, as well as the challenge in associating discovered regulatory elements to gene regulatory cascades due to Plasmodium's complex life cycle. Results: We report a new method of using comparative genomics to systematically discover motifs in Plasmodium without requiring any functional data. Different from previous methods, our method does not depend on sequence alignments, and thus is particularly suitable for highly divergent genomes. We applied our method to discovering regulatory motifs between the human parasite, P.falciparum, and its rodent-infectious relative, P.yoelii. We also tested our procedure against comparisons between P.falciparum and the primate-infectious, P.knowlesi. Our computational effort leads to an initial catalog of 38 distinct motifs, corresponding to over 16 200 sites in the Plasmodium genome. The functionality of these motifs was further supported by their defined distribution within the genome as well as a correlation with gene expression patterns. This initial map provides a systematic view of gene regulation in Plasmodium, which can be refined as additional genomes become available. Availability: The new algorithm, named motif discovery using orthologous sequences (MDOS), is available at http://www.ics.uci.edu/~xhx/project/mdos/. Contact: xhx@ics.uci.edu Supplementary information:Supplementary data are available at Bioinformatics online.


#*Multiple ellipses detection in noisy environments: A hierarchical approach
#@Zhi-Yong Liu,Hong Qiao
#t2009
#cPattern Recognition
#index127276
#%4041
#%86972
#%449303
#%477131
#%299294
#%520010
#%317340
#%450253
#%461794
#%324260
#!Detection of multiple ellipses in noisy environments is a basic yet challenging task in many vision related problems. The key area of difficulty is on distinguishing the pixels pertaining to each target in the presence of noise. To tackle with the issue, we propose a hierarchical approach which is motivated by the fact that any segment of an ellipse can identify itself in ellipse reconstruction. First, we find all the neat edges without any branches, followed by an ellipse fitting on each of them. Second, some target candidates are estimated based on the neat edges, by a proposed grouping strategy. Finally, the targets are detected based on the candidates, by a proposed selective competitive algorithm to distinguish the true pixels of each target. A real application of the proposed method is illustrated in addition to some other demonstrative experiments.


#*A Review of Shape Descriptors for Document Analysis
#@O. R. Terrades,S. Tabbone,E. Valveny
#t2007
#cProceedings of the Ninth International Conference on Document Analysis and Recognition - Volume 01
#index350998
#!Shape descriptors play an important role in many doc- ument analysis application. In this paper we review some of the shape descriptors proposed in the last years from a new point of view. We propose the definitions of descriptor and primitive and introduce the notion of feature extraction method. With these definitions, we propose a new classifica- tion of shape descriptors that permits to classify according to their properties pointing out their strengths and weak- nesses.


#*Exploring Sound Design for Interactive Media (Design Exploration Series)
#@Joseph Cancellaro
#t2005
#c
#index1375


#*A Constrained Dynamic Evolutionary Algorithm with Adaptive Penalty Coefficient
#@Bo Xiao,Danpin Yu,Lei Zhang,Xin Tian,Song Gao,Sanyou Zeng
#t2008
#cProceedings of the 3rd international workshop on Hybrid Artificial Intelligence Systems
#index405839
#!This paper proposes a new evolutionary algorithm with adaptive penalty coefficient. Firstly, the crossover operator of the new algorithm searches a lower-dimensional neighbor of the parent points, so that the algorithm converges fast, especially for high-dimensional problems. Secondly, the violation values of all constraint functions and the value of the objective function are normalized, and therefore, only one penalty coefficient is needed in the scheme. The penalty coefficient is selected adaptively. It is not too big, so as the algorithm can converge fast, and it is not too small so as the algorithm can avoid local optimal as much as possible. Thirdly, the standard deviation of violation values of the constraint functions is added to the violation item in the penalty function, and therefore, the individuals in the population can evenly approach the feasible region from the infeasible space. We have used the 24 constrained benchmark problems to test the new algorithm. The experimental results show it works better than or competitive to a known effective algorithm [7]


#*Video-based nonphotorealistic and expressive illustration of motion
#@B. Kim,I. Essa
#t2005
#cProceedings of the Computer Graphics International 2005
#index427672
#!We present a semi-automatic approach for adding expressive renderings to images and videos that highlight motions and movement. Our technique relies on motion analysis of video where the motion information from the image sequence is used to add expressive information. The first step in our approach is to extract a moving region of the video by segmenting and then grouping regions of compatible motions. In the second step, a user can interactively choose or refine a grouping region that represents the moving object of interest. In the third and final stage, the user can apply various visual effects such as a temporal-flare, time-lapse, and particle-effects. We have implemented a prototype system that can be used to illustrate and expressively render motions in videos and images, with simple user interaction. Our system can deal with most translational and rotational motions without a need for a fixed background.


#*Spain (Living in)
#@Su Kent
#t2007
#c
#index5109


#*Going Critical: Perspective and Proportion in the Epistemology of Rob Kling
#@John Leslie King,Suzanne Iacono,Jonathan Grudin
#t2007
#cThe Information Society
#index40308
#%445001
#%182004
#%573736
#%214712
#%178077
#%546171
#%321490
#%590216
#%466513
#%304501
#%620364
#!One foundational element of Rob Kling's research and writing is his critical perspective on the nature, role, and dynamics of computerization. His main argument was that one should view as dubious any statements that are not grounded in empirical evidence or theoretical analysis. Rob's work was replete with critical refutation, in which he challenged assumptions or statements about computerization and provided alternative interpretations. Much of his work delivered indictments against hyperbolic statements that claimed either utopian or dystopian outcomes from computerization. However, some of his own writings on emerging technologies tended to be dismissive and marginalizing, revealing in his own work some of the weaknesses he pointed out in others' rhetoric and writing. This article identifies intellectual traps inherent in critical perspectives that can catch even the most acute practitioners. The objective is to help elucidate and stabilize the epistemological foundations for Rob's critical perspective on the role of computerization.


#*TTY phone: direct, equal emergency access for the deaf
#@Zahoor Zafrulla,John Etherton,Thad Starner
#t2008
#cProceedings of the 10th international ACM SIGACCESS conference on Computers and accessibility
#index389103
#!Seeking to enable direct and equal access for the Deaf to emergency call centers, we analyze the current state of the emergency phone system in the United States and elsewhere in the world. Leveraging teletypewriter (TTY) technology mandated by the Americans with Disabilities Act of 1990 to be installed in all emergency call centers in the United States, we developed software that emulates a TTY on a smart phone. We present an Instant Messaging style interface for mobile phones that uses the existing emergency infrastructure and allows Deaf users to communicate directly with emergency operators.


#*Evaluating adaptive resource management for distributed real-time embedded systems
#@Nishanth Shankaran,Xenofon Koutsoukos,Douglas C. Schmidt,Aniruddha Gokhale
#t2005
#cProceedings of the 4th workshop on Reflective and adaptive middleware systems
#index578483
#%87698
#%436421
#%439050
#!A challenging problem faced by researchers and developers of distributed real-time and embedded (DRE) systems is devising and implementing effective adaptive resource management strategies that can meet end-to-end quality of service (QoS) requirements in varying operational conditions. This paper presents two contributions to research in adaptive resource management for DRE systems. First, we describe the structure and functionality of the Hybrid Adaptive Resource management Middleware (HyARM), which provides adaptive resource management using hybrid control techniques for adapting to workload fluctuations and resource availability. Second, we evaluate the adaptive behavior of HyARM via experiments on a DRE multimedia system that distributes video in real-time. Our results indicate that HyARM yields predictable, stable, and high system performance, even in the face of fluctuating workload and resource availability.


#*A performance study of general-purpose applications on graphics processors using CUDA
#@Shuai Che,Michael Boyer,Jiayuan Meng,David Tarjan,Jeremy W. Sheaffer,Kevin Skadron
#t2008
#cJournal of Parallel and Distributed Computing
#index405999
#%49558
#%438316
#!Graphics processors (GPUs) provide a vast number of simple, data-parallel, deeply multithreaded cores and high memory bandwidths. GPU architectures are becoming increasingly programmable, offering the potential for dramatic speedups for a variety of general-purpose applications compared to contemporary general-purpose processors (CPUs). This paper uses NVIDIA's C-like CUDA language and an engineering sample of their recently introduced GTX 260 GPU to explore the effectiveness of GPUs for a variety of application types, and describes some specific coding idioms that improve their performance on the GPU. GPU performance is compared to both single-core and multicore CPU performance, with multicore CPU implementations written using OpenMP. The paper also discusses advantages and inefficiencies of the CUDA programming model and some desirable features that might allow for greater ease of use and also more readily support a larger body of applications.


#*DDDAS for Autonomic Interconnected Systems: The National Energy Infrastructure
#@C. Hoffmann,E. Swain,Y. Xu,T. Downar,L. Tsoukalas,P. Top,M. Senel,M. Bell,E. Coyle,B. Loop,D. Aliprantis,O. Wasynczuk,S. Meliopoulos
#t2007
#cProceedings of the 7th international conference on Computational Science, Part I: ICCS 2007
#index394755
#!The most critical element of the nation's energy infrastructure is our electricity generation, transmission, and distribution system known as the "power grid." Computer simulation is an effective tool that can be used to identify vulnerabilities and predict the system response for various contingencies. However, because the power grid is a very large-scale nonlinear system, such studies are presently conducted "open loop" using predicted loading conditions months in advance and, due to uncertainties in model parameters, the results do not provide grid operators with accurate "real time" information that can be used to avoid major blackouts such as were experienced on the East Coast in August of 2003. However, the paradigm of Dynamic Data-Driven Applications Systems (DDDAS) provides a fundamentally new framework to rethink the problem of power grid simulation. In DDDAS, simulations and field data become a symbiotic feedback control system and this is refreshingly different from conventional power grid simulation approaches in which data inputs are generally fixed when the simulation is launched. The objective of the research described herein was to utilize the paradigm of DDDAS to develop a marriage between sensing, visualization, and modelling for large-scale simulation with an immediate impact on the power grid. Our research has focused on methodological innovations and advances in sensor systems, mathematical algorithms, and power grid simulation, security, and visualization approaches necessary to achieve a meaningful large-scale real-time simulation that can have a significant impact on reducing the likelihood of major blackouts.


#*T Cell Receptor Signalling Inspired Kernel Density Estimation and Anomaly Detection
#@Nick D. Owens,Andy Greensted,Jon Timmis,Andy Tyrrell
#t2009
#cProceedings of the 8th International Conference on Artificial Immune Systems
#index492548
#!The T cell is able to perform fine-grained anomaly detection via its T Cell Receptor and intracellular signalling networks. We abstract from models of T Cell signalling to develop a new Artificial Immune System concepts involving the internal components of the TCR. We show that the concepts of receptor signalling have a natural interpretation as Parzen Window Kernel Density Estimation applied to anomaly detection. We then demonstrate how the dynamic nature of the receptors allows anomaly detection when probability distributions vary in time.


#*Estimating p-values in small microarray experiments
#@Hyuna Yang,Gary Churchill
#t2007
#cBioinformatics
#index30867
#!Motivation: Microarray data typically have small numbers of observations per gene, which can result in low power for statistical tests. Test statistics that borrow information from data across all of the genes can improve power, but these statistics have non-standard distributions, and their significance must be assessed using permutation analysis. When sample sizes are small, the number of distinct permutations can be severely limited, and pooling the permutation-derived test statistics across all genes has been proposed. However, the null distribution of the test statistics under permutation is not the same for equally and differentially expressed genes. This can have a negative impact on both p-value estimation and the power of information borrowing statistics. Results: We investigate permutation based methods for estimating p-values. One of methods that uses pooling from a selected subset of the data are shown to have the correct type I error rate and to provide accurate estimates of the false discovery rate (FDR). We provide guidelines to select an appropriate subset. We also demonstrate that information borrowing statistics have substantially increased power compared to the t-test in small experiments. Contact: garyc@jax.org Supplementary information: Supplementary data are available at Bioinformatics online.


#*Instruction scheduling for a clustered VLIW processor with a word-interleaved cache: Research Articles
#@Enric Gibert,Jesús Sánchez,Antonio González
#t2006
#cConcurrency and Computation: Practice Experience
#index34323
#!Clustering is a common technique to overcome the wire delay problem incurred by the evolution of technology. Fully distributed architectures, where the register file, the functional units and the data cache are partitioned, are particularly effective to deal with these constraints and moreover they are very scalable. In this paper, effective instruction scheduling techniques for a word-interleaved cache clustered VLIW processor are presented. Such scheduling techniques rely on (i) loop unrolling and variable alignment to increase the fraction of local accesses, (ii) a latency assignment process to schedule memory instructions with an appropriate latency, and (iii) different heuristics to assign memory instructions to clusters. Memory consistency is guaranteed by constraining the assignment of memory instructions to clusters. In addition, the use of Attraction Buffers is also introduced. An Attraction Buffer is a hardware mechanism that allows some data replication in order to increase the number of local accesses and, in consequence, reduces stall time. Performance results for the Mediabench benchmark suite demonstrate the effectiveness of the presented techniques and mechanisms. The number of local accesses is increased by more than 25&percnt; by using the mentioned scheduling techniques, while stall time is reduced by more than 30&percnt; when Attraction Buffers are used. Finally, IPC results for such an architecture are 10&percnt; and 5&percnt; better compared to those of a clustered VLIW processor with a centralized&#x002F;unified data cache depending on the scheduling heuristic, respectively. Copyright &copy; 2006 John Wiley & Sons, Ltd.


#*A Fast Reassembly Methodology for Polygon Fragment
#@Gang Xu,Yi Xian
#t2009
#cProceedings of the 2009 International Conference on Computer Engineering and Technology - Volume 01
#index62778
#!A new general methodology is introduced for computer-aided reassembly of the polygon image fragments. Since polygon image fragment has a characteristic that it has obvious corners, this methodology takes advantage of such characteristic, and detects the corners by Hough transform and fuzzy reasoning. Meanwhile, it computes the length of each side, compares the side length, finds out the sides with equal length in different fragments, and then computes the gray correlation of equal sides to determine the most optimal matching location for reassembly. Experimental results show that the reassembly methodology for polygon fragment based on corner alignment and gray correlation is effective and fast.


#*Introduction to the Special Section on Nano Systems and Computing
#@Andre DeHon,Craig S. Lent,Fabrizio Lombardi
#t2007
#cIEEE Transactions on Computers
#index31618


#*Modular over-the-wire configurable security for long-lived critical infrastructure monitoring systems
#@Erik Solum,Carl Hauser,Rasika Chakravarthy,Dave Bakken
#t2009
#cProceedings of the Third ACM International Conference on Distributed Event-Based Systems
#index492301
#%240393
#%419134
#%422500
#%469637
#!This paper presents a modular, software-based, over-the-wire configurable, end-to-end security architecture for critical infrastructure monitoring systems. The architecture provides mechanisms allowing it to evolve, during operation, over the long lifetimes typically encountered in these systems by allowing security modules to be securely added and replaced at runtime. Our security architecture addresses these systems' need for high-performance secure multi-cast with modules for confidentiality, integrity, authentication, and obfuscation. The variety of available modules provides tradeoffs between performance and security now and for the future. Experimental performance results for various existing modules, in the context of the architecture, are presented. To achieve long system lifetime a secure management system, using protocols based on symmetric-key cryptography, is described.


#*Towards Feature Fusion for Human Identification by Gait
#@Shi Chen,Tianjun Ma,Laicang Dong
#t2007
#cProceedings of the Fourth International Conference on Image and Graphics
#index342735
#!In this paper, we propose a statistical gait feature fusion approach for human recognition by gait. First, we produce a gait period estimation function by converting the contour of silhouette in specific regions into an 1D signal, and divide each silhouette sequence into cycles. With a novel shape descriptor while retaining translation, scale and rotation invariance, a statistical feature extraction method is used for learning gait features from individual frame and consecutive frames, respectively. Features learned from individual frame characterize human silhouette properties, and features learned from consecutive frames describe dynamic properties of human motion. Next, we employ Jeffrey divergence and dynamic time warping for measuring the similarity between test and reference sequences. To improve the recognition performance, a fusion rule on silhouette and dynamic gait features is developed. Experimental results show that recognition performance achieved by the proposed feature fusion approach is better than that achieved by individual silhouette or dynamic feature classification approaches, and better than existed methods.


#*A Development Toolkit for Unified Web-Based User Interfaces
#@C. Doulgeraki,N. Partarakis,A. Mourouzis,C. Stephanidis
#t2008
#cProceedings of the 11th international conference on Computers Helping People with Special Needs
#index404274
#!EAGER is a prototype development toolkit that allows embedding accessibility and ease of use for all potential users into Web-based artefacts. Web-based user interfaces developed by means of the EAGER toolkit incarnate the concept of Unified User Interfaces and exhibit adaptation behaviour with respect to diverse user abilities, requirements and preferences. Ultimately, the process of employing EAGER is significantly less demanding in terms of time, experience and skills required from the developer, than the typical process of developing for the "average" user.


#*Proceedings of the 11th International Database Engineering and Applications Symposium
#@
#t2007
#cIDEAS
#index352487


#*Exploiting Information Theory for Filtering the Kadir Scale-Saliency Detector
#@Pablo Suau,Francisco Escolano
#t2007
#cProceedings of the 3rd Iberian conference on Pattern Recognition and Image Analysis, Part II
#index390922
#!In this paper we propose a Bayesian filter for the Kadir Scale Saliency Detector. Such filter is addressed to deal with the main bottleneck of the Kadir detector, which is the scale space search for all pixels in the image. Given some statistical knowledge about images considered, we show that it is possible to discard some points before applying the Kadir detector by using Information Theory and Bayesian Analysis, increasing efficiency with low error. Our method is based on the intuitive idea that homogeneous (not salient) image regions at high scales probably will be also homogeneous at lower scales of scale space.


#*Designing a summative evaluation tool for the online class
#@Amany Saleh,Marcia Lamkin
#t2007
#cProceedings of the sixth conference on IASTED International Conference Web-Based Education - Volume 2
#index347039
#%233340
#!Research has found that one of the biggest weaknesses of online education is the lack of consistent evaluation which provides input on the effectiveness of this methodology (McVay Lynch, 2002). The authors of this article developed and conducted pilot testing for a summative evaluation tool that can be used to provide such feedback. In the development of this instrument, the authors addressed issues that traditional class evaluation tools cannot address, such as course delivery, instructor's online input, and effectiveness of the medium.


#*Research on the Application of Improved Text Classific Algorithm in Intelligent Learning Platform
#@Rurui Zhou,You-fu Du,Ming Zhao
#t2008
#cProceedings of the 2008 Second International Conference on Genetic and Evolutionary Computing
#index395619
#!With the rapid developing of the network information, it seems to be quite important to provide a more reasonable text classification algorithm for learners. In this paper,we adopt a sensitivity method to modify the characteristic weight in the distance formula and put up with a cutting method of training sample database based on CURE algorithm and Tabu algorithm; then adopt CURE cluster algorithm to acquire each representative sample in order to constitute a new training sample collection, then use Tabu algorithm to make a further maintenance to this sample collection. While appending the sample, it is only necessary to consider appending the samples of different type boundary. Append or delete sample with classification accuracy highest and with the original training sample database nearest to the rule, and provide learners with reasonable text classification system.


#*Design automation of real-life asynchronous devices and systems
#@Alexander Taubin,Jordi Cortadella,Luciano Lavagno,Alex Kondratyev,Ad Peeters
#t2007
#cFoundations and Trends® in Electronic Design Automation
#index351223
#%99436
#%115431
#%122461
#%155743
#%233414
#%245503
#%291836
#%304643
#%305038
#%308336
#%311634
#%322995
#%323972
#%330862
#%558916
#%475349
#%589139
#%448220
#%588144
#%595145
#%529100
#%529355
#%519586
#%563941
#%356130
#%451540
#!The number of gates on a chip is quickly growing toward and beyond the one billion mark. Keeping all the gates running at the beat of a single or a few rationally related clocks is becoming impossible. In static timing analysis process variations and signal integrity issues stretch the timing margins to the point where they become too conservative and result in significant overdesign. Importance and difficulty of such problems push some developers to once again turn to asynchronous alternatives. However, the electronics industry for the most part is still reluctant to adopt asynchronous design (with a few notable exceptions) due to a common belief that we still lack a commercial-quality Electronic Design Automation tools (similar to the synchronous RTL-to-GDSII flow) for asynchronous circuits. The purpose of this paper is to counteract this view by presenting design flows that can tackle large designs without significant changes with respect to synchronous design flow. We are limiting ourselves to four design flows that we believe to be closest to this goal. We start from the Tangram flow, because it is the most commercially proven and it is one of the oldest from a methodological point of view. The other three flows (Null Convention Logic, de-synchronization, and gate-level pipelining) could be considered together as asynchronous re-implementations of synchronous (RTL-or gate-level) specifications. The main common idea is substituting the global clocks by local synchronizations. Their most important aspect is to open the possibility to implement large legacy synchronous designs in an almost "push button" manner, where all asynchronous machinery is hidden, so that synchronous RTL designers do not need to be re-educated. These three flows offer a trade-off from very low overhead, almost synchronous implementations, to very high performance, extremely robust dual-rail pipelines.


#*TLM method for thermal investigation of IGBT modules in PWM mode
#@R. Hocine,S. H. Pulko,A. Boudghene Stambouli,A. Saidane
#t2009
#cMicroelectronic Engineering
#index133381
#%572288
#!The insulated gate bipolar transistor (IGBT) is popularly used in high power, high frequency power-electronic applications such as motor control and inverters. These applications require well designed thermal management system to ensure the protection of IGBTs. Choice simulation tools for accurate prediction of device power dissipation and junction temperature become important in achieving optimised designs. In this paper, thermal analysis of a 1200A, 3.3kV IGBT module was investigated and analysed using the three-dimensional transmission line matrix (3D-TLM) method. The results show a three-dimensional visualisation of self-heating phenomena in the device. Since the comparison TLM results with the analytical solutions do not exist for this IGBT module, we use the MSC.NASTRAN tool to find the similar range of the temperatures. Results are compared. Typically, IGBT is used in a three-phase inverter leg where the control signals are generated via PWM scheme so, the prediction of the temperature rise is important in the pulse operation conditions for the IGBT device. A view of the dynamic thermal temperature rise is obtained with 100W-step pulse dissipation applied at IGBT chips. The temperature rises are calculated using TLM method during the PWM load cycles. Simulations give clear indications of the importance of the spreader material and are helpful in selecting the proper one. TLM has been successful in modelling heat diffusion problems and has proven to be efficient in terms of stability and complex geometry. The three-dimensional results show that method has a considerable potential in power devices thermal analysis and design.


#*Static specification mining using automata-based abstractions
#@Sharon Shoham,Eran Yahav,Stephen Fink,Marco Pistoia
#t2007
#cProceedings of the 2007 international symposium on Software testing and analysis
#index423221
#%82926
#%244732
#%250063
#%622690
#!We present a novel approach to client-side mining of temporal API specifications based on static analysis. Specifically, we present an interprocedural analysis over a combined domain that abstracts both aliasing and event sequences for individual objects. The analysis uses a new family of automata-based abstractions to represent unbounded event sequences, designed to disambiguate distinct usage patterns and merge similar usage patterns. Additionally, our approach includes an algorithm that summarizes abstract traces based on automata clusters, and effectively rules out spurious behaviors. We show experimental results mining specifications from a number of Java clients and APIs. The results indicate that effective static analysis for client-side mining requires fairly precise treatment of aliasing and abstract event sequences. Based on the results, we conclude that static client-side specification mining shows promise as a complement or alternative to dynamic approaches.


#*Chapter III: Particular Challenges in Applications
#@
#t2009
#cSimilarity-Based Clustering: Recent Developments and Biomedical Applications
#index129879


#*Accelerated Gradient Learning Algorithm for Neural Network Weights Update
#@Zeljko Hocenski,Mladen Antunovic,Damir Filko
#t2008
#cProceedings of the 12th international conference on Knowledge-Based Intelligent Information and Engineering Systems, Part I
#index400339
#!This work proposes decomposition of gradient learning algorithm for neural network weights update. Decomposition enables parallel execution convenient for implementation on computer grid. Improvements are reflected in accelerated learning rate which may be essential for time critical decision processes. Proposed solution is tested and verified on MLP neural network case study, varying a wide range of parameters, such as number of inputs/outputs, length of input/output data, number of neurons and layers. Experimental results show time savings in multiple thread execution.


#*Using entropy based clustering method to optimize heterogenous antennas in ad hoc wireless networks
#@Yong Wang,Kang K. Yen,Hao Zhu
#t2009
#cProceedings of the 6th IEEE Conference on Consumer Communications and Networking Conference
#index354786
#%235907
#%248496
#!Directional antennas widely used in IEEE 802.11 series protocols can offer high gain and low interference to other stations. But they also cause some side effects like the hidden terminal and deafness problems, which will deteriorate the performance of the networks significantly. Therefore, omni-directional antennas have to be used in some cases to avoid these problems. So a station equipped with antennas capable of operating in both omni-directional and directional modes is desired. In this paper, an entropy-based clustering algorithm is proposed to find an improved solution between using omni- and directional antennas, which utilizes the advantage of directional antennas and meanwhile alleviates the effects brought by directional antennas. We compare our proposed algorithms with the traditional ones and the simulation results confirm the effectiveness of our proposed method.


#*A Fast Algorithm for Critical Path Tracing in VLSI Digital Circuits
#@Lei Wu,D. M. H. Walker
#t2005
#cProceedings of the 20th IEEE International Symposium on Defect and Fault Tolerance in VLSI Systems
#index573976
#!An exact, linear-time critical path tracing algorithm is presented. The performance of critical path tracing is determined primarily by the efficiency of stem analysis. The proposed strategy can determine stem criticality in one pass based on six rules. Experiments on ISCAS85 and ISCAS89 benchmark circuits show that the computation time is nearly linear in the number of nets.


#*Information-Theoretic Measures for Meta-learning
#@Saddys Segrera,Joel Pinho,María N. Moreno
#t2008
#cProceedings of the 3rd international workshop on Hybrid Artificial Intelligence Systems
#index388075
#!Information-theoretic measures are suitable to characterize datasets with discrete attributes (or continuous which can be transformed). They can find information that can be decisive in order to analyze the behavior of different learning algorithms with specific datasets. The objective of the work presented in this paper is to study by means of three similar datasets from UCI Repository Machine Learning, the possible reasons for which breast-cancer-wisconsin dataset, in comparison with other 20 datasets, showed in a previous research that Stacking by Meta-Decision Trees (MDT) was significant better than all other multiclassifier models, including Stacking by Multi-Response Linear Regression (MLR). In our experiments the proportion of missing values, among other significant changes in different measure values, provided evidences about the possible origin of the different behaviors presented by these multiclassifier schemes depending on data characteristics.


#*Modular Reduction in GF(2n) without Pre-computational Phase
#@M. Knežević,K. Sakiyama,J. Fan,I. Verbauwhede
#t2008
#cProceedings of the 2nd international workshop on Arithmetic of Finite Fields
#index404802
#!In this study we show how modular multiplication with Barrett and Montgomery reductions over certain finite fields of characteristic 2 can be implemented efficiently without using a pre-computational phase. We extend the set of moduli that is recommended by Standards for Efficient Cryptography (SEC) by defining two distinct sets for which either Barrett or Montgomery reduction is applicable. As the proposed algorithm is very suitable for a fast modular multiplication, we propose an architecture for the fast modular multiplier that can efficiently be used without pre-computing the inverse of the modulus.


#*A Multiple-Level 3D-LEGO Game in Augmented Reality for Improving Spatial Ability
#@Trien V. Do,Jong-Weon Lee
#t2009
#cProceedings of the 13th International Conference on Human-Computer Interaction. Part IV: Interacting in Various Application Domains
#index504648
#!Inspired by the real LEGO game, an Augmented Reality 3D LEGO game is introduced. With multiple levels, the game provides a tool to improve spatial ability for a wide range of ages. Through the game, users can practice many spatial skills such as analyzing a 3D model's structure, figuring out what to do to make a primitive geometry become a component of a 3D model, assembling components to create a complex model. The users mainly use their hands controlling physical makers to play the game. A user study was also carried out to evaluate the game and to compare it with the real LEGO game. The game is believed to be a useful and interesting tool to enhance not only human's spatial ability but also human's creation in 3D reconstruction.


#*Foreword
#@Pierluigi Crescenzi,Fabrizio Luccio,Geppino Pucci
#t2009
#cTheory of Computing Systems
#index57797


#*Gradual Typing for Objects
#@Jeremy Siek,Walid Taha
#t2007
#cProceedings of the 21st European conference on ECOOP 2007: Object-Oriented Programming
#index394291
#!Static and dynamic type systems have well-known strengths and weaknesses. In previous work we developed a gradual type system for a functional calculus named $\lambda^?_\to$. Gradual typing provides the benefits of both static and dynamic checking in a single language by allowing the programmer to control whether a portion of the program is type checked at compile-time or run-time by adding or removing type annotations on variables. Several object-oriented scripting languages are preparing to add static checking. To support that work this paper develops $\mathbf{Ob}^{?}_{, a gradual type system for object-based languages, extending the Ob < : calculus of Abadi and Cardelli. Our primary contribution is to show that gradual typing and subtyping are orthogonal and can be combined in a principled fashion. We also develop a small-step semantics, provide a machine-checked proof of type safety, and improve the space efficiency of higher-order casts.


#*Biometric and Color Features Fusion for Face Detection and Tracking in Natural Video Sequences
#@Juan Zapata,Ramón Ruiz
#t2007
#cProceedings of the 2nd international work-conference on Nature Inspired Problem-Solving Methods in Knowledge Engineering: Interplay Between Natural and Artificial Computation, Part II
#index407816
#!A system that performs the detection and tracking of a face in real-time in real video sequences is presented in this paper. The face is detected in a complex environment by a model of human colour skin. Very good results are obtained, since the colour segmentation removes almost all the complex background and it is realized to a very high-speed, making the system very robust. On the other hand, fast and stable real-time tracking is then achieved via biometric feature extraction of face using connected components labelling. Tracking does not require a precise initial fit of the model. Therefore, the system is initialised automatically using a very simple 2D face detector based on target ellipsoidal shape. Results are presented showing a significant improvement in detection rates when the whole sequence is used instead of a single image of the face. Experiments in tracking are reported.


#*Teaching CS to undergraduates at UPMC
#@Christian Queinnec
#t2007
#cProceedings of the 2007 International Lisp Conference
#index489218
#!This presentation is about some experiments done at UPMC since 2000 in the CS undergraduate department. An initiation course, based on Scheme, was introduced offering some facilities for home work and stand alone offline studies. I will describe "Web continuations" that were invented for that occasion. Many of these innovations were ported to other languages or environments to grade students' programs en masse.


#*Fast Kernel Classifiers with Online and Active Learning
#@Antoine Bordes,Seyda Ertekin,Jason Weston,Léon Bottou
#t2005
#cThe Journal of Machine Learning Research
#index26112
#%371477
#%516190
#%584715
#%564235
#%355199
#%361380
#%364163
#%184117
#%373962
#!Very high dimensional learning systems become theoretically possible when training examples are abundant. The computing cost then becomes the limiting factor. Any efficient learning algorithm should at least take a brief look at each example. But should all examples be given equal attention?This contribution proposes an empirical answer. We first present an online SVM algorithm based on this premise. LASVM yields competitive misclassification rates after a single pass over the training examples, outspeeding state-of-the-art SVM solvers. Then we show how active example selection can yield faster training, higher accuracies, and simpler models, using only a fraction of the training example labels.


#*A Novel Expression of Spatial Correlation by a Random Curved Surface Model and Its Application to LSI Design
#@Shin-ichi Ohkawa,Hiroo Masuda,Yasuaki Inoue
#t2008
#cIEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences
#index68981
#!We have proposed a random curved surface model as a new mathematical concept which enables the expression of spatial correlation. The model gives us an appropriate methodology to deal with the systematic components of device variation in an LSI chip. The key idea of the model is the fitting of a polynomial to an array of Gaussian random numbers. The curved surface is expressed by a new extension from the Legendre polynomials to form two-dimensional formulas. The formulas were proven to be suitable to express the spatial correlation with reasonable computational complexity. In this paper, we show that this approach is useful in analyzing characteristics of device variation of actual chips by using experimental data.


#*Descriptological foundations of information technologies
#@V. N. Red'Ko,I. V. Red'Ko
#t2007
#cCybernetics and Systems Analysis
#index345300
#!The theses of compoundness, descriptiveness, and descriptologicality are proved. The conformance of these theses with the reversibility principle is substantiated. Logical-subject structures of information-technological systems are disclosed on this basis. Descriptological foundations of information technologies are created.


#*Real-time estimation of olive oil quality parameters: a combined approach based on ANNs and machine vision
#@Monica Carfagni,Marco Daou,Rocco Furferi
#t2008
#cProceedings of the 12th WSEAS international conference on Computers
#index64822
#%232646
#!The present work describes a combined approach based on Artificial Neural Networks and Machine Vision for the real-time estimation of some qualitative olive oil parameters. The proposed methodology proves to be a useful tool for the real-time estimation of acidity level and of peroxides number of olive oil extracted with a continuous extraction process. The two qualitative parameters are estimated on the basis of a number of technological and agronomical parameters. Some of the parameters correlated to the sanitary condition of olives and to ripeness are evaluated by means of image processing algorithms. The estimation may be performed during the extraction thus allowing a quality control of the oil quality without the requirement of a time-expensive chemical analysis.


#*Application of fuzzy Naive Bayes and a real-valued genetic algorithm in identification of fuzzy model
#@Yongchuan Tang,Yang Xu
#t2005
#cInformation Sciences&mdash;Informatics and Computer Science: An International Journal
#index97582
#%80020
#%586466
#%596204
#%541338
#%219109
#!We present a method to identify a fuzzy model from data by using the fuzzy Naive Bayes and a real-valued genetic algorithm. The identification of a fuzzy model is comprised of the extraction of "if-then" rules that is followed by the estimation of their parameters. The involved parameters include those which determine the membership function of fuzzy sets and the certainty factors of fuzzy if-then rules. In our method, as long as the fuzzy partition in the input-output space is given, the certainty factor of each rule is computed with the fuzzy conditional probability of the consequent conditioned on the antecedent by using the fuzzy Naive Bayes, which is a generalization of Naive Bayes. The fuzzy model involves the rules characterized by the highest values of certainty factors. The certainty factor of each rule is the fuzzy conditional probability, and it reflects the inner relationship between the antecedent and the consequent. In order to improve the accuracy of the fuzzy model, the real-valued genetic algorithm is incorporated into our identification process. This process concerns the optimization of the membership functions occurring in the rules. We just involve the parameters of membership function of the fuzzy sets into the real-valued genetic algorithm, since the certainty factor of each rule can be computed automatically. The performance of the model is shown for the backing-truck problem and the prediction of Mackey-Glass time series.


#*Broadcasting in cycles with chords
#@Frances L. Scoy
#t2008
#c
#index142309
#!Broadcasting is the process of information dissemination in which one node, the originator, knows a single piece of information and using a series of calls must inform every other node in the network of this information. We assume that at any given time, a node can communicate the message to another node, with which it shares an edge, by acting as either a sender or receiver, but not both. Multiple message broadcasting considers the case when the originator has m messages, where m > 1, to disseminate. Whereas broadcasting limits the communication of a message from one node to another node via a single edge, line broadcasting allows one node to send a message to any other node in the network as long as a simple path exists between the sending node and the receiving node and every edge along the path is not in use. In this dissertation, we consider the problem of broadcasting in a cycle with chords and we develop broadcast schemes for this type of network. We begin by investigating the problem of broadcasting in a cycle with one and two chords, respectively. Then, we consider the problem of multiple message broadcasting in cycles with one and two chords. Finally, we consider the problem of line broadcasting in cycles with chords. Through our investigations, we develop two algorithms for the problem of broadcasting in a cycle with one and two chords, respectively and we analyze the correctness and complexity of these algorithms. Then, we discuss problems associated with multiple message broadcasting in cycles with one and two chords. Finally, we use techniques developed for line broadcasting in cycles to create minimum time broadcast schemes for cycles through the addition of chords. Using techniques developed in this dissertation, we are able to broadcast in minimum time in cycles with chords. In cycles whose size is a power of 2, we have proved that the number of chords that we add to the cycle is the minimum number of chords required to broadcast in minimum time in such a cycle.


#*Data exchange and schema mappings in open and closed worlds
#@Leonid Libkin,Cristina Sirangelo
#t2008
#cProceedings of the twenty-seventh ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems
#index36351
#%21743
#%23635
#%5199
#%517966
#%101744
#%157706
#%422152
#%377966
#%108716
#%414269
#%173605
#%348171
#!In the study of data exchange one usually assumes an open-world semantics, making it possible to extend instances of target schemas. An alternative closed-world semantics only moves 'as much data as needed' from the source to the target to satisfy constraints of a schema mapping. It avoids some of the problems exhibited by the open-world semantics, but limits the expressivity of schema mappings. Here we propose a mixed approach: one can designate different attributes of target schemas as open or closed, to combine the additional expressivity of the open-world semantics with the better behavior of query answering in closed worlds. We define such schema mappings, and show that they cover a large space of data exchange solutions with two extremes being the known open and closed-world semantics. We investigate the problems of query answering and schema mapping composition, and prove two trichotomy theorems, classifying their complexity based on the number of open attributes. We find conditions under which schema mappings compose, extending known results to a wide range of closed-world mappings. We also provide results for restricted classes of queries and mappings guaranteeing lower complexity.


#*Perl Hacks: Tips & Tools for Programming, Debugging, and Surviving (Hacks)
#@chromatic,Damian Conway,Curtis "Ovid" Poe
#t2006
#c
#index4907
#!With more than a million dedicated programmers, Perl has proven to be the best computing language for the latest trends in computing and business. While other languages have stagnated, Perl remains fresh, thanks to its community-based development model, which encourages the sharing of information among users. This tradition of knowledge-sharing allows developers to find answers to almost any Perl question they can dream up.And you can find many of those answers right here in Perl Hacks. Like all books in O'Reilly's Hacks Series, Perl Hacks appeals to a variety of programmers, whether you're an experienced developer or a dabbler who simply enjoys exploring technology. Each hack is a short lesson--some are practical exercises that teach you essential skills, while others merely illustrate some of the fun things that Perl can do. Most hacks have two parts: a direct answer to the immediate problem you need to solve right now and a deeper, subtler technique that you can adapt to other situations. Learn how to add CPAN shortcuts to the Firefox web browser, read files backwards, write graphical games in Perl, and much more.For your convenience, Perl Hacks is divided by topic--not according to any sense of relative difficulty--so you can skip around and stop at any hack you like. Chapters include:Productivity HacksUser InteractionData MungingWorking with ModulesObject HacksDebuggingWhether you're a newcomer or an expert, you'll find great value in Perl Hacks, the only Perl guide that offers something useful and fun for everyone.


#*Immersive Mixed-Reality Configuration of Hybrid User Interfaces
#@Christian Sandor,Alex Olwal,Blaine Bell,Steven Feiner
#t2005
#cProceedings of the 4th IEEE/ACM International Symposium on Mixed and Augmented Reality
#index581182
#%196302
#%282943
#%287410
#%527230
#%580954
#%622144
#!Information in hybrid user interfaces can be spread over a variety of different, but complementary, displays, with which users interact through a potentially equally varied range of interaction devices. Since the exact configuration of these displays and devices may not be known in advance, it is desirable for users to be able to reconfigure at runtime the data fIow between interaction devices and objects on the displays. To make this possible, we present the design and implementation of a prototype mixed reality system that allows users to immersively reconfigure a running hybrid user interface.


#*GNetIc --- Using Bayesian Decision Networks for Iconic Gesture Generation
#@Kirsten Bergmann,Stefan Kopp
#t2009
#cProceedings of the 9th International Conference on Intelligent Virtual Agents
#index496159
#!Expressing spatial information with iconic gestures is abundant in human communication and requires to transform a referent representation into resembling gestural form. This task is challenging as the mapping is determined by the visuo-spatial features of the referent, the overall discourse context as well as concomitant speech, and its outcome varies considerably across different speakers. We present a framework, GNetIc, that combines data-driven with model-based techniques to model the generation of iconic gestures with Bayesian decision networks. Drawing on extensive empirical data, we discuss how this method allows for simulating speaker-specific vs. speaker-independent gesture production. Modeling results from a prototype implementation are presented and evaluated.


#*Using ASR for Transcription of Teleconferences in IM Systems
#@Ira R. Forman,Thomas Brunet,Paul Luther,Allen Wilson
#t2009
#cProceedings of the 5th International Conference on Universal Access in Human-Computer Interaction. Part III: Applications and Services
#index499214
#!The integration of voice transmission into instant messaging systems may be a boon for most of us, but causes a problem for others, that is, this integration will disadvantage those who are deaf and hard of hearing. This problem may be mitigated with transcription implemented with automated speech recognition (ASR). This paper describes a plug-in for IBM's Sametime instant messaging product that uses commercial ASR products to provide transcription. The user interface and the lessons learned from the wide use of the plug-in are described.


#*Towards Automated Game Design
#@Mark J. Nelson,Michael Mateas
#t2007
#cProceedings of the 10th Congress of the Italian Association for Artificial Intelligence on AI*IA 2007: Artificial Intelligence and Human-Oriented Computing
#index400902
#!Game generation systems perform automated, intelligent design of games (i.e. videogames, boardgames), reasoning about both the abstract rule system of the game and the visual realization of these rules. Although, as an instance of the problem of creative design, game generation shares some common research themes with other creative AI systems such as story and art generators, game generation extends such work by having to reason about dynamic, playable artifacts. Like AI work on creativity in other domains, work on game generation sheds light on the human game design process, offering opportunities to make explicit the tacit knowledge involved in game design and test game design theories. Finally, game generation enables new game genres which are radically customized to specific players or situations; notable examples are cell phone games customized for particular users and newsgames providing commentary on current events. We describe an approach to formalizing game mechanics and generating games using those mechanics, using WordNet and ConceptNet to assist in performing common-sense reasoning about game verbs and nouns. Finally, we demonstrate and describe in detail a prototype that designs micro-games in the style of Nintendo's WarioWare series.


#*Fuzzy control approach to mixed culture cultivation for PHB production process: nitrogen time profile synthesis
#@Petia D. Koprinkova-Hristova
#t2008
#cProceedings of the 9th WSEAS International Conference on Fuzzy Systems
#index386218
#%213071
#!The present paper considers the control problems of the mixed culture system where sugars (glucose) were converted to lactate by the microorganism L. delbrueckii and then the lactate was converted to PHB (poly-β-hydroxybutyrate) by the microorganism R. euthropha. The strategy to determine the optimal nitrogen concentration profile that maximizes the PHB production at the end of the process is discussed. Fuzzy rules based on experts' knowledge of the process and previous investigations are proposed. They are applied together with previously developed fuzzy approach that maintains the lactate concentration at its' optimal value by means of the dissolved oxygen concentration set point and the substrate (glucose) concentration feeding rate simultaneously. It is shown that the intelligent approach proposed here outperforms the classical control strategies applied before.


#*Unit response matrix coefficients development: ANN approach
#@Saeed Alimohammadi,Abbas Afshar
#t2005
#cProceedings of the 5th WSEAS/IASME International Conference on Systems Theory and Scientific Computation
#index39661
#!The ANN methodology, inspired by neurobiology theories of massive interconnection and parallelism has been successfully employed in variety of optimization problems. In ground water management models, either governing equations are embedded into the management model or unit response matrixes are employed. Unit response matrixes development requires huge amount of data and/or simulation runs. In this paper, ANN is employed to develop unit response matrix coefficients to be later used in the management model. To do it, a ANN model has been trained to predict the outcome of the flow code, which results in unit response matrix coefficients for the aquifer under consideration. To train the ANN model different realizations from pumping well co-ordinates, distance between pumping and observation wells, and hydraulic conductivities of pumping wells were used, it was concluded that pumping well co-ordinates may be successfully employed for developing unit response matrix coefficients to be later used in management models. To test the performance of the proposed approach, the hypothetical aquifer was assumed. The aquifer response to different pumping stresses were compared using a well-defined simulation model and those resulted from unit response matrixes developed by (1) ANN approach and (2) direct data from groundwater simulation runs. It was concluded that ANN may be successfully employed for development of unit response matrix with limited data from field study or ground water simulation runs.


#*Internet security threat landscape: scaling to meet the threat
#@Robert J. Stratton, III
#t2009
#cProceedings of the 5th Annual Workshop on Cyber Security and Information Intelligence Research: Cyber Security and Information Intelligence Challenges and Strategies
#index142390


#*Advent Rising Official Strategy Guide (Official Strategy Guides (Bradygames))
#@
#t2005
#c
#index14013


#*Proceedings of the 2009 Second International Workshop on Knowledge Discovery and Data Mining
#@
#t2009
#cWKDD
#index56165


#*Effective Leadership Skills for the CISO
#@Todd Fitzgerald,Micki Krause
#t2007
#c
#index9684


#*AOI-cast strategies for P2P massively multiplayer online games
#@Luca Genovali,Laura Ricci
#t2009
#cProceedings of the 6th IEEE Conference on Consumer Communications and Networking Conference
#index354224
#%36883
#%272470
#%534099
#%387954
#!This paper presents a P2P support for Massively Multiplayer On line Games. The P2P overlay is defined by considering a Voronoi diagram where the sites correspond to the peers and a link connects Voronoi neigbours. An AOI-cast mechanism is defined to notify events generated by a peer to peers located in its Area of Interest. A routing algorithm exploiting the properties of the Voronoi graph has been defined as well. AOI-cast has been evaluated through a set of simulations developed by Peersim.


#*Characteristic morphisms of generalized episturmian words
#@Michelangelo Bucci,Aldo de Luca,Alessandro De Luca
#t2009
#cTheoretical Computer Science
#index128688
#%1587
#%9238
#%400934
#%313828
#%234766
#!In a recent paper with L.Q. Zamboni, the authors introduced the class of @q-episturmian words. An infinite word over A is standard @q-episturmian, where @q is an involutory antimorphism of A^*, if its set of factors is closed under @q and its left special factors are prefixes. When @q is the reversal operator, one obtains the usual standard episturmian words. In this paper, we introduce and study @q-characteristic morphisms, that is, morphisms which map standard episturmian words into standard @q-episturmian words. They are a natural extension of standard episturmian morphisms. The main result of the paper is a characterization of these morphisms when they are injective. In order to prove this result, we also introduce and study a class of biprefix codes which are overlap-free, i.e., any two code words do not overlap properly, and normal, i.e., no proper suffix (prefix) of any code-word is left (right) special in the code. A further result is that any standard @q-episturmian word is a morphic image, by an injective @q-characteristic morphism, of a standard episturmian word.


#*Optimal network design and storage management in petroleum distribution network under uncertainty
#@Mehdi Ghatee,S. Mehdi Hashemi
#t2009
#cEngineering Applications of Artificial Intelligence
#index125234
#%517341
#%292435
#!This paper studies the status of storage tanks in petroleum distribution network under uncertainty. It is difficult to describe the topology of this network precisely. As an instance, the capacity of pipelines and tanks due to corrosion cannot be presented as real numbers. Also production of oil fields, demand of costumers and food of refineries in a long-term programming are given under uncertainty. The contribution of this paper is to capture with the corresponding granular information applying fuzzy concepts. For this mission, an off-line basic framework is proposed in order to find the least daily-transportation-cost of crude oil flows through a capacitated network. To transform this management problem into a traditional minimal cost flow problem (MCFP), a T-floors network is provided which simulates the oil transportation in T days. The dummy links adjoining two consecutive floors are embedded as storage depots and their flows are corresponded to maintained flow. To exhibit with imprecision concerning this dynamic network, a fuzzifier can be applied which obtains a fuzzy number reflecting system description. Then a fully fuzzified MCFP is solved applying a ranking function understood by authors in previous works. We illustrate the performance of the proposed scheme on a simplified pilot of Iranian petroleum industry network. Furthermore, we offer a modified version of successive shortest path algorithm which is able to find the optimal place and the optimal capacity of storage tanks when they are required through the long-term programming period.


#*Decentralized Information Retrieval Systems Based on Contents Information for Ubiquitous Services
#@Takeshi Tsuchiya,Hirokazu Yoshinaga,Keiichi Koyanagi
#t2007
#cProceedings of the 21st International Conference on Advanced Information Networking and Applications Workshops - Volume 02
#index423394
#!In this paper, we propose and clarify distributed Information Retrieval (IR) manner uses of Peer-to-Peer (P2P) Technology, which has same accuracy approximately at current index-integrated search engine use of statistical information calculated from the contents. Decentralized IR mechanisms use of statistic information have following problems. One is the manner calculates the statistic information from all contens by the collaborated with distributed peers (nodes). Second problem is the efficient allocation of indices on logical space created by peers, and named it "Multiple-Ring". And the last problem is constructing efficient IR strategies with high accuracy on them. At end, the proposal distributed IR mechanism is suitable for the flexible IR systems from middle scale to small scale such as office, because the system scalability is limited by the propagation time periodically among peers.


#*An adaptive online system for efficient processing of hierarchical data
#@Athanasia Asiki,Dimitrios Tsoumakos,Nectarios Koziris
#t2009
#cProceedings of the 18th ACM international symposium on High performance distributed computing
#index125943
#%121812
#%347466
#%308192
#%436106
#!Concept hierarchies greatly help in the organization and reuse of information and are widely used in a variety of information systems applications. In this paper, we describe a method for efficiently storing and querying data organized into concept hierarchies and dispersed over a DHT. In our method, peers individually decide on the level of indexing according to the granularity of the incoming queries. Roll-up and drill-down operations are performed on a per-node basis in order to minimize the required bandwidth for answering queries on variable aggregation levels. We motivate our approach by applying it on a large-scale Grid system: Specifically, we plan to apply our fully decentralized scheme that creates, queries and updates large volumes of hierarchical data on-line and replace the traditional centralized and strictly indexed information systems. Our extensive experimental results support this argument on many diverse configurations: Our system proves very efficient in skewed workloads, both over single and multiple hierarchy levels at the same time. It adapts to sudden changes in popularity and effectively stores and updates large amounts of data at very low cost.


#*Special Thanks to IC's Reviewers
#@
#t2007
#cIEEE Internet Computing
#index424377


#*Implementation of a smart antenna base station for mobile WiMAX based on OFDMA
#@Seungheon Hyeon,Changhoon Lee,Chang-eui Shin,Seungwon Choi
#t2009
#cEURASIP Journal on Wireless Communications and Networking
#index141101
#!We present an implementation of a mobile-WiMAX (m-WiMAX) base station (BS) that supports smart antenna (SA) functionality. To implement the m-WiMAX SA BS, we must address a number of key issues in baseband signal processing related to symbol-timing acquisition, the beamforming scheme, and accurate calibration. We propose appropriate solutions and implement an m-WiMAX SA BS accordingly. Experimental tests were performed to verify the validity of the solutions. Results showed a 3.5-time (5.5 dB) link-budget enhancement on the uplink compared to a single antenna system. In addition, the experimental results were consistent with the results of the computer simulation.


#*Deciding the physical implementation of ETL workflows
#@Vasiliki Tziovara,Panos Vassiliadis,Alkis Simitsis
#t2007
#cProceedings of the ACM tenth international workshop on Data warehousing and OLAP
#index339039
#%98761
#%597359
#%339266
#!In this paper, we deal with the problem of determining the best possible physical implementation of an ETL workflow, given its logical-level description and an appropriate cost model as inputs. We formulate the problem as a state-space problem and provide a suitable solution for this task. We further extend this technique by intentionally introducing sorter activities in the workflow in order to search for alternative physical implementations with lower cost. We experimentally assess our method based on a principled organization of test suites.


#*How well do visual verbs work in daily communication for young and old adults?
#@Xiaojuan Ma,Perry R. Cook
#t2009
#cProceedings of the 27th international conference on Human factors in computing systems
#index56013
#%539661
#!In this paper we study how verbs are visually conveyed in daily communication contexts for both young and old adults. Four visual modes are compared: a single static image, a panel of four static images, an animation, and a video clip. The results reveal age effects, as well as performance differences introduced by lexical verb properties and visual cues. We also suggest guidelines for visual verb creation.


#*Exploiting temporal discontinuities for event detection and manipulation in video streams
#@Hugh Denman,Erika Doyle,Anil Kokaram,Daire Lennon,Rozenn Dahyot,Ray Fuller
#t2005
#cProceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval
#index579512
#%618350
#!Discontinuities in any information bearing signal serve to represent much of the vital or interesting content in that signal. A sharp loud noise in a movie could be a gun, or something breaking. In sports like tennis, cricket or snooker/pool it would indicate a point scoring event. In both cases the discontinuity is likely to be semantically relevant without further inference being necessary, once a particular domain is adopted. This paper discusses the importance of temporal motion discontinuities in inferring events in visual media. Two particular application domains are considered: content based audio/video synchronisation and event spotting in observational Psychology.


#*Hierarchical Time-Stamp Protocol: Acquiring Reliable Time-stamp from Local Time Stamping Server
#@Xian Pan,J.-L. Zheng
#t2009
#cProceedings of the 2009 Second International Symposium on Electronic Commerce and Security - Volume 01
#index493826
#!Time Stamp Protocol (TSP) is a basic security component in e-world, and Time Stamping Server (TSS)as a Trusted Third Party (TTP) generally is implemented on Internet other than in LAN. The acquiring reliability of the existing time-stamp protocols has been mainly focused by researchers in recent years, but the time delay problem produced by frequent time-stamp request has not been paid enough attention to yet. However, simply putting the TSS into LAN may deteriorate its reliability.To solve this problem, a novel Hierarchical Time-Stamp Protocol (HTSP) is proposed in this paper which enables making reliable time stamp in LAN. The hierarchy model in HTSP contains two TSS: Internet TSS and local TSS.Therefore, the advantage of a quick time stamp response of the local TSS is used, whereas the disadvantage of a possible time stamp fake in the local TSS could be overcome by periodically acquiring time stamp from the Internet TSS. The security analysis shows that reliability of time stamp in the HTSP is still remaining unchanged in comparison with the current TSP.


#*Opponent Modeling in Adversarial Environments through Learning Ingenuity
#@Arash Afkanpour,Saeed Bagheri Shouraki
#t2005
#cProceeding of the 2005 conference on Self-Organization and Autonomic Informatics (I)
#index137135
#%381876
#%569014
#%611946
#%540389
#!In Multiagent systems there are several agents with cooperative or competitive goals. Here, we are especially interested in zero-sum games which contain exactly two players with fully opposite goals. We describe a method based on Maximum-Expected-Utility [7] principle that learns the ingenuity of the opponent based on the moves of the opponent through a game and exploits this knowledge to play better against that opponent. Then we demonstrate an application of proposed method in the popular board game of Connect-4. The results show that the proposed method is superior compared to previous methods for adversarial environments especially when there is not adequate training for appropriate adaptation against an opponent.


#*Multi-dimensional classification of biomedical text
#@Hagit Shatkay,Fengxia Pan,Andrey Rzhetsky,W. John Wilbur
#t2008
#cBioinformatics
#index629196
#!Motivation: Much current research in biomedical text mining is concerned with serving biologists by extracting certain information from scientific text. We note that there is no ‘average biologist’ client; different users have distinct needs. For instance, as noted in past evaluation efforts (BioCreative, TREC, KDD) database curators are often interested in sentences showing experimental evidence and methods. Conversely, lab scientists searching for known information about a protein may seek facts, typically stated with high confidence. Text-mining systems can target specific end-users and become more effective, if the system can first identify text regions rich in the type of scientific content that is of interest to the user, retrieve documents that have many such regions, and focus on fact extraction from these regions. Here, we study the ability to characterize and classify such text automatically. We have recently introduced a multi-dimensional categorization and annotation scheme, developed to be applicable to a wide variety of biomedical documents and scientific statements, while intended to support specific biomedical retrieval and extraction tasks. Results: The annotation scheme was applied to a large corpus in a controlled effort by eight independent annotators, where three individual annotators independently tagged each sentence. We then trained and tested machine learning classifiers to automatically categorize sentence fragments based on the annotation. We discuss here the issues involved in this task, and present an overview of the results. The latter strongly suggest that automatic annotation along most of the dimensions is highly feasible, and that this new framework for scientific sentence categorization is applicable in practice. Contact: shatkay@cs.queensu.ca


#*Performance analysis of security aspects in UML models
#@D. C. Petriu,C. M. Woodside,D. B. Petriu,J. Xu,T. Israr,Geri Georg,Robert France,James M. Bieman,Siv Hilde Houmb,Jan Jürjens
#t2007
#cProceedings of the 6th international workshop on Software and performance
#index11712
#%613750
#%108269
#!The focus of the paper is on the analysis of performance effects of different security solutions modeled as aspects in UML. Aspect oriented modeling (AOM) allows software designers to isolate and separately address solutions for crosscutting concerns, which are defined as distinct UML aspect models, then are composed with the primary UML model of the system under development. For performance analysis we use techniques developed previously in the PUMA project, which take as input UML models annotated with the standard UML Profile for Schedulability, Performance and Time (SPT), and transform them first into Core Scenario Model (CSM) and then into different performance models. The contribution of this paper is in performing the composition of the aspects with the primary model at the CSM level. The input is represented by the primary model and a number of aspect models in UML+SPT, which are processed as follows: a) converted separately to CSM; b) composed into a single CSM model; c) transformed into a Layered Queueing Networks (LQN) model and d) analyzed. The proposed approach is illustrated with a case study based on two standards, TPC-W and SSL.


#*The Feature Importance Ranking Measure
#@Alexander Zien,Nicole Krämer,Sören Sonnenburg,Gunnar Rätsch
#t2009
#cProceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases: Part II
#index492657
#!Most accurate predictions are typically obtained by learning machines with complex feature spaces (as e.g. induced by kernels). Unfortunately, such decision rules are hardly accessible to humans and cannot easily be used to gain insights about the application domain. Therefore, one often resorts to linear models in combination with variable selection, thereby sacrificing some predictive power for presumptive interpretability. Here, we introduce the Feature Importance Ranking Measure (FIRM), which by retrospective analysis of arbitrary learning machines allows to achieve both excellent predictive performance and superior interpretation. In contrast to standard raw feature weighting, FIRM takes the underlying correlation structure of the features into account. Thereby, it is able to discover the most relevant features, even if their appearance in the training data is entirely prevented by noise. The desirable properties of FIRM are investigated analytically and illustrated in simulations.


#*An Empirical Analysis of the Impact of Software Vulnerability Announcements on Firm Stock Price
#@Rahul Telang,Sunil Wattal
#t2007
#cIEEE Transactions on Software Engineering
#index402206
#!Security defects in software cost millions of dollars to firms in terms of downtime, disruptions, and confidentiality breaches. However, the economic implications of these defects for software vendors are not well understood. Lack of legal liability and the presence of switching costs and network externalities may protect software vendors from incurring significant costs in the event of a vulnerability announcement, unlike such industries as auto and pharmaceuticals, which have been known to suffer significant loss in market value in the event of a defect announcement. Although research in software economics has studied firms' incentives to improve overall quality, there have not been any studies which show that software vendors have an incentive to invest in building more secure software. The objectives of this paper are twofold. 1) We examine how a software vendor's market value changes when a vulnerability is announced. 2) We examine how firm and vulnerability characteristics mediate the change in the market value of a vendor. We collect data from leading national newspapers and industry sources, such as the Computer Emergency Response Team (CERT), by searching for reports on published software vulnerabilities. We show that vulnerability announcements lead to a negative and significant change in a software vendor's market value. In our sample, on average, a vendor loses around 0.6 percent value in stock price when a vulnerability is reported. We find that a software vendor loses more market share if the market is competitive or if the vendor is small. To provide further insight, we use the information content of the disclosure announcement to classify vulnerabilities into various types. We find that the change in stock price is more negative if the vendor fails to provide a patch at the time of disclosure. Also, more severe flaws have a significantly greater impact. Our analysis provides many interesting implications for software vendors as well as policy makers. In particular, our study provides some evidence of the value of secure software.


#*ARMAX modelling of international tourism demand
#@Christine Lim,Michael McAleer,Jennifer C. H. Min
#t2009
#cMathematics and Computers in Simulation
#index140222
#%247546
#!Box-Jenkins (1970) models are often used to capture the autoregressive moving average of past observations of tourist arrivals from Japan to Taiwan and New Zealand. However, other explanatory variables, such as real income in the origin country, have also affected the demand for international travel. The purpose of this paper is to use the ARMAX model to investigate the dynamic relationship between tourism demand and real income of Japan, and to compare the findings with the single-equation model. Unit root tests and diagnostics are performed before estimating the income elasticity of travel demand by Japan for New Zealand and Taiwan based on seasonally unadjusted quarterly data for 1980(1) to 2004(2). The empirical results of the ARMAX model support the economic theory that the demand for international travel is positively related to income of the origin country.


#*An opportunity for engagement in cyberspace: Political youth Web sites during the 2004 European Parliament election campaign
#@Janelle Ward
#t2005
#cInformation Polity
#index411366
#!The Internet is playing an increasing role in the political arena. Online election campaigns work to generate voter interest by providing more varied information and encouraging citizen participation in the electoral process. However, research has infrequently focused on how political websites particularly address young people. While youth are much more active online in many realms, including politics, than the average citizen, they are also becoming progressively more disconnected from traditional governmental and party politics. Some argue that such disengagement leads to increased apathy and even alienation. Political detachment, coupled with the younger generations' noteworthy online use and presence, points to a considerable Internet potential for reversing such indifference. Based on quantitative content analysis, this article examines the possibilities for online participation available to youth in the context of the 2004 European Parliament election campaign. Specifically, it evaluates the websites of youth branches of political parties and youth organisations in Britain and Ireland (n=46), to determine the amount and nature of information provided and engagement opportunities offered. This article provides an exploratory examination as to how the EP election was presented to youth and how youth are addressed online.


#*II Intelligence Everywhere: Computational Intelligence in Human Cancer Research
#@
#t2008
#cProceedings of the 12th international conference on Knowledge-Based Intelligent Information and Engineering Systems, Part II
#index393862


#*Tensor-based hardness of the shortest vector problem to within almost polynomial factors
#@Ishay Haviv,Oded Regev
#t2007
#cProceedings of the thirty-ninth annual ACM symposium on Theory of computing
#index429310
#%94807
#%171660
#%175999
#%185200
#%245006
#%250220
#%288868
#%598717
#%436200
#!We show that unless NP ⊆ RTIME (2poly(log n)), for any ε > 0 there is no polynomial-time algorithm approximating the Shortest Vector Problem (SVP) on n-dimensional lattices inthe lp norm (1 ≤q p<∞) to within a factor of 2(log n)1-ε. This improves the previous best factor of 2(logn)1/2-ε under the same complexity assumption due to Khot. Under the stronger assumption NP ࣰ RSUBEXP, we obtain a hardness factor of nc/log log n for some c > 0. Our proof starts with Khot's SVP instances from that are hard to approximate to within some constant. To boost the hardness factor we simply apply the standard tensor product oflattices. The main novel part is in the analysis, where we show that Khot's lattices behave nicely under tensorization. At the heart of the analysis is a certain matrix inequality which was first used in the context of lattices by de Shalit and Parzanchevski.


#*Improving change descriptions with change contexts
#@Chris Parnin,Carsten Görg
#t2008
#cProceedings of the 2008 international working conference on Mining software repositories
#index53074
#%349084
#%475735
#%379224
#%285911
#%578679
#%591160
#%574390
#%310007
#!Software archives are one of the best sources available to researchers for understanding the software development process. However, much detective work is still necessary in order to unravel the software development story. During this process, researchers must isolate changes and follow their trails over time. In support of this analysis, several research tools have provided different representations for connecting the many changes extracted from software archives. Most of these tools are based on textual analysis of source code and use line-based differencing between software versions. This approach limits the ability to process changes structurally resulting in less concise and comparable items. Adoption of structure-based approaches have been hampered by complex implementations and overly verbose change descriptions. We present a technique for expressing changes that is fine-grained but preserves some structural aspects. The structural information itself may not have changed, but instead provides a context for interpreting the change. This in turn, enables more relevant and concise descriptions in terms of software types and programming activities. We apply our technique to common challenges that researchers face, and then we discuss and compare our results with other techniques.


#*Adaptive Query Optimization Method for Multiple Continuous Queries
#@Yousuke Watanabe,Hiroyuki Kitagawa
#t2005
#cProceedings of the 21st International Conference on Data Engineering Workshops
#index33700
#!Continuous query is widely recognized as a scheme for processing queries over data streams, and efficient methods for processing multiple continuous queries are needed. Our research group has proposed a multiple query optimization method for continuous queries. In our method, the system forms clusters of queries with similar execution patterns, and derives query plans sharing the result of common operators. Our previous experiments have shown that a parameter value in the clustering phase controls divisions of clusters and has a great impact on query processing effi- ciency. However, the optimal parameter value must be decided by trial and error. This paper extends our previous work. The proposed method automatically estimates the optimal value and iteratively adjusts it even if properties of underlying data streams dramatically change.


#*How many leads are necessary for a reliable reconstruction of surface potentials during atrial fibrillation?
#@María de la Salud Guillem,Andreas Bollmann,Andreu M. Climent,Daniela Husser,Jose Millet-Roig,Francisco Castells
#t2009
#cIEEE Transactions on Information Technology in Biomedicine
#index19742
#!In this study, we aimed at determining how many leads are necessary for accurately reconstructing ECG potentials during atrial fibrillation (AF) on the body surface. Although the standard ECG is appropriate for the detection of this arrhythmia, its accuracy for extracting other diagnostic features or constructing surface potential maps may not be optimal. We evaluated the suitability of the standard ECG in AF and proposed a new lead system for improving the information content of AF signals in limited lead systems. We made use of 64-lead body surface potential mapping recordings of 17 patients during AF and 18 healthy subjects. Lead selection was performed by making use of a lead selection algorithm proposed by Lux, and error curves were calculated for increasing number of selected leads for QRS complexes and P waves from healthy subjects and AF signals. From our results, at least 23 leads are needed in order to have the same degree of accuracy in the derivation of AF waves as the 12-lead ECG for a normal QRS complex (25% error). The 12-lead ECG allows a reconstruction of surface potentials with 53% error. If a limited lead set is to be chosen, a repositioning of only four electrodes from the standard ECG reduces reconstruction error in 11%. This repositioning of electrodes may include more right anterior electrodes and one posterior electrode.


#*Support System for Developing Web Service Composition Scenarios without Need for Web Application Skills
#@Yasutoshi Miyagi,Yoji Yamato,Yusuke Nakano,Miki Hirano
#t2009
#cProceedings of the 2009 Ninth Annual International Symposium on Applications and the Internet
#index496319
#!There are support systems for developing cooperating Web Service applications for writing a Business Process Execution Language (BPEL) scenario. However, these systems are intended for Web Application developers since end-users cannot write scenarios without web application skills. There are two problems with these systems: writing a scenario is difficult and end-users cannot develop complex ones using these systems.To solve these problems, we propose a new support system for scenario writing in which a service composition application can be easily developed using the weight from a component rank method, such as Page Rank by Google. Our system is not only used when considering the history of a developer to estimate the rank, but uses end-user history, which is the number of time end-users used scenarios. As a result, our proposed system can be used to easily produce a new complex scenario. We also conduct a simulation of the proposed system and compare it with the current support systems to show its effectiveness.


#*Latchup effect in CMOS IC: a solution for crypto-processors protection against fault injection attacks?
#@N. Buard,F. Miller,C. Ruby,R. Gaillard
#t2007
#cProceedings of the 13th IEEE International On-Line Testing Symposium
#index425757
#!Latchup is a short-circuit that can be triggered in CMOS ICs when a current pulse is produced by parasitic perturbations. It is usually regarded as very disturbing for reliability, especially in space applications where it is triggered by ionizing particles naturally present in the environment. But in another context, the one of crypto-processors, it could be used as a way to protect the device from attacks by fault injections. Indeed, if all the parts of the ICs containing the secret data have the property to be more sensitive to latchup than to upsets, it will be impossible for attackers to retrieve the key with fault injections attacks. This paper describes how to design a crypto-processor with such features, and how to verify its properties.


#*Replay debugging for distributed applications
#@Dennis Geels,Gautam Altekar,Scott Shenker,Ion Stoica
#t2006
#cProceedings of the annual conference on USENIX '06 Annual Technical Conference
#index415193
#%120332
#%319217
#%413631
#%424022
#!We have developed a new replay debugging tool, liblog, for distributed C/C++ applications. It logs the execution of deployed application processes and replays them deterministically, faithfully reproducing race conditions and non-deterministic failures, enabling careful offline analysis. To our knowledge, liblog is the first replay tool to address the requirements of large distributed systems: lightweight support for long-running programs, consistent replay of arbitrary subsets of application nodes, and operation in a mixed environment of logging and nonlogging processes. In addition, it requires no special hardware or kernel patches, supports unmodified application executables, and integrates GDB into the replay mechanism for simultaneous source-level debugging of multiple processes. This paper presents liblog's design, an evaluation of its runtime overhead, and a discussion of our experience with the tool to date.


#*Smart support functions for sequential pattern mining
#@Dunren Che,Wei Zheng
#t2006
#cJournal of Computational Methods in Sciences and Engineering
#index405935
#%246709
#%355878
#%360581
#%378420
#!In real applications, transaction data typically contain quantitative attributes. Existing approaches and algorithms proposed for sequential pattern mining such as AprioriAll often assume Boolean attributes (i.e., quantitative values are simply interpreted/transformed as Boolean values). This article addresses the impact of varied quantitative attributes in sequential pattern mining. More specifically, we define alternate smart support functions for computing the support measure of candidate sequential patterns. A noticeable advantage of this work is that the proposed smart support functions can be smoothly integrated into the framework of existing sequential pattern mining algorithms. In the discussion of this article, we assume adoption of the well-known AprioriAll algorithm and discuss the incorporation of the proposed smart support functions into this framework. The expected mining results are believed better reflecting the particular interests of different user groups and thus are more satisfactory to the intended users.


#*A Novel Approach to Optimize Information Dissemination in IMS Presence System
#@Rongheng Lin,Hua Zou,Yao Zhao,Fangchun Yang
#t2008
#cProceedings of the 8th international conference, NEW2AN and 1st Russian Conference on Smart Spaces, ruSMART on Next Generation Teletraffic and Wired/Wireless Advanced Networking
#index386089
#!Presence is an important service in IMS. The user in IMS would use presence as a necessary component. But the more user uses, the harder presence information transmits. Previous researches show that the traffic increases rapidly with the presentity number grows. In this paper, we propose an approach to optimize information dissemination in IMS Presence System. Comparing with previous researches, a new architecture is set up. In this architecture, presence information transmission is modeled as a growing tree. A k sequence method is proposed to construct the tree. And some key algorithms are introduced for the tree adjustment. With a mathematical analysis, the new method is more suitable for presence information dissemination. And in the experiment, the result shows that the method can do a better job with smaller traffic and jitter.


#*Penalty for power reduction -: performance or schedule or yield?
#@Bodhisatya Sarker,Jaswinder Ahuja,Arijit Dutta,Srinath D.,Kaip Sridhar,Radhakrishnan Nair,Jayant Lahiri
#t2008
#cProceeding of the 13th international symposium on Low power electronics and design
#index48997
#!It is often said "It is always give and take" and that "there is no such thing as a free lunch". The same would hold true for Low Power designs. The questions oft asked is What are the trade-offs for reduction in power? What would be the limits of power reduction, before it starts impacting other parameters? Designs are generally characterized by four predominant parameters - performance, timing, area and power. As design and manufacturing became different disciplines supported by independent teams, two additional parameters were added to the design characterization, schedule and yield. Schedule implies the time taken to get the design to the desired performance and yield indicates the percentage of designs that meet the performance criterion, after manufacturing. Performance, schedule and yield have become a proxy for the expertise built in the design team and the capability of the tools to handle the complex designs. Teams with expertise and access to appropriate tools, can build high performance designs faster and at the desired yields. Traditionally performance has been correlated with timing or the maximum operating frequency of the design. More recently power is becoming an important area of concern, and is forcing designers to design within the power specifications of the design. Power has been seen as limiting the timing performance for many designs. In this key panel, we will discuss: What could be some of the best practices to reduce power while maintaining timing performanceHow could one analyze the performance, schedule, yield trade-off with an exampleDiscuss industry-wide effort to reduce the penalty for further power reduction


#*Bright CdSe quantum dot inserted in single ZnSe nanowires
#@A. Tribu,G. Sallen,T. Aichele,C. Bougerol,R. André,J. P. Poizat,S. Tatarenko,K. Kheng
#t2009
#cMicroelectronics Journal
#index65385
#!We report the evidence of CdSe quantum dot (QD) insertion in single defect-free ZnSe nanowire. These nanowires have been grown by molecular beam epitaxy in vapour-liquid-solid growth mode catalysed with gold particles. We developed a two-step process allowing us to grow very thin (from 15 to 5nm) defect-free ZnSe nanowire on top of a nanoneedle, where all defects are localised. The CdSe QDs are incorporated to the defect-free nanowires part. Owing to the extraction efficiency of the nanowires and the reduced number of stacking fault defects in the two-step-process nanowires, a very efficient photoluminescence is observed even on isolated single nanowire. Time-resolved photoluminescence and correlation photon give evidences that the bright photon emission is related to the CdSe QD.


#*A fast learning algorithm for deep belief nets
#@Geoffrey E. Hinton,Simon Osindero,Yee-Whye Teh
#t2006
#cNeural Computation
#index22273
#%441416
#%594837
#%621848
#%104776
#%312788
#!We show how to use "complementary priors" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.


#*Image Retrieval: Color and Texture Combining Based on Query-Image
#@Ilya Markov,Natalia Vassilieva
#t2008
#cProceedings of the 3rd international conference on Image and Signal Processing
#index403308
#!It is a common way to process different image features independently in order to measure similarity between images. Color and texture are the common ones to use for searching in natural images. In [10] a technique to combine color and texture features based on a particular query-image in order to improve retrieval efficiency was proposed. Weighted linear combination of color and texture metrics was considered as a mixed-metrics. In this paper the mixed-metrics with different weights are compared to pure color and texture metrics and widely used CombMNZ data fusion algorithm. Experiments show that proposed metrics outperform CombMNZ method in some cases, and have close results in others.


#*Best Practice: The Pros On Adobe Illustrator
#@Toni Toland
#t2006
#c
#index5583


#*Proceedings of the 5th international conference on Sequences and Their Applications
#@Solomon W. Golomb,Matthew G. Parker,Alexander Pott,Arne Winterhof
#t2008
#cLecture Notes In Computer Science; Vol. 5203
#index385073


#*A Tailored Design Partitioning Method for Hardware Emulation
#@R. Beckert,T. Fuchs,St. Ruelke,W. Hardt
#t2007
#cProceedings of the 18th IEEE/IFIP International Workshop on Rapid System Prototyping
#index427343
#!Partial run time reconfiguration (pRTR) enables a dynamic replacement of design modules to optimize the resource utilization of FPGA-based hardware emulation. This requires an appropriate partitioning of the entire design into particular hardware modules. There exist various methods to partition a design at functional as well as at structural level. In this paper, an adapted functional method to partition the design into independent modules is proposed. In consideration of typical functional modules (e.g. controller, DSP1 parts, memory) of a System-on-Chip (SoC), the design is partitioned. The method is especially suited if the design consists of regular structures (multiprocessor design, vector-DSP). The results of the design partitioning are used to determine significant parameters of a generic emulator environment implemented on a state-ofthe- art FPGA2 platform. The benefits are a decreasing number of run time reconfigurations and an improved utilization of the FPGA resources.


#*Entities and relations in medical imaging: An analysis of computed tomography reporting
#@Dirk Marwede,James Matthew Fielding
#t2007
#cApplied Ontology
#index404808
#%438130
#!Biomedical ontologies define entities and relations in order to represent knowledge in the biomedical domain. In addition, many ontologies further represent supplementary knowledge by linking terms from an external controlled vocabulary to the entities defined within the ontology itself. In this paper we concentrate on the domain of medical imaging, for which controlled vocabularies are emerging, but no ontology currently exists. We analyzed computed tomography reports in order to determine to which entities terms used in such reports refer and which relations are used with regard to the recently published Open Biomedical Ontologies (OBO) Relation Ontology. Our analysis revealed that the majority of entities referred to in radiological reporting practice are anatomical entities and anatomical coordinates. Based on the Open Biomedical Ontologies (OBO) Relation Ontology we provide a set of additional relations for the ontological structuring of image features such as shape, morphology, size and signal, frequently found in the reports. On the basis of these results we conclude that the construction of an imaging ontology may benefit greatly from already existing reference ontologies such as the Foundational Model of Anatomy (FMA), which represent those entities to which radiological reports most frequently refer.


#*Technical communique: Robust H2 optimal filtering for continuous-time stochastic systems with polytopic parameter uncertainty
#@Kwan Ho Lee,Biao Huang
#t2008
#cAutomatica (Journal of IFAC)
#index385106
#%249652
#!In this paper, robust H"2 optimal filtering is addressed for continuous-time stochastic systems with polytopic parameter uncertainty. A new robust stability condition is presented. A continuous-time robust H"2 optimal filter is obtained by solving a sufficient linear matrix inequality condition characterizing a solution of a robust minimum variance filtering problem which takes into account the polytopic type of model uncertainties. The proposed approach is demonstrated through numerical examples.


#*Hybrid statistical pronunciation models designed to be trained by a medium-size corpus
#@Bahram Vazirnezhad,Farshad Almasganj,Seyed Mohammad Ahadi
#t2009
#cComputer Speech and Language
#index37587
#%231443
#%294198
#%282791
#%300127
#%432049
#%322046
#%297503
#!Generating pronunciation variants of words is an important subject in speech research and is used extensively in automatic speech recognition and segmentation systems. Decision trees are well known tools in modeling pronunciation over words or sub-word units. In the case of word units and very large vocabulary, in order to train necessary decision trees, a huge amount of speech utterances are required. This training data must contain all of the needed words in the vocabulary with a sufficient number of repetitions for each one. Additionally, an extra corpus is needed for every word which is not included in the original training corpus and may be added to the vocabulary in the future. To overcome these drawbacks, we have designed generalized decision trees, which can be trained using a medium-size corpus over groups of similar words to share information on pronunciation, instead of training a separate tree for every single word. Generalized decision trees predict places in the word where substitution, deletion and insertion of phonemes may occur. After this step, appropriate statistical contextual rules are applied to the permitted places, in order to specifically determine word variants. The hybrids of generalized decision trees and contextual rules are designed in static and dynamic versions. The hybrid static pronunciation models take into account word phonological structures, unigram probabilities, stress and phone context information simultaneously, while the hybrid dynamic models consider an extra feature, speaking rate, to generate pronunciation variants of words. Using the word variants, generated by static and dynamic models, in the lexicon of the SHENAVA Persian continuous speech recognizer, relative word error rate reductions as high as 8.1% and 11.6% are obtained, respectively.


#*Constructing Stereotypes for an Adaptive e-Shop Using AIN-Based Clustering
#@M. Virvou,A. Savvopoulos,G. A. Tsihrintzis,D. N. Sotiropoulos
#t2007
#cProceedings of the 8th international conference on Adaptive and Natural Computing Algorithms, Part I
#index401331
#!This paper describes an adaptive electronic video store application that monitors customers' actions and provides dynamic movie recommendation. The adaptive recommendation is formed based on double stereotypes that have been constructed for user modeling. The construction of stereotypes has been based on a novel approach that uses an Immune Network System (INS). In particular, the INS has been applied on data collected from 150 users of an earlier version of the e-commerce application. Specifically, the INS clustered users' interests as well as movies and represented each resulting cluster with corresponding antibodies. The double classification (users' interests --- movies) was performed in a hierarchical way that resulted in several levels of user stereotypes: These stereotypes are then used dynamically by the e-commerce application to infer users' interests in movies based on a small set of observed users' actions.


#*A Matched FIR Filter Bank for Audio Coding.
#@Rodrigo Capobianco Guido,Lucimar Sasso Vieira,Fabrycio Lopes Sanchez,Jan Frans Willem Slaets,Lyrio Onofre Almeida,Adilson Gonzaga,Marcelo Bianchi
#t2005
#cProceedings of the Seventh IEEE International Symposium on Multimedia
#index579605
#!This paper describes a novel technique for audio coding, a lossy compression algorithm, that considers perceptual and rate-distortion criteria. It is based on matched finite impulse response (FIR) wavelet-packet-like filter banks, the filter coefficients being produced adaptively according to the input signal. This technique achieves perceptually transparent coding of high-quality audio, signals sampled at 44.1 KHz - 16 bits PCM, at bit rates of about 54 - 64 Kbps. The matched filter-bank makes a time-frequencyshape analysis, reducing the number of sub-bands requiring quantization. The decoder that implements this algorithm works effectively in real time. This reassures the efficacy of our technique.


#*On sequential track extraction within the PMHT framework
#@Monika Wieneke,Wolfgang Koch
#t2008
#cEURASIP Journal on Advances in Signal Processing
#index51840
#%153949
#!Tracking multiple targets in a cluttered environment is a challenging task. Probabilistic multiple hypothesis tracking (PMHT) is an efficient approach for dealing with it. Essentially PMHT is based on expectation-maximization for handling with association conflicts. Linearity in the number of targets and measurements is the main motivation for a further development and extension of this methodology. In particular, the problem of track extraction and deletion is apparently not yet satisfactorily solved within this framework. A sequential likelihood-ratio (LR) test for track extraction has been developed and integrated into the framework of traditional Bayesian multiple hypothesis tracking by Günter van Keuk in 1998. As PMHT is a multiscan approach as well, it also has the potential for track extraction. In this paper, an analogous integration of a sequential LR test into the PMHT framework is proposed. We present an LR formula for track extraction and deletion using the PMHT update formulae. The LR is thus a by-product of the PMHT iteration process, as PMHT provides all required ingredients for a sequential LR calculation. Therefore, the resulting update formula for the sequential LR test affords the development of track-before-detect algorithms for PMHT. The approach is illustrated by a simple example.


#*Estimation of Net Primary Production of the Kii Peninsula Using Terra/MODIS Data
#@Yi Cen,Kanako Muramatsu,Liangpei Zhang
#t2007
#cProceedings of the Fourth International Conference on Image and Graphics
#index353423
#!Precise estimations of zonal net primary production (NPP) are vital for understanding global carbon circulation. To estimate NPP, light use efficiency (LUE) model using normalized differential vegetation index (NDVI) has been used mainly. NDVI is obtained from red and near-infrared channels only, however, recent sensors onboard satellites always have hyper-multi-spectral channels; In order to use these data effectively, which include more details about land cover, a vegetation index based on pattern decomposition method (VIPD) has been set up to estimate NPP. The present study used 2001 Terra/MODIS (Moderate Resolution Imaging Spectroradiometer) data for the Kii Peninsula, which is mainly covered by temperate forest. To validate the proposed method, we compared the satellite data-based NPP values for the evergreen with values derived from land-survey data. The proposed method estimated the annual NPP of a temperate forest on Yoshino Mountain to be 1.52 ± 0.39 kg CO2/m2/year, which agreed with the ground-survey result of 1.50 ± 0.75 kg CO2/m2/year, within the algorithm error. An average zonal NPP of 1.55 ± 0.40 kg CO2/m2/year was calculated for the whole land region from 32°30' to 36°24' N latitude, 134°30' to 137°06' E longitude with an area of 3.94×104 km2.


#*Software Estimation: Demystifying the Black Art (Best Practices (Microsoft))
#@Steve McConnell
#t2006
#c
#index3638
#!A practical guide for software developers and development teams, this book features effective and understandable formulas, procedures, and heuristics to help organizations improve their project cost estimates.


#*Sentence Understanding and Learning of New Words with Large-Scale Neural Networks
#@Heiner Markert,Zöhre Kara Kayikci,Günther Palm
#t2008
#cProceedings of the 3rd IAPR workshop on Artificial Neural Networks in Pattern Recognition
#index397554
#!We have implemented a speech command system which can understand simple command sentences like "Bot lift ball" or "Bot go table" using hidden Markov models (HMMs) and associative memories with sparse distributed representations. The system is composed of three modules: (1) A set of HMMs is used on phoneme level to get a phonetic transcription of the spoken sentence, (2) a network of associative memories is used to determine the word belonging to the phonetic transcription and (3) a neural network is used on the sentence level to determine the meaning of the sentence. The system is also able to learn new object words during performance.


#*The impact of self-efficacy, ease of use and usefulness on e-purchasing: An analysis of experienced e-shoppers
#@Blanca Hernandez,Julio Jimenez,M. Jose Martin
#t2009
#cInteracting with Computers
#index72358
#%31132
#%35347
#%416265
#%607659
#%565976
#%594066
#%588896
#%217146
#%471361
#%465318
#%459811
#%605535
#%594539
#%566991
#%331010
#%566375
#%437451
#%304373
#%508686
#%590317
#%436206
#%433170
#%308094
#%333051
#!The objective of the present research is to study the Internet purchasing behaviour of consumers who are experienced with the channel, employing a dual perspective for the analysis: (1) present e-purchasing behaviour and (2) future repurchasing behaviour measured through repurchasing intentions. On the basis of this approach, we attempt to understand the effect of perceived self-efficacy, ease of use and usefulness on both types of behaviour and the links between them. Furthermore, the research includes other variables related to Internet experience, extracted from models widely tested in the literature. These variables, namely, acceptance, frequency of use and satisfaction with the Internet, act as antecedents of e-purchasing behaviour and permit a deeper analysis of the consumer. The results obtained show that self-efficacy and usefulness are important perceptions in explaining the behaviour of experienced consumers, while ease of use does not have a significant influence.


#*Consistent Main-Memory Database Federations under Deferred Disk Writes
#@Rodrigo Schmidt,Fernando Pedone
#t2005
#cProceedings of the 24th IEEE Symposium on Reliable Distributed Systems
#index581371
#!Current cluster architectures provide the ideal environment to run federations of main-memory database systems (FMMDBs). In FMMDBs, data resides in the main memory of the federation servers, significantly improving performance by avoiding I/O during the execution of read operations. To maximize the performance of update transactions as well, some applications recur to deferred disk writes. This means that update transactions commit before their modifications are written on stable storage and durability must be ensured outside the database. While deferred disk writes in centralized MMDBs relax the durability property of transactions only, in FMMDBs transaction atomicity may be also violated in case of failures. We address this issue from the perspective of log-based rollback-recovery in distributed systems and provide an efficient solution to the problem.


#*HashCache: cache storage for the next billion
#@Anirudh Badam,KyoungSoo Park,Vivek S. Pai,Larry L. Peterson
#t2009
#cProceedings of the 6th USENIX symposium on Networked systems design and implementation
#index142654
#%88514
#%115078
#%314219
#%423656
#%422259
#%424482
#%625832
#%425918
#%427264
#%417484
#%294475
#%255806
#!We present HashCache, a configurable cache storage engine designed to meet the needs of cache storage in the developing world. With the advent of cheap commodity laptops geared for mass deployments, developing regions are poised to become major users of the Internet, and given the high cost of bandwidth in these parts of the world, they stand to gain significantly from network caching. However, current Web proxies are incapable of providing large storage capacities while using small resource footprints, a requirement for the integrated multi-purpose servers needed to effectively support developing-world deployments. Hash-Cache presents a radical departure from the conventional wisdom in network cache design, and uses 6 to 20 times less memory than current techniques while still providing comparable or better performance. As such, Hash-Cache can be deployed in configurations not attainable with current approaches, such as having multiple terabytes of external storage cache attached to low-powered machines. HashCache has been successfully deployed in two locations in Africa, and further deployments are in progress.


#*Computing surface offsets and bisectors using a sampled constraint solver
#@David E. Johnson,Elaine Cohen
#t2009
#cProceedings of Graphics Interface 2009
#index128558
#%84786
#%327851
#%282013
#%185853
#%382210
#%234773
#%278143
#%183240
#%240260
#%214565
#%277295
#!This paper describes SCSolver, a geometric constraint solver based on adaptive sampling of an underlying constraint space. The solver is demonstrated on the computation of the offset to a surface as well as the computation of the bisector between two surfaces. The adaptive constraint sampling generates a solution manifold through a generalized dual-contouring approach appropriate for higher-dimensional problems. Experimental results show that the SCSolver approach can compute solutions for complex input geometry at interactive rates for each example application.


#*Product Based Workflow Support: Dynamic Workflow Execution
#@Irene Vanderfeesten,Hajo A. Reijers,Wil M. Aalst
#t2008
#cProceedings of the 20th international conference on Advanced Information Systems Engineering
#index393554
#!Product Based Workflow Design (PBWD) is a successful new approach to workflow process support. A description of the product, the Product Data Model (PDM), is central to this approach. While other research so far has focused on deriving a process model from the PDM, this paper presents a way to directly execute the PDM. This leads to a more dynamic and flexible support for the workflow process.


#*Authoring Verified Documents by Interactive Proof Construction and Verification in Text-Editors
#@Dominik Dietrich,Ewaryst Schulz,Marc Wagner
#t2008
#cProceedings of the 9th AISC international conference, the 15th Calculemas symposium, and the 7th international MKM conference on Intelligent Computer Mathematics
#index408250
#!Aiming at a document-centric approach to formalizing and verifying mathematics and software we integrated the proof assistance system ¿mega with the standard scientific text-editor MACS. The author writes her mathematical document entirely inside the text-editor in a controlled language with formulas in style. The notation specified in such a document is used for both parsing and rendering formulas in the document. To make this approach effectively usable as a real-time application we present an efficient hybrid parsing technique that is able to deal with the scalability problem resulting from modifying or extending notation dynamically. Furthermore, we present incremental methods to quickly verify constructed or modified proof steps by ¿mega. If the system detects incomplete or underspecified proof steps, it tries to automatically repair them. For collaborative authoring we propose to manage partially or fully verified documents together with its justifications and notational information centrally in a mathematics repository using an extension of OMDoc.


#*Advanced features in SMART: the stochastic model checking analyzer for reliability and timing
#@Gianfranco Ciardo,Andrew S. Miner,Min Wan
#t2009
#cACM SIGMETRICS Performance Evaluation Review
#index60664
#%555501
#%293288
#%285720
#%66659
#%61457
#!We describe some of the advanced features of the software tool SmArT, the Stochastic Model checking Analyzer for Reliability and Timing. Initially conceived as a software package for numerical solution and discrete-event simulation of stochastic models, SmArT now also provides powerful modelchecking capabilities, thanks to its extensive use of various forms of decision diagrams, which in turn also greatly increase the efficiency of its stochastic analysis algorithms. These aspects make it an excellent choice when tackling systems with extremely large state spaces.


#*Reversible logic for supercomputing
#@Erik P. DeBenedictis
#t2005
#cProceedings of the 2nd conference on Computing frontiers
#index105567
#%121991
#%567986
#!This paper is about making reversible logic a reality for supercomputing. Reversible logic offers a way to exceed certain basic limits on the performance of computers, yet a powerful case will have to be made to justify its substantial development expense. This paper explores the limits of current, irreversible logic for supercomputers, thus forming a threshold above which reversible logic is the only solution. Problems above this threshold are discussed, with the science and mitigation of global warming being discussed in detail. To further develop the idea of using reversible logic in supercomputing, a design for a 1 Zettaflops supercomputer as required for addressing global climate warming is presented. However, to create such a design requires deviations from the mainstream of both the software for climate simulation and research directions of reversible logic. These deviations provide direction on how to make reversible logic practical


#*Performance-based middleware for Grid computing: Research Articles
#@G. R. Nudd,S. A. Jarvis
#t2005
#cConcurrency and Computation: Practice Experience
#index101737
#!This paper describes a stateful service-oriented middleware infrastructure for the management of scientific tasks running on multi-domain heterogeneous distributed architectures. Allocating scientific workload across multiple administrative boundaries is a key issue in Grid computing and as a result a number of supporting services including match-making, scheduling and staging have been developed. Each of these services allows the scientist to utilize the available resources, although a sustainable level of service in such shared environments cannot always be guaranteed. A performance-based middleware infrastructure is described in which prediction data for each scientific task are calculated, stored and published through a Globus-based performance information service. Distributing these data allows additional performance-based middleware services to be built, two of which are described in this paper: an intra-domain predictive co-scheduler and a multi-domain workload steering system. These additional facilities significantly improve the ability of the system to meet task deadlines, as well as enhancing inter-domain load-balancing and system-wide resource utilization. Copyright &copy; 2005 John Wiley & Sons, Ltd.


#*Grafta: A 3D environment for biomolecular networks
#@Peyman Najmabadi,Hans He Lee,Tony Aung,Aung Thuya,Julio Ng,James J. La Clair,Michael D. Burkart
#t2009
#cInternational Journal of Bioinformatics Research and Applications
#index506906
#%32050
#!The importance of a comprehensive environment for the depiction of biomolecular networks in the domain of system biology has been emphasised after the completion of genomic, proteomic and metabolomic initatives. Grafta is a software application developed for the three dimensional illustration of biomolecular interactions such as protein interaction networks. Grafta allows its user to move in a 3D environment through a complex assembly of biomolecules represented by 3D objects such as spheres. Their interactions are displayed by an array of 3D tubes. One novelty in Grafta is its anthropomorphic navigation of the viewpoint with respect to the displayed biomolecular network.


#*Adobe Photoshop CS2 On Demand
#@Andy Anderson,Steve Johnson
#t2005
#c
#index17499
#!Photoshop can be an intimidating and time-consuming program to learn. Wouldn't you rather spend your time learning by doing rather than reading? Adobe Photoshop CS 2 On Demand features step-by-step instructions with accompanying visuals so that you spend more time learning and less time reading. The in-depth, wide-ranging coverage will enable you to get the most out of Photoshop CS 2 and included tool, such as: File browser Brush special effects Photo retouching Enhanced web output features Healing brushStudying for the Adobe Certified Exam for Photoshop? This tutorial also includes exam objectives throughout its pages. You will become a master of Photoshop CS 2 with the help of Adobe Photoshop CS 2 On Demand.


#*Decision fusion based on voting scheme for IR and visible face recognition
#@M. D. Shahbe,S. Hati
#t2008
#cMachine Graphics Vision International Journal
#index68915
#%17280
#%481213
#%593911
#%95021
#%312085
#!In this paper we present an evaluation study of decision fusion strategies for infrared (IR) and visible face recognition. Several decision fusion methods based on a voting scheme (minimization, product and averaging) are discussed, and experiments for various conditions of probe and gallery sets are performed on two databases with paired IR and visible face imageries. The Eigenfaees and Fisherface classification techniques are used to extract the face features, and the performance of fusion methods on both classification approaches is discnssed.


#*Possible Occurrence of Scale-Free Topology in Highly Statistically Associated Polymorphic Positions in Two Potyviral Proteins
#@Ioannis N. Manoussopoulos,Ioanna Zevlekari
#t2009
#cProceedings of the 2009 International Conference on Advances in Social Network Analysis and Mining
#index502658
#!We examined the associations between polymorphic positions of two Potyviral proteins, HCPro and NIb, using a combined statistical and bioinformatic methodology. We constructed the relevant graph for each protein by assigning the polymorphic positions as vertices and the identified associations between them as links. We found that the relationships among positions in both molecules displayed a complex topology. In addition, the degree distribution of each network adequately fit a power law distribution, with a small number of vertices dominating a large number of associations. The graphs for both proteins shared similar topological features despite differences in protein size, similarity, functionality, and location of the coding regions in the potyviral genome. Our findings suggest that the intramolecular associations of potyviral proteins display scale free architecture, implying that this system may undergo developmental processes similar to those described for other scale free systems.


#*The "Beauty Dilemma": beauty is valued but discounted in product choice
#@Sarah Diefenbach,Marc Hassenzahl
#t2009
#cProceedings of the 27th international conference on Human factors in computing systems
#index68989
#!The empirical study of aesthetics in Human-Computer Interaction (HCI) is concerned with - among other topics - the relationship between beauty and usability and the general impact of beauty on product choice and use. Specifically, the present paper explores the notion of a "beauty dilemma" - the idea that people discount beauty in a choice situation, although they value it in general (i.e., they are not choosing what makes them happy). We explored this idea in three studies with a total of over 600 participants. Study 1 revealed a reluctance to pay for beauty due to its hedonic nature (i.e., associated with luxury etc.). Study 2 showed that people prefer a more beautiful product, but justify their choice by referring to spurious advantages in usability. Finally, Study 3 revealed that a choice situation which requires a trade-off between beauty and usability, and which offers no further way to justify choosing beauty, leads to a sharp increase in the preference of usability. The underlying reasons for this "beauty dilemma" and further implications are discussed.


#*An Approach to Provisioning E-Commerce Applications with Commercial Components
#@Lei Wang,Padmanabhan Krishnan
#t2006
#cProceedings of the IEEE International Conference on e-Business Engineering
#index34380
#!Component-based development is a trend towards building e-commerce applications. However, commercial components are rarely used during the development. The reason is that existing approaches to selecting and composing components suffer from the problem that the components retrieved usually do not exactly fit with other components in the system being developed. While formal methods can be used to describe and check semantic characteristics to better match components, there are practical limitations which restrict their adoption. We have proposed a framework to support a semantic description and selection of components. We used Simple Component Interface Language (SCIL) to describe user requirements and pre-built components from the current component sources. Specifications in SCIL can be translated to a variety of models including those that have a formal basis. In this paper, we preform a case study of searching commercial components for a generic e-commerce application. We specify the commercial components in SCIL and use two specific tools: jMocha and Alloy Analyser to identify the correct components that suit a particular task.


#*BSGI: An Effective Algorithm towards Stronger l-Diversity
#@Yang Ye,Qiao Deng,Chi Wang,Dapeng Lv,Yu Liu,Jianhua Feng
#t2008
#cProceedings of the 19th international conference on Database and Expert Systems Applications
#index403927
#!To reduce the risk of privacy disclosure during personal data publishing, the approach of anonymization is widely employed. On this topic, current studies mainly focus on two directions: (1)developing privacy preserving models which satisfy certain constraints, such as k-anonymity, l-diversity, etc.; (2)designing algorithms for certain privacy preserving model to achieve better privacy protection as well as less information loss. This paper generally belongs to the second class. We introduce an effective algorithm "BSGI" for the widely accepted privacy preserving model: l-diversity. In the meantime, we propose a novel interpretation of l-diversity: Unique Distinct l-diversity, which can be properly achieved by BSGI. We substantiate it's a stronger l-diversity model than other interpretations. Related to the algorithm, we conduct the first research on the optimal assignment of parameter l according to certain dataset. Extensive experimental evaluation shows that Unique Distinct l-diversity provides much better protection than conventional l-diversity models, and BSGI greatly outperforms the state of the art in terms of both efficiency and data quality.


#*Error resilient locally adaptive data compression
#@Hsien-Wen Tseng,Chin-Chen Chang
#t2006
#cJournal of Systems and Software
#index29022
#%152978
#!A data compression scheme that exploits locality of reference has been proposed by Bentley et al. in 1986 [Bentley, J.L., Sleator, D.D., Tarjan, R.E., Wei, V.K., 1986. A locally adaptive data compression scheme. Commun. ACM 29 (4), 320-330]. The scheme is based on a self-organizing move-to-front word list. However, a single error occurred on transmission channel could cause the lists of the encoder and decoder to differ, which could corrupt all reference data that follows. To reduce the impact of losing synchronization, a new list structure for the locally adaptive data compression scheme is proposed in this paper. From our analysis and experiments, the proposed scheme can enhance error resiliency of locally adaptive data compression while preserving high compression performance.


#*iPod & iTunes For Dummies: For Dummies Computer/Tech, 5th edition
#@Tony Bove,Cheryl Rhodes
#t2007
#c
#index136305
#!Whether its the iPod Nano, iPod Shuffle, video iPod, or some other variation, iTunes and iPods go together like treble and bass. Its so easy to purchase the latest music and videos, download podcasts, and even keep track of your calendar on your iPodso why wouldnt you? But if its so easy, why do you need iPod & iTunes For Dummies? iPods now come in everything from 1GB to 80GB models and play movies, store photos, function as a spare hard drive, and even wake you up in the morning. If this is your first one, youll find no better place to get acquainted with it than in this bestselling book. If youve just purchased a brand-new iPod, youll find this Fifth Edition packed with valuable tidbits about the latest and greatest features. Youll discover how to: Set up an iTunes account Build a playlist of streaming radio stations Synchronize your iPod with other devices Record memos and appointments Play movies from your iPod on a TV Connect your iPod to your car stereo or portable speakers Add and edit iTunes song information Organize music and media into iTunes playlists Fine-tune sound playback with either the iPod or iTunes equalizer Transfer music to your iPod from old tapes and phonograph records Find out how to use every feature of your favorite iPod model and get the scoop on making the most of iTunes with iPod & iTunes For Dummies, 5th Edition!


#*Online fuzzy identification for an intelligent controller based on a simple platform
#@Sašo Blaič,Igor Škrjanc,Samo Gerkšič,Gregor Dolanc,Stanko Strmčnik,Mincho B. Hadjiski,Anna Stathaki
#t2009
#cEngineering Applications of Artificial Intelligence
#index128712
#%224609
#%527769
#!The paper presents the identification issues of the self-tuning nonlinear controller ASPECT (Advanced control algorithmS for ProgrammablE logiC conTrollers). The controller is implemented on a simple PLC platform with an extra mathematical coprocessor, but is intended for the advanced control of complex processes. The model of the controlled plant is obtained by means of experimental modelling. A special batch-wise algorithm that is based on the Takagi-Sugeno model and uses ''fuzzy instrumental variables'' technique is described in the paper. Many robustness problems of the classical adaptive approaches can be circumvented to some extent by the proposed batch-wise approach combined with a supervisory mechanism. The paper also includes some experimental results on the hydraulic pilot plant and some simulation case studies.


#*Invited papers
#@
#t2008
#cProceedings of the fifth on Asia-Pacific conference on conceptual modelling - Volume 79
#index37535


#*Cooperative Security Schemes for Mobile Ad-Hoc Networks
#@P. Caballero-Gil,C. Hernández-Goya
#t2008
#cProceedings of the 5th international conference on Cooperative Design, Visualization, and Engineering
#index387880
#!The existence of selfish nodes, who do not cooperate in routing and forwarding, is one of the most critical problems for the applicability of Mobile Ad-hoc NETworks (MANETs). In this paper we propose several novel currency-based methods for stimulating cooperation among nodes of a MANET. In particular, the proposed protocols allow improving different aspects of previous schemes based on virtual currency thanks to the incorporation of the concept of credit that will allow broke nodes to use the network while they have not a selfish behaviour. A complete analysis of simulations leads to several conclusions that establish the improvement of the proposal with respect to previous schemes.


#*Hybrid Branching
#@Tobias Achterberg,Timo Berthold
#t2009
#cProceedings of the 6th International Conference on Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems
#index133291
#!State-of-the-art solvers for Constraint Satisfaction Problems (CSP), Mixed Integer Programs (MIP), and satisfiability problems (SAT) are usually based on a branch-and-bound algorithm. The question how to split a problem into subproblems (branching) is in the core of any branch-and-bound algorithm. Branching on individual variables is very common in CSP, MIP, and SAT. The rules, however, which variable to choose for branching, differ significantly. In this paper, we present hybrid branching, which combines selection rules from all three fields.


#*On the evaluation of recommender systems with recorded interactions
#@Romain Robbes
#t2009
#cProceedings of the 2009 ICSE Workshop on Search-Driven Development-Users, Infrastructure, Tools and Evaluation
#index133463
#%416392
#!Recommender systems are Integrated Development Environment (IDE) extensions which assist developers in the task of coding. However, since they assist specific aspects of the general activity of programming, their impact is hard to assess. In previous work, we used with success an evaluation strategy using automated benchmarks to automatically and precisely evaluate several recommender systems, based on recording and replaying developer interactions. In this paper, we highlight the challenges we expect to encounter while applying this approach to other recommender systems.


#*Experimental Evaluation of Protein Secondary Structure Predictors
#@Luca Miceli,Luigi Palopoli,Simona E. Rombo,Giorgio Terracina,Giuseppe Tradigo,Pierangelo Veltri
#t2009
#cProceedings of the 9th International Conference on Computational Science: Part I
#index140434
#!Understanding protein biological function is a key issue in modern biology, which is largely determined by its 3D shape. Protein 3D shape, in its turn, is functionally implied by its amino acid sequence. Since the direct inspection of such 3D structures is rather expensive and time consuming, a number of software techniques have been developed in the last few years that predict a spatial model, either of the secondary or of the tertiary form, for a given target protein starting from its amino acid sequence.This paper offers a comparison of several available automatic secondary structure prediction tools. The comparison is of the experimental kind, where two relevant sets of proteins, a non-redundant one including 100 elements, and a 180-protein set taken from the CASP 6 contest, were used as test cases. Comparisons have been based on evaluating standard quality measures, such as the Q3 and SOV. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Winner Price Monotonicity for Approximated Combinatorial Auctions
#@Naoki Fukuta,Takayuki Ito
#t2008
#cProceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Volume 03
#index629324
#!Combinatorial auctions are suitable mechanisms for efficient allocation of set of items for self-interested attendees such as software agents. Since optimal winner determination problem of combinatorial auctions is NP-hard, much work focuses on tackling the computational costs for winner determination. Since it is an important issue to guarantee the quality of approximated results, we have proposed desirable properties for such approximation algorithms. In this paper, we analyze the advantages and side-effects of preserving winner price monotonicity, one of our proposed desirable properties for approximation algorithms of combinatorial auctions.


#*CompTIA Network+ Review Guide
#@Bill Ferguson
#t2009
#c
#index498440
#!Serving as a concise, focused study aid to help you prepare for the leading non-vendor-specific networking certification exam, this book features more review questions and study review features than any other guide, with over 120 review questions, two bonus exams, and electronic Flashcard, as well as a searchable Glossary of Terms database on CD-ROM. Fully updated for the first revision of the CompTIA Network+ exam since 2005, the book is organized by exam objectives and broken into six parts corresponding to the six domain areas of the Network+ exam: technologies, media and topologies, devices, management, tools, and security. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Learning Games
#@
#t2007
#cProceeding of the 2007 conference on Supporting Learning Flow through Integrative Technologies
#index139047


#*Finitary winning in &omega;-regular games
#@Krishnendu Chatterjee,Thomas A. Henzinger,Florian Horn
#t2009
#cACM Transactions on Computational Logic (TOCL)
#index495708
#%49157
#%82419
#%172119
#%239555
#%466660
#%510571
#%548628
#%521898
#!Games on graphs with &omega;-regular objectives provide a model for the control and synthesis of reactive systems. Every &omega;-regular objective can be decomposed into a safety part and a liveness part. The liveness part ensures that something good happens &ldquo;eventually.&rdquo; Two main strengths of the classical, infinite-limit formulation of liveness are robustness (independence from the granularity of transitions) and simplicity (abstraction of complicated time bounds). However, the classical liveness formulation suffers from the drawback that the time until something good happens may be unbounded. A stronger formulation of liveness, so-called finitary liveness, overcomes this drawback, while still retaining robustness and simplicity. Finitary liveness requires that there exists an unknown, fixed bound b such that something good happens within b transitions. While for one-shot liveness (reachability) objectives, classical and finitary liveness coincide, for repeated liveness (B&uuml;chi) objectives, the finitary formulation is strictly stronger. In this work we study games with finitary parity and Streett objectives. We prove the determinacy of these games, present algorithms for solving these games, and characterize the memory requirements of winning strategies. We show that finitary parity games can be solved in polynomial time, which is not known for infinitary parity games. For finitary Streett games, we give an EXPTIME algorithm and show that the problem is NP-hard. Our algorithms can be used, for example, for synthesizing controllers that do not let the response time of a system increase without bound.


#*Short note: An operational MODIS processing scheme for PC dedicated to direct broadcasting applications in meteorology and earth sciences
#@T. Nauss,J. Bendix
#t2005
#cComputers Geosciences
#index19142


#*Parallax cues in the design of graphics used in technical education to illustrate complex spatial problems
#@Santiago Martín,Ramón Rubio
#t2009
#cComputers Education
#index128773
#%624058
#!The explanation of certain 3D concepts is based on 2D drawings. These drawings should contain certain depth cues, such as perspective and overlapping. Until recently, parallax has not been used as a depth cue. Nevertheless, new technologies allow it to be incorporated. This forms the background to our study of the design of interactive educational resources and stereoscopic graphics. The results obtained demonstrate that (1) the use of parallax cues improves the interpretation of the figures and (2) that the assistance they afford is most appreciated by the students with less highly developed spatial perception.


#*Workshop on Intelligent Agents in Simulation and Evolvable Systems
#@
#t2009
#cProceedings of the 9th International Conference on Computational Science
#index127648


#*Learning Maya 7: The Modeling and Animation Handbook
#@
#t2005
#c
#index15982


#*A Minimum Time to Release Job Scheduling Algorithm in Computational Grid Environment
#@N. Malarvizhi,V. Rhymend Uthariaraj
#t2009
#cProceedings of the 2009 Fifth International Joint Conference on INC, IMS and IDC
#index18227
#!Computational grids have the potential for solving large-scale scientific problems using heterogeneous and geographically distributed resources. However, a number of major technical hurdles must be overcome before this potential can be realized. One problem that is critical to effective utilization of computational grids is the efficient scheduling of jobs. This work addresses this problem by describing and evaluating a grid scheduling architecture and a job-scheduling algorithm. The architecture is scalable and does not assume control of local site resources. In our algorithm Grid Resource Manager or Grid Scheduler performs resource brokering and job scheduling. The scheduler selects computational resources based on job requirements, job characteristics and information provided by the resources. The main aim of these schedulers is to minimize the total time to release for the individual application. The Time To Release (TTR) includes the processing time of the program, waiting time in the queue, transfer of input and output data to and from the resource. Since grid resources are heterogeneous and distributed over many areas the transmission time is very important criteria. In this paper, an algorithm for minimum time to release is proposed. The proposed scheduling algorithm has been compared with other scheduling schemes such as First Come First Served (FCFS) and Min-Min. These existing algorithms does not consider the transmission time (in time and out time) when scheduling jobs to resources. The proposed algorithm has been verified through the GridSim simulation toolkit and the simulation results confirm that the proposed algorithm produce schedules where the execution time of the application is minimized. The average weighted response times of all submitted jobs decrease up to about 19.79%. The results have been verified using different workloads and Grid configurations.


#*The Conformal Monogenic Signal
#@Lennart Wietzke,Gerald Sommer
#t2008
#cProceedings of the 30th DAGM symposium on Pattern Recognition
#index396748
#!The conformal monogenic signal is a novel rotational invariant approach for analyzing i(ntrinsic)1D and i2D local features of two-dimensional signals (e.g. images) without the use of any heuristics. It contains the monogenic signal as a special case for i1D signals and combines scale-space, phase, orientation, energy and isophote curvature in one unified algebraic framework. The conformal monogenic signal will be theoretically illustrated and motivated in detail by the relation of the Radon and the Riesz transform. One of the main ideas is to lift up two-dimensional signals to a higher dimensional conformal space where the signal can be analyzed with more degrees of freedom. The most interesting result is that isophote curvature can be calculated in a purely algebraic framework without the need of any derivatives.


#*Dynamic information source selection for intrusion detection systems
#@Martin Rehak,Eugen Staab,Michal Pechoucek,Jan Stiborek,Martin Grill,Karel Bartos
#t2009
#cProceedings of The 8th International Conference on Autonomous Agents and Multiagent Systems - Volume 2
#index142525
#%110980
#%125110
#%160896
#%247244
#%386049
#%395443
#%406873
#%384703
#%408539
#%409023
#%430883
#%147509
#!Our work presents a mechanism designed for the selection of the optimal information provider in a multi-agent, heterogeneous and unsupervised monitoring system. The self-adaptation mechanism is based on the insertion of a small set of prepared challenges that are processed together with the real events observed by the system. The evaluation of the system response to these challenges is used to select the optimal information source. Our algorithm uses the concept of trust to identify the best source and to optimize the number of challenges inserted into the system. The mechanism is designed for intrusion/fraud detection systems, which are frequently deployed as part of online transaction processing (banking, telecommunications or process monitoring systems). Our approach features unsupervised adjustment of its configuration and dynamic adaptation to the changing environment, which are both vital for these domains.


#*ReMo: An Energy Efficient Reprogramming Protocol for Mobile Sensor Networks
#@Pradip De,Yonghe Liu,Sajal K. Das
#t2008
#cProceedings of the 2008 Sixth Annual IEEE International Conference on Pervasive Computing and Communications
#index46892
#!Existing code update protocols for reprogramming nodes in a sensornetwork are either unsuitable or inefficient when used in a mobile environment. The prohibitive factor of uncertainty about a node's location due to their continuous movement coupled with the obvious constraint of a node's limited resources, pose daunting challengesto the design of an effective code dissemination protocol for mobilesensor networks. In this paper, we propose \emph{ReMo}, an energy efficient, multihop reprogramming protocol for mobile sensor networks.Without making any assumptions on the location of nodes, ReMo uses the LQI and RSSI measurements of received packets to estimate link qualities and relative distances with neighbors in order to select the best node for code exchange. The protocol is based on a probabilisticbroadcast paradigm with the mobile nodes smoothly modifying their advertisement transmission rates based on the dynamic changes in network density, thereby saving valuable energy. Contrary to previous protocols, ReMo downloads pages regardless of their order, thus, exploiting the mobility of the nodes and facilitating a fast transfer of the code. Our simulation results show significant improvement in reprogramming time and number of message transmissions over other existing protocols under different settings of network mobility.


#*23rd Annual Symposium on Computational Geometry
#@
#t2009
#cDiscrete Computational Geometry
#index127911


#*Resource Load Balancing Based on Multi-agent in ServiceBSP Model
#@Yan Jiang,Weiqin Tong,Wentao Zhao
#t2007
#cProceedings of the 7th international conference on Computational Science, Part III: ICCS 2007
#index393023
#!Based on ServiceBSP model, a resource load balancing algorithm with Multi-Agent is put forward in this paper which achieves the goal of dynamic load balancing and favorable fault-tolerant. The algorithm calculates the load value according to the status of usage of resources of a node and scheduling tasks relies on the load value, while updating the load information dynamically depending on Multi-Agent. The method also can avoid frequent communications on load information. Furthermore, the paper introduces the function of agents, relations and communications among agents in details. Finally, by comparing response time and distribution of load using proposed method with other available methods such as without no load balancing and load balancing only based on the usage of CPU, the experimental simulation shows that the load balancing based on Multi-Agent possesses superior performance on response time and load balancing.


#*A Streamlined and Generalized Analysis of Chromatin ImmunoPrecipitation Paired-End diTag Data
#@Vinsensius B. Vega,Yijun Ruan,Wing-Kin Sung
#t2008
#cProceedings of the 8th international conference on Computational Science, Part III
#index394363
#!Comprehensive, accurate and detailed maps of transcription factor binding sites (TFBS) help to unravel the transcriptional regulatory relationship between genes and transcription factors. The recently developed sequencing-based genome-wide approach ChIP-PET (Chromatin ImmunoPrecipitation coupled with Paired-End diTag analysis) permits accurate and unbiased mapping of TF-DNA interactions. In this paper we outline a methodical framework to analyze ChIP-PET sequence data to identify most likely binding regions. Mathematical formulations were derived to streamline and strengthen the analysis. We established a more faithful noise distribution estimation that leads to the adaptive threshold scheme. The algorithms were evaluated using three real-world datasets. Using motif enrichment as indirect evidence and additional ChIP-qPCR validations, the overall performance was consistently satisfactory.


#*Translation model pruning via usage statistics for statistical machine translation
#@Matthias Eck,Stephan Vogel,Alex Waibel
#t2007
#cHuman Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers on XX
#index493000
#%514342
#!We describe a new pruning approach to remove phrase pairs from translation models of statistical machine translation systems. The approach applies the original translation system to a large amount of text and calculates usage statistics for the phrase pairs. Using these statistics the relevance of each phrase pair can be estimated. The approach is tested against a strong baseline based on previous work and shows significant improvements.


#*A distributed virtual lab: for practical activities in electronics
#@Jean-Pierre Gerval,Yann Le Ru
#t2007
#cProceedings of the 10th IASTED International Conference on Computers and Advanced Technology in Education
#index18606
#!This paper sets out a distributed virtual reality application intended to practical activities in electronics: circuit design and simulation. The distributed virtual environment offers virtual components and devices (resistors, capacitors, transistors, generators and oscilloscopes) described in a standard Virtual Reality Modeling Language (VRML) format. Users are enabled to choose components and build a circuit. The simulation of the circuit is done using the SPICE programme that is a general-purpose circuit simulation programme for non-linear dc, non-linear transient, and linear ac analyses. The implementation is based on VRML and Java as languages and Cortona VRML plug-in from ParallelGraphics. The distribution of virtual worlds is obtained using DeepMatrix as environment server.


#*C2 / Editorial Board
#@
#t2009
#cJournal of Visual Communication and Image Representation
#index73214


#*Type nanotheories: a framework for term comparison
#@John Prager,Sarah Luger,Jennifer Chu-Carroll
#t2007
#cProceedings of the sixteenth ACM conference on Conference on information and knowledge management
#index340936
#%586947
#%592683
#!We present in this paper Type Nanotheories (TN), a framework for representing the knowledge necessary for performing similarity comparisons between pairs of terms of the same type. TN itself uses another methodology, namely Support Outcomes, which is also introduced. Many IR and NLP applications use redundancy as a factor to increase confidence, and TN-based comparisons can determine redundancy better than simple string comparisons. Results include a showing of a 14% increase in Confidence-Weighted Score for an end-to-end QA system and an up to 68% improvement over baseline in an answer-key equivalencing experiment.


#*Robust Impulsive Synchronization of Coupled Delayed Neural Networks
#@Lan Xiang,Jin Zhou,Zengrong Liu
#t2007
#cProceedings of the 4th international symposium on Neural Networks: Part II--Advances in Neural Networks
#index406937
#!The present paper studies robust impulsive synchronization of coupled delayed neural networks. Based on impulsive control theory on dynamical systems, a simple yet less conservative criteria ensuring robust impulsive synchronization of coupled delayed neural networks is established. Furthermore, the theoretical result is applied to a typical scale-free (SF) network composing of the representative chaotic delayed Hopfield neural network nodes, and numerical results are presented to demonstrate the effectiveness of the proposed control techniques.


#*An ordering method for intuitionistic fuzzy numbers
#@Hassan Mishmast Nehi
#t2005
#cProceedings of the 9th WSEAS International Conference on Systems
#index41944
#%156977
#%467382
#!In this paper first we review two ranking methods for intuitionistic fuzzy numbers (IF numbers), then we proposed a new ordering method for IF numbers in which we consider two characteristic values of membership and non-membership for an IF number.


#*The CellML Model Repository
#@Catherine M. Lloyd,James R. Lawson,Peter J. Hunter,Poul F. Nielsen
#t2008
#cBioinformatics
#index627773
#!Summary: The CellML Model Repository provides free access to over 330 biological models. The vast majority of these models are derived from published, peer-reviewed papers. Model curation is an important and ongoing process to ensure the CellML model is able to accurately reproduce the published results. As the CellML community grows, and more people add their models to the repository, model annotation will become increasingly important to facilitate data searches and information retrieval. Availability: The CellML Model Repository is publicly accessible at http://www.cellml.org/models Contact: c.lloyd@auckland.ac.nz


#*3D Integration: Technology and Applications
#@Philip Garrou,Christopher Bower,Peter Ramm
#t2008
#c
#index72886
#!The first encompassing treatise of this new, but very important field puts the known physical limitations for classic 2D electronics into perspective with the requirements for further electronics developments and market necessities. This two-volume handbook presents 3D solutions to the feature density problem, addressing all important issues, such as wafer processing, die bonding, packaging technology, and thermal aspects.It begins with an introductory part, which defines necessary goals, existing issues and relates 3D integration to the semiconductor roadmap of the industry, before going on to cover processing technology and 3D structure fabrication strategies in detail. This is followed by fields of application and a look at the future of 3D integration.The contributions come from key players in the field, from both academia and industry, including such companies as Lincoln Labs, Fraunhofer, RPI, ASET, IMEC, CEA-LETI, IBM, and Renesas.


#*"I Love My iPhone ... But There Are Certain Things That `Niggle' Me"
#@Anna Haywood,Gemma Boguslawski
#t2009
#cProceedings of the 13th International Conference on Human-Computer Interaction. Part I: New Trends
#index488326
#!Touchscreen technology is gaining sophistication, and the freedom offered by finger-based interaction has heralded a new phase in mobile phone evolution. The list of touchscreen mobiles is ever increasing as the appeal of `touch' moves beyond the realms of the early adopter or fanboy, into the imagination of the general consumer. However, despite this increasing popularity, touchscreen cannot be considered a panacea. It is important to look beyond the promise of a more direct and intuitive interface, towards the day-to-day reality. Based on our independent research, this paper explores aspects of the touchscreen user experience, offering iPhone insights as examples, before presenting key best practice guidelines to help design and evaluate finger-activated touchscreen solutions for small screen devices.


#*Automatic Identification of Shaft Orbits for Steam Turbine Generator Sets
#@Changfeng Yan,Hao Zhang,Hui Li,Li Yang,Wen Huang
#t2009
#cProceedings of the 2009 WRI Global Congress on Intelligent Systems - Volume 04
#index498480
#!The shaft orbits and dynamic characteristics of the shaft centre orbit contain abundant information for the fault diagnosis of rotating machinery and reflect different faults of rotating machine. Therefore the shaft orbits recognition plays an important role in the fault diagnosis of steam turbine generator set. An automatic identification method of shaft orbit for steam turbine generator sets is proposed in this paper. The median morphological filter combining the open-closing with clos-opening is used to eliminate the noise in the original X and Y vibration signals. Then the seven invariant moment feature are extracted from the shaft orbit reconstructed. Input the seven invariant moments to the trained BP neural network, the shaft orbit can be identified automatically. A case is verified this model. It is shown that this model is feasible and high precision for identify the shaft orbit in fault diagnosis.


#*Analysis methodology: are we done?
#@Sigrün Andradóttir,David Goldsman,Lee W. Schruben,Bruce W. Schmeiser,Enver Yücesan
#t2005
#cProceedings of the 37th conference on Winter simulation
#index24087
#%89715
#%608120
#%610670
#%246511
#%557620
#%456415
#!Since 1967, the Winter Simulation Conference has been a forum for the introduction of innovative approaches to effectively analyze discrete-event simulation experiments. The goal of this panel is to bring together key contributors to analysis methodology research in order to clarify areas that they think are essentially complete, and identify areas that need more work. In doing so, we hope to help provide direction to younger researchers looking for the "right" problems to work on.


#*Efficient breadth-first mining of frequent pattern with monotone constraints
#@Francesco Bonchi,Fosca Giannotti,Alessio Mazzanti,Dino Pedreschi
#t2005
#cKnowledge and Information Systems
#index104438
#!The key point of this article is that, in frequent pattern mining, the most appropriate way of exploiting monotone constraints in conjunction with frequency is to use them in order to reduce the input data; this reduction in turn induces a stronger pruning of the search space of the problem. Following this intuition, we introduce ExAMiner, a breadth-first algorithm that exploits the real synergy of antimonotone and monotone constraints: the total benefit is greater than the sum of the two individual benefits. ExAMiner generalizes the basic idea of the preprocessing algorithm ExAnte (Bonchi et al. 2003(b)), embedding such ideas at all levels of an Apriori-like computation. The resulting algorithm is the generalization of the Apriori algorithm when a conjunction of monotone constraints is conjoined to the frequency antimonotone constraint. Experimental results confirm that this is, so far, the most efficient way of attacking the computational problem in analysis.


#*Logic Circuit Design Based on MOS-NDR Devices and Circuits Fabricated by CMOS Process
#@Kwang-Jow Gan,Dong-Shong Liang,Chung-Chih Hsiao,Shih-Yu Wang,Feng-Chang Chiang,Cher-Shiung Tsai,Yaw-Hwang Chen,Shun-Huo Kuo,Chi-Pin Chen
#t2005
#cProceedings of the Fifth International Workshop on System-on-Chip for Real-Time Applications
#index575914
#!We propose a new MOS-NDR device that is composed of the metal-oxide-semiconductor field-effect-transistor(MOS) devices. This device could exhibit the negative differential resistance (NDR) characteristics in the current-voltage characteristics by suitably modulating the MOS parameters. We design a logic circuit which can operate the inverter, NOR, and NAND gates. The devices and circuits are fabricated by the standard 0.35µm CMOS process.


#*Art and technology in interface devices
#@Hiroo Iwata
#t2005
#cProceedings of the ACM symposium on Virtual reality software and technology
#index579922
#%454716
#%456347
#!This paper presents work carried out for a project to develop interface devices for haptics that includes finger/hand manipulation, locomotion. It is well known that sense of touch is inevitable for understanding the real world. The last decade has seen significant advance in development of haptic interface. However, methods for implementation of haptic devices are still in try-and-error. Compared to visual and auditory displays, haptic display has not been used in everyday life. In order to overcome this limitation, we have been exhibiting the interface devices as art work. This paper introduces issues and solutions in haptic device through 18-years history of our research activities.


#*Detecting opponent concessions in multi-issue automated negotiation
#@Scott Buffett,Luc Comeau,Bruce Spencer,Michael W. Fleming
#t2006
#cProceedings of the 8th international conference on Electronic commerce: The new e-commerce: innovations for conquering current barriers, obstacles and limitations to conducting successful business on the internet
#index22563
#%103408
#!An agent engaged in multi-issue automated negotiation can benefit greatly from learning about its opponent's preferences. Knowledge of the opponent's preferences can help the agent not only to find mutually acceptable agreements more quickly, but also to negotiate deals that are better for the agent in question. In this paper, we describe a new technique for learning about an opponent's preferences by observing its history of offers in a negotiation. Patterns in the similarity between the opponent's offers and our own agent's offers are used to determine the likelihood that the opponent is making a concession at each stage in the negotiation. These probabilities of concession are then used to determine the opponent's most likely preference relation over all offers. Experimental results show that our technique significantly outperforms a previous method that assumes that a negotiation agent will always make concessions during the course of a negotiation.


#*A parameterized graph-based framework for high-level test synthesis
#@Saeed Safari,Amir Hossein Jahangir,Hadi Esmaeilzadeh
#t2006
#cIntegration, the VLSI Journal
#index34954
#%80041
#%607938
#%371538
#%325612
#%81519
#%315098
#%86597
#%293472
#%609366
#%329004
#%549495
#%150284
#%307669
#!Improving testability during the early stages of high-level synthesis has several benefits including reduced test hardware overheads, reduced test costs, reduced design iterations, and significant improved fault coverage. In this paper, we present a novel register allocation method, which is based on weighted graph coloring algorithm, targeting testability improvement for digital circuits. In our register allocation method, several high-level testability parameters including sequential depth, sequential loop, and controllability/ observability are considered. Our experiments show using this register allocation method results in significant improvement in automatic test pattern generation time and fault coverage.


#*Analysis on fuzzy risk of landfall typhoon in Zhejiang province of China
#@Li-Hua Feng,Gao-Yuan Luo
#t2009
#cMathematics and Computers in Simulation
#index132283
#%109973
#!The simplest way to perform a fuzzy risk assessment is to calculate the fuzzy expected value and convert fuzzy risk into non-fuzzy risk, i.e. a crisp value. In doing so, there is a transition from a fuzzy set to crisp set. Therefore, the first step is to define an @a level value, and then select the elements x with a subordinate degree A(x)>=@a. The higher the value of @a, the lower the degree of uncertainty-the probability is closer to its true value. The lower the value of @a, the higher the degree of uncertainty-this results in a lower probability serviceability. The possibility level @a is dependent on technical conditions and knowledge. A fuzzy expected value of the possibility-probability distribution is a set with E_"@a(x) and E@?"@a(x) as its boundaries. The fuzzy expected values E_"@a(x) and E@?"@a(x) of a possibility-probability distribution represent the fuzzy risk values being calculated. Therefore, we can obtain a conservative risk value, a venture risk value and a maximum probability risk value. Under such an @a level, three risk values can be calculated. As @a adopts all values throughout the set [0,1], it is possible to obtain a series of risk values. Therefore, the fuzzy risk may be a multi-valued risk or set-valued risk. Calculation of the fuzzy expected value of landfall typhoon risk in Zhejiang province has been performed based on the interior-outer set model. Selection of an @a value depends on the confidence in different groups of people, while selection of a conservative risk value or venture risk value depends on the risk preference of these people.


#*Surface reconstruction from point set using projection operator
#@Ly Phan,Lu Liu,Sasakthi Abeysinghe,Tao Ju,Cindy M. Grimm
#t2008
#cACM SIGGRAPH 2008 posters
#index405829


#*Review of "Object-Oriented Programming with Visual Basic.NET by Michael McMillan"; Cambridge University Press: Cambridge, &copy;2004, 0-521-53983-8
#@Haoyang Che
#t2005
#cACM SIGSOFT Software Engineering Notes
#index97414
#!I've already been a VB user for almost seven years. However, I must confess that I've rarely touched it since the last multimedia medical project. We used VB 6 in our development team, for that VB.NET didn't gain ground at that time. The first time I heard of VB.NET was in mid-2002. Then all of a sudden when I got up in the next morning, Microsoft .NET technology seemed to have become popular overnight. Buzzwords and slogans were everywhere: on the Internet, on the weighty books of published abstracts, on T-shirts, on sweatshirts, and even on souvenir pens. Is VB.NET still VB? Everyone may bear the question in his mind when he first glimpses at it. Object-Oriented Programming with Visual Basic.NET by Michael McMillan will give you a reasonable answer.


#*A high-end virtual reality setup for the study of mental rotations
#@Alexandre Lehmann,Manuel Vidal,Heinrich H. Bülthoff
#t2008
#cPresence: Teleoperators and Virtual Environments
#index385684
#%30934
#%562800
#!Mental rotation is the capacity to predict the orientation of an object or the layout of a scene after a change in viewpoint. Previous studies have shown that the cognitive cost of mental rotations is reduced when the viewpoint change results from the observer's motion rather than the object or spatial layout's rotation. The classical interpretation for these findings involves the use of automatic updating mechanisms triggered during self-motion. Nevertheless, little is known about how this process is triggered and particularly how sensory cues combine in order to facilitate mental rotations. The previously existing setups, either real or virtual, did not allow disentangling the different sensory contributions, which motivated the development of a new high-end virtual reality platform overcoming these technical limitations. In the present paper we will start by a didactic review of the literature on mental rotations and expose the current technical limitations. Then we will fully describe the experimental platform that was developed at the Max Planck Institute for Biological Cybernetics in Tübingen. The setup consisted of a cabin mounted on the top of a six degree-of-freedom Stewart platform inside of which was an adjustable seat, a physical table with a screen embedded, and a large projection screen. A 5-PC cluster running Virtools was used to drive the platform and render the two passive stereovision scenes that were displayed on the table and background screens. Finally, we will present the experiment using this setup that allowed replicating the classical advantage found for a moving observer, which validates our setup. We will conclude by discussing the experimental validation and the advantages of such a setup.


#*An Assessment of Case-Based Reasoning for Spam Filtering
#@Sarah Jane Delany,Pádraig Cunningham,Lorcan Coyle
#t2005
#cArtificial Intelligence Review
#index574623
#%214951
#%286105
#%310357
#%360014
#%380361
#!Because of the changing nature of spam, a spam filtering system that uses machine learning will need to be dynamic. This suggests that a case-based (memory-based) approach may work well. Case-Based Reasoning (CBR) is a lazy approach to machine learning where induction is delayed to run time. This means that the case base can be updated continuously and new training data is immediately available to the induction process. In this paper we present a detailed description of such a system called ECUE and evaluate design decisions concerning the case representation. We compare its performance with an alternative system that uses Naïve Bayes. We find that there is little to choose between the two alternatives in cross-validation tests on data sets. However, ECUE does appear to have some advantages in tracking concept drift over time.


#*The Set Connector Problem in Graphs
#@Takuro Fukunaga,Hiroshi Nagamochi
#t2007
#cProceedings of the 12th international conference on Integer Programming and Combinatorial Optimization
#index393512
#!Given a graph G = (V,E) with an edge cost and families $\mathcal{V}_i\subseteq 2^V$, i = 1,2,...,m of disjoint subsets, an edge subset F ¿ E is called a set connector if, for each $\mathcal{V}_i$, the graph $(V,F)/\mathcal{V}_i$ obtained from (V,F) by contracting each $X\in \mathcal{V}_i$ into a single vertex x has a property that every two contracted vertices x and x¿ are connected in $(V,F)/\mathcal{V}_i$. In this paper, we introduce a problem of finding a minimum cost set connector, which contains several important network design problems such as the Steiner forest problem, the group Steiner tree problem, and the NA-connectivity augmentation problem as its special cases. We derive an approximate integer decomposition property from a fractional packing theorem of set connectors, and present a strongly polynomial 2¿-approximation algorithm for the set connector problem, where $\alpha=\max_{1 \leq i \leq m}(\sum_{X \in \mathcal{V}_i}|X|)-1$.


#*Tolerance to Small Delay Defects by Adaptive Clock Stretching
#@Swaroop Ghosh,Patrick NDai,Swarup Bhunia,Kaushik Roy
#t2007
#cProceedings of the 13th IEEE International On-Line Testing Symposium
#index427342
#!Bridging defects typically manifest themselves as increased path delays instead of stuck-at failures. On the other hand, parametric variations (both inter- and intra-die) increase the spread of the circuit delay. Low power design techniques such as voltage scaling, dual-Vth etc. deteriorate the delay spread further. These mechanisms for delay variations in nanoscaled technologies significantly affect the parametric yield. We propose a new design methodology to tolerate subtle delay failures that arise both due to manufacturing defects and parameter fluctuations. We synthesize the circuit to (a) isolate and predict the critical paths of a circuit; (b) create timing slack between critical and off-critical paths and ensure that they are activated rarely; and, (c) avoid the delay failures in these paths by adaptively stretching the clock period. Since critical paths are the most sensitive section of the circuit in terms of delay defects, we ensure fault-free operation by isolating them and providing extra computation time by predicting their activation. This allows us to achieve the required yield with small performance penalty (due to occasional clock stretching under critical path activation). We present application of the proposed methodology for both linear and non-linear pipeline designs. We also suggest two possible circuit-level implementations of clock stretching using clock gating and handshaking, respectively. Simulations on MCNC benchmark circuits with BPTM 70nm devices show that the proposed technique can achieve good yield by tolerating increased path delays (under variations and bridging defects of various sizes) with small overhead in performance and ~14% die-area compared to the conventional design. For performance analysis, we have implemented the proposed methodology in simple in-order pipeline in Simplescalar. Simulation results on SPEC2000 benchmarks show less that 2% of IPC (instructions-per-cycle) degradation.


#*A Learning Support System based on Question-posing and Its Evaluation
#@Yuuki HIRAI,Atsuo HAZEYAMA
#t2007
#cProceedings of the Fifth International Conference on Creating, Connecting and Collaborating through Computing
#index426536
#!This paper proposes a Web-based collaborative learning system, which supports question-posing by learners, assessment from peers, and discussions with question-poser and peers. It also describes evaluation of effectiveness of the system. Based on the results, the system contributed to enhancement of understanding of those who used the system. Although facilities for discussions were not used as much as we expected, we found some functions to be enhanced for discussions support.


#*Proceedings of the 5th international workshop on Grid Economics and Business Models
#@Jörn Altmann,Dirk Neumann,Thomas Fahringer
#t2008
#cLecture Notes In Computer Science; Vol. 5206
#index412999


#*Ultra Low Voltage High Speed Differential CMOS Inverter
#@Omid Mirmotahari,Yngvar Berg
#t2009
#cIntegrated Circuit and System Design. Power and Timing Modeling, Optimization and Simulation: 18th International Workshop, PATMOS 2008, Lisbon, Portugal, September 10-12, 2008. Revised Selected Papers
#index54884
#!In this paper we demonstrate and analyse how the differential ultra low voltage inverter can be designed in order to achieve the most beneficial conditions concerning speed, stability and EDP.


#*How to Mask the Structure of Codes for a Cryptographic Use
#@Thierry P. Berger,Pierre Loidreau
#t2005
#cDesigns, Codes and Cryptography
#index109177
#%261643
#%258406
#%146820
#%588351
#%451650
#%172362
#!In this paper we show how to strengthen public-key cryptosystems against known attacks, together with the reduction of the public-key. We use properties of subcodes to mask the structure of the codes used by the conceiver of the system. We propose new parameters for the cryptosystems and even a modified Niederreiter cryptosystem in the case of Gabidulin codes, with a public-key size of less than 4000 bits.


#*Design and Implementation of a Parallel Heterogeneous Algorithm for Hyperspectral Image Analysis Using HeteroMPI
#@David Valencia,Alexey Lastovetsky,Antonio Plaza
#t2006
#cProceedings of the Proceedings of The Fifth International Symposium on Parallel and Distributed Computing
#index35704
#!The development of efficient techniques for transforming the massive volume of remotely sensed hyperspectral data collected on a daily basis into scientific understanding is critical for space-based Earth science and planetary exploration. Although most available parallel processing strategies for hyperspectral image analysis assume homogeneity in the computing platform, heterogeneous networks of computers represent a promising cost-effective solution expected to play a major role in many on-going and planned remote sensing missions. To address the need for cost-effective parallel hyperspectral imaging algorithms, this paper develops an innovative heterogeneous parallel algorithm for spatial/spectral morphological analysis of hyperspectral image data. The algorithm has been developed using Heterogeneous MPI (HeteroMPI), an extension of MPI for programming high-performance computations on heterogeneous networks of computers. Experimental results are presented and discussed in the context of a realistic application, based on hyperspectral data collected by NASA's Jet Propulsion Laboratory.


#*A Pseudo-Boolean Optimization for Multiple Criteria Decision Making in Complex Systems
#@Bahram Alidaee,Haibo Wang,Yaquan Xu
#t2007
#cProceedings of the 7th international conference on Computational Science, Part IV: ICCS 2007
#index407279
#!In complex system problems, a Decision Maker (DM) is often faced with choosing a subset of alternatives from a bigger set. This process is known as multiple criteria decision making (MCDM). Examples of MCDM include decision making in human resource management, water resource management, environmental management and site selection, energy policy issues, portfolio selection, transportation and routing selection, student admission. In general, there are several criteria that need to be satisfied; however, they are usually at least partly conflicting. In this study, we propose a pseudo-boolean approach for multiple criteria decision making on complex system problems. The computational results illustrate both robustness and attractiveness of this solution approach.


#*Hyperbox clustering with Ant Colony Optimization (HACO) method and its application to medical risk profile recognition
#@G. N. Ramos,Y. Hatakeyama,F. Dong,K. Hirota
#t2009
#cApplied Soft Computing
#index70706
#%311413
#%568387
#%616075
#%101758
#%254744
#!A clustering method, called HACO (Hyperbox clustering with Ant Colony Optimization), is proposed for classifying unlabeled data using hyperboxes and an ant colony meta-heuristic. It acknowledges the topological information (inherently associated to classification) of the data while looking in a small search space, providing results with high precision in a short time. It is validated using artificial 2D data sets and then applied to a real medical data set, automatically extracting medical risk profiles, a laborious operation for doctors. Clustering results show an improvement of 36% in accuracy and 7 times faster processing time when compared to the usual ant colony optimization approach. It can be further extended to hyperbox shape optimization (fine tune accuracy), automatic parameter setting (improve usability), and applied to diagnosis decision support systems.


#*Processor Scheduler for Multi-Service Routers
#@Ravi Kokku,Upendra Shevade,Nishit Shah,Ajay Mahimkar,Taewon Cho,Harrick Vin
#t2006
#cProceedings of the 27th IEEE International Real-Time Systems Symposium
#index29243
#!In this paper, we describe the design and evaluation of a scheduler (referred to as Everest) for allocating processors to services in high performance, multi-service routers. A scheduler for such routers is required to maximize the number of packets processed within a given delay tolerance, while isolating the performance of services from each other. The design of such a scheduler is novel and challenging because of three domain-specific characteristics: (1) difficultto- predict and high packet arrival rates, (2) small delay tolerances of packets, and (3) significant overheads for switching allocation of processors from one service to another. These characteristics require that the scheduler be agile and wary simultaneously. Whereas agility enables the scheduler to react quickly to fluctuations in packet arrival rates, wariness prevents the scheduler from wasting computational resources in unnecessary context switches. We demonstrate that by balancing agility and wariness, Everest, as compared to conventional schedulers, reduces by more than an order of magnitude the average delay and the percentage of packets that experience delays greater than their tolerance. We describe a prototype implementation of Everest on Intel's IXP2400 network processor.


#*Approximately-strategyproof and tractable multiunit auctions
#@Anshul Kothari,David C. Parkes,Subhash Suri
#t2005
#cDecision Support Systems
#index107247
#%244211
#%564416
#%562154
#%241257
#%320779
#%616871
#!We present an approximately-efficient and approximately-strategyproof auction mechanism for a single-good multiunit allocation problem. The bidding language allows marginal-decreasing piecewise-constant curves and quantity-based side constraints. We develop a fully polynomial-time approximation scheme for the multiunit allocation problem, which computes a (1+ε) approximation in worst-case time T=O(n3/ε), given n bids each with a constant number of pieces. We integrate this approximation scheme within a Vickrey-Clarke-Groves (VCG) mechanism and compute payments for an asymptotic cost of O(T log n). The maximal possible gain from manipulation to a bidder in the combined scheme is bounded by εV/(1+ε), where V is the total surplus in the efficient outcome.


#*Dopant effects on the thermal stability of FUSI NiSi
#@P. Zhao,M. J. Kim,B. E. Gnade,R. M. Wallace
#t2008
#cMicroelectronic Engineering
#index350031
#!The thermal stability of fully silicided (FUSI) NiSi with arsenic or boron doping on silicon on insulator (SOI) was investigated. After the stacks were subjected to a typical back-end of line (BEOL) thermal annealing in a N"2 ambient, abnormal oxidation of As doped FUSI NiSi stacks is observed by X-ray photoelectron spectroscopy (XPS), and confirmed by high-resolution transmission electron microscopy (HRTEM). X-ray diffraction (XRD) results show Ni-rich phases like Ni"3Si are formed due to abnormal oxidation of FUSI NiSi. In contrast to As doped stacks, no phase transformation nor abnormal oxidation are observed for B doped stacks under similar annealing. However, backside secondary ion mass spectrometry (SIMS) results indicate B penetration through a 3nm SiON layer into the Si channel after N"2 annealing for 4h at 400^oC. There is no evidence for Ni diffusion into the Si channel for B doped stacks. However, Ni penetration into the Si channel is observed for As doped stacks due to the enhancement of abnormal oxidation of FUSI NiSi.


#*Food Webs: From Connectivity to Energetics
#@Hal Caswell
#t2005
#c
#index107633


#*Authentication Mechanisms for Mobile Agents
#@Leila Ismail
#t2007
#cProceedings of the The Second International Conference on Availability, Reliability and Security
#index429061
#!This paper describes authentication mechanisms for mobile agents. In these mechanisms, the authentication of mobile agents is controlled by the mobile-agents platform using digital signature and a Public Key Infrastructure. Agents are authenticated via the authentication of their running platforms. An important advantage of our technique is transparency of the mechanisms and the portability of non-secure applications onto a secure environment. The authentication mechanisms are integrated within the transportation layer of a mobile-agents system. A minimal mobile agent system and the authentication mechanisms have been implemented. The implementation experiments have shown the feasibility and the advantage of these mechanisms.


#*A fast and accurate approach for 3D image registration using the scatter search evolutionary algorithm
#@O. Cordón,S. Damas,J. Santamaría
#t2006
#cPattern Recognition Letters
#index27780
#%538698
#%195566
#%597561
#%528217
#%122235
#%599654
#!Nowadays, image registration (IR) is still an important and useful task in several areas such as remote sensing, medicine, cartography, and computer vision. Different approaches to solve the existing variants of the problem are commonly proposed in the specialized literature. In this paper, we focus our interest on the 3D IR problem considering similarity transformations and our proposal is based on the use of a new procedure based on the evolutionary computation framework for non-linear optimization. We apply an emergent global optimization strategy called scatter search providing a fast and accurate algorithm. To measure its performance, we design an experimental setup considering some of the most accepted and accurate classical and evolutionary techniques for the problem, as well as six different shapes, one synthetic and five magnetic resonance images, dealing with different levels of noise and occlusion in the scenarios treated.


#*News
#@
#t2009
#cCommunications of the ACM
#index56622


#*Tracking Multiple Mouse Contours (without Too Many Samples)
#@Kristin Branson,Serge Belongie
#t2005
#cProceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Volume 1 - Volume 01
#index104471
#!We present a particle filtering algorithm for robustly tracking the contours of multiple deformable objects through severe occlusions. Our algorithm combines a multiple blob tracker with a contour tracker in a manner that keeps the required number of samples small. This is a natural combination because both algorithms have complementary strengths. The multiple blob tracker uses a natural multitarget model and searches a smaller and simpler space. On the other hand, contour tracking gives more fine-tuned results and relies on cues that are available during severe occlusions. Our choice of combination of these two algorithms accentuates the advantages of each. We demonstrate good performance on challenging video of three identical mice that contains multiple instances of severe occlusion.


#*Modelling of batch production systems using Petri nets with dynamic tokens
#@Ernesto López-Mellado,Norma Villanueva-Paredes,Hugo Almeyda-Canepa
#t2005
#cMathematics and Computers in Simulation
#index107788
#%232387
#%319379
#!This article deals with the qualitative modelling of batch production plants. The approach held is Petri net based. First a definition of a three-level net formalism is presented; the formalism extends the Valk's approach of nets in nets in which the tokens are other nets; in this extension the lower level net handles symbolic tokens. Then a methodology for the modelling of batch processes is proposed; in this methodology the upper level describes the plant layout, the next level models an entity that goes with the batch through the plant and specifies the material and the process routes that the batch must follow, and the third level represents detailed treatments to perform into the process cells using specific equipment. The use of the modelling formalism is illustrated through an example dealing with the coordination of a batch manufacturing system.


#*Intelligent Tutors for All: The Constraint-Based Approach
#@Antonija Mitrovic,Brent Martin,Pramuditha Suraweera
#t2007
#cIEEE Intelligent Systems
#index351923
#%392493
#%403428
#!Intelligent tutoring systems have revolutionized online education by providing individualized instruction for each student. Constraint-based tutors model instructional domains at an abstract level, a novel approach that simplifies development of these systems. Over the last decade, the University of Canterbury's Intelligent Computer Tutoring Group has developed effective constraint-based tutors for various instructional domains; some of these tutors have been successfully commercialized. Constraint-based tutoring is a mature, successful approach to providing adaptive learning environments. ICTG-developed authoring tools aim to make this technology widely available to teachers and students. This article is part of a special issue on intelligent educational systems.


#*A Platform for OnBoard Credentials
#@N. Asokan,Jan-Erik Ekberg
#t2008
#cFinancial Cryptography and Data Security: 12th International Conference, FC 2008, Cozumel, Mexico, January 28-31, 2008. Revised Selected Papers
#index393215
#!Securely storing and using credentials for authentication is an essential part of protecting financial applications like on-line banking and other distributed applications. Existing approaches fall short: Requiring users to memorize credentials suffers from bad usability and is vulnerable to phishing. "Password managers" ease the usability problem somewhat, but are open to software attacks, like Trojans that steal passwords. At the other extreme, dedicated hardware tokens provide high levels of security, but are expensive and not very flexible. We observe that general-purpose secure hardware are becoming widely available and use them to develop a platform for "OnBoard Credentials" (ObCs) which combine the flexibility of virtual credentials with the higher levels of protection due to the use of secure hardware.


#*Towards Propagation of Changes by Model Approximations
#@Antonio Cicchetti,Davide Di Ruscio,Romina Eramo
#t2006
#cProceedings of the 10th IEEE on International Enterprise Distributed Object Computing Conference Workshops
#index35075
#!A number of model transformation approaches have been proposed both from academia and industry since automated manipulation of models plays a central role in model driven development. Ideally, a model transformation technique should also be compatible with manual changes that might be performed by designers on the generated models in order to resolve unforeseen requirements or limited expressiveness of the involved metamodels. This paper proposes an approach to model transformation based on answer set programming. Starting from target models that have been manually modified (and possibly not belong to the co-domain of the transformation being used), the approach is able to deduce a collection of models that approximate the ideal one from which it is possible to generate the previously modified target.


#*MixCast: A New Group Communication Model in Large-Scale Network
#@Yusong Lin,Binqiang Wang,Zongmin Wang
#t2005
#cProceedings of the 19th International Conference on Advanced Information Networking and Applications - Volume 2
#index101222
#!The traditional multicast model has some problems, such as access control, address allocation and protocol extensibility. To solve these problems, we provide a new group communication model named MixCast, which is suitable for large-scale heterogeneous networks. MixCast uses unicast between different access networks and use multicast in the same access network; at the same time, MixCast uses IEEE 802.1X protocol to provide user access control and billing scheme for carriers. We also analysis the cost of MixCast communication in the network equipments.


#*Solving a Problem in Grid Applications: Using Aspect Oriented Programming
#@Hyuck Han,Shingyu Kim,Hyungsoo Jung,Heon Y. Yeom
#t2007
#cProceedings of the 7th international conference on Computational Science, Part IV: ICCS 2007
#index390249
#!Aspect Oriented Programming (AOP) was introduced 10 years ago and many research projects have focused on broadening AOP and its target areas. However, few applications in the Grid computing world adopt AOP in comparison with very vigorous research of AOP. Therefore, we present a case study that covers a general networking problem in the Grid computing. AOP provides a novel solution of the problem without modifying existing source code. Aspects that we define are simple, intuitive and reusable. We believe that our implementation is very useful in developing other Grid computing software platforms, and AOP can be a powerful method in modularizing source codes and solving problems of software architectures.


#*A Bayesian Methodology for Estimating Uncertainty of Decisions in Safety-Critical Systems
#@Vitaly Schetinin,Jonathan E. Fieldsend,Derek Partridge,Wojtek J. Krzanowski,Richard M. Everson,Trevor C. Bailey,Adolfo Hernandez
#t2006
#cProceeding of the 2006 conference on Integrated Intelligent Systems for Engineering Design
#index128237
#%378210
#!Uncertainty of decisions in safety-critical engineering applications can be estimated on the basis of the Bayesian Markov Chain Monte Carlo (MCMC) technique of averaging over decision models. The use of decision tree (DT) models assists experts to interpret causal relations and find factors of the uncertainty. Bayesian averaging also allows experts to estimate the uncertainty accurately when a priori information on the favored structure of DTs is available. Then an expert can select a single DT model, typically the Maximum a Posteriori model, for interpretation purposes. Unfortunately, a priori information on favored structure of DTs is not always available. For this reason, we suggest a new prior on DTs for the Bayesian MCMC technique. We also suggest a new procedure of selecting a single DT and describe an application scenario. In our experiments on real data our technique outperforms the existing Bayesian techniques in predictive accuracy of the selected single DTs.


#*The Evaluation Model of Knowledge Management Based on Information Entropy and RBF Neural Network (IE-RBF)
#@Yu Chen
#t2009
#cProceedings of the 2009 Asia-Pacific Conference on Information Processing - Volume 01
#index507338
#!Knowledge management is a complex systems engineering, so the evaluation of knowledge management is of non-linear characteristics. Neural network with the ability of adaptive learning is an excellent tool to deal with the issue of non-linear. This paper analyzed the essence of knowledge and knowledge management. We proposed an evaluation model of knowledge management based on the theory of information entropy and RBF neural network. After reduction of the indices system with information entropy to reduce, we would evaluate the knowledge management with RBF neural network. After empirical research with MATLAB7.0, it is had been proved that the method is validity and practicality. And then it did not only overcome the traditional methods’ shortcoming which is too subjective, but also avoided complex process of the traditional evaluation method.


#*Simulation & Implementation of Shortest Path Algorithm with a Mobile Robot Using Configuration Space Approach
#@T. C. Manjunath,B. G. Nagaraja,Ashok Kusagur,Gopala
#t2009
#cProceedings of the 2009 International Conference on Advanced Computer Control
#index65383
#!A simulation & implementation of a shortest path from the source to the destination in the amidst of obstacles using configuration space approach both with translations & rotations is presented in this paper. One of the most important problems in robotics is the task-planning problem. A task is a job or an application or an operation that has to be done by the robot, whether it is a stationary robot or a mobile robot. The word ‘planning’ means deciding on a course of action before acting. Before a robot does a particular task, how the task has to be done or performed in its workspace has to be planned. This is what is called as Robot Task Planning (RTP). A plan is a representation of a course of action for achieving the goal. How the problem has to be solved has to be planned properly. Robot task planning is also called as problem solving techniques and is one of the important topics of Artificial Intelligence. For eg., when a problem is given to a human being to be solved; first, he or she thinks about how to solve the problem, then devises a strategy / plan how to tackle the problem. Then only he or she starts solving the problem. Hence, robot task planning is also called as robot problem solving techniques. Many of the items in task planning are currently under active research in the fields of Artificial Intelligence, Image Processing and Robotics. Lot of research is going on in the robot problem solving techniques. The simulation & the experimental results show the effectives of the method used.


#*Decision Making in Uncertain Situations: An Extension to the Mathematical Theory of Evidence
#@Fabio Campos
#t2006
#c
#index13003


#*Creating Transformations for Matrix Obfuscation
#@Stephen Drape,Irina Voiculescu
#t2009
#cProceedings of the 16th International Symposium on Static Analysis
#index492567
#!There are many programming situations where it would be convenient to conceal the meaning of code, or the meaning of certain variables. This can be achieved through program transformations which are grouped under the term obfuscation. Obfuscation is one of a number of techniques that can be employed to protect sensitive areas of code. This paper presents obfuscation methods for the purpose of concealing the meaning of matrices by changing the pattern of the elements.We give two separate methods: one which, through splitting a matrix, changes its size and shape, and one which, through a change of basis in a ring of polynomials, changes the values of the matrix and any patterns formed by these. Furthermore, the paper illustrates how matrices can be used in order to obfuscate a scalar value. This is an improvement on previous methods for matrix obfuscation because we will provide a range of techniques which can be used in concert.This paper considers obfuscations as data refinements. Thus we consider obfuscations at a more abstract level without worrying about implementation issues. For our obfuscations, we can construct proofs of correctness easily. We show how the refinement approach enables us to generalise and combine existing obfuscations. We then evaluate our methods by considering how our obfuscations perform under certain relevant program analysis-based attacks.


#*Design and performance of speculative flow control for high-radix datacenter interconnect switches
#@Cyriel Minkenberg,Mitchell Gusat
#t2009
#cJournal of Parallel and Distributed Computing
#index141485
#%387102
#%578157
#%578971
#!High-radix switches are desirable building blocks for large computer interconnection networks, because they are more suitable to convert chip I/O bandwidth into low latency and low cost than low-radix switches [J. Kim, W.J. Dally, B. Towles, A.K. Gupta, Microarchitecture of a high-radix router, in: Proc. ISCA 2005, Madison, WI, 2005]. Unfortunately, most existing switch architectures do not scale well to a large number of ports, for example, the complexity of the buffered crossbar architecture scales quadratically with the number of ports. Compounded with support for long round-trip times and many virtual channels, the overall buffer requirements limit the feasibility of such switches to modest port counts. Compromising on the buffer sizing leads to a drastic increase in latency and reduction in throughput, as long as traditional credit flow control is employed at the link level. We propose a novel link-level flow control protocol that enables high-performance scalable switches that are based on the increasingly popular buffered crossbar architecture, to scale to higher port counts without sacrificing performance. By combining credited and speculative transmission, this scheme achieves reliable delivery, low latency, and high throughput, even with crosspoint buffers that are significantly smaller than the round-trip time. The proposed scheme substantially reduces message latency and improves throughput of partially buffered crossbar switches loaded with synthetic uniform and non-uniform bursty traffic. Moreover, simulations replaying traces of several typical MPI applications demonstrate communication speedup factors of 2 to 10 times.


#*Development of Safety-Critical Systems with RTCP-Nets Support
#@Marcin Szpyrka
#t2005
#cProceeding of the 2005 conference on Software Engineering: Evolution and Emerging Technologies
#index131385
#!Safety-critical systems require the utmost care in their specification and design to avoid errors in their implementation. Development of such systems may be supported by formal methods. The paper presents a subclass of timed coloured Petri nets called RTCP-nets that may be used for the modelling and analysis of safety-critical systems. Subclass of RTCP-nets is described shortly and some aspects of the modelling of safety-critical systems with RTCP-nets and implementation in Ada are also presented. (The work is carried out within KBN Research Project, Grant No. 4 T11C 035 24.)


#*Composition of software artifacts modelled using colored Petri nets
#@Leandro Dias da Silva,Angelo Perkusich
#t2005
#cScience of Computer Programming
#index102609
#%315650
#%293288
#%626222
#%232742
#%598103
#%303045
#!In this work we introduce a new formal model for software components supporting behavioral interpretability based on temporal logic, Petri nets, model checking, and an assume-guarantee strategy to specify and reason about the composition of concurrent component systems. The formal specification and verification strategies, methods, and techniques presented in this work contribute to the development of more dependable component-based software systems, in a modular way. An approach based on two complementary formalisms, Hierarchical Colored Petri Nets (HCPN) and temporal logic, is introduced. HCPN are used to visualize the structure and model the behavior of software architectures and components, and temporal logic is used to specify the required properties of software architectures and component interfaces.


#*Assessing the Relationship between Software Assertions and Faults: An Empirical Investigation
#@Gunnar Kudrjavets,Nachiappan Nagappan,Thomas Ball
#t2006
#cProceedings of the 17th International Symposium on Software Reliability Engineering
#index33720
#!The use of assertions in software development is thought to help produce quality software. Unfortunately, there is scant empirical evidence in commercial software systems for this argument to date. This paper presents an empirical case study of two commercial software components at Microsoft Corporation. The developers of these components systematically employed assertions, which allowed us to investigate the relationship between software assertions and code quality. We also compare the efficacy of assertions against that of popular bug finding techniques like source code static analysis tools. We observe from our case study that with an increase in the assertion density in a file there is a statistically significant decrease in fault density. Further, the usage of software assertions in these components found a large percentage of the faults in the bug database.


#*Simultaneous well-balanced orientations of graphs
#@Zoltán Király,Zoltán Szigeti
#t2006
#cJournal of Combinatorial Theory Series B
#index21468
#%599858
#!Nash-Williams' well-balanced orientation theorem [C.St.J.A. Nash-Williams, On orientations, connectivity and odd-vertex-pairings in finite graphs, Canad. J. Math. 12 (1960) 555-567] is extended for orienting several graphs simultaneously.We prove that if G1,...,Gk are pairwise edge-disjoint subgraphs of a graph G, then G has a well-balanced orientation G→ such that the inherited orientations Gi→ of Gi are well-balanced for all 1 ≤ i ≤ k. We also have new results about simultaneous well-balanced orientations of non-disjoint subgraphs of an Eulerian graph as well as those of different contractions of a graph.


#*A Study on How Technological Innovation Affected the 2008 U.S. Presidential Election: Young Voters' Participation and Obama's Victory
#@Shoko Kiyohara
#t2009
#cProceedings of the 2009 Ninth Annual International Symposium on Applications and the Internet
#index502128
#!This paper will argue how technological innovation affected the 2008 U.S. presidential election. Sending or receiving text messages by mobile phones and SNS are very popular among young adults 18-24. During the 2008 U.S. presidential election campaign, most of the candidates had own profile pages on Facebook and MySpace. And, CNN teamed with YouTube to hold the Democratic and Republican Presidential Candidates Debates in 2007 for the first time.However, it is said that especially, Barack Obama and his campaign “successfully” used the new technology to mobilize young voters. So, I will discuss if their targeted young voters did help Obama’s victory. In conclusion, I would like to underscore relevance of technological innovation to the 2008 U.S. presidential election. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player


#*Bridging distance between actual and potential development: A case of using ICT mediated consultation tool
#@D. Ng'Ambi,S. Goodman
#t2009
#cEducation and Information Technologies
#index63926
#!It is an ongoing challenge in higher education context to design appropriate learning tasks for students that balances the diversity in student knowledge and variable skills with student's potential to learn under guidance. Obtaining feedback from students on what they know is made more complicated when students are passive during learning activities. In this paper we report on a project that ran over 2 years in which 67 students (28 in 2005; 39 in 2006) from culturally diverse socio-historical backgrounds used an anonymous knowledge sharing tool, the dynamic frequently asked questions (DFAQ) to engage with authentic learning tasks in an Organisational Learning Module. The module was part of the Organisational Psychology honours degree programme at a higher learning institution. The students used the DFAQ tool to consult with both peers and faculty staff. DFAQ is a special purpose web-based tool with a Short Message Services (SMS) interface. A thematic analysis was conducted on students' experiences gathered from focus group discussions. Artefacts from DFAQ are also analysed. The paper reports that DFAQ mediated the educator's access to the students' level of understanding and the potential to learn under guidance. The DFAQ tool therefore allowed the educator to provide students with appropriate guidance that met individual students' knowledge gaps. The paper concludes that DFAQ mediated access to the gap between actual and potential development, stimulated knowledge sharing, peer learning and impacted on pedagogical designs of learning tasks.


#*An intuitionistic fuzzy system for time series analysis in plant monitoring and diagnosis
#@Oscar Castillo,Arnulfo Alanis,Mario Garcia,Hector Arias
#t2007
#cApplied Soft Computing
#index426814
#%320215
#!We describe in this paper a proposed new approach for fuzzy inference in intuitionistic fuzzy systems. The new approach combines the outputs of two traditional fuzzy systems to obtain the final conclusion of the intuitionistic fuzzy system. The new method provides an efficient way of calculating the output of an intuitionistic fuzzy system, and as consequence can be applied to real-world problems in many areas of application. We illustrate the new approach with a simple example to motivate the ideas behind this work. We also illustrate the new approach for fuzzy inference with a more complicated example of monitoring a non-linear dynamic plant.


#*Load Balance Scheduling Algorithm for CMP Architecture
#@Qingsong Shi,Tianzhou Chen,Wei Hu,Changbin Huang
#t2009
#cProceedings of the 2009 International Conference on Electronic Computer Technology
#index58798
#!Chip MultiProcessor (CMP) has been the main stream in microprocessor design. Shared on-chip L2 caches are widely used in processors with homogeneous CMP architecture. In the paper, we propose a scheduling algorithm for such processors and the shared L2 caches are taken into account in this algorithm. First, the processor cores on chip will be divided into different core groups. The scheduling domain is also constructed according to these core groups. And then the load vectors for load balance are defined. Then a scheduling algorithm is designed and implemented for load balance on CMP architecture. We have compared our algorithm with the CMP scheduling algorithm of Linux. The experimental results show that, when there are multi-threads in execution, the load balancing between processors is achieved by our algorithm, the total execution time is reduced by 3%, and the miss rate of L2 cache is reduced by 0.2% as well.


#*Evaluating Mobile Proactive Context-Aware Retrieval: An Incremental Benchmark
#@Davide Menegon,Stefano Mizzaro,Elena Nazzi,Luca Vassena
#t2009
#cProceedings of the 2nd International Conference on Theory of Information Retrieval: Advances in Information Retrieval Theory
#index505465
#!We present the evaluation of a novel application for Web content perusal by means of context-aware mobile devices that proactively query an external search engine. To this aim, we develop a TREC-like benchmark and we use it to evaluate different strategies for automatic query construction on the basis of user's current context. We discuss both the methodology and the results.


#*Towards Formal Verification of ASIP Based on HDPN
#@Yanyan Gao,Xi Li,Hongxing Ma
#t2009
#cProceedings of the 2009 International Conference on Electronic Computer Technology
#index64745
#!Verification is one of the most complex and expensive tasks in current Application Specific Instruction-set Processor (ASIP) design process. Many existing approaches utilize a multi-level strategy to efficiently design and verify ASIP aiming to discover the flaws earlier. This paper presents a verification approach based on HDPN (Hardware Design based-on Petri Net) and NuSMV. The validation of static properties, viz. structural and functional description of ASIP architecture, implements with HDPN, and the verification of dynamic properties, viz. logic design, implements with NuSMV. In order to check the dynamic properties of HDPN-based models, a scheme of translating from a HDPN description into SMV is discussed in this paper. In addition, a DLX pipelined processor is presented to demonstrate the verification approach.


#*Full and relative awareness: a decidable logic for reasoning about knowledge of unawareness
#@Thomas Ågotnes,Natasha Alechina
#t2007
#cProceedings of the 11th conference on Theoretical aspects of rationality and knowledge
#index342090
#%168956
#%589756
#%512558
#!In the most popular logics combining knowledge and awareness, it is not possible to express statements about knowledge of unawareness such as "Ann knows that Bill is aware of something Ann is not aware of" - without using a stronger statement such as "Ann knows that Bill is aware of p and Ann is not aware of p", for some particular p. Recently, however, Halpern and R&ecirc;go (2006) introduced a logic in which such statements about knowledge of unawareness can be expressed. The logic extends the traditional framework with quantification over formulae, and is thus very expressive. As a consequence, it is not decidable. In this paper we introduce a decidable logic which can be used to reason about certain types of unawareness. The logic extends the traditional framework with an operator expressing full awareness, i.e., the fact that an agent is aware of everything, and another operator expressing relative awareness, the fact that one agent is aware of everything another agent is aware of The logic is less expressive than Halpern's and R&ecirc;go's logic. It is, however, expressive enough to express all of Halpern's and R&ecirc;go's motivating examples. In addition to proving that the logic is decidable and that its satisfiability problem is PSPACE-complete, we present an axiomatisation which we show is sound and complete.


#*Observations, measurements and semantic reference spaces
#@Florian Probst
#t2008
#cApplied Ontology
#index412551
#%242057
#%379071
#%616422
#%619789
#%480437
#!What is needed to enable communication about observation and measurement results in information systems? Information system ontologies make a certain conceptualization explicit and partially account for the meanings of symbols associated with this conceptualization. Yet, the meaning of signs denoting measurement results such as &ldquo;10 m&rdquo;, &ldquo;red&rdquo; or &ldquo;high&rdquo; cannot be specified with currently available ontologies. They fail to separate the ontological nature of some observable quality from the specification of how to observe and name the measurement result. We employ the foundational ontology DOLCE for characterizing the ontological nature of observable magnitudes. This involves dealing with ontological questions like &ldquo;What kinds of observable qualities exist, in which entity does the observed quality inhere and how are the magnitudes of the observed quality structured?&rdquo;. Then, in order to capture the semantic aspects of an observation result, we introduce semantic reference spaces, which help deal with semantic questions like &ldquo;Do the signs &ldquo;10 m&rdquo;, &ldquo;33 feet&rdquo; or &ldquo;shallow&rdquo; have the same meaning? Do these signs refer to the same entity, e.g. the depth magnitude of a lake? How to establish a unit of measure?". We posit that the semantic questions can be approached efficiently only if agreement is reached on the ontological questions, and show that the specification of the meaning of signs denoting measurement results is enabled via the extension of the foundational ontology DOLCE with semantic reference spaces. This work was conducted while the author (Probst) was working at the Institute for Geoinformatics, University of M&uuml;nster, Germany.


#*Detecting Defects in Object Oriented Designs Using Design Metrics
#@Munkhnasan Choinzon,Yoshikazu Ueda
#t2006
#cProceeding of the 2006 conference on Knowledge-Based Software Engineering: Proceedings of the Seventh Joint Conference on Knowledge-Based Software Engineering
#index140486
#%78479
#%89755
#%121319
#%438866
#%584558
#%605973
#%592651
#%281933
#%442265
#%621109
#%606837
#%219298
#%239193
#!In order to decrease the cost, it is recommended to detect defects in the phase they occur. This paper presents a metrics-based approach to detect defects in OO designs. We first identify a list of OO design defects which have a significant impact on the design quality based on the violations of many design guidelines and best practices expressed by experts. Then, we define the metrics for automatically detecting each of these defects. Several number of well-known metrics are used. For some defects, however, there are no suitable design metrics. Therefore, we define new design metrics to detect these defects. Moreover, thresholds to judge whether a metrics value indicates a critical situation, or not are defined for each of the metrics. By defining metrics on each design defect, many design rules and heuristics, and flaws which are described qualitatively can be evaluated quantitatively. On the other hand, we will show that intended application of metrics becomes clear.


#*Transient stability of an adaptive sliding-mode load torque observer
#@Wirote Sangtungtong,Sarawut Sujitjorn
#t2008
#cProceedings of the 8th conference on Systems theory and scientific computation
#index60117
#!This article reveals the detailed analysis of the stability of an adaptive sliding-mode load torque observer. Using the Lyapunov's direct method, the stability can be concluded only in some time intervals during transient state. Using the LaSalle's invariance principle, it can be concluded that by the end of the transient state the observer definitely enters the stable steady-state.


#*Keynote panel
#@Doug Maughan George Hull,Salvatore Stolfo,Robert Stratton
#t2009
#cProceedings of the 5th Annual Workshop on Cyber Security and Information Intelligence Research: Cyber Security and Information Intelligence Challenges and Strategies
#index126441


#*Microsoft Office: Project 2002 and 2003- W/CD
#@
#t2005
#c
#index13321


#*In search of query patterns: a case study of a university OPAC
#@Eng Pwey Lau,Dion Hoe-Lian Goh
#t2006
#cInformation Processing and Management: an International Journal
#index27613
#%332625
#%601703
#%325833
#%289767
#%604052
#%244411
#%331525
#%323801
#%587490
#!A transaction log analysis of the Nanyang Technological University (NTU) OPAC was conducted to identify query and search failure patterns with the goal of identifying areas of improvement for the system. One semester's worth of OPAC transaction logs were obtained and from these, 641, 991 queries were extracted and used for this work. Issues investigated included query length, frequency and type of search options and Boolean operators used as well as their relationships with search failure. Among other findings, results indicate that a majority of the queries were simple, with short query lengths and a low usage of Boolean operators. Failure analysis revealed that on average, users had an almost equal chance of obtaining no records or at least one record to a submitted query. We propose enhancements and suggest future areas of work to improve the users' search experience with the NTU OPAC.


#*Surface Segmentation through Concentrated Curvature
#@Mohammed Mostefa Mesmoudi,Emanuele Danovaro,Leila De Floriani,Umberto Port
#t2007
#cProceedings of the 14th International Conference on Image Analysis and Processing
#index352169
#!Curvature is one of the most relevant notions that links the metric properties of a surface to its geometry and to its topology (Gauss-Bonnet theorem). In the literature, a variety of approaches exist to compute curvatures in the discrete case. Several techniques are computationally intensive or suffer from convergence problems. In this paper, we discuss the notion of concentrated curvature, introduced by Troyanov [24]. We discuss properties of this curvature and compare with a widely-used technique that estimates the Gaussian curvatures on a triangulated surface. We apply our STD method [13] for terrain segmentation to segment a surface by using different curvature approaches and we illustrate our comparisons through examples.


#*A low-power CMOS thyristor based delay element with programmability extensions
#@Colin J. Ihrig,Gerold Joseph Dhanabalan,Alex K. Jones
#t2009
#cProceedings of the 19th ACM Great Lakes symposium on VLSI
#index56653
#!This paper presents a low-power CMOS thyristor based delay element for inclusion in standard cell ASIC libraries, and a reconfigurable delay element designed for reconfigurable devices. Our design is based on a basic delay element, which serves as a buffer which has been specially designed to have a fixed propagation delay. We present leakage power optimizations, which when applied to the circuit reduces the on-state leakage power consumption by more than 99%, while reducing the off-state leakage power by roughly 96%. We have created delay elements with delay lengths of 4, 5, 7, 9, 11, and 17 ns for inclusion in a standard cell library targeting the IBM 0.13 μm technology. The delay element is then further extended to introduce a programmability feature which allows the delay to be varied. Two reconfigurable delay elements are then added to the delay element standard cell library. The first can be configured for delays of 4, 5, or 7 ns, while the second can be programmed for delays of 9, 11, or 17 ns. Finally, potential uses of the circuits in application specific, as well as reconfigurable systems are explored.


#*Military applications: M&S support to future combat systems
#@
#t2006
#cProceedings of the 38th conference on Winter simulation
#index16008


#*Measuring Anonymous Systems with the Probabilistic Applied Pi Calculus
#@Xiaojuan Cai,Yonggen Gu
#t2009
#cProceedings of the International Conference on Computational Science and Its Applications: Part II
#index506768
#!In [1] a formulation of anonymity based on metrics of Probabilistic Applied Pi processes was proposed. As an extension to [1], we consider to neglect all the internal interactions in the definition of metric. In other words, the new metric between two processes turns out to be 0 when these two processes are weakly bisimilar (strongly bisimilar in [1]). Upon metric, the degree of probabilistic anonymity is modelled for general anonymous systems where there are no explicit senders or receivers. In addition, we devise an algorithm to calculate the metric between two finite processes. As a running example, we analyze the classical anonymous protocol -- Probabilistic Dining Cryptographer Problem -- to illustrate the effectiveness of our approach.


#*Fitting a Step Function to a Point Set
#@Hervé Fournier,Antoine Vigneron
#t2008
#cProceedings of the 16th annual European symposium on Algorithms
#index396243
#!We consider the problem of fitting a step function to a set of points. More precisely, given an integer k and a set P of n points in the plane, our goal is to find a step function f with k steps that minimizes the maximum vertical distance between f and all the points in P. We first give an optimal ¿(n logn) algorithm for the general case. In the special case where the points in P are given in sorted order according to their x-coordinates, we give an optimal ¿(n) time algorithm. Then, we show how to solve the weighted version of this problem in time O(n log4 n). Finally, we give an O(n h 2 logh) algorithm for the case where h outliers are allowed, and the input is sorted. The running time of all our algorithms is independent of k.


#*Osteochondral defect repair using a novel tissue engineering approach: Sheep model study
#@R. M. Pilliar,R. A. Kandel,M. D. Grynpas,P. Zalzal,M. Hurtig
#t2007
#cTechnology and Health Care
#index46268
#!Porous calcium polyphosphate (CPP) constructs of desired density were formed by sintering CPP powders. Articular cartilage was formed on these constructs in cell culture over an 8-week period with the resulting cartilage layer forming on the CPP surface and within the near surface pores thereby mechanically anchoring the cartilage to the CPP. The biphasic constructs so formed were implanted in sheep femoral condyle sites and left for short-term periods (3 to 4 months) or longer periods (9 months). Implant fixation within the condyle sites was achieved through bone ingrowth into the inferior CPP pores. The properties and characteristics of the as-in vitro-formed, short- and long-term implanted tissues were compared. The results indicated that such implants might be useful for repair of small subchondral defects.


#*FairTrust: Toward secure and high performance P2P networks
#@Haiying (Helen) Shen,Yingwu Zhu
#t2007
#cProceedings of the 13th International Conference on Parallel and Distributed Systems - Volume 01
#index44006
#!Peer-to-Peer (P2P) networks are becoming increasingly popular and are an exciting new class of innovative, internet-based resource sharing systems. In a P2P network, a reputation system is essential to evaluate the trustworthiness of participating peers and to combat the selfish, dishonest, and malicious peer behaviors. The system collects locally-generated peer feedbacks and aggregates them to yield the global reputation values to represent peer trustworthiness. Reputation system guides peers in choosing a server for services/resources. Most of the approaches for peers to exploit reputation metrics are to select the one with the highest reputation value as a providing server. However, it may lead to unexpectedly low efficiency for high-reputed peers, and prevents P2P networks from taking full advantage of all resources for high performance. Other approaches restrict a peer to select a server in the same or lower reputation values. However, these approaches prevent P2P networks from achieving their goal of widely resource sharing and service exchanges. In this paper, we introduce a trust-based fairness-oriented server selection policy, FairTrust, for a peer to choose anther peer to interact. FairTrust takes into account both reputation and capacity factors in server selection. It helps to create a secure P2P communication environment, and meanwhile to take full advantage of system resources for high performance by fair load distribution. Simulation results show the superiority of the FairTrust policy in achieving both high security and high performance in P2P networks in comparison with other related policies.


#*Dual watermark for image tamper detection and recovery
#@Tien-You Lee,Shinfeng D. Lin
#t2008
#cPattern Recognition
#index48916
#%595756
#%101027
#!An effective dual watermark scheme for image tamper detection and recovery is proposed in this paper. In our algorithm, each block in the image contains watermark of other two blocks. That is to say, there are two copies of watermark for each non-overlapping block in the image. Therefore, we maintain two copies of watermark of the whole image and provide second chance for block recovery in case one copy is destroyed. A secret key, which is transmitted along with the watermarked image, and a public chaotic mixing algorithm are used to extract the watermark for tamper recovery. By using our algorithm, a 90% tampered image can be recovered to a dim yet still recognizable condition (PSNR ~20dB). Experimental results demonstrate that our algorithm is superior to the compared techniques, especially when the tampered area is large.


#*Fuzzy Neural Networks and Genetic Algorithms for Medical Images Interpretation
#@N. Benamrane,A. Aribi L. Kraoula
#t2006
#cProceedings of the conference on Geometric Modeling and Imaging: New Trends
#index32586
#!In this paper, we propose an approach for detection and specification of anomalies present in medical images. The idea is to combine three metaphors: Neural Networks, Fuzzy Logic and Genetic Algorithms in a hybrid system. The Neural Networks and Fuzzy Logic metaphors are coupled in one system called Fuzzy Neural Networks. The Genetic Algorithm adds to this hybridizing the property of total research like an initialization of the Fuzzy Neural Networks training algorithm witch is based on an adapted version of the back propagation algorithm. After applying the growing region algorithm to extract regions, the Fuzzy Neural Network detect the suspect regions, which are interpreted by the Fuzzy Neural Network of specification. Some of experimental results on brain images show the feasibility of the proposed approach


#*Haptic conviction widgets
#@Gerry Chu,Tomer Moscovich,Ravin Balakrishnan
#t2009
#cProceedings of Graphics Interface 2009
#index130674
#%85598
#%594358
#%429341
#%324221
#%617260
#%611017
#!We introduce a haptic mousewheel as a platform for design exploration of haptic conviction widgets. Conviction is how strongly one wants to do something, or how strongly one desires a parameter to be as it is. Using the haptic mousewheel, the widgets allow users to communicate conviction using force, where greater conviction requires greater force. These widgets include buttons that take varying amounts of force to click, a trash can that requires overcoming force to delete files, an instant message client that requires more force to communicate a stronger emotion, and widgets that allow parameters to be locked using force.


#*Ursa minor: versatile cluster-based storage
#@Michael Abd-El-Malek,William V. Courtright, II,Chuck Cranor,Gregory R. Ganger,James Hendricks,Andrew J. Klosterman,Michael Mesnier,Manish Prasad,Brandon Salmon,Raja R. Sambasivan,Shafeeq Sinnamohideen,John D. Strunk,Eno Thereska,Matthew Wachs,Jay J. Wylie
#t2005
#cProceedings of the 4th conference on USENIX Conference on File and Storage Technologies - Volume 4
#index422237
#%320284
#%591556
#%567872
#%435440
#%450444
#%469580
#%486786
#%605241
#%444385
#!No single encoding scheme or fault model is optimal for all data. A versatile storage system allows them to be matched to access patterns, reliability requirements, and cost goals on a per-data item basis. Ursa Minor is a cluster-based storage system that allows data-specific selection of, and on-line changes to, encoding schemes and fault models. Thus, different data types can share a scalable storage infrastructure and still enjoy specialized choices, rather than suffering from "one size fits all." Experiments with Ursa Minor show performance benefits of 2-3× when using specialized choices as opposed to a single, more general, configuration. Experiments also show that a single cluster supporting multiple workloads simultaneously is much more efficient when the choices are specialized for each distribution rather than forced to use a "one size fits all" configuration. When using the specialized distributions, aggregate cluster throughput nearly doubled.


#*Mining Molecular Structure Data for the Patterns of Interactions Between Protein and RNA
#@Kyungsook Han,Chirag Nepal
#t2007
#cProceedings of the 7th international conference on Computational Science, Part I: ICCS 2007
#index396822
#!Mining useful information from a large amount of biological data is becoming important, but most data mining research in bioinformatics is limited to molecular sequence data. We have developed a set of algorithms for analyzing hydrogen bond and van der Waals interactions between protein and RNA. Analysis of the most representative set of protein-RNA complexes revealed several interesting observations: (1) in both hydrogen bond and van der Waals interactions, arginine has the highest interaction propensity, whereas cytosine has the lowest interaction propensity; (2) side chain contacts are more frequent than main chain contacts in amino acids, whereas backbone contacts are more frequent than base contacts in nucleotides; (3) amino acids, in which side chain contacts are dominant, reveal more diverse interaction propensities than nucleotides; and (4) valine rarely binds to any nucleotide. The interaction patterns found in this study should prove useful for determining binding sites in protein-RNA complexes.


#*Semantic Grid Services for Video Analysis
#@Gayathri Nadarajan,Yun-Heh Chen-Burger,James Malone
#t2006
#cProceedings of the 2006 IEEE/WIC/ACM international conference on Web Intelligence and Intelligent Agent Technology
#index26549
#!Employing the power of Semantic Grid services into pervasive problem domains such as video analysis would allow for more effective distributed processing. A vast amount of ecological data from the EcoGrid of varying qualities and features will need to be analysed efficiently. As manual processing by humans can be time and labour intensive, video and image processing tools can go some way to addressing such problems since they are computationally fast. However, most video analyses that utilise a combination of these tools are still done manually. We propose a semantic-based hybrid workflow composition method that strives to provide automation to speed up this process. The main components of this framework are presented, along with the illustration of a scenario where these components act as Semantic Grid services for EcoGrid video analysis.


#*Using PVsolve to Analyze and Locate Positions of Parallel Vectors
#@Allen Van Gelder,Alex Pang
#t2009
#cIEEE Transactions on Visualization and Computer Graphics
#index129540
#!A new method for finding the locus of parallel vectors is presented, called PVsolve. A parallel-vector operator has been proposed as a visualization primitive, as several features can be expressed as the locus of points where two vector fields are parallel. Several applications of the idea have been reported, so accurate and efficient location of such points is an important problem. Previously published methods derive a tangent direction under the assumption that the two vector fields are parallel at the current point in space, then extend in that direction to a new point. PVsolve includes additional terms to allow for the fact that the two vector fields may not be parallel at the current point, and uses a root-finding approach. Mathematical analysis sheds new light on the feature flow field technique (FFF) as well. The root-finding property allows PVsolve to use larger step sizes for tracing parallel-vector curves, compared to previous methods, and does not rely on sophisticated differential equation techniques for accuracy. Experiments are reported on fluid flow simulations, comparing FFF and PVsolve.


#*Building and Running Application Codes on the ARL Linux Networx Cluster (JVN)
#@George Petit
#t2006
#cProceedings of the HPCMP Users Group Conference
#index422056
#!Porting, building and running application codes in the high-performance Linux cluster environment are different than the traditional high-performance computing environment with which many users are familiar. There are multiple compiling environments to choose from, along with their associated MPICH environments and optimized scientific libraries. Determining which of these environments is best suited to a user's application is not always apparent, as is defining the user's environment to properly access the chosen compiler and libraries during the build process. After successfully building an application, creating LSF batch run scripts that will successfully and efficiently run these newly built applications to solve user-defined problems has its own unique requirements inherent to the Linux environment. The objective of this paper is to provide the information necessary for new users to the Linux cluster to determine the most appropriate compiling environment for their application, as well as the means to access the compiler and associated libraries to successfully build and, if necessary, debug the desired application. Usage of the LSF batch system to submit batch jobs that will successfully and efficiently run on Linux cluster compute nodes will also be addressed. A discussion of each compiler's characteristics will provide a basis for users to determine which compiling system is most appropriate for their application. An introduction to the use of software "modules" will provide a way for users to easily tailor their environment to use the desired compiling environment for code development/building. Finally, LSF batch script examples will be used to demonstrate correct script usage. By better understanding the ARL Linux Networx cluster environment, new users will be able to become effective and productive users of the system more quickly. By minimizing the time required by users to port their codes onto a new platform and begin production jobs, the overall efficacy of the cluster's capability as a research tool is enhanced thereby increasing its overall value to the program.


#*An improved energy landscape paving algorithm for the problem of packing circles into a larger containing circle
#@Jingfa Liu,Shengjun Xue,Zhaoxia Liu,Danhua Xu
#t2009
#cComputers and Industrial Engineering
#index497793
#%98231
#%103545
#%250188
#!The problem of packing circles into a larger containing circle is a kind of NP-hard problem. It is of high theoretical and practical value. Lacking powerful optimization method is the key obstacle to solving this problem. The energy landscape paving (ELP) method is a class of heuristic global optimization algorithm and a generation of Monte Carlo method. By incorporating new configuration update mechanism into ELP method, an improved energy landscape paving (ELP+) algorithm is put forward. The computational results, on two sets of instances taken from the literature, show the effectiveness of the proposed algorithm.


#*Tree amalgamation of graphs and tessellations of the Cantor sphere
#@Bojan Mohar
#t2006
#cJournal of Combinatorial Theory Series B
#index25272
#%159896
#!A general method is described which gives rise to highly symmetric tessellations of the Cantor sphere, i.e., the 2-sphere with the Cantor set removed and endowed with the hyperbolic geometry with constant negative curvature. These tessellations correspond to almost vertex-transitive planar graphs with infinitely many ends. Their isometry groups have infinitely many ends and are free products with amalgamation of other planar groups, possibly one or two-ended or finite. It is conjectured that all vertex-transitive tessellations of the Cantor sphere can be obtained in this way.Although our amalgamation construction is rather simple, it gives rise to some extraordinary examples with properties that are far beyond expected. For example, for every integer k, there exists a k-connected vertex-transitive planar graph such that each vertex of this graph lies on at least k infinite faces. These examples disprove a conjecture of Bonnington and Watkins that there are no 5-connected vertex-transitive planargraphs with infinite faces. This also disproves another conjecture that in a 4-connected vertex-transitive planar graph each vertex lies on the boundary of at most one infinite face. Further examples give rise to counterexamples of some other conjectures of similar flavor.


#*The Challenge at the Interface
#@
#t2008
#cinteractions
#index45666


#*Traffic adaptive active period control with adaptive backoff window for cluster-based IEEE 802.15.4 wireless sensor networks
#@Kazuo Mori,Katsuhiro Naito,Hideo Kobayashi
#t2009
#cProceedings of the 16th international conference on Telecommunications
#index354839
#%242710
#!This paper proposes an adaptive 2-level active period control method with adaptive backoff window based on traffic load in each cluster for cluster-based wireless sensor networks (WSNs) employing IEEE 802.15.4 medium access control (MAC) protocol under temporal and geographical non-uniform traffic distribution. The proposed method consists of three elements: cluster level active period control, network level active period control, and adaptive backoff window control. In the cluster level control, cluster heads autonomously control their active period length in the superframe defined by a personal area network (PAN) coordinator. The PAN coordinator manages the superframe structure for the whole network in the network level control. In the adaptive backoff window control, the backoff window size is determined according to the length of current active period. The results evaluated by computer simulation show that the proposed method can improve the energy efficiency for the cluster-based WSNs with geographical non-uniform traffic distribution in addition to the improvement of the transmission performance.


#*Dynamic Community Entertainment Services Composition on Next Generation Mobile Network IP Multimedia Subsystem
#@Yasuhiro Araki,Akio Yamamoto,Michael Sweeney
#t2007
#cProceedings of the 2007 International Symposium on Applications and the Internet Workshops
#index419528
#!With the advent of Web services and dynamic service composition, flexible and adaptable complex services may be realized. Assuming that such services have been provided with all the necessary service orchestration and end user information, simple services may be enhanced with contextual information, such as location, presence and user preferences, to provide a more tailored experience for the end user. Mobile next generation service environments include many functional components suitable for the provision of contextual data with which to build tailored and complex services for subscribers. Specifically, the IP Multimedia Subsystem (IMS) defined by 3rd Generation Partnership Project (3GPP) and its enablers provide an interesting environment for researching techniques for the composition and delivery of complex context-specific personalized and community services to mobile users. In this paper we discuss our ongoing research into dynamic service composition for mobile communities. As such, we investigate community-based mobile entertainment services, their provisioning requirements, enablers, and dynamic composition of group-specific real-time next generation packet mobile services. To the end, we have developed a service platform called the Group Entertainment Service platform (GESP) for IMS that we describe in detail.


#*Open Educational Topic Maps: A Text-Oriented Perspective
#@Lars Johnsen
#t2008
#cScaling Topic Maps: Third International Conference on Topic Maps Research and Applications, TMRA 2007 Leipzig, Germany, October 11-12, 2007 Revised Selected Papers
#index397510
#!This article makes the case for a text-oriented approach to the creation and presentation of open Topic Maps based information architectures for e-learning. More specifically, it argues that importance should be attached to the communicative aspects of such architectures, in particular consistency, cohesion and coherence. The article further suggests that one way of keeping this aim in focus is to work with standardized text modules as communication vehicles. To exemplify more concretely the role that standardized text might play, two specific sets of tools for modular text production are briefly discussed, namely CNXML and Structured Writing. Finally, it is demonstrated how a descriptive framework such as Rhetorical Structure Theory may be used to support the analysis, design and creation of communicative structures in open educational Topic Maps architectures.


#*On the computational content of the Lawson topology
#@Frédéric De Jaeger,Martín Escardó,Gabriele Santini
#t2006
#cTheoretical Computer Science
#index22491
#%296468
#%299580
#%374130
#%183108
#%227096
#%471601
#%317271
#!An element of an effectively given domain is computable iff its basic Scott open neighbourhoods are recursively enumerable. We thus refer to computable elements as Scott computable and define an element to be Lawson computable if its basic Lawson open neighbourhoods are recursively enumerable. Since the Lawson topology is finer than the Scott topology, a stronger notion of computability is obtained. For example, in the powerset of the natural numbers with its standard effective presentation, an element is Scott computable iff it is a recursively enumerable set, and it is Lawson computable iff it is a recursive set. Among other examples, we consider the upper powerdomain of Euclidean space, for which we prove that Scott and Lawson computability coincide with two notions of computability for compact sets recently proposed by Brattka and Weihrauch in the framework of type-two recursion theory.


#*A Truthful Two-Stage Mechanism for Eliciting Probabilistic Estimates with Unknown Costs
#@Athanasios Papakonstantinou,Alex Rogers,Enrico H. Gerding,Nicholas R. Jennings
#t2008
#cProceeding of the 2008 conference on ECAI 2008: 18th European Conference on Artificial Intelligence
#index134208
#%32708
#!This paper reports on the design of a novel two-stage mechanism, based on strictly proper scoring rules, that motivates selfish rational agents to make a costly probabilistic estimate or forecast of a specified precision and report it truthfully to a centre. Our mechanism is applied in a setting where the centre is faced with multiple agents, and has no knowledge about their costs. Thus, in the first stage of the mechanism, the centre uses a reverse second price auction to allocate the estimation task to the agent who reveals the lowest cost. While, in the second stage, the centre issues a payment based on a strictly proper scoring rule. When taken together, the two stages motivate agents to reveal their true costs, and then to truthfully reveal their estimate. We prove that this mechanism is incentive compatible and individually rational, and then present empirical results comparing the performance of the well known quadratic, spherical and logarithmic scoring rules. We show that the quadratic and the logarithmic rules result in the centre making the highest and the lowest expected payment to agents respectively. At the same time, however, the payments of the latter rule are unbounded, and thus the spherical rule proves to be the best candidate in this setting.


#*Access 2002 (La Biblia De)
#@Celeste Robinson
#t2005
#c
#index12767


#*IMS Crash Course, 1 edition
#@Steven Shepard
#t2006
#c
#index9716
#!An Introduction to This Innovative and Revolutionary Next-Generation Communication Solution The IP Multimedia Subsystem (IMS) is a powerful, emerging technology that will change the way we live, work, and communicate. Through convergence of fixed and wireless networks, IMS delivers seamless roaming to multimedia devices regardless of location or access modality. This much-needed resource gives you an easy-to-understand overview of the development, evolving standards, and excitingly imminent future of IMS. Expand Your Understanding of IMS Written by a renowned professional author and educator with 25 years of experience in the telecommunications industry, IMS Crash Course gives you a broad perspective on why IMS evolved, how the technology works, its system requirements, and potential regulatory issues—all in one convenient package. If you are looking to make sense of this breakthrough technology, its benefits, and its real-world implementations, read this book first. Full coverage of IMS including: An early history of IMS Converging wireless and wireline Network, software, and signaling requirements IMS regulatory issues IMS’s future


#*Laguerre polynomials as Jensen polynomials of Laguerre-Pólya entire functions
#@Dimitar K. Dimitrov,Youssèf Ben Cheikh
#t2009
#cJournal of Computational and Applied Mathematics
#index500217
#%453803
#!We prove that the only Jensen polynomials associated with an entire function in the Laguerre-Polya class that are orthogonal are the Laguerre polynomials.


#*Real-Time Task Assignment in Rechargeable Multiprocessor Systems
#@Jian Lin,Albert M. K. Cheng
#t2008
#cProceedings of the 2008 14th IEEE International Conference on Embedded and Real-Time Computing Systems and Applications
#index393528
#!This paper introduces the scheduling of frame-based real-time tasks in partitioning schemes for multiprocessor systems powered by rechargeable batteries. In frame-based real-time systems, a set of tasks must execute in a frame, and the whole frame is repeated. This system model is widely used in real-time communication, real-time imaging and a lot of other real-time/embedded systems. Nowadays, many of these systems are powered by rechargeable batteries. Scheduling real-time tasks on these rechargeable systems is an important yet largely ignored issue. The problem for uniprocessor systems had been studied in [1], in which an algorithm of complexity O(N) was proposed for determining the feasibility of the task set. However, it poses a challenge when doing so in a rechargeable multiprocessor system considering different characteristics of the batteries. In this paper, we first show this problem to be NP-Hard, and then propose efficient algorithms to overcome it. The simulation results have shown that our algorithms exhibit very good behaviors and they can be considered as solutions to the problem.


#*Engineering grid applications and middleware for high performance
#@Umar Farooq,Shikharesh Majumdar,Eric W. Parsons
#t2007
#cProceedings of the 6th international workshop on Software and performance
#index11484
#%114511
#%439764
#%309259
#!Meeting QoS objectives of applications while maintaining high system utilization is a challenging task in multi-institutional Grids. In this paper, we effectively engineer Grid applications and resource management middleware for achieving user satisfaction and high resource utilizations. The paper presents a complete framework based on advance reservations (ARs) for resource management in Grids. The framework is capable of providing QoS guarantees to applications while maintaining high resource utilizations. The paper focuses on the scheduling component of the framework and presents a novel heuristic-based algorithm, Grid Scheduling with Deadlines (GSD), for an NP-Complete problem of scheduling ARs with laxities on a shared resource. GSD can be configured with the help of pluggable strategies to adapt to various workload conditions and needs of the system. The paper studies with the aid of an extensive set of experiments the effect of various workload and system parameters on system performance. It is not always possible to accurately predict the runtimes of the jobs. The paper discusses the impact of error in user-estimated runtimes on system performance and investigates strategies to avoid substandard performance resulting from such inaccuracies. Experimental results demonstrate the efficacy of our methodology.


#*Revenue Driven Resource Allocation: Funding Authority, Incentives, and New Product Development Portfolio Management
#@Raul O. Chao,Stylianos Kavadias,Cheryl Gaimon
#t2009
#cManagement Science
#index505638
#!The first step in transforming strategy from a hopeful statement about the future into an operational reality is to allocate resources to innovation and new product development (NPD) programs in a portfolio. Resource allocation and NPD portfolio decisions often span multiple levels of the organization's hierarchy, leading to questions about how much authority to bestow on managers and how to structure incentives for NPD. In this study, we explore how funding authority and incentives affect a manager's allocation of resources between existing product improvement (relatively incremental projects) and new product development (more radical projects). Funding may be either fixed or variable depending on the extent to which the manager has the authority to use revenue derived from existing product sales to fund NPD efforts. We find that the use of variable funding drives higher effort toward improving existing products and developing new products. However, variable funding has a subtle side effect: it induces the manager to focus on existing product improvement to a greater degree than new product development, and the relative balance in the NPD portfolio shifts toward incremental innovation. In addition, we highlight a substitution effect between explicit incentives (compensation parameters) and implicit incentives (career concerns). Explicit incentives are reduced as career concerns become more salient.


#*Models for Patch Based Image Restoration
#@Mithun Das Gupta,Shyamsundar Rajaram,Nemanja Petrovic,Thomas S. Huang
#t2006
#cProceedings of the 2006 Conference on Computer Vision and Pattern Recognition Workshop
#index34200
#!In this paper we present a supervised learning approach for object-category specific restoration, recognition and segmentation of images which are blurred using an unknown kernel. The feature of this work is a multi layer graphical model which unifies the low level vision task of restoration, and the high level vision task of recognition in a cooperative framework. Proposed graphical model is an interconnected two layer Markov Random Field. The restoration layer accounts for the compatibility between sharp and blurred patches, and models the association between adjacent patches in the sharp image. The recognition layer encodes the patch location and class. The potentials are represented using non-parametric kernel densities and are learnt from the training data. Inference is performed using nonparametric belief propagation. We propose a similar model for super-resolution from multiple frames, and suggest the use of ordinal regression for sub-pixel shift estimation to address the registration issues. Experiments demonstrate the effectiveness of proposed models for the restoration and recognition of blurred license plate and face images.


#*A Unified Iterative Scheme for Solving Fully Fuzzy Linear System
#@Jing Gao,Qiang Zhang
#t2009
#cProceedings of the 2009 WRI Global Congress on Intelligent Systems - Volume 01
#index494048
#!In this paper, a unified iterative scheme to solve general fully fuzzy linear system (FFLS) in which all parameters are LR fuzzy numbers is discussed. By this iterative scheme, we present Gradient iterative algorithm and Least-squares iterative algorithm for solving non-square FFLS. Also, we test the iterative algorithm and show its effectiveness using a numerical example.


#*Why noise and fluctuations can make life simpler
#@Ferdinand Peper
#t2008
#cProceedings of the 3rd International Conference on Bio-Inspired Models of Network, Information and Computing Sytems
#index56696
#!Noise and Fluctuations are usually considered obstacles in the operation of electronic and mechanical devices, and most strategies to deal with them aim to maximize the Signal/Noise ratio. This presentation gives a short overview of systems that follow a different scenario: such systems exploit noise and fluctuations in order to improve their efficiency of operation. A key element in these systems is the ability of noise and fluctuation to work as a stochastic search process that is able to explore a solution space and settle on a suitable solution. The attraction of this strategy is that it simplifies the mechanisms required to accomplish a task. This presentation reviews an example in computation and speculates about the likely use of this strategy in biological organisms.


#*Towards Intelligent Interaction in Classroom
#@Pengfei Xu,Guanghui Han,Wen Li,Zhongke Wu,Mingquan Zhou
#t2009
#cProceedings of the 5th International Conference on Universal Access in Human-Computer Interaction. Part III: Applications and Services
#index507902
#!In classroom environments, complex and valuable communication takes place. To augment and record these communications effectively, various computer-based systems were deigned in the past decade. In fact, with advancements of multimedia technology and interaction technologies, research in this field has already brought some of these systems into regular usage. The main contribution of this paper is to give an overview of the human-computer interaction technologies and approaches used in intelligent classroom systems. Current challenges in intelligent interaction in classroom are also discussed. Improving these interaction techniques has a significant effect on the overall system performance and user experience.


#*Detection and Grammaticality Judgment of Forms in a Language Education System Oriented for Focus on Form
#@Makoto Kondo,Takafumi Shiratori,Naoki Minai,Satoru Kogure,Tatsuhiro Konishi,Yukihiro Itoh
#t2005
#cProceeding of the 2005 conference on Towards Sustainable and Scalable Educational Innovations Informed by the Learning Sciences: Sharing Good Practices of Research, Experimentation and Innovation
#index128026
#!This paper describes how to develop a language education system oriented for a pedagogical approach called focus on form (FonF). FonF aims at improving skills to produce grammatically correct sentences. The approach has attracted much attention in the field of second language education because it could overcome a potential problem of another pervasively adopted approach called communicative approach (CA). The CA puts the highest priority on cultivating communicative fluency and grammatical correctness is considered less important than conveying intention. As a result, there is a risk that learners would miss a chance to correct their misunderstanding of grammatical rules in target languages. If FonF instruction is effectively incorporated into a language education system oriented for the CA, it should overcome the problem by giving appropriate grammatical instruction while learners are engaging in conversation practice based on the CA. In this study, we selected 145 linguistic forms to teach based on the FonF approach and implemented functions necessary for FonF instruction: a function to detect the linguistic forms in input sentences, and a function to judge whether detected forms are used correctly from the viewpoints of morphosyntactic correctness and semantic correctness.


#*Implementation of ebXML Message Transaction supported on a Security and Reliability for Effective e-Business
#@Chang-ryul Jung,B. N. Sudhakar,Sung-keun Lee,Jin-gwang Koh
#t2007
#cProceedings of the 5th ACIS International Conference on Software Engineering Research, Management & Applications
#index353815
#!..In this paper, we propose the development strategy of message transaction system in electronic business to business system with consideration of security. B2B must be designed to transfer electronic data between business and business in completely secured and reliable form. For the purpose of secured and reliable transaction of electronic data, we propose the complete framework . Also, we provide message system for communication and transaction for E-business, and provide message test set through the development strategy for interoperability of message. The message test set is a data class modeling of ebXML MSH(message service handler) which supports message test set to ebXML message transaction of e-business. Finally, we implemented the message processing system through SMTP Mail transaction into ebMSH for the ebXML Message Test-Set for message service transaction after database relationship.


#*Ball Position and Motion Reconstruction from Blur in a Single Perspective Image
#@Giacomo Boracchi,Vincenzo Caglioti,Alessandro Giusti
#t2007
#cProceedings of the 14th International Conference on Image Analysis and Processing
#index353540
#!We consider the problem of localizing a moving ball from a single calibrated perspective image; after showing that ordinary algorithms fail in analyzing motion blurred scenes, we describe a theoretically-sound model for the blurred image of a ball. Then, we present an algorithm capable of recovering both the ball 3D position and its velocity. The algorithm is experimentally validated both on real and synthetic images.


#*An Authentication Scheme Using Non-Commutative Semigroups
#@M. M. Chowdhury
#t2007
#cProceedings of the Third International Symposium on Information Assurance and Security
#index339851
#!We give a new two-pass authentication scheme, which is a generalisation of an authentication scheme of Sibert- Dehornoy-Girault based on the Diffie-Hellman conjugacy problem. Compared to the above scheme, for some parameters it is more efficient with respect to multiplications. We sketch a proof that our authentication scheme is secure.


#*Package level interconnect options
#@J. Balachandran,S. Brebels,G. Carchon,T. Webers,W. De Raedt,B. Nauwelaers,E. Beyne
#t2005
#cProceedings of the 2005 international workshop on System level interconnect prediction
#index101989
#%313384
#%357748
#%447900
#%311988
#%308570
#!Scaling enhances intrinsic transistor performance and degrades interconnects. As the technology steps into nanometer era, global interconnects are becoming bottleneck for overall chip performance. In this paper, we show package level interconnects are an effective alternative for on-chip global wiring. These interconnects behave as LC transmission lines and can be exploited for their near speed of light transmission and low attenuation characteristics. We compare performance - bandwidth, bandwidth density, latency and power consumption - of the package level transmission lines with conventional on-chip global interconnects for different ITRS technology nodes. Based on these results, we show package level interconnects are well suited for power demanding low latency applications and we analyze different interconnect options like memory buses, long inter tile interconnects, clock and power distribution.


#*Implementing Atomic Section by Using Hybrid Concurrent Control
#@Lei Zhao,Yu Zhang
#t2007
#cProceedings of the 2007 IFIP International Conference on Network and Parallel Computing Workshops
#index348045
#!Atomic section is an important language feather in multithread synchronizing. So far, it can only be implemented by using pessimistic or optimistic concurrent control singly. This paper introduces a flexible hybrid concurrent control system which could harmonize the two modes of concurrent control. Accordingly, a new atomic section is proposed as language level support to open an interface for both manual and compiler-assisted optimization.


#*On Random Ordering Constraints
#@Andreas Goerdt
#t2009
#cProceedings of the Fourth International Computer Science Symposium in Russia on Computer Science - Theory and Applications
#index502877
#!Ordering constraints are analogous to instances of the satisfiability problem in conjunctive normalform, but instead of a boolean assignment we consider a linear ordering of the variables in question. A clause becomes true given a linear ordering iff the relative ordering of its variables obeys the constraint. The naturally arising satisfiability problems are NP-complete for many types of constraints.The present paper seems to be one of the first looking at random ordering constraints. Experimental evidence suggests threshold phenomena as in the case of random k-SAT instances. We prove first that random instances of the cyclic ordering and betweenness constraint have a sharp threshold for unsatisfiability. Second, random instances of the cyclic ordering constraint are satisfiable with high probability if the number of clauses is $\le 1 \times\,\, \sharp$variables.


#*Evolution of a Spherical Universe in a Short Range Collapse/Generation Interval
#@Ivana Bochicchio,Ettore Laserra
#t2007
#cProceedings of the 7th international conference on Computational Science, Part II
#index403417
#!We study the final/initial behavior of a dust Universe with spatial spherical symmetry. This study is done in proximity of the collapse/generation times by an expansion in fractional Puiseux series. Even if the evolution of the universe has different behaviours depending on the initial data (in particular on the initial spatial curvature), we show that, in proximity of generation or collapse time, the Universe expands or collapses with the same behavior.


#*Predictive performance modelling of parallel component compositions
#@Lei Zhao,Stephen A. Jarvis
#t2007
#cCluster Computing
#index418369
#%78833
#%157440
#%198254
#%240410
#%312481
#%369485
#%384248
#%592704
#%596954
#!Large-scale scientific computing applications frequently make use of closely-coupled distributed parallel components. The performance of such applications is therefore dependent on the component parts and their interaction at run-time. This paper describes a methodology for predictive performance modelling and evaluation of parallel applications composed of multiple interacting components. In this paper, the fundamental steps and required operations involved in the modelling and evaluation process are identified--including component decomposition, component model combination, M×N communication modelling, dataflow analysis and overall performance evaluation. A case study is presented to illustrate the modelling process and the methodology is verified through experimental analysis.


#*Trust and honour in information-based agency
#@Carles Sierra,John Debenham
#t2006
#cProceedings of the fifth international joint conference on Autonomous agents and multiagent systems
#index25203
#%112537
#%313004
#%91355
#%303474
#!An argumentation based negotiation model is supported by information theory. Argumentative dialogues change the models of agents with respect to ongoing relationships. Trust and Honour are key components. Trust measures expected deviations of behaviour in the execution of commitments. Honour measures the expected integrity of the arguments exchanged. We understand rhetorical moves in dialogues as actions to project the current relationships into the future.


#*A study of identical twins' palmprints for personal verification
#@Adams Wai-Kin Kong,David Zhang,Guangming Lu
#t2006
#cPattern Recognition
#index9071
#%439415
#!Automatic biometric systems based on human characteristics for personal identification have attracted great attention. Their performance highly depends on the distinctive information in the biometrics. Identical twins having the closest genetics-based relationship are expected to have maximum similarity in their biometrics. Classifying identical twins is a challenging problem for some automatic biometric systems. Palmprint has been studied for personal identification for over seven years. Most of the previous research concentrates on algorithm development. In this paper, we systemically examine palmprints from the same DNA for automatic personal identification and to uncover the genetically related palmprint features. The experimental results show that the three principal lines and some portions of weak lines are genetically related features but our palms still contain rich genetically unrelated features for classifying identical twins.


#*DBNet: A Service-Oriented Database Architecture
#@Wee Hyong Tok,Stephane Bressan
#t2006
#cProceedings of the 17th International Conference on Database and Expert Systems Applications
#index22148
#!At the convergence of peer-to-peer (P2P) and service oriented architectures is the idea of effectively and efficiently managing distribution, heterogeneity and autonomy of information sources and services. In this paper, we take the point of view that next generation database management systems (DBMS) should be a federation of distributed, heterogeneous and autonomous components. Such components constitute web database services. We challenge the conventional notions of what constitute a DBMS, and presents the full spectrum of possible DBMSs based on such a Service- Oriented Database Architecture (SODA). We examine the issues and challenges of SODA. Finally, we propose one possible instance of SODA that we call DBNet. In order to illustrate some of the research issues involved, we present query processing and optimization techniques that we have devised for DBNet.


#*Assessing and Scaffolding Collaborative Learning in Online Discussions
#@Erin Shaw
#t2005
#cProceeding of the 2005 conference on Artificial Intelligence in Education: Supporting Learning through Intelligent and Socially Informed Technology
#index142067
#!In this paper we present two computational approaches that can be used characterize and measure online threaded discussions and demonstrate that they can objectively validate student-reported differences in collaborative learning between tutor-scaffolded and non-scaffolded discussion activities. The first approach, thread profiling, is used to characterize user interactions that tend to broaden and deepen discussions, and gives insight into how tutors participate in discussions. The second approach, which uses a natural language discourse processor, is used to compare the rhetoric of tutors and students, and shows that tutors consistently use more attributions, elaborations, and enablements to scaffold discussions. To test these ideas we processed twenty-four online activities, constituting over one thousand message posts, during a course at the British Open University. These computational methods and findings have application in virtual tutoring systems and the automated assessment of discussions.


#*A conservative approximation to compressible two-phase flow models in the stiff mechanical relaxation limit
#@Vincent Deledicque,Miltiadis V. Papalexandris
#t2008
#cJournal of Computational Physics
#index406402
#%76198
#%321822
#!In this article, we present and analyze a conservative approximation to reduced one-pressure one-velocity models for compressible two-phase flows that contain non-conservative products. This approximation is valid when certain material properties of the two phases are considerably different from each other. Although it cannot be applied to arbitrary mixtures, it is applicable to many heterogeneous mixtures of technological interest. Herein, we derive the Rankine-Hugoniot relations and Riemann invariants for the homogeneous part of the proposed model and develop an exact Riemann solver for it. Further, we investigate the structure of the steady two-phase detonation waves, with inert or reactive solid particles, admitted by the proposed model. Comparisons with the corresponding gaseous detonations are also made. Moreover, we derive a lower limit for the propagation speed of steady two-phase detonations in the case of reactive particles. At the limiting case of very dilute mixtures, this minimum speed tends to the Chapman-Jouguet velocity of gaseous detonations. Finally, we report on numerical simulations of the transmission of a purely gaseous detonation to heterogeneous mixtures containing inert or reactive solid particles. The effect of the solid particles on the structure of the resulting two-phase detonation is discussed in detail.


#*Parallel Problem Solving from Nature - PPSN IX: 9th International Conference, Reykjavik, Iceland, September 9-13, 2006, Proceedings (Lecture Notes in Computer Science)
#@Thomas Philip Runarsson,Hans-Georg Beyer,Edmund Burke,Juan J. Merelo-Guervós,L. Darrell Whitley,Xin Yao
#t2006
#c
#index7148


#*Confusion of memory
#@Lawrence S. Moss
#t2008
#cInformation Processing Letters
#index48429
#!It is a truism that for a machine to have a useful access to memory or workspace, it must ''know'' where its input ends and its working memory begins. Most machine models separate input from memory explicitly, in one way or another. We are interested here in computational models which do not separate input from working memory. We study the situation on deterministic single-queue machines working on a two symbol alphabet. We establish a negative result about such machines: they cannot compute the length of their input. This confirms the intuition that such machines are ''unable to tell'' where on the queue the input ends and the memory begins. On the positive side, we note that there are some interesting things that one can do with such queue machines: their halting problem is undecidable, there are self-replicating machines, and there are recognizable languages outside of the control hierarchy.


#*APlace: a general analytic placement framework
#@Andrew B. Kahng,Sherief Reda,Qinke Wang
#t2005
#cProceedings of the 2005 international symposium on Physical design
#index98273
#%577044
#!We streamline and extend APlace, the general analytic placement engine based on ideas of Naylor et al. [7] and described in [3, 4, 5]. Previous work explored the adaptability of APlace to multiple contexts with good quality of results. For example, the framework was extended to traditional wirelength-driven standard-cell placement in [3, 5], achieving good results in placed HPWL and routed final wire-length. The framework was also extended to top-down multilevel placement, congestion-directed placement, mixed-size placement, timing-driven placement, I/O-core co-placement and constraint handling for mixed-signal contexts [3, 4, 5]. In this work, we have modified the implementation of APlace for speed and scalability. Improvements have been made in clustering, legalization and detailed placement strategies, as well as via a distributable solution framework for both global and detailed placement phases.


#*Editorial
#@Tamer &#x00d6;zsu
#t2005
#cThe VLDB Journal &mdash; The International Journal on Very Large Data Bases
#index108820


#*Complex networks in recommendation systems
#@Massimiliano Zanin,Pedro Cano,Javier M. Buldú,Oscar Celma
#t2008
#cProceedings of the 2nd WSEAS International Conference on Computer Engineering and Applications
#index45420
#%317569
#!Complex network theory was boosted in 1967 thanks to the experiment of Milgram: since then, the application of this special kind of graphs has given fruitful results in social science problems, from sexual disease control to music communities identification. When focusing on the problem of recommending items to a user (i.e. a customer of an e-store), the underlying transaction data can be seen as a complex network (specifically, a bipartite network): inside this structure, information about customer tastes is codified and can be of good use for future suggestions.


#*Algorithm for XML Schema Extraction Based on Node Relative Path
#@Hong-Bin Cheng,Xia Sun
#t2009
#cProceedings of the 2009 WASE International Conference on Information Engineering - Volume 02
#index495008
#!Schema extracting for XML is broadly used in the field of data storing, query optimization and heterogeneous data integration. This paper presents a method based on noderelative path for extracting XML Schema. The new approachfinishes extracting schema by scanning XML document onceoverand extracting nodes and relative paths. It can overcomethe defects including circles and Lack of sides. This approach requires lower cost and has more efficiency for the final schema information.


#*Intelligent Data Analysis of Out-of-Hospital Cardiac Arrest
#@Mateja Verlic,Miljenko Krizmaric,Stefek Grmec,Peter Kokol
#t2007
#cProceedings of the Twentieth IEEE International Symposium on Computer-Based Medical Systems
#index429909
#!The rate of survival for the out-of-hospital cardiac arrest (OHCA) is not encouraging. Quick and quality prognosis affects the OHCA outcome. Identification of important factors in prognosis can improve the survival rate. Intelligent data analysis of data obtained in a 4 year study of OHCA outcome in Maribor shows that arrival time of emergency medical team, witnessed arrest, bystander cardiopulmonary resuscitation and especially end-expired CO2 are of great importance for the OHCA outcome.


#*Artificial Intelligence in Theory and Practice: Ifip 19th World Computer Congress, Ti12 Ifip AI 2006 Stream, August 21-24, 2006, Santiago, Chile (IFIP ... Federation for Information Processing)
#@Max Bramer
#t2006
#c
#index12409


#*Guest Editors' Introduction: Interaction of Many-Core Computer Architecture and Operating Systems
#@Sangyeun Cho,Tao Li,Onur Mutlu
#t2008
#cIEEE Micro
#index388336
#!Rapid changes in platform hardware resources with the evolution of many-core architectures will require a fundamental reexamination of mainstream system-software design decisions to support multiple cores and to efficiently manage on-chip hardware resources shared among the multiple cores. In turn, the evolution of many-core processor architectures will be successfully sustained by the new capabilities and features added to the system software, perhaps while requiring substantial support from hardware. The guest editors introduce five articles on the interaction of computer architecture and operating systems for this special issue of IEEE Micro.


#*Innovative Methodology for IR Acquisition
#@G. Acciani,A. Camposarcone,S. Vergura
#t2008
#cProceedings of the international conference on Computational Science and Its Applications, Part II
#index398831
#!This paper propose an innovative and cheap methodology to guarantee a uniform heating of the sample under examination before an IR acquisition. The comparison with the standard heating confirms the goodness of the approach. Moreover, this paper proposes an algorithm for the processing of the IR images, able to detect the weft of the wall. The overall procedure can be also utilized for the defect diagnosis.


#*Multiple Terminologies in a Health Portal: Automatic Indexing and Information Retrieval
#@Stéfan J. Darmoni,Suzanne Pereira,Saoussen Sakji,Tayeb Merabti,Élise Prieur,Michel Joubert,Benoit Thirion
#t2009
#cProceedings of the 12th Conference on Artificial Intelligence in Medicine: Artificial Intelligence in Medicine
#index502443
#!Background: In the specific context of developing quality-controlled health gateways, several standards must be respected (e.g. Dublin Core for metadata element set; thesaurus MeSH as the controlled vocabulary to index Internet resources; HON code to accredit quality of health Web sites). These standards were applied to create the CISMeF Web site (French acronym for Catalog Index of Health Internet resources in French). Objective: In this work, the strategic shift of the CISMeF team is intended to index and retrieve French resources not anymore with a single terminology (MeSH thesaurus) but with the main health terminologies available in French (ICD 10, SNOMED International, CCAM, ATC). Methods Results: Since 2005, we have developed the French Multi-Terminology Indexer (F-MTI), using a multi-terminology approach and mappings between health terminologies. This tool is used for automatic indexing and information retrieval. Conclusion: Since the last quarter of 2008, F-MTI is daily used in the CISMeF production environment and is connected to a French Health Multi-Terminology Server.


#*A self-adaptive query service for pervasive environments
#@Hocine Grine,Thierry Delot,Sylvain Lecomte
#t2008
#cProceedings of the 8th international conference on New technologies in distributed systems
#index399706
#%24011
#%280715
#%464045
#%419661
#!The query service is the key element enabling users to identify and access data or services. If the growth of mobility in recent years makes it necessary to support different types of queries (continuous, location dependent, spatio-temporal, etc.,), it has also resulted in the emergence of new and specifique evaluation and optimization techniques. These different types of queries or techniques are useful and efficient depending on the usage conditions in which the user is located. Today, it is necessary to have, in pervasive environments, a query service that adapts to context changes (application constraints, user preferences, connectivity profile mobility, etc.). In this paper we propose an architecture of a query service dynamically adaptable to the context. This adaptability is managed and controled by an adaptation manager by use of rules. Our solution not only allows the addition and removal of new features dynamically, it also allows the change of used evaluation techniques in order to use the adapted one to the environment.


#*Adaptive Action Selection in Autonomic Software Using Reinforcement Learning
#@Mehdi Amoui,Mazeiar Salehie,Siavash Mirarab,Ladan Tahvildari
#t2008
#cProceedings of the Fourth International Conference on Autonomic and Autonomous Systems
#index41566
#!The planning process in autonomic software aims at selecting an action from a finite set of alternatives for adaptation. This is an abstruse problem due to the fact that software behavior is usually very complex with numerous number of control variables. This research work focuses on proposing a planning process and specifically an action selection technique based on "Reinforcement Learning" (RL). We argue why, how, and when RL can be beneficial for an autonomic software system. The proposed approach is applied to a simulated model of a news web application. Evaluation results show that this approach can learn to select appropriate actions in a highly dynamic environment. Furthermore, we compare this approach with another technique from the literature, and the results suggest that it can achieve similar performance in spite of no expert involvement.


#*A discriminative model for tree-to-tree translation
#@Brooke Cowan,Ivona Kučerová,Michael Collins
#t2006
#cProceedings of the 2006 Conference on Empirical Methods in Natural Language Processing
#index498504
#%582068
#%579587
#!This paper proposes a statistical, tree-to-tree model for producing translations. Two main contributions are as follows: (1) a method for the extraction of syntactic structures with alignment information from a parallel corpus of translations, and (2) use of a discriminative, feature-based model for prediction of these target-language syntactic structures---which we call aligned extended projections, or AEPs. An evaluation of the method on translation from German to English shows similar performance to the phrase-based model of Koehn et al. (2003).


#*Guarding curvilinear art galleries with vertex or point guards
#@Menelaos I. Karavelas,Csaba D. Tóth,Elias P. Tsigaridas
#t2009
#cComputational Geometry: Theory and Applications
#index63123
#%9870
#%51412
#%333699
#%147280
#%328539
#%464167
#%471666
#%536912
#%164083
#%144048
#!We study a variant of the classical art gallery problem, where an art gallery is modeled by a polygon with curvilinear sides. We focus on piecewise-convex and piecewise-concave polygons, which are polygons whose sides are convex and concave arcs, respectively. It is shown that for monitoring a piecewise-convex polygon with n>=2 vertices, @?2n3@? vertex guards are always sufficient and sometimes necessary. We also present an algorithm for computing at most @?2n3@? vertex guards in O(nlogn) time and O(n) space. For the number of point guards that can be stationed at any point in the polygon, our upper bound @?2n3@? carries over and we prove a lower bound of @?n2@?. For monitoring a piecewise-concave polygon with n>=3 vertices, 2n-4 point guards are always sufficient and sometimes necessary, whereas there are piecewise-concave polygons where some points in the interior are hidden from all vertices, hence they cannot be monitored by vertex guards. We conclude with bounds for some special types of curvilinear polygons.


#*Leveraging social media for training object detectors
#@E. Chatzilari,S. Nikolopoulos,I. Kompatsiaris,E. Giannakidou,A. Vakali
#t2009
#cProceedings of the 16th international conference on Digital Signal Processing
#index354405
#%23865
#%32002
#%108292
#%306816
#!The fact that most users tend to tag images emotionally rather than realistically makes social datasets inherently flawed from a computer vision perspective. On the other hand they can be particularly useful due to their social context and their potential to grow arbitrary big. Our work shows how a combination of techniques operating on both tag and visual information spaces, manages to leverage the associated weak annotations and produce region-detail training samples. In this direction we make some theoretical observations relating the robustness of the resulting models, the accuracy of the analysis algorithms and the amount of processed data. Experimental evaluation performed against manually trained object detectors reveals the strengths and weaknesses of our approach.


#*Proposing new metrics to evaluate web usability for the blind
#@Kentarou Fukuda,Shin Saito,Hironobu Takagi,Chieko Asakawa
#t2005
#cCHI '05 extended abstracts on Human factors in computing systems
#index98641
#!Accessibility-related regulations and guidelines are contributing to the steady improvement of Web accessibility. There are various accessibility evaluation tools, and they also help Web authors make their pages compliant with guidelines. As a result, an increasing number of Web pages are compliant with the evaluation tools. These days, however, blind people face the serious problem that reading Web pages is quite difficult. Improvements in information density by using visual effects such as two-dimensional layouts are making it difficult for blind people to understand the page structure. Also, inappropriate alternative texts mislead or confuse blind users.In this paper, to evaluate these kinds of usability problems, we introduce two metrics: navigability and listenability. Navigability evaluates how well structured the Web content is by using headings, intra-page links, labels, etc. Listenability denotes how appropriate the alternative texts are. By using these metrics, we summarize the historical transition of Web usability for blind people.


#*Proceedings of the 4th International Symposium on Location and Context Awareness
#@Tanzeem Choudhury,Aaron Quigley,Thomas Strang,Koji Suginuma
#t2009
#cLecture Notes In Computer Science; Vol. 5561
#index128857


#*Introduction to Service Issues in Industrial IT Infrastructures
#@Ralf Gitzel
#t2008
#cProceedings of the 2008 12th International IEEE Enterprise Distributed Object Computing Conference
#index404364


#*Testing Reversible One-Dimensional QCA Arrays for Multiple F
#@J. Huang,X. Ma,C. Metra,F. Lombardi
#t2007
#cProceedings of the 22nd IEEE International Symposium on Defect and Fault-Tolerance in VLSI Systems
#index338269
#!Reversible logic design is a well-known paradigm in digital computation. In this paper, Quantum-dot Cellular Automata (QCA) is investigated for testable implementations of reversible logic in array systems. C-testability of a 1D array is investigated for multiple cell faults. It has been shown that fault masking is possible in the presence of multiple faults [9]. A technique for achieving C-testability of 1D array is introduced by adding lines for controllability and observability. Rules for choosing lines for controllability and observability are proposed. Examples using the QCA reversible logic gates proposed in [9] are presented.


#*Sequence Mining Without Sequences: A New Way for Privacy Preserving
#@Stephanie Jacquemont,Francois Jacquenet,Marc Sebban
#t2006
#cProceedings of the 18th IEEE International Conference on Tools with Artificial Intelligence
#index23843
#!During the last decade, sequential pattern mining has been the core of numerous researches. It is now possible to efficiently discover users' behavior in various domains such as purchases in supermarkets,Web site visits, etc. Nevertheless, classical algorithms do not respect individual's privacy, exploiting personal information (name, IP address, etc.). We provide an original solution to privacy preserving by using a probabilistic automaton instead of the original data. An application in car flow modeling is presented, showing the ability of our algorithm to discover frequent routes without any individual information. A comparison with SPAM is done showing that even if we sample from the automaton, our approach is more efficient.


#*A gentle introduction to the boundary element method in Matlab/Freemat
#@Stephen Kirkup,Javad Yazdani
#t2008
#cProceedings of the 10th WSEAS international conference on Mathematical methods, computational techniques and intelligent systems
#index141766
#%472273
#!The Boundary Element Method is developed in its most simple form; for the solution of Laplace's equation in an interior domain with a straight line approximation to the boundary. The direct and indirect approaches to the boundary element method are included. The methods are developed in Freemat, a language similar to Matlab. The codes for the solution of Laplace's equation in a general domain with a general (Robin) boundary condition are developed. The codes are applied to a typical test problem. The codes are made available as open source and can be downloaded from www.east-lancashire-research.org.uk (report AR-08-14).


#*The use of Second Life for distance education
#@Tim Ritzema,Billy Harris
#t2008
#cJournal of Computing Sciences in Colleges
#index43520
#!This paper explores the feasibility of utilizing the vaunted Second Life environment for distance education in the area of computer science. Two sets of user groups were enlisted to determine whether the virtual environment was suitable for conveying concepts ranging from the simplistic to the complex. Due to the overwhelmingly positive responses provided via the anonymous surveying of the participants, it can be determined that the Second Life platform is indeed a viable solution for distance education in the area of computer science.


#*Proceedings of the 27th international conference on Computer Safety, Reliability, and Security
#@Michael D. Harrison,Mark-Alexander Sujan
#t2008
#cLecture Notes In Computer Science; Vol. 5219
#index407676


#*Biologically-Inspired Engineering Mechanisms and Test-beds
#@
#t2008
#cProceedings of the 3rd International Conference on Bio-Inspired Models of Network, Information and Computing Sytems
#index57986


#*An Improved Condensing Algorithm
#@Xiulan Hao,Chenghong Zhang,Hexiang Xu,Xiaopeng Tao,Shuyun Wang,Yunfa Hu
#t2008
#cProceedings of the Seventh IEEE/ACIS International Conference on Computer and Information Science (icis 2008)
#index39488
#!kNN classifier is widely used in text categorization, however, kNN has the large computational and store requirements, and its performance also suffers from uneven distribution of training data. Usually, condensing technique is resorted to reducing the noises of training data and decreasing the cost of time and space. Traditional condensing technique picks up samples in a random manner when initialization. Though random sampling is one means to reduce outliers, the extremely stochastic may lead to bad performance sometimes, that is, advantages of sampling may be suppressed. To avoid such a misfortune, we propose a variation of traditional condensing technique. Experiment results illustrate this strategy can solve above problems effectively.


#*Vol. Author Index
#@
#t2008
#cJournal of Approximation Theory
#index52995


#*Discovering original motifs with different lengths from time series
#@Heng Tang,Stephen Shaoyi Liao
#t2008
#cKnowledge-Based Systems
#index390185
#%250589
#%305665
#%311052
#!Finding previously unknown patterns in a time series has received much attention in recent years. Of the associated algorithms, the k-motif algorithm is one of the most effective and efficient. It is also widely used as a time series preprocessing routine for many other data mining tasks. However, the k-motif algorithm depends on the predefine of the parameter w, which is the length of the pattern. This paper introduces a novel k-motif-based algorithm that can solve the existing problem and, moreover, provide a way to generate the original patterns by summarizing the discovered motifs.


#*History Calls: Delivering Automated Audio Tours to Visitors' Cell Phones
#@Matthew Nickerson
#t2005
#cProceedings of the International Conference on Information Technology: Coding and Computing (ITCC'05) - Volume II - Volume 02
#index106725
#!Many museums around the world rent audio players to their visitors to provide automated tours delivering pre-recorded information about their exhibits. Though generally pleased with their patrons' responses to automated audio tours museum administrators find that hosting them can be expensive, time consuming, and frustrating. Ongoing advances in mobile wireless technology provide an alternative to the current cumbersome method of renting sound players to museum visitors. Many patrons bring their own "digital sound player" with them in the guise of their personal cell phone. As cell phones proliferate and the price of calling plans falls cell phones may present a viable alternative to current audio tour systems. History Calls was a recent experiment using VXML technology to deliver an automated audio museum tour directly to patrons' cell phones.


#*A scientific workflow construction command line
#@Paul T. Groth,Yolanda Gil
#t2009
#cProceedings of the 13th international conference on Intelligent user interfaces
#index71232
#%67112
#%149915
#%217939
#!Workflows have emerged as a common tool for scientists to express their computational analyses. While there are a multitude of visual data flow editors for workflow construction, to date there are none that support the input of workflows using natural language. This work presents the design of a hybrid system that combines natural language input through a command line with a visual editor.


#*Client-Centric Performance Analysis of a High-Availability Cluster
#@Jesper Grønbæk,Hans-Peter Frejek,Thibault Renier,Hans-Peter Schwefel
#t2007
#cProceedings of the 4th international symposium on Service Availability
#index387154
#!High-Availability as provided by fault-tolerance mechanisms comes at the price of increased overhead due to additional processing and communication, which may be a limiting factor to service performance as perceived by the clients. In order to quantify this impact and to understand the underlying mechanisms for performance degradation, this paper presents an approach for the analysis of client-centric performance metrics in cluster-based service deployment scenarios using High-Availability Middleware. The approach is based on a combination of measurement based empiric analysis under synthetically generated load patterns and simple queueing models, that allow for the extrapolation of empiric results and are used to gain insights into the underlying causes of the empiric performance behavior. The empiric and numerical results in the paper are based on an abstracted SIP-like call control service as deployed in future version of IP-based cellular networks, running on a two-node cluster system.


#*Multi-user Video Streaming over Multi-hop Wireless Networks: A Cross-Layer Priority Queuing Scheme
#@Hsien-Po Shiang,Mihaela van der Schaar
#t2006
#cProceedings of the 2006 International Conference on Intelligent Information Hiding and Multimedia
#index25804
#!In this paper, we propose a distributed, end-to-end, integrated cross-layer scheme to maximize the decoded video quality of multiple users engaged in simultaneous real-time streaming sessions over a multi-hop wireless network. Our algorithm explicitly considers the distortion impact and delay constraints in assigning priorities to the various packets and then relies on priority queuing to drive the optimization of the various users' transmission strategies across the multi-hop network. The proposed solution is enabled by the scalable coding of the video content and the design of cross-layer optimization strategies including a dynamic routing algorithm, which allow priority-based adaptation to varying channel conditions. Our proposed delay-driven, packet-based transmission is superior in terms of both network scalability and video quality to previous static flow-based solutions based on predetermined paths and rate requirements.


#*Secrecy and group creation
#@Luca Cardelli,Giorgio Ghelli,Andrew D. Gordon
#t2005
#cInformation and Computation
#index101775
#%87752
#%257921
#%259736
#%275445
#%444874
#%314158
#%218630
#%252101
#%272116
#%253202
#%267773
#!We add an operation of group creation to the typed π-calculus, where a group is a type for channels. Creation of fresh groups has the effect of statically preventing certain communications, and can block the accidental or malicious leakage of secrets. Intuitively, no channel belonging to a fresh group can be received by processes outside the initial scope of the group, even if those processes are untyped. We formalize this intuition by adapting a notion of secrecy introduced by Abadi, and proving a preservation of secrecy property.


#*Network Attack-Defense Simulation Training System Based on HLA
#@Gang Chen,Shang Xiang,GuanQun Ji,YiLong Jia
#t2009
#cProceedings of the 2009 International Conference on Computer Modeling and Simulation
#index64338
#!Soldiers possessing of network attack-defense ability are the key factor for future information war. Aiming at the problem of lacking daily training and drilling environment, a method of building Network Attack-Defense Simulation Training System (NADSTS) based on HLA is put forward. With the method, attack and defense training are designed as different federation member. The system is divided to presentation, application and adapter layer clearly. Key technologies involves network attack-defense, network simulation and simulation driving are also presented. Software is developed based on plug-in framework. Its simulation examples show greatest traits on building similar large-scale simulation system.


#*Just culture: who gets to draw the line?
#@Sidney W. A. Dekker
#t2009
#cCognition, Technology and Work
#index505995
#!A just culture is meant to balance learning from incidents with accountability for their consequences. All the current proposals for just cultures argue for a clear line between acceptable and unacceptable behavior. This alone, however, cannot promote just culture as it falsely assumes that culpability inheres in the act, bearing immutable features independent of context, language or interpretation. The critical question is not where to draw the line, but who gets to draw it. Culpability is socially constructed: the result of deploying one language to describe an incident, and of enacting particular post-conditions. Different accounts of the same incident are always possible (e.g. educational, organizational, political). They generate different repertoires of countermeasures and can be more constructive for safety. The issue is not to exonerate individual practitioners but rather what kind of accountability promotes justice and safety: backward-looking and retributive, or forward-looking and change-oriented.


#*Algorithms for spherical harmonic lighting
#@Ian G. Lisle,S.-L. Tracy Huang
#t2007
#cProceedings of the 5th international conference on Computer graphics and interactive techniques in Australia and Southeast Asia
#index347704
#%15720
#%238938
#!Spherical harmonic (SH) lighting models require efficient and general libraries for evaluation of SH functions and of Wigner matrices for rotation. We introduce an efficient algebraic recurrence for evaluation of SH functions, and also implement SH rotation via Wigner matrices constructed for the real SH basis by a recurrence. Using these algorithms, we provide a freely distributable C / OpenGL implementation for SH diffuse unshadowed, shadowed and inter-reflected models. Our implementation allows flexible switching of scene, light probe, SH degree and lighting model at run time.


#*Multimedia-Aware Congestion Control for Video Streaming over the Internet
#@Thomas K. Yan,H. Peter Dommel
#t2007
#cProceedings of the Second International Conference on Digital Telecommunications
#index430403
#!This paper presents congestion control protocols designed for use in video applications over the Internet. Such protocols should take video traffic characteristics into account while behaving in a friendly manner with respect to competing flows in the Internet. Building on the TEAR protocol, additional video traffic characteristics are taken into account by considering flows with variable packet sizes, a characteristic of video traffic due to the packetization and error-control schemes of video coding systems. Our experiments show our proposed protocols take more video traffic characteristics into account than TEAR while maintaining TEAR's TCP-friendliness.


#*Decision Procedures for the Grand Challenge
#@Daniel Kroening
#t2005
#cVerified Software: Theories, Tools, Experiments: First IFIP TC 2/WG 2.3 Conference, VSTTE 2005, Zurich, Switzerland, October 10-13, 2005, Revised Selected Papers and Discussions
#index394884
#!The Verifying Compiler checks the correctness of the program it compiles. The workhorse of such a tool is the reasoning engine, which decides validity of formulae in a suitably chosen logic. This paper discusses possible choices for this logic, and how to solve the resulting decision problems. A framework for reducing decision problems to propositional logic is described, which allows the surprising improvements in the performance of propositional SAT solvers to be exploited. The only assumption the framework makes is that an axiomatization of the desired logic is given.


#*A large-scale behavior corpus including multi-angle video data for observing infants' long-term developmental processes
#@Shinya Kiriyama,Goh Yamamoto,Naofumi Otani,Shogo Ishikawa,Yoichi Takebayashi
#t2007
#cProceedings of the 9th international conference on Multimodal interfaces
#index338332
#!We have developed a method for multimodal observation of infant development. In order to analyze development of problem solving skills by observing scenes of task achievement or communication with others, we have introduced a method for extracting detailed behavioral features expressed by gestures or eyes. We have realized an environment for recording behavior of the same infants continuously as multi-angle video. The environment has evolved into a practical infrastructure through the following four steps; (1) Establish an infant school and study the camera arrangement. (2) Obtain participants in the school who agree with the project purpose and start to hold regular classes. (3) Begin to construct a multimodal infant behavior corpus with considering observation methods. (4) Practice development process analyses using the corpus. We have constructed a support tool for observing a huge amount of video data which increases with age. The system has contributed to enrich the corpus with annotations from multimodal viewpoints about infant development. With a focus on the demonstrative expression as a fundamental human behavior, we have extracted 240 scenes from the video during 10 months and observed them. The analysis results have revealed interesting findings about the developmental changes in infants' gestures and eyes, and indicated the effectiveness of the proposed observation method.


#*Variant of Gaussian kernel and parameter setting method for nonlinear SVM
#@Shui-Sheng Zhou,Hong-Wei Liu,Feng Ye
#t2009
#cNeurocomputing
#index134593
#%117601
#%618113
#%162102
#%435316
#%586607
#!The classification problem by the nonlinear support vector machine (SVM) with kernel function is discussed in this paper. Firstly, the stretching ratio is defined to analyze the performance of the kernel function, and a new type of kernel function is introduced by modifying the Gaussian kernel. The new kernel function has many properties as good as or better than Gaussian kernel: such as its stretching ratio is always lager than 1, and its implicit kernel map magnifies the distance between the vectors in local but without enlarging the radius of the circumscribed hypersphere that includes the whole mapping vectors in feature space, which maybe gets a bigger margin. Secondly, two aspects are considered to choose a good spread parameter for a given kernel function approximately and easily. One is the distance criterion which minimizes the sum-square distance between the labeled training sample and its own center and maximizes the sum-square distance between the training sample and the other labeled-center, which is equivalent to the famous Fisher ratio. The other is the angle criterion which minimizes the angle between the kernel matrix and the target matrix. Then a better criterion is given by combined those aspects. Finally, some experiments show that our methods are efficient.


#*Comparison of Visible, Thermal Infra-Red and Range Images for Face Recognition
#@Ajmal Mian
#t2009
#cProceedings of the 3rd Pacific Rim Symposium on Advances in Image and Video Technology
#index55001
#!Existing literature compares various biometric modalities of the face for human identification. The common criterion used for comparison is the recognition rate of different face modalities using the same recognition algorithms. Such comparisons are not completely unbiased as the same recognition algorithm or features may not be suitable for every modality of the face. Moreover, an important aspect which is overlooked in these comparisons is the amount of variation present in each modality which will ultimately effect the database size each modality can handle. This paper presents such a comparison between the most common biometric modalities of the face namely visible, thermal infra-red and range images. Experiments are performed on the Equinox and the FRGC databases with results indicating that visible images capture more interpersonal variations of the human face compared to thermal IR and range images. We conclude that under controlled conditions, visible face images have a greater potential of accommodating large databases compared to long-wave IR and range images.


#*Observing the swarm behaviour during its evolutionary design
#@Laura Diosan,Mihai Oltean
#t2007
#cProceedings of the 2007 GECCO conference companion on Genetic and evolutionary computation
#index422952
#%256845
#%424380
#%517247
#%425754
#!Evolutionary Algorithms (EAs) can be used for designing Particle Swarm Optimization (PSO) algorithms that work, in some cases, considerably better than the human-designed ones. By analyzing the evolutionary process of design PSO algorithm we can identify different swarm phenomena (such as patterns or rules) that can give us deep insights about the swarm's behaviours. The observed rules can help us to design better PSO algorithms for optimization. In this paper we investigate and analyze swarm phenomena by looking to process of evolving PSO algorithms. Several interesting facts are inferred from the strategy evolution process (the particle quality could influence the update order, some particles are updated more frequently than others are, the initial swarm size is not always optimal).


#*Adobe Photoshop CS3 Studio Techniques
#@Ben Willmore
#t2007
#c
#index141602
#!Adobe Photoshop CS3 Studio Techniques has been completely updated to cover the new features in CS3. In a friendly, easy-going style that's long on information and short on techno-babble, Photoshop Hall-of-Famer Ben Willmore guides you through the concepts, features that will truly make a difference in how you use Photoshop every day. He takes you from blindly following step-by-step instructions to an in-depth understanding of how Photoshop works, cutting through the fat to focus on what he considers to be Photoshop's essential features. This full-color book delivers the content in three easily digestible sections: Working Foundations, Production Essentials, and Creative Explorations, and includes a companion CD with bonus chapters and practice images so you can quickly and easily apply the techniques covered throughout. Beginning with the working foundations of Photoshop--the basic tools, palettes, layers, and masks, you'll quickly move on to real-world production techniques, such as how to sharpen scans, correct and optimize images, and use the powerful Curves and Channels features to your advantage. Finally, you'll get to fully explore Photoshop's creative potential by blending and enhancing images, creating collages, retouching photographs, colorizing, and working with filters and layer masks. By the time you finish this book, your creativity and efficiency levels should soar and you'll start to feel like you finally "get" Photoshop.


#*Guest editorial: Special issue on robot learning, Part A
#@Jan Peters,Andrew Y. Ng
#t2009
#cAutonomous Robots
#index131462


#*Equivalence of queries that are sensitive to multiplicities
#@Sara Cohen
#t2009
#cThe VLDB Journal &mdash; The International Journal on Very Large Data Bases
#index130571
#%74371
#%104064
#%358493
#%553970
#%227456
#%299740
#%290663
#%364494
#%370855
#%573085
#%621279
#%588625
#%165008
#%606679
#%570065
#%373243
#%167001
#!The query equivalence problem has been studied extensively for set-semantics and, more recently, for bag and bag-set semantics. However, SQL queries often combine set, bag and bag-set semantics. For example, an SQL query that returns a multiset of elements may call a subquery or view that returns a set of elements. Queries may access both relations that do not contain duplicates, as well as relations with duplicates. As another example, in SQL one can compute a multiset-union of queries, each of which returns a set of answers. This paper presents combined semantics, which formally models query evaluation combining set, bag and bag-set semantics. The equivalence problem for queries evaluated under combined semantics is studied. A sufficient condition for equivalence is presented. For several important common classes of queries necessary and sufficient conditions for equivalence are presented.


#*Estimation of rotor angles of synchronous machines using artificial neural networks and local PMU-based quantities
#@Alberto Del Angel,Pierre Geurts,Damien Ernst,Mevludin Glavic,Louis Wehenkel
#t2007
#cNeurocomputing
#index338970
#!This paper investigates a possibility for estimating rotor angles in the time frame of transient (angle) stability of electric power systems, for use in real-time. The proposed dynamic state estimation technique is based on the use of voltage and current phasors obtained from a phasor measurement unit supposed to be installed on the extra-high voltage side of the substation of a power plant, together with a multilayer perceptron trained off-line from simulations. We demonstrate that an intuitive approach to directly map phasor measurement inputs to the neural network to generator rotor angle does not offer satisfactory results. We found out that a good way to approach the angle estimation problem is to use two neural networks in order to estimate the sin(@d) and cos(@d) of the angle and recover the latter from these values by simple post-processing. Simulation results on a part of the Mexican interconnected system show that the approach could yield satisfactory accuracy for real-time monitoring and control of transient instability.


#*Blended Interaction Design: A Spatial Workspace Supporting HCI and Design Practice
#@Florian Geyer
#t2009
#cProceedings of the 12th IFIP TC 13 International Conference on Human-Computer Interaction: Part II
#index488972
#!This research investigates novel methods and techniques along with tool support that result from a conceptual blend of human-computer interaction with design practice. Using blending theory with material anchors as a theoretical framework, we frame both input spaces and explore emerging structures within technical, cognitive, and social aspects. Based on our results, we will describe a framework of the emerging structures and will design and evaluate tool support within a spatial, studio-like workspace to support collaborative creativity in interaction design.


#*Improving the recommendation of mobile services by interpreting the user's icon arrangement
#@Matthias Böhmer,Gernot Bauer
#t2009
#cProceedings of the 11th International Conference on Human-Computer Interaction with Mobile Devices and Services
#index498580
#%40103
#%300643
#!The aether soon will be pervaded with a high density of digital services for usage on mobile phones. Personalization plays a crucial role for the success and acceptance of such systems. In this paper, we present work in progress on a new approach for improving the personalization of recommender systems for pervasive services. Mobile utilization is extended from services inherent in devices to pervasive services. We describe a new concept for collaborative and content-based filtering based on the users' service rankings given by arrangement of menu icons and discuss different models for interaction with a varying icon menu.


#*A New Architecture For Multiple-Precision Floating-Point Multiply-Add Fused Unit Design
#@Libo Huang,Li Shen,Kui Dai,Zhiying Wang
#t2007
#cProceedings of the 18th IEEE Symposium on Computer Arithmetic
#index432850
#!The floating-point multiply-add fused (MAF) unit sets a new trend in the processor design to speed up floatingpoint performance in scientific and multimedia applications. This paper proposes a new architecture for the MAF unit that supports multiple IEEE precisions multiply-add operation (A×B+C) with Single Instruction Multiple Data (SIMD) feature. The proposed MAF unit can perform either one double-precision or two parallel single-precision operations using about 18% more hardware than a conventional double-precision MAF unit and with 9% increase in delay. To accommodate the simultaneous computation of two single-precision MAF operations, several basic modules of double-precision MAF unit are redesigned. They are either segmented by precision mode dependent multiplexers or attached by the duplicated hardware. The proposed MAF unit can be fully pipelined and the experimental results show that it is suitable for processors with floatingpoint unit (FPU).


#*Resolving Dilemmas in Software Engineering Education
#@David Parnas
#t2007
#cProceedings of the 20th Conference on Software Engineering Education & Training
#index425050
#!Anyone developing a Software Engineering curriculum is faced with several dilemmas: Should it emphasize fundamental principles or current technology? Should it teach about a wide variety of approaches or how to use a few important methods? When discussing how the software industry does things, should we teach that this is what to do or what not to do? How should we balance "Core Engineering' vs. "Software Engineering' This talk will discuss one set of answers to these questions and outline a curriculum that implements them.


#*Using Location for Personalized POI Recommendations in Mobile Environments
#@Tzvetan Horozov,Nitya Narasimhan,Venu Vasudevan
#t2006
#cProceedings of the International Symposium on Applications on Internet
#index579299
#!Internet-based recommender systems have traditionally employed collaborative filtering techniques to deliver relevant "digital" results to users. In the mobile Internet however, recommendations typically involve "physical" entities (e.g., restaurants), requiring additional user effort for fulfillment. Thus, in addition to the inherent requirements of high scalability and low latency, we must also take into account a "convenience" metric in making recommendations. In this paper, we propose an enhanced collaborative filtering solution that uses location as a key criterion for generating recommendations. We frame the discussion in the context of our "restaurant recommender" system, and describe preliminary results that indicate the utility of such an approach. We conclude with a look at open issues in this space, and motivate a future discussion on the business impact and implications of mining the data in such systems.


#*Dynamic memory balancing for virtual machines
#@Weiming Zhao,Zhenlin Wang
#t2009
#cProceedings of the 2009 ACM SIGPLAN/SIGOPS international conference on Virtual execution environments
#index63317
#%320968
#%228925
#!Virtualization essentially enables multiple operating systems and applications to run on one physical computer by multiplexing hardware resources. A key motivation for applying virtualization is to improve hardware resource utilization while maintaining reasonable quality of service. However, such a goal cannot be achieved without efficient resource management. Though most physical resources, such as processor cores and I/O devices, are shared among virtual machines using time slicing and can be scheduled flexibly based on priority, allocating an appropriate amount of main memory to virtual machines is more challenging. Different applications have different memory requirements. Even a single application shows varied working set sizes during its execution. An optimal memory management strategy under a virtualized environment thus needs to dynamically adjust memory allocation for each virtual machine, which further requires a prediction model that forecasts its host physical memory needs on the fly. This paper introduces MEmory Balancer (MEB) which dynamically monitors the memory usage of each virtual machine, accurately predicts its memory needs, and periodically reallocates host memory. MEB uses two effective memory predictors which, respectively, estimate the amount of memory available for reclaiming without a notable performance drop, and additional memory required for reducing the virtual machine paging penalty. Our experimental results show that our prediction schemes yield high accuracy and low overhead. Furthermore, the overall system throughput can be significantly improved with MEB.


#*For use of adobe reader 6 or earlier
#@
#t2009
#cProceedings of the 2009 ICSE Workshop on Aspect-Oriented Requirements Engineering and Architecture Design
#index137780


#*Using routing and tunneling to combat DoS attacks
#@Adam Greenhalgh,Mark Handley,Felipe Huici
#t2005
#cProceedings of the Steps to Reducing Unwanted Traffic on the Internet on Steps to Reducing Unwanted Traffic on the Internet Workshop
#index426809
#%321452
#!Thorough defense against DoS attacks is extremely difficult without incurring significant changes to the Internet architecture. We present a series of changes aimed at establishing protection boundaries to reduce the effectiveness of most flooding DoS attacks against servers. Only minimal and local changes are required to current network architectures. We show that our scheme is highly beneficial even if deployed at a single ISP, with additional benefits arising from multiple-ISP deployment. Finally, we show that the changes can be implemented with off-the-shelf components.


#*Techniques for Image Classification, Object Detection and Object Segmentation
#@Ville Viitaniemi,Jorma Laaksonen
#t2008
#cProceedings of the 10th international conference on Visual Information Systems: Web-Based Visual Information Search and Management
#index386804
#!In this paper we outline the techniques which we used to participate in the PASCAL NoE VOC Challenge 2007 image analysis performance evaluation campaign. We took part in three of the image analysis competitions: image classification, object detection and object segmentation. In the classification task of the evaluation our method produced comparatively good performance, the 4th best of 19 submissions. In contrast, our detection results were quite modest. Our method's segmentation accuracy was the best of all submissions. Our approach for the classification task is based on fused classifications by numerous global image features, including histograms of local features. The object detection combines similar classification of automatically extracted image segments and the previously obtained scene type classifications. The object segmentations are obtained in a straightforward fashion from the detection results.


#*Secure, archival storage with POTSHARDS
#@Mark W. Storer,Kevin M. Greenan,Ethan L. Miller,Kaladhar Voruganti
#t2007
#cProceedings of the 5th USENIX conference on File and Storage Technologies
#index415241
#%326992


#*Computation in Noisy Radio Networks
#@Eyal Kushilevitz,Yishay Mansour
#t2005
#cSIAM Journal on Discrete Mathematics
#index98636
#!In this paper, we examine noisy radio (broadcast) networks in which every bit transmitted has a certain probability of being flipped. Each processor has some initial input bit, and the goal is to compute a function of these input bits. In this model, we show a protocol to compute any threshold function using only a linear number of transmissions.


#*Timna: a framework for automatically combining aspect mining analyses
#@David Shepherd,Jeffrey Palm,Lori Pollock,Mark Chu-Carroll
#t2005
#cProceedings of the 20th IEEE/ACM international Conference on Automated software engineering
#index579949
#%106346
#%239918
#%281933
#!To realize the benefits of Aspect Oriented Programming (AOP), developers must refactor active and legacy code bases into an AOP language. When refactoring, developers first need to identify refactoring candidates, a process called aspect mining. Humans perform mining by using a variety of clues to determine which code to refactor. However, existing approaches to automating the aspect mining process focus on developing analyses of a single program characteristic. Each analysis often finds only a subset of possible refactoring candidates and is unlikely to find candidates which humans find by combining analyses. In this paper, we present Timna, a framework for enabling the automatic combination of aspect mining analyses. The key insight is the use of machine learning to learn when to refactor, from vetted examples. Experimental evaluation of the cost-effectiveness of Timna in comparison to Fan-in, a leading aspect mining analysis, indicates that such a framework for automatically combining analyses is very promising.


#*CPR graphs and regular polytopes
#@Daniel Pellicer
#t2008
#cEuropean Journal of Combinatorics
#index339539
#!This paper studies C-group permutation representation graphs, or for short, CPR graphs. C-groups are the groups of abstract regular polytopes. CPR graphs are shown to be a useful tool for studying such polytopes. We establish general properties of CPR graphs. Moreover, we illustrate their use by constructing regular polyhedra with alternating groups A"n as the automorphism groups.


#*Practical Gold Mining, Its Commercial Aspects: A Collection Of Statistics And Data Relating To Gold Mining And Gold Mining Finance Companies
#@William S. Welton
#t2009
#c
#index506734


#*All-IPv6 service interworking gateway
#@Jiann-Liang Chen,Wen-Hao Chen,Sy-Yen Kuo
#t2005
#cInternational Journal of Network Management
#index98722
#%248496
#!Improvements of inter-operability, interface IP and dual mobility function must be investigated to move toward full IP and seamless multimedia applications. An All-IPv6 service architecture that consists of cellular systems and Wireless LAN networks has been constructed. A GPRS/WLAN interworking gateway with an IPv6 facility has been designed and its performance examined in terms of queue length, system throughput, loss rate and delay. The results of the simulation of a 1Mbps WLAN and 144kbps GPRS interworking system show that: (1) the queue length is directly proportional to the traffic load (the length increases to 100 packets in 61 seconds at a rate of increase of around 50% per 30 seconds); (2) if the size of the queue is increased to 100 packets, then the loss rate declines to 0.017, (a longer queue corresponds to a lower loss rate); (3) the size of the queue only weakly influences the system throughput when the queue length is increased; and (4) the average delay is approximately 0.83 second/bit, when the queue size is 100 packets. The delay doubles as the queue size doubles.


#*Platform Relative Sensor Abstractions across Mobile Robots Using Computer Vision and Sensor Integration
#@Robert Smith,Glenn Smith,Aster Wardhani
#t2005
#cProceedings of the Digital Image Computing on Techniques and Applications
#index576196
#!Uniform sensor management and abstraction across different robot platforms is a difficult task due to the sheer diversity of sensing devices. However, because these sensors can be grouped into categories that in essence provide the same information, we can capture their similarities and create abstractions. An example would be distance data measured by an assortment of range sensors, or alternatively extracted from a camera using image processing. This paper describes how using software components it is possible to uniformly construct high-level abstractions of sensor information across various robots in a way to support the portability of common code that uses these abstractions (e.g. obstacle avoidance, wall following). We demonstrate our abstractions on a number of robots using different configurations of range sensors and cameras.


#*Part V. Methodology
#@
#t2008
#cProceeding of the 2008 conference on Ontology Learning and Population: Bridging the Gap between Text and Knowledge
#index125686


#*Getting More from Reputation Systems: A Context-Aware Reputation Framework Based on Trust Centers and Agent Lists
#@Rehab AlNemr,Christoph Meinel
#t2008
#cProceedings of the 2008 The Third International Multi-Conference on Computing in the Global Information Technology (iccgi 2008)
#index397859
#!Reputation is a crucial factor in trust and thus in web communities. Trust strategies may involve investigating user reputation or directly using transitive reputation to form the Web of Trust. We suggest an approach that takes advantage of both strategies without increasing the cost of investigation. Several systems nowadays form what we call “user web communities”. In these communities, reputation related to different contexts needs to be exchanged. The perception, calculation and interpretation of this reputation differ from one community to another. We propose the development of reference models to diminish the distance between these multi-perceptions. We also propose the use of reputation centers to facilitate reputation transfer and highlight the importance of their role in analyzing attacks on reputation.


#*Facilitating multiple target tracking using semantic depth of field (SDOF)
#@Nivedita R. Kadaba,Xing-Dong Yang,Pourang P. Irani
#t2009
#cProceedings of the 27th international conference extended abstracts on Human factors in computing systems
#index69494
#%101969
#%607479
#!Users of radar control systems and monitoring applications have to constantly extract essential information from dynamic scenes. In these environments a critical and elemental task consists of tracking multiple targets that are moving simultaneously. However, focusing on multiple moving targets is not trivial as it is very easy to lose continuity, particularly when the objects are situated within a very dense or cluttered background. While focus+context displays have been developed to improve users' ability to attend to important visual information, such techniques have not been applied to the visualization of moving objects. In this paper we evaluate the effectiveness of a focus+context technique, referred to as Semantic Depth of Field (SDOF), to the task of facilitating multiple target tracking. Results of our studies show an inclination for better performance with SDOF techniques, especially in low contrast scenarios.


#*A Log Analysis Audit Model Based on Optimized Clustering Algorithm
#@Hui Yu,Xingjian Shi
#t2007
#cProceedings of the 2007 IFIP International Conference on Network and Parallel Computing Workshops
#index336291
#!In view of the problem how to detect the network unknown attacks, a security log analysis audit model based on optimized clustering algorithm is proposed in this paper. Since the main question which influence the clustering algorithm application in the log analysis is uneasy to determine the network attack type and the cluster number, so we bring forward an optimized cluster algorithm to solve this problem. By means of simulated experiments, this algorithm is proved feasible, efficient and extensible for unknown intrusion detection.


#*On Tamper-Resistance from a Theoretical Viewpoint
#@Paulo Mateus,Serge Vaudenay
#t2009
#cProceedings of the 11th International Workshop on Cryptographic Hardware and Embedded Systems
#index504430
#!Tamper-proof devices are pretty powerful. They can be used to have better security in applications. In this work we observe that they can also be maliciously used in order to defeat some common privacy protection mechanisms. We propose the theoretical model of trusted agent to formalize the notion of programmable secure hardware. We show that protocols not using tamper-proof devices are not deniable if malicious verifiers can use trusted agents. In a strong key registration model, deniability can be restored, but only at the price of using key escrow. As an application, we show how to break invisibility in undeniable signatures, how to sell votes in voting schemes, how to break anonymity in group/ring signatures, and how to carry on the Mafia fraud in non-transferable protocols. We conclude by observing that the ability to put boundaries in computing devices prevents from providing full control on how private information spreads: the concept of sealing a device is in some sense incompatible with privacy.


#*Congestion Control in InfiniBand Networks
#@M. Gusat,D. Craddock,W. Denzel,T. Engbersen,N. Ni,G. Pfister,W. Rooney,J. Duato
#t2005
#cProceedings of the 13th Symposium on High Performance Interconnects
#index575504
#!Driving computer interconnection networks closer to saturation minimizes cost/performance and power consumption, but requires efficient congestion control to prevent catastrophic performance degradation during traffic peaks or "hot spot" traffic patterns. The InfiniBand™Architecture provides such congestion control, but lacks guidance for setting its parameters. At its adoption, it was unproven that there were any settings that would work at all, avoid instability or oscillations. This paper reports on a simulation-driven exploration of that parameter space which verifies that the architected scheme can, in fact, work properly despite inherent delays in its feedback mechanism.


#*On-Chip Spectrum Analyzer for Analog Built-In Self Test
#@Anup P. Jose,Keith A. Jenkins,Scott K. Reynolds
#t2005
#cProceedings of the 23rd IEEE VLSI Test Symposium
#index105277
#!This paper presents the design of an on-chip spectrum analyzer. A novel architecture is used to mitigate the problems encountered in trying to implement architectures employed in conventional stand-alone instruments on a chip. Specifically, it makes use of a very-low IF architecture, which leads to a highly compact design, that can be used for measuring the frequency content of high frequency on-chip signals. The architecture and design considerations along with an implementation in a 0.18 µm CMOS process is described. The design takes up an area of approximately 0.384 mm^2 with a simulated frequency range of 33 MHz to 3 GHz and a dynamic range of 60 dB.


#*Topology Selection for Fault-Tolerant Beacon Vector Routing in Wireless Sensor Networks
#@Luke Demoracski,D. R. Avresky
#t2005
#cProceedings of the Joint International Conference on Autonomic and Autonomous Systems and International Conference on Networking and Services
#index575522
#!This paper presents a performance analysis comparison for different topology types that can be used with an improved fault-tolerant Beacon Vector Routing (BVR) protocol. The topology types of Mesh, Torus, FCR, and Communication Graph are compared. The performance of these topology types is analyzed using BVR and three-phase faulttolerant BVR. Performance metrics include throughput, latency, overhead, saturation points, and packet success rate in the presence of multiple node failures. Using this analysis, we recommend for the user a given topology type, depending on the desired tradeoffs for their given application.


#*Step decision rules for multistage stochastic programming: A heuristic approach
#@J. Thénié,J. -Ph. Vial
#t2008
#cAutomatica (Journal of IFAC)
#index47716
#%437589
#%88997
#%94584
#%438766
#%162290
#!Stochastic programming with step decision rules (SPSDR) aims to produce efficient solutions to multistage stochastic optimization problems. SPSDR, like plain multistage Stochastic Programming (SP), operates on a Monte Carlo ''computing sample'' of moderate size that approximates the stochastic process. Unlike SP, SPSDR does not strive to build a balanced event tree out of that sample. Rather, it defines a solution as a special type of decision rule, with the property that the decisions at each stage are piecewise constant functions on the sample of scenarios. Those pieces define a partition of the set of scenarios at each stage t, but the partition at t+1 need not be refinement of the partition at t. However, the rule is constructed so that the non-anticipativity condition is met, a necessary condition to make the rules operational. To validate the method we show how to extend a non-anticipatory decision rule to arbitrary scenarios within a very large validation sample of scenarios. We apply three methods, SPSDR, SP and Robust Optimization, to the same 12-stage problem in supply chain management, and compare them relatively to different objectives and performance criteria. It appears that SPSDR performs better than SP in that it produces a more accurate estimate (prediction) of the value achieved by its solution on the validation sample, and also that the achieved value is better.


#*Discovering frequent sets from data streams with CPU constraint
#@Xuan Hong Dang,Wee-Keong Ng,Kok-Leong Ong,Vincent C S Lee
#t2007
#cProceedings of the sixth Australasian conference on Data mining and analytics - Volume 70
#index41318
#%362949
#%254260
#%618924
#%311231
#%309599
#%348495
#%337637
#%348421
#!Data streams are usually generated in an online fashion characterized by huge volume, rapid unpredictable rates, and fast changing data characteristics. It has been hence recognized that mining over streaming data requires the problem of limited computational resources to be adequately addressed. Since the arrival rate of data streams can significantly increase and exceed the CPU capacity, the machinery must adapt to this change to guarantee the timeliness of the results. We present an online algorithm to approximate a set of frequent patterns from a sliding window over the underlying data stream -- given apriori CPU capacity. The algorithm automatically detects overload situations and can adaptively shed unprocessed data to guarantee the timely results. We theoretically prove, using probabilistic and deterministic techniques, that the error on the output results is bounded within a pre-specified threshold. The empirical results on various datasets also confirmed the feasiblity of our proposal.


#*Towards an optimal separation of space and length in resolution
#@Jakob Nordström,Johan Håstad
#t2008
#cProceedings of the 40th annual ACM symposium on Theory of computing
#index41011
#%243254
#%607658
#%323263
#%120160
#%156601
#%544896
#%319150
#%619701
#%424517
#%599245
#%169757
#!Most state-of-the-art satisfiability algorithms today are variants of the DPLL procedure augmented with clause learning. The main bottleneck for such algorithms, other than the obvious one of time, is the amount of memory used. In the field of proof complexity, the resources of time and memory correspond to the length and space of resolution proofs. There has been a long line of research trying to understand these proof complexity measures, as well as relating them to the width of proofs, i.e., the size of the largest clause in the proof, which has been shown to be intimately connected with both length and space. While strong results have been proven for length and width, our understanding of space is still quite poor. For instance, it has remained open whether the fact that a formula is provable in short length implies that it is also provable in small space (which is the case for length versus width), or whether on the contrary these measures are completely unrelated in the sense that short proofs can be arbitrarily complex with respect to space. In this paper, we present some evidence that the true answer should be that the latter case holds and provide a possible roadmap for how such an optimal separation result could be obtained. We do this by proving a tight bound of Theta(√(n)) on the space needed for so-called pebbling contradictions over pyramid graphs of size n. Also, continuing the line of research initiated by (Ben-Sasson 2002) into trade-offs between different proof complexity measures, we present a simplified proof of the recent length-space trade-off result in (Hertel and Pitassi 2007), and show how our ideas can be used to prove a couple of other exponential trade-offs in resolution.


#*Generalized Graph Matching for Data Mining and Information Retrieval
#@Alexandra Brügger,Horst Bunke,Peter Dickinson,Kaspar Riesen
#t2008
#cProceedings of the 8th industrial conference on Advances in Data Mining: Medical Applications, E-Commerce, Marketing, and Theoretical Aspects
#index410742
#!Graph based data representation offers a convenient possibility to represent entities, their attributes, and their relationships to other entities. Consequently, the use of graph based representation for data mining has become a promising approach to extracting novel and useful knowledge from relational data. In order to check whether a certain graph occurs, as a substructure, within a larger database graph, the widely studied concept of subgraph isomorphism can be used. However, this conventional approach is rather limited. In the present paper the concept of subgraph isomorphism is substantially extended such that it can cope with don't care symbols, variables, and constraints. Our novel approach leads to a powerful graph matching methodology which can be used for advanced graph based data mining.


#*Outside back cover
#@
#t2007
#cThe Journal of Strategic Information Systems
#index348143


#*Robust spatiotemporal analysis of architectural imagery
#@Christopher E. Rasmussen
#t2007
#c
#index391963
#!This thesis addresses the issue of understanding and manipulating images of architectural scenes. Automatically modeling the structure and appearance of buildings with a robot is challenging; an end-to-end system would have to tackle a whole spectrum of tasks such as planning, sensor fusion, navigation, image acquisition and matching, structure estimation and texture mapping. Purely bottom-up techniques are inadequate for this task due to ambiguities and missing information inherent in sensor data. My solution is to introduce additional domain-specific models that can capture dependencies such as restricted spatial configurations or geometric patterns in images of buildings. Techniques to encode, discover and exploit these relationships for retrieving semantic information about buildings are illustrated. These interaction models are shown to be powerful for such varied tasks as object recognition and detection, segmentation, inference of missing information, and realistic image synthesis&mdash;even without supervised training or other appearance models. A primary focus of this work is on constructing "clean'' texture map mosaics of building facades. Without explicit handling, foreground objects such as trees, signs, and people will appear pasted as artifacts on the model. As a first major contribution, given an image sequence captured around the building, I developed a novel spatiotemporal timeline-based inpainting technique to remove non-building pixels from the median mosaic. These polluted regions are a result of the majority of views being occluded, which makes conventional techniques such as the median filter unreliable. Outlier pixels are then automatically identified by a robust measure of spread. A combination of motion cues and an automatically trained appearance-based classifier are used to fill the majority occluded holes with true building background. A second stage of spatial inpainting is applied to the relatively small unanimously occluded regions in which the background was never imaged. Results are shown on a variety of campus buildings. My second major innovation is a series of methods that enable foreground removal from single images of buildings or brick walls without any motion information. The key insight is to use a priori knowledge about grid patterns on building facades that can be modeled as Near Regular Textures (NRT). I describe a Markov Random Field (MRF) model for such textures and introduce a Markov Chain Monte Carlo (MCMC) optimization procedure for discovering grid structures on building images. Results are shown on both synthetic NRT as well as building images. This simple spatial rule is then used as a starting point for inference of missing windows, facade segmentation, grammar-based image parsing, outlier identification, and foreground removal. I also describe related work on how aerial imagery may be exploited for navigating a robot around the building perimeter. A randomized approach to view planning is presented that generates paths to simultaneously address visual coverage and quality. A Monte Carlo Localization framework for vehicle localization and guidance is also described.


#*Guidelines for Designing and Developing Contents for Mobile Learning
#@Antonella Grasso,Teresa Roselli
#t2005
#cProceedings of the IEEE International Workshop on Wireless and Mobile Technologies in Education
#index578662
#!The learning benefits deriving from the use of mobile technologies in in-field research and professional training have been demonstrated by a number of initiatives worldwide. Because learning can occur in highly variable places and conditions, the choice of mobile device and an accurate analysis of the target users are essential during the design phase of Mobile Learning applications, to identify the user scenarios and various possible experiences deriving from use of the system. The present work reconstructs previous experiences in the field of designing contents for Mobile Learning, with the aim of gleaning clear guidelines for designing and implementing highly efficacious, usable contents and courses for mobile devices. These guidelines were applied to create a course on the work of Caravaggio, to be studied using a handheld device.


#*Intelligent Interface for Elderly Games
#@Changhoon Park
#t2009
#cProceedings of the 5th International on ConferenceUniversal Access in Human-Computer Interaction. Part II: Intelligent and Ubiquitous Interaction Environments
#index490808
#!This paper proposes an intelligent interface to improve the game accessibility for the elderly based on the multimodal interface and dynamic load balancing. This approach aims to control the fidelity of feedback and the level of difficulty dynamically when the elderly become bored or frustrated with the game. By applying the proposed intelligent interface, we will present the implementation of a rhythm game for the elderly with a specialized game controller like a drum.


#*Analysis of Energy Consumption in Direct Transmission and Multi-hop Transmission for Wireless Sensor Networks
#@Jin Wang,Yu Niu,Jinsung Cho,Sungyoung Lee
#t2007
#cProceedings of the 2007 Third International IEEE Conference on Signal-Image Technologies and Internet-Based System
#index408389
#!In this paper, we primary focus on prolonging the network lifetime of Wireless Sensor Networks (WSN), since the small, portable batteries integrated into the sensor chips can not be re-charged easily from an economical point of view. We first made a further analysis about the relationship between energy consumption and hop number. Then, an optimal hop number is deduced for minimizing the energy consumption during the multi-hop transmission. The importance of hop number to the energy consumption is usually neglected by many routing protocols. In fact, a considerable amount of energy can be saved if the relationship between hop number and energy consumption is carefully studied. After further analysis about the energy consumption of different transmission manner as well as design parameters, we presented our judging criterion of transmission manner. Also, an energy efficient routing scenario is presented with diagram so as to illustrate how the network lifetime can be prolonged.


#*Compromised Resources Allocation Model for Emergency Response
#@Susheng Wang,Yan Wang,Jian Sun
#t2007
#cProceedings of the Third International Conference on Natural Computation - Volume 04
#index338333
#!Under the constraint of resources requirement, a compromised resources allocation model for emergency response and a negotiation strategy as a fast access between resource suppliers and requesters are mainly discussed in this paper. According to the characteristics of continuous emergency problem, the mathematical model is presented to help solve the large-scale public emergency difficulties. Finally, a case study is carried on to prove the algorithm effective.


#*Software Quality Engineering: Testing, Quality Assurance, and Quantifiable Improvement
#@Jeff Tian
#t2005
#c
#index97781


#*Joint LFMTP/PSTT invited talk
#@
#t2009
#cProceedings of the Fourth International Workshop on Logical Frameworks and Meta-Languages: Theory and Practice
#index127558


#*Online Discussion Processes: How do earlier messages affect evaluations, knowledge contents, social cues and responsiveness of current message?
#@Gaowei Chen
#t2005
#cProceeding of the 2005 conference on Artificial Intelligence in Education: Supporting Learning through Intelligent and Socially Informed Technology
#index136850


#*Robust management of outliers in sensor network aggregate queries
#@Yannis Kotidis,Vasilis Vassalos,Antonios Deligiannakis,Vassilis Stoumpos,Alex Delis
#t2007
#cProceedings of the 6th ACM international workshop on Data engineering for wireless and mobile access
#index432023
#%22429
#%25278
#%27699
#%84152
#%98664
#%109437
#%115533
#%284348
#%310978
#%313527
#%433919
#%618543
#!Sensor networks are increasingly applied for monitoring diverse environments and applications. Due to their unsupervised nature of operation and inexpensive hardware used, sensor nodes may furnish readings of rather poor quality. We thus need to devise techniques that can withstand "dirty" data during query processing. In this paper we introduce a robust aggregation framework that can detect and isolate spurious measurements from computed aggregate values. Such readings are not injected in the reported aggregate, in order not to obscure the outcome, but are still maintained and returned to the user/application, which may investigate them further and take appropriate decisions. In addition, our framework provides a form of positive feedback to the user by enhancing the result with a set of nodes that contain the most characteristic values out of those included in the aggregation process. We perform an extensive experimental evaluation of our framework using real traces of sensory data and demonstrate its utility to the monitoring of applications.


#*Toward a Regional ICT Hub: Need for Cyber Laws in Kenya
#@Alexander Mwaura Ng'ang'a
#t2009
#cInformation Security Journal: A Global Perspective
#index66232
#%615775
#!This paper discusses potential security issues in business process outsourcing environment arising due to lack of cyber legislation. A set of solutions based on existing cyber laws in developed nations is discussed, suggesting the need for implementation of cyber laws in Kenya and other developing nations wishing to take part in the business process outsourcing industry.


#*Repair checking in inconsistent databases: algorithms and complexity
#@Foto N. Afrati,Phokion G. Kolaitis
#t2009
#cProceedings of the 12th International Conference on Database Theory
#index55101
#%296818
#%421210
#%100970
#%377966
#%380599
#%601077
#!Managing inconsistency in databases has long been recognized as an important problem. One of the most promising approaches to coping with inconsistency in databases is the framework of database repairs, which has been the topic of an extensive investigation over the past several years. Intuitively, a repair of an inconsistent database is a consistent database that differs from the given inconsistent database in a minimal way. So far, most of the work in this area has addressed the problem of obtaining the consistent answers to a query posed on an inconsistent database. Repair checking is the following decision problem: given two databases r and r', is r' a repair of r? Although repair checking is a fundamental algorithmic problem about inconsistent databases, it has not received as much attention as consistent query answering. In this paper, we give a polynomial-time algorithm for subset-repair checking under integrity constraints that are the union of a weakly acyclic set of local-as-view (LAV) tuple-generating dependencies and a set of equality-generating dependencies. This result significantly generalizes earlier work for subset-repair checking when the integrity constraints are the union of an acyclic set of inclusion dependencies and a set of functional dependencies. We also give a polynomial-time algorithm for symmetric-difference repair checking, when the integrity constraints form a weakly acyclic set of LAV tgds. After this, we establish a number of complexity-theoretic results that delineate the boundary between tractability and intractability for the repair-checking problem. Specifically, we show that the aforementioned tractability results are optimal; in particular, subset-repair checking for arbitrary weakly acyclic sets of tuple-generating dependencies is a coNP-complete problem. We also study cardinality-based repairs and show that cardinality-repair checking is coNP-complete for various classes of integrity constraints encountered in database design and data exchange.


#*Studying the Fault-Detection Effectiveness of GUI Test Cases for Rapidly Evolving Software
#@Atif M. Memon,Qing Xie
#t2005
#cIEEE Transactions on Software Engineering
#index575496
#%118927
#%206941
#%300962
#%438700
#%444506
#%446224
#%617699
#!Software is increasingly being developed/maintained by multiple, often geographically distributed developers working concurrently. Consequently, rapid-feedback-based quality assurance mechanisms such as daily builds and smoke regression tests, which help to detect and eliminate defects early during software development and maintenance, have become important. This paper addresses a major weakness of current smoke regression testing techniques, i.e., their inability to automatically (re)test graphical user interfaces (GUIs). Several contributions are made to the area of GUI smoke testing. First, the requirements for GUI smoke testing are identified and a GUI smoke test is formally defined as a specialized sequence of events. Second, a GUI smoke regression testing process called Daily Automated Regression Tester (DART) that automates GUI smoke testing is presented. Third, the interplay between several characteristics of GUI smoke test suites including their size, fault detection ability, and test oracles is empirically studied. The results show that: 1) the entire smoke testing process is feasible in terms of execution time, storage space, and manual effort, 2) smoke tests cannot cover certain parts of the application code, 3) having comprehensive test oracles may make up for not having long smoke test cases, and 4) using certain oracles can make up for not having large smoke test suites.


#*Instrumentness for creativity mediation, materiality & metonymy
#@Olav W. Bertelsen,Morten Breinbjerg,Søren Pold
#t2007
#cProceedings of the 6th ACM SIGCHI conference on Creativity cognition
#index432062
#%14288
#%287112
#%375779
#%580377
#!We introduce the concept instrumentness as a quality of human-computer interfaces. Instrumentness points to the way musical instruments are controlled and conceptualized through values such as virtuosity and playability, which are important for computer-mediated creative work supporting development in use beyond what is initially designed for. The paper performs a conceptual investigation into qualities in software interfaces that support creativity, supported by analysis of, and interviews with, musical composers. Instrumentness is explained through discussions of materiality and metonymy as central strategies for computer mediated creativity. The paper is contributing to an investigation of the aesthetics of use in relation to software, pointing to alternative values, differing from traditional usability, which are also relevant in creative work outside art and music composition.


#*Osa-express Implementation Guide
#@Bill White
#t2005
#c
#index12957
#!This IBM Redbook helps you to install, tailor, and configure the Open Systems Adapter-Express (OSA-Express) features that are available on IBM System z9 and IBM eServer zSeries servers (System z9 109 and zSeries 990, 890, 900, and 800). It focuses on the hardware installation and the software definitions that you need to provide connectivity to various LAN environments. It provides information to help you with planning and system setup. It also includes helpful utilities and commands for monitoring and managing the OSA-Express features. The target audience for this redbook is system engineers, network administrators, and system programmers who will plan for and install OSA-Express. Prior to reading this redbook, you must have a solid background in System z9 and zSeries hardware, HCD or IOCP, OSA/SF, SNA/APPN, and TCP/IP.


#*Error detection and concealment for video transmission using information hiding
#@Ayhan Yılmaz,A. Aydın Alatan
#t2008
#cImage Communication
#index52675
#%230495
#%414975
#%416169
#%418391
#!Video transmission over noisy channels makes error concealment an indispensable job. Utilization of data hiding for this problem provides a reserve information about the content at the receiver, while unchanging the transmitted bit-stream syntax; hence, improves the reconstructed video quality with almost no extra channel utilization. A spatial domain error concealment technique, which hides edge orientation information of a block, and a resynchronization technique, which embeds bit-length of a block into other blocks are composed. The proposed method also exploits these two techniques for detecting errors via some extra parity information. Moreover, the motion vectors between consecutive frames are also embedded into the consecutive frames for better concealment at the receiver. Finally, as a novel approach, the bit-streams are further protected against errors via channel codes and the parity bits of these codes are embedded into other slices. In this manner, implicit utilization of error correction codes improves the reconstruction quality significantly. The simulation results show that the proposed approaches perform quite promising for concealing the errors in any compressed video bit-stream.


#*Information Retrieval Related Posters
#@
#t2008
#cProceedings of the 13th international conference on Natural Language and Information Systems: Applications of Natural Language to Information Systems
#index407178


#*Partitioning a Weighted Tree to Subtrees of Almost Uniform Size
#@Takehiro Ito,Takeaki Uno,Xiao Zhou,Takao Nishizeki
#t2008
#cProceedings of the 19th International Symposium on Algorithms and Computation
#index60228
#!Assume that each vertex of a graph G is assigned a nonnegative integer weight and that l and u are integers such that 0 ≤ l ≤ u. One wishes to partition G into connected components by deleting edges from G so that the total weight of each component is at least l and at most u. Such an "almost uniform" partition is called an (l, u)-partition. We deal with three problems to find an (l, u)-partition of a given graph: the minimum partition problem is to find an (l, u)-partition with the minimum number of components; the maximum partition problem is defined analogously; and the p-partition problem is to find an (l, u)-partition with a given number p of components. All these problems are NP-hard even for series-parallel graphs, but are solvable for paths in linear time and for trees in polynomial time. In this paper, we give polynomial-time algorithms to solve the three problems for trees, which are much simpler and faster than the known algorithms.


#*Mobile Datenbanksysteme: Architektur, Implementierung, Konzepte (Xpert.press)
#@Bela Mutschler,Günther Specht
#t2006
#c
#index11659


#*Adventures in the Blogosphere
#@Nick Koudas
#t2008
#cProceedings of the 20th international conference on Scientific and Statistical Database Management
#index388362
#!Blogs, social networks, wikis and microblogging are proliferating at unprecedented pace. The numbers reported quantifying user engagement are profound. In this talk, I will present BlogScope (www.blogscope.net) a system under development at the University of Toronto, that aims to collect, process and distill in real time the information in social media. I will present the system, its architecture the difficulties encountered and highlight the various research challenges in building the various components of the system. I will also present, Grapevine, BlogScope's sister project that aims to make sense in real time of the social media space. I will detail areas of research related to the scope of these projects and present challenges that could be addressed via the utilization of scientific and statistical database techniques. If time permits, I'll present demos.


#*Modeling QCA Defects at Molecular-level in Combinational Circuits
#@Mariam Momenzadeh,Marco Ottavi,Fabrizio Lombardi
#t2005
#cProceedings of the 20th IEEE International Symposium on Defect and Fault Tolerance in VLSI Systems
#index579562
#!This paper analyzes the deposition defects in devices and circuits made of Quantum-dot Cellular Automata (QCA) for molecular implementation. Differently from metal-based QCA, in this type of implementation a defect may occur due to the erroneous deposition of cells (made of molecules) on a substrate, i.e. no cell, or an additional cell is placed either near, or within the layout configuration of a QCA device. The effects of an erroneous cell deposition defect are analyzed by considering the induced functional faults for different QCA devices, such as the majority voter, the inverter and various wire configurations (straight, L-shape, coplanar crossing and fanout). Extensive simulation results are provided. As an example, testing of an EXOR circuit is analyzed in detail.


#*A Cluster-Based Random Key Pre-distribution Scheme in Large Scale Sensor Networks
#@Yi Jiang,Haoshan Shi
#t2007
#cProceedings of the Third International Conference on Natural Computation - Volume 02
#index353930
#!Several random key pre-distribution schemes have been proposed to bootstrap keys for encryption in recent years. In this paper, we present a new random key pre-distribution scheme using clustering according to the probability of node compromise in different deployment regions, which is suitable for large scale networks greatly. In each cluster, the deployment region is divided into multiple hexagons which give a better approximation of the circular wireless transmission coverage of a sensor node, and the qcomposite keys scheme has been improved. The performance analysis shows that the scheme we presented can improve resilience against node capture greater than previous schemes.


#*Branch predictor guided instruction decoding
#@Oliverio J. Santana,Ayose Falcón,Alex Ramirez,Mateo Valero
#t2006
#cProceedings of the 15th international conference on Parallel architectures and compilation techniques
#index34221
#%563343
#%83477
#%333274
#%512367
#%476212
#%318312
#%279057
#%434240
#%602684
#!Fast instruction decoding is a challenge for the design of CISC microprocessors. A well-known solution to overcome this problem is using a trace cache. It stores and fetches already decoded instructions, avoiding the need for decoding them again. However, implementing a trace cache involves an important increase in the fetch architecture complexity.In this paper, we propose a novel decoding architecture that reduces the fetch engine implementation cost. Instead of using a special-purpose buffer like the trace cache, our proposal stores frequently decoded instructions in the memory hierarchy. The address where the decoded instructions are stored is kept in the branch prediction mechanism, enabling it to guide our decoding architecture. This makes it possible for the processor front-end to fetch already decoded instructions from memory instead of the original nondecoded instructions. Our results show that an 8-wide superscalar processor achieves an average 14% performance improvement by using our decoding architecture. This improvement is comparable to the one achieved by using the more complex trace cache, while requiring 16% less chip area and 21% less energy consumption in the fetch architecture.


#*Refinement of Interface Automata Strengthened by Action Semantics
#@Sebti Mouelhi,Samir Chouali,Hassan Mountassir
#t2009
#cElectronic Notes in Theoretical Computer Science (ENTCS)
#index501047
#%156755
#%174956
#%267756
#%431334
#%621316
#!Interface automata are light-weight models that capture the temporal interface behavior of software components. They have the ability to model both the input requirements and the output behavior of a component. They support the compatibility check between interface models to ensure a correct interaction between components and they adopt an alternating simulation approach to design refinement. In this paper, we extend our previous works on checking interface automata interoperability by adapting their alternating refinement relation to the action semantics. We show the relation between pre and post-conditions of transitions in the abstract version of an interface and their corresponding ones in its concrete version. We illustrate our extensions by a case study of the CyCab car component-based system.


#*Generalized hypertree decompositions: NP-hardness and tractable variants
#@Georg Gottlob,Zoltán Miklós,Thomas Schwentick
#t2009
#cJournal of the ACM (JACM)
#index135267
#%37111
#%102759
#%112718
#%249971
#%185263
#%542264
#%553970
#%248919
#%299740
#%524296
#%441024
#%602953
#%429745
#%386093
#%332842
#%283530
#%160774
#%220097
#!The generalized hypertree width GHW(H) of a hypergraph H is a measure of its cyclicity. Classes of conjunctive queries or constraint satisfaction problems whose associated hypergraphs have bounded GHW are known to be solvable in polynomial time. However, it has been an open problem for several years if for a fixed constant k and input hypergraph H it can be determined in polynomial time whether GHW(H) &le; k. Here, this problem is settled by proving that even for k &equals; 3 the problem is already NP-hard. On the way to this result, another long standing open problem, originally raised by Goodman and Shmueli [1984] in the context of join optimization is solved. It is proven that determining whether a hypergraph H admits a tree projection with respect to a hypergraph G is NP-complete. Our intractability results on generalized hypertree width motivate further research on more restrictive tractable hypergraph decomposition methods that approximate generalized hypertree decomposition (GHD). We show that each such method is dominated by a tractable decomposition method definable through a function that associates a set of partial edges to a hypergraph. By using one particular such function, we define the new Component Hypertree Decomposition method, which is tractable and strictly more general than other approximations to GHD published so far.


#*Mining Privilege Escalation Paths for Network Vulnerability Analysis
#@Baowen Zhang,William Zhu,Zhi Xue
#t2007
#cProceedings of the Fourth International Conference on Fuzzy Systems and Knowledge Discovery - Volume 04
#index338438
#!Computer security is an important issue in our society. In order to prevent computer systems and networks from attacks, we should try to find flaws in these systems and evaluate them. Generally researchers and red teams use attack graphs to perform network vulnerability analysis, which tend to suffer scalability problems. In this paper we put forward a mining method to generate privilege escalation paths in networks. With these privilege escalation paths we create net privilege graphs and use them for network vulnerability analysis. Experiments show that our approach is valid and scalable to find the possible vulnerabilities exploitation ways in networks.


#*Stereoanalyse und Bildsynthese
#@O. Schreer
#t2007
#c
#index10740


#*Hierarchy Encoding with Multiple Genes
#@Martin Bommel,Ping Wang
#t2008
#cProceedings of the 19th international conference on Database and Expert Systems Applications
#index391316
#!Efficient implementation of type inclusion testing is important for data and knowledge base systems employing large hierarchies. The bit vector encoding of a partially ordered set representing a type hierarchy permits constant-time type inclusion testing. Current such methods employ a simple encoding, associating a single gene for each join-irreducible element. We present an algorithm using multiple genes for those elements with many siblings. The new algorithm provides a significant improvement on the encoding size for hierarchies with low multiple inheritance factors.


#*Least Upper Bounds for Probability Measures and Their Applications to Abstractions
#@Rohit Chadha,Mahesh Viswanathan,Ramesh Viswanathan
#t2008
#cProceedings of the 19th international conference on Concurrency Theory
#index405153
#!Abstraction is a key technique to combat the state space explosion problem in model checking probabilistic systems. In this paper we present new ways to abstract Discrete Time Markov Chains (DTMCs), Markov Decision Processes (MDPs), and Continuous Time Markov Chains (CTMCs). The main advantage of our abstractions is that they result in abstract models that are purely probabilistic, which maybe more amenable to automatic analysis than models with both nondeterministic and probabilistic steps that typically arise from previously known abstraction techniques. A key technical tool, developed in this paper, is the construction of least upper bounds for any collection of probability measures. This upper bound construction may be of independent interest that could be useful in the abstract interpretation and static analysis of probabilistic programs.


#*The Research of Adaptive Digital Predistortion Based on SISO-Neural Network
#@Qiu Wei,Zhong Zhi-ming,Ren Guo-chun,Xu Yi-tao
#t2009
#cProceedings of the 2009 WRI International Conference on Communications and Mobile Computing - Volume 01
#index57658
#!Because of the inherent nonlinearity of high power amplifier, there are in-band distortion and adjacent-channel interference, which may have a negative influence on communication systems. We have to make a linearization processing to overcome them. First, this paper attempts to analyze nonlinearity distortion of HPA in a mathematic approach, and then briefly introduces the basic principle about digital predistortion. Furthermore, after depicting simple neural network, the paper proposed an adaptive digital predistortion technology based on Single Input and Single Onput Neural Network(SISO-Neural Network), which can improve third-order and fifth-order intermodulation effectively. The proposed technique is more advantageous on convergence speed and complicacy of hardware realization compared with polynomial-fitting technique. Last, a matlab simulation of double-tone signal is done and the results also verify that the proposed technique is superior.


#*Enterprise Master Data Management: An SOA Approach to Managing Core Information, 1 edition
#@Allen Dreibelbis,Eberhard Hechler,Ivan Milman,Martin Oberhofer,Paul van Run,Dan Wolfson
#t2008
#c
#index42440
#!The Only Complete Technical Primer for MDM Planners, Architects, and ImplementersCompanies moving toward flexible SOA architectures often face difficult information management and integration challenges. The master data they rely on is often stored and managed in ways that are redundant, inconsistent, inaccessible, non-standardized, and poorly governed. Using Master Data Management (MDM), organizations can regain control of their master data, improve corresponding business processes, and maximize its value in SOA environments.Enterprise Master Data Management provides an authoritative, vendor-independent MDM technical reference for practitioners: architects, technical analysts, consultants, solution designers, and senior IT decisionmakers. Written by the IBM data management innovators who are pioneering MDM, this book systematically introduces MDMs key concepts and technical themes, explains its business case, and illuminates how it interrelates with and enables SOA.Drawing on their experience with cutting-edge projects, the authors introduce MDM patterns, blueprints, solutions, and best practices published nowhere elseeverything you need to establish a consistent, manageable set of master data, and use it for competitive advantage.Coverage includesHow MDM and SOA complement each otherUsing the MDM Reference Architecture to position and design MDM solutions within an enterpriseAssessing the value and risks to master data and applying the right security controlsUsing PIM-MDM and CDI-MDM Solution Blueprints to address industry-specific information management challengesExplaining MDM patterns as enablers to accelerate consistent MDM deploymentsIncorporating MDM solutions into existing IT landscapes via MDM Integration BlueprintsLeveraging master data as an enterprise assetbringing people, processes, and technology together with MDM and data governanceBest practices in MDM deployment, including data warehouse and SAP integration


#*Case-Based Collective Inference for Maritime Object Classification
#@Kalyan Moy Gupta,David W. Aha,Philip Moore
#t2009
#cProceedings of the 8th International Conference on Case-Based Reasoning: Case-Based Reasoning Research and Development
#index503746
#!Maritime assets such as merchant and navy ships, ports, and harbors, are targets of terrorist attacks as evidenced by the USS Cole bombing. Conventional methods of securing maritime assets to prevent attacks are manually intensive and error prone. To address this shortcoming, we are developing a decision support system that shall alert security personnel to potential attacks by automatically processing maritime surveillance video. An initial task that we must address is to accurately classify maritime objects from video data, which is our focus in this paper. Object classification from video images can be problematic due to noisy outputs from image processing. We approach this problem with a novel technique that exploits maritime domain characteristics and formulates it as a graph of spatially related objects. We then apply a case-based collective classification algorithm on the graph to classify objects. We evaluate our approach on river traffic video data that we have processed. We found that our approach significantly increases classification accuracy in comparison with a conventional (i.e., non-relational) alternative.


#*Genetic Algorithms: A Decision Tool in Industrial Disassembly
#@Luminita Duta,Florin Gheorghe Filip,Constantin Zamfirescu
#t2008
#cProceedings of the 2008 First International Conference on Complexity and Intelligence of the Artificial and Natural Complex Systems. Medical Applications of the Complex Systems. Biomedical Computing
#index502080
#!In the recycling process of the Waste Electrical and Electronic Equipment (WEEE) the disassembly process has a central role. Disassembly is not the reverse of the assembly process, real difficulties occur in the tasks assignment process of the disassembly operations. Since this is a multi objective optimization problem, we prove that genetic algorithms provide a useful multi-criteria decision tool in the industrial disassembly process.


#*Synergy in the multi-local statistics of gradient directions in images
#@Alexandre J. Nasrallah,Lewis D. Griffin
#t2006
#cProceedings of the 2006 Conference on Computer Vision and Pattern Recognition Workshop
#index28380
#!Gestalt psychologists were able to establish a number of qualitative grouping rules which govern human visual perceptions. It is possible that natural image statistics underlie those grouping rules, specifically multi-local statistics. We define multi-local to mean local measurements made simultaneously at multiple locations. To assess whether multi- local interactions occur in natural images we have used information-theoretic methods, specifically interaction information. For example, we have measured triples of gradient directions, and computed the mutual information between a pair of gradient directions, and how the context of a third gradient direction affects that mutual information. If it increases, then measuring triples of gradient directions is synergetic. We find that triples of gradient directions show synergy for all of the following image classes: natural images, their phase randomized and whitened versions and Gaussian noise images. Further, we find that the mean power spectrum of image ensembles determines the dependencies between gradient directions.


#*XML keyword query refinement
#@Jiaheng Lu,Zhifeng Bao,Tok Wang Ling,Xiaofeng Meng
#t2009
#cProceedings of the First International Workshop on Keyword Search on Structured Data
#index136139
#%243716
#%629663
#!Existing works in XML keyword search have addressed the problem of finding matching results of a query. However, user input queries always contain irrelevant or mismatched terms, spelling errors etc, which causes the search results to be either empty or not meaningful. In this paper, we introduce the problem of XML keyword query refinement, and propose a set of effective and efficient solutions. Finally, extensive experiments show the efficiency and effectiveness of our approach.


#*E-Bicycle Demonstration on the Tour De France
#@Amine Dhraief,Nicolas Montavont,Romain Kuntz,Manabu Tsukada
#t2007
#cProceedings of the International Multi-Conference on Computing in the Global Information Technology
#index416231
#!In this paper, we describe the E-bicycle demonstration held within the Tour De France. It was performed by the Nautilus6 working group in order to see the impact and usage of new IPv6 mobility protocols in the real life. We report our experience of settting an IPv6 mobile network demonstration where a E-car and two E-bicycles are communicating together while being in motion. The scenario involves network mobility managed by NEMO Basic support and optimized group communication via Xcast6. We finally put forward the results of the demonstration and give recommendations for future deployment.


#*Algebraic structures for fuzzy numbers from categorial point of view
#@Alexandru Mihai Bica
#t2007
#cSoft Computing - A Fusion of Foundations, Methodologies and Applications
#index413748
#!Using a classic algebraic construction additive and multiplicative structures (as commutative monoids) for fuzzy numbers are obtained. Moreover, we realize here an isomorphism between these structures.


#*Network Synchronization of an Orthogonal CDMA Satellite Communication System
#@Diakoumis Gerakoulis,Hsuan-Jung Su,Evaggelos Geraniotis
#t2007
#cWireless Personal Communications: An International Journal
#index415848
#%242836
#%603912
#!This paper provides the network synchronization of an orthogonal CDMA geostationary satellite system for fixed service communications. It includes the synchronization procedures, the system architecture and the performance evaluation. The main objective is to provide network wide synchronization of all uplink orthogonal CDMA transmissions. This is achieved in steps; first by providing coarse synchronization using the uplink random access channel and then fine sync using innovative tracking control mechanisms. The uplink access channel receiver utilize a parallel/serial search method for rapid code acquisition, while the code tracking of the uplink orthogonal CDMA traffic channel is based on a delay feedback early-late gate in which the sych control resides in the receiver. The proposed system is designed to minimize the onboard complexity and satisfy the performance requirements. As shown in the performance section, the requirement that all uplink transmissions are synchronized to a reference time within 10% of the chip length can be achieved. In addition, the system analysis determines the design parameters values which optimize performance.


#*Coded cooperation diversity for uncoded oversampled OFDM systems
#@Alireza Rahmati,Paeiz Azmi
#t2009
#cSignal Processing
#index68128
#%253278
#!Recently, user-cooperation diversity has been introduced as an effective scheme that can bring about antenna diversity in wireless networks. In this paper, we introduce a coded cooperation diversity technique for single antenna uncoded orthogonal frequency division multiplexing (OFDM) systems, in which implementation of coded cooperation is provided by the oversampling potential in OFDM, instead of using extra channel coding. In fact, zero-padding followed by IFFT in OFDM is similar to oversampling and could be an alternative to applying correction codes. Furthermore, we use this oversampling to implement an iterative receiver at the partner terminal. This receiver works based on the nonuniform sampling theorem for reconstructing of lost symbols. The lost symbols appear at the partner terminal of cooperative network because of dividing each OFDM block into two segments through the puncturing at the user terminal of the cooperative network. We provide simulation results for our proposed scenario, and observe significant gains over the non-cooperative oversampled OFDM systems without any need whatever for using extra channel coding.


#*Location tracking of test vehicles using accelerometers
#@Joshua D. Jackson,Dale W. Callahan,Percy F. Wang
#t2006
#cProceedings of the 5th WSEAS International Conference on Circuits, Systems, Electronics, Control & Signal Processing
#index43385
#!This paper proposes a cost effective solution to localized mobile positioning with high accuracy requirements when high grade GPS is cost excessive or unavailable. Specifically this solution is targeted for accurate position determination of test vehicles on a known stretch of bridge.


#*Proceedings of the 2009 30th IEEE Symposium on Security and Privacy
#@
#t2009
#cSP
#index495453


#*Cata-Fisheye Camera for Panoramic Imaging
#@Gurunandan Krishnan,Shree K. Nayar
#t2008
#cProceedings of the 2008 IEEE Workshop on Applications of Computer Vision
#index133684
#!We present a novel panoramic imaging system which uses a curved mirror as a simple optical attachment to a fish-eye lens. When compared to existing panoramic cameras, our "cata-fisheye" camera has a simple, compact and inexpensive design, and yet yields high optical performance. It captures the desired panoramic field of view in two parts. The upper part is obtained directly by the fisheye lens and the lower part after reflection by the curved mirror. These two parts of the field of view have a small overlap that is used to stitch them into a single seamless panorama. The cata-fisheye concept allows us to design cameras with a wide range of fields of view by simply varying the parameters and position of the curved mirror. We provide an automatic method for the one-time calibration needed to stitch the two parts of the panoramic field of view. We have done a complete performance evaluation of our concept with respect to (i) the optical quality of the captured images, (ii) the working range of the camera over which the parallax is negligible, and (iii) the spatial resolution of the computed panorama. Finally, we have built a prototype cata-fisheye video camera with a spherical mirror that can capture high resolution panoramic images (3600x550 pixels) with a 360° (horizontal) x 55° (vertical) field of view.


#*A Robust Active Appearance Models Search Algorithm
#@Yong-Fong Lin,Chih-Wei Tang
#t2008
#cProceedings of the 9th Pacific Rim Conference on Multimedia: Advances in Multimedia Information Processing
#index66071
#!With the aid of AAMs search algorithm, Active Appearance Models (AAMs) can represent non-rigid image objects with shape and texture variations well. However, the performance of the traditional AAMs search algorithm(TAAMS) is limited by its assumption that the error function is convex. Therefore, this paper proposes a robust AAMs search algorithm (RAAMS) which combines the multi-pose search (MS) for better pose matching and an estimation mechanism of parameter search direction (EPSD) for more accurate search direction. Moreover, a precaution mechanism of local minimum (PLM) is proposed to avoid the search trapped into the local minimum of the error function. Experimental results show that the proposed algorithm can significantly reduce 36.41% of shape error and 30.81% of texture error between the synthesized instance and target image.


#*Benefits of Parallel I/O in Ab Initio Nuclear Physics Calculations
#@Nikhil Laghave,Masha Sosonkina,Pieter Maris,James P. Vary
#t2009
#cProceedings of the 9th International Conference on Computational Science: Part I
#index125888
#!Many modern scientific applications rely on highly parallel calculations, which scale to 10's of thousands processors. However, most applications do not concentrate on parallelizing input/output operations. In particular, sequential I/O has been identified as a bottleneck for the highly scalable MFDn (Many Fermion Dynamics for nuclear structure) code performing ab initio nuclear structure calculations. In this paper, we develop interfaces and parallel I/O procedures to use a well-known parallel I/O library in MFDn. As a result, we gain efficient input/output of large datasets along with their portability and ease of use in the downstream processing.


#*Modified booth multipliers with a regular partial product array
#@Shiann-Rong Kuang,Jiun-Ping Wang,Cang-Yuan Guo
#t2009
#cIEEE Transactions on Circuits and Systems II: Express Briefs
#index19356
#%330626
#%33582
#!The conventional modified Booth encoding (MBE) generates an irregular partial product array because of the extra partial product bit at the least significant bit position of each partial product row. In this brief, a simple approach is proposed to generate a regular partial product array with fewer partial product rows and negligible overhead, thereby lowering the complexity of partial product reduction and reducing the area, delay, and power of MBE multipliers. The proposed approach can also be utilized to regularize the partial product array of posttruncated MBE multipliers. Implementation results demonstrate that the proposed MBE multipliers with a regular partial product array really achieve significant improvement in area, delay, and power consumption when compared with conventional MBE multipliers.


#*The Design of the Zinc Modelling Language
#@Kim Marriott,Nicholas Nethercote,Reza Rafeh,Peter J. Stuckey,Maria Garcia De La Banda,Mark Wallace
#t2008
#cConstraints
#index37158
#%2651
#%39443
#%365629
#!Zinc is a new modelling language developed as part of the G12 project. It has four important characteristics. First, Zinc allows specification of models using a natural mathematical-like notation. To do so it supports overloaded functions and predicates and automatic coercion and provides arithmetic, finite domain and set constraints. Second, while Zinc is a relatively simple and small language, it can be readily extended to different application areas by means of powerful language constructs such as user-defined predicates and functions and constrained types. Third, Zinc provides sophisticated type and instantiation checking which allows early detection of errors in models. Finally, perhaps the main novelty in Zinc is that it is designed to support a modelling methodology in which the same conceptual model can be automatically mapped into different design models, thus allowing modellers to easily "plug and play" with different solving techniques and so choose the most appropriate for that problem. We describe in detail the various language features of Zinc and the many trade-offs we faced in its design.


#*Hexagonal stratification of numbers
#@Manuel Meireles
#t2008
#cProceedings of the 13th WSEAS international conference on Applied mathematics
#index141775
#%208832
#!In this article is presented a stratification of the natural numbers in way to highlight potential prime numbers. Initially it was done the hexagonal stratification and it is verified that all and any prime number can be written in the form 6a+1 or 6a+5. Then, it was done to the penta-hexagonal stratification and it was observed that all and any prime number can be written as: 30a+1; 30a+7; 30a+13; 30a+19; 30a+11; 30a+17; 30a+23 and 30a+29. All and any prime number can be written in one these ways. With the hexagonal or hexapentagonal stratification becomes easier to identify a potential prime number but. This article interests potentially for all those that are researching primality tests with views to reduce time in the computational algorithms.


#*A software-defined ultra-wideband transceiver testbed for communications, ranging, and imaging
#@Jeffrey H. Reed
#t2006
#c
#index414434
#!Impulse Ultra Wideband (UWB) communications is an emerging technology that promises a number of benefits over traditional narrowband or broadband signals: extremely high data rates, extremely robust operation in dense multipath environments, low probability of intercept/detection, and the ability to operate concurrently with existing users. Unfortunately, most currently available UWB systems are based on dedicated hardware, preventing researchers from investigating algorithms or architectures that take advantage of some of the unique properties of UWB signals. This dissertation outlines the development of a general purpose software radio transceiver testbed for UWB signals. The testbed is an enabling technology that provides a development platform for investigating ultra wideband communication algorithms (e.g., acquisition, synchronization, modulation, multiple access), ranging or radar (e.g., precision position location, intrusion detection, heart and respiration rate monitoring), and could potentially be used in the area of ultra wideband based medical imaging or vital signs monitoring. As research into impulse ultra wideband expands, the need is greater now than ever for a platform that will allow researchers to collect real-world performance data to corroborate theoretical and simulation results. Additionally, this dissertation outlines the development of the Time-Interleaved Analog to Digital Converter array which served as the core of the testbed, along with a comprehensive theoretical and simulation-based analysis on the effects of Analog to Digital Converter mismatches in a Time-Interleaved Sampling array when the input signal is an ultra wideband Gaussian Monocycle. Included in the discussion is a thorough overview of the implementation of both a scaled-down prototype as well as the final version of the testbed. This dissertation concludes by evaluating the of the transceiver testbed in terms of the narrowband dynamic range, the accuracy with which it can sample and reconstruct a UWB pulse, and the bit error rate performance of the overall system.**This dissertation is a compound document (contains both a paper copy and a CD as part of the dissertation). The CD requires the following system requirements: WinZip.


#*A Hybrid Approach to Land Cover Classification from Multi Spectral Images
#@Primo Zingaretti,Emanuele Frontoni,Eva Savina Malinverni,Adriano Mancini
#t2009
#cProceedings of the 15th International Conference on Image Analysis and Processing
#index505705
#!This work is part of a wider project whose general objective is to develop a methodology for the automatic classification, based on CORINE land-cover (CLC) classes, of high resolution multispectral IKONOS images. The specific objective of this paper is to describe a new methodology for producing really exploitable results from automatic classification algorithms. Input data are basically constituted by multispectral images, integrated with textural and contextual measures. The output is constituted by an image with each pixel assigned to one out of 15 classes at the second level of the CLC legend or let unclassified (somehow a better solution than a classification error), plus a stability map that helps users to separate the regions classified with high accuracy from those whose classification result should be verified before being used.


#*FPGA Implementation of a Pipelined On-Line Backpropagation
#@Rafael Gadea Gironés,Ricardo Colom Palero,Joaquín Cerdá Boluda,Angel Sebastia Cortés
#t2005
#cJournal of VLSI Signal Processing Systems
#index101404
#%599809
#%482255
#%535933
#%537573
#%587700
#%111817
#!The paper describes the implementation of a systolic array for a multilayer perceptron with a hardware-friendly learning algorithm. A pipelined modification of the on-line backpropagation algorithm is shown and explained. It better exploits the parallelism because both the forward and backward phases can be performed simultaneously. The neural network performance for the proposed modification is discussed and compared with the standard so-called on-line backpropagation algorithm in typical databases and with the various precisions required. Although the preliminary results are positive, subsequent theoretical analysis and further experiments with different training sets will be necessary. For this reason our VLSI systolic architecture--together with the combination of FPGA reconfiguration properties and a design flow based on generic VHDL--can create a reusable, flexible, and fast method of designing a complete ANN on a single FPGA and can permit very fast hardware verifications for our trials of the Pipeline On-line Backpropagation algorithm and the standard algorithms.


#*Approximate Versus Linguistic Representation in Fuzzy-UCS
#@Albert Orriols-Puig,Jorge Casillas,Ester Bernadó-Mansilla
#t2008
#cProceedings of the 3rd international workshop on Hybrid Artificial Intelligence Systems
#index389066
#!This paper introduces an approximate fuzzy representation to Fuzzy-UCS, a Michigan-style Learning Fuzzy-Classifier System that evolves linguistic fuzzy rules, and studies whether the flexibility provided by the approximate representation results in a significant improvement of the accuracy of the models evolved by the system. We test Fuzzy-UCS with both approximate and linguistic representation on a large collection of real-life problems and compare the results in terms of training and test accuracy and interpretability of the evolved rule sets.


#*Reports
#@Brian Cooper
#t2009
#cACM SIGMOD Record
#index57082


#*Towards Context-Aware Telecom End User Services through SOA
#@Philipp H. Mohr,Giuseppe Raffa,Marina Pettinari,Tullio Salmon Cinotti,Cristina Frà,Claudio Venezia,Paolo Protto
#t2009
#cService-Oriented Computing - ICSOC 2007 Workshops: ICSOC 2007, International Workshops, Vienna, Austria, September 17, 2007, Revised Selected Papers
#index67057
#!In this paper a SOA inspired context-aware platform for enabling context-aware Telecom services is presented. The SOA related components are highlighted and the platform's integration into a Telecom provider's service architecture is described -- pointing out challenges in terms of protocols and semantic interoperability. An example application bridging the gap between data collected through a user's mobile phone and a web based portal in order to provide a Virtual Location Application through our platform is presented.


#*SRM: a tool for supplier performance
#@Angela Fabregues,Jordi Madrenas-Ciurana
#t2009
#cProceedings of The 8th International Conference on Autonomous Agents and Multiagent Systems - Volume 2
#index133730
#!Supplier Relationship Management (SRM) is an application that gives support to a company in the task of deciding which supplier to choose when a new supply has to be ordered. It is based on a measure of trust and provides several tools that visualize that measure and support its use on decision making.


#*Cohesion Analysis in Linux Kernel
#@Vinay Kumar Reddy,D. Janakiram
#t2006
#cProceedings of the XIII Asia Pacific Software Engineering Conference
#index21973
#!It is widely accepted that strong coupling such as common coupling should be used with caution among modules. Linux kernel is analyzed in terms of these common coupling instances and the results show the presence of excessive common coupling among modules. It is mentioned that unless the kernel is restructured with a bare minimum of common coupling, it would be exceedingly difficult to maintain kernel in the near future. We attribute this problem to the lack of data abstractions in the kernel. To support our argument, we have analyzed the cohesion in the Linux kernel both at the module level (file level) and function level. Although the cohesion at the function level is high, low cohesion prevails at the module level indicating the lack of focus on data abstractions at the module level. We believe that this is an inherent drawback in procedural paradigm where functionality is considered first rather than data. Hence, we suggest to migrate the kernel to object-oriented paradigm to minimize coupling among modules and increase cohesion within the modules. As performance is one of the prime concerns for an OS kernel, object oriented features can be introduced in the kernel in an incremental fashion using the technique of object-oriented wrappers.


#*Simulation-specific characteristics and software reuse
#@Joseph C. Carnahan,Paul F. Reynolds, Jr.,David C. Brogan
#t2005
#cProceedings of the 37th conference on Winter simulation
#index21478
#%614456
#%333809
#%593112
#%88644
#%21531
#%618096
#%622552
#%323728
#%595082
#%219097
#%94927
#%555208
#%589351
#%329737
#%548279
#%321277
#%34864
#!We argue that simulations possess interesting characteristics that facilitate adaptation. Simplifying assumptions, stochastic sampling, and event generation are common features which lend themselves to adaptation for reuse. In this paper, we explore simulation-specific characteristics amenable to adaptation and the ways they can be exploited in support of reuse. Our work is of particular relevance to research in component based simulations and dynamic data driven application systems, where adaptability and reuse are essential.


#*Bayesian robustness for decision making problems: Applications in medical contexts
#@J. Martín,C. J. Pérez,P. Müller
#t2009
#cInternational Journal of Approximate Reasoning
#index57357
#!Practical implementation of Bayesian decision making is hindered by the fact that optimal decisions may be sensitive to the model inputs: the prior, the likelihood and/or the underlying utility function. Given the structure of a problem, the analyst has to decide which sensitivity measures are relevant and compute them efficiently. We address the issue of robustness of the optimal action in a decision making problem with respect to the prior model and the utility function. We discuss some general principles and apply novel computational strategies in the context of two relatively complex medical decision making problems.


#*Collaboration and Cognitive Tutoring: Integration, Empirical Results, and Future Directions
#@Andreas Harrer,Bruce M. McLaren,Erin Walker,Lars Bollen,Jonathan Sewall
#t2005
#cProceeding of the 2005 conference on Artificial Intelligence in Education: Supporting Learning through Intelligent and Socially Informed Technology
#index138203
#!In this paper, we describe progress we have made toward providing cognitive tutoring to students within a collaborative software environment. First, we have integrated a collaborative software tool, Cool Modes, with software designed to develop Cognitive Tutors (the Cognitive Tutor Authoring Tool). Our initial integration provides a means to capture data that acts as the foundation of a tutor for collaboration but does not yet fully support actual tutoring. Second, we've performed two exploratory studies in which dyads of students used our software to collaborate in solving modelling tasks. These studies uncovered five dimensions of observed behavior that point to the need for abstraction of student actions to better recognize, analyze, and correct collaborative steps in problem solving. We discuss plans to incorporate such analyses into our approach and to extend our tools to eventually provide tutoring of collaboration.


#*Knowledge Representation Environments: An Investigation of the CASSMs between Creators, Composers and Consumers
#@Ann Blandford,Thomas R. Green,Iain Connell,Tony Rose
#t2008
#cEngineering Interactive Systems: EIS 2007 Joint Working Conferences, EHCI 2007, DSV-IS 2007, HCSE 2007, Salamanca, Spain, March 22-24, 2007. Selected Papers
#index61571
#!Many systems form `chains' whereby developers use one system (or `tool') to create another system, for use by other people. For example, a web development tool is created by one development team then used by others to compose web pages for use by yet other people. Little work within Human-Computer Interaction (HCI) has considered how usability considerations propagate through such chains. In this paper, we discuss three-link chains involving people that we term Creators (commonly referred to as designers), Composers (users of the tool who compose artefacts for other users) and Consumers (end users of artefacts). We focus on usability considerations and how Creators can develop systems that are both usable themselves and also support Composers in producing further systems that Consumers can work with easily. We show how CASSM, an analytic evaluation method that focuses attention on conceptual structures for interactive systems, supports reasoning about the propagation of concepts through Creator-Composer-Consumer chains. We use as our example a knowledge representation system called Tallis, which includes specific implementations of these different perspectives. Tallis is promoting a development culture within which individuals are empowered to take on different roles in order to strengthen the `chain of comprehension' between different user types.


#*Computer-Assisted Diagnosis of Primary Headaches
#@Svetlana Simić,Dragan Simić,Petar Slankamenac,Milana Simić-Ivkov
#t2008
#cProceedings of the 3rd international workshop on Hybrid Artificial Intelligence Systems
#index385336
#!Headache is not a disease which typically shortens one's life. However, it can be a serious social as well as a health problem. Approximately 27 billion euros per year are lost through reduced work productivity in the European Community. While the diagnostic criteria developed by the International Headache Society (IHS) have been extensively used in the epidemiological research, there is no such a tool which helps physicians make diagnoses. This research focussed on diagnosing certain primary headache types in working people employing the rule-based fuzzy logic system. The rules were facilitated by the application of the IHS criteria for headache types. Clinical experience was used to extend the established rules and improve the system. The proposed system is in the starting phase of the implementation at the Clinical Centre Vojvodina, Institute of Neurology in Novi Sad.


#*Target Acquisition with Force Feedback: The Effect of Different Forces on the User's Performance
#@Joan Boeck,Lode Vanacken,Karin Coninx
#t2009
#cProceedings of the 4th International Conference on Haptic and Audio Interaction Design
#index489968
#!Besides realistic haptic rendering of objects, haptic feedback can also be used to provide an abstract feedback channel. This can either be realised by a tactile or a force feedback stimulus. When using forces, care has to be taken that the user's performance is not influenced in a negative way. However, as it is not obvious to determine a suitable force, and currently not many guidelines exist. Therefore, in this paper we investigate the influence on some important parameters that define a force (shape, duration and amplitude). In order to compare different forces, we propose to use the definite integral (Force Integral, FI) which combines the considered parameters. From the conducted experiment we learn that the FI can be used (within bounds) to make an estimation of the result of the force. Besides this, we also found that above a given FI value, the user's performance degrades significantly.


#*Message from the Symposium Chairs - Volume 2
#@
#t2009
#cProceedings of the 2009 Second International Workshop on Computer Science and Engineering - Volume 02
#index19725


